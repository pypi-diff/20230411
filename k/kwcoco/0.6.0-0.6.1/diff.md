# Comparing `tmp/kwcoco-0.6.0-py3-none-any.whl.zip` & `tmp/kwcoco-0.6.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,107 +1,109 @@
-Zip file size: 349088 bytes, number of entries: 105
--rw-r--r--  2.0 unx    21711 b- defN 23-Apr-05 02:39 kwcoco/__init__.py
--rw-r--r--  2.0 unx      276 b- defN 23-Apr-05 02:39 kwcoco/__main__.py
--rw-rw-rw-  2.0 unx        1 b- defN 23-Apr-05 02:39 kwcoco/__main__.pyi
--rw-r--r--  2.0 unx     5937 b- defN 23-Apr-05 02:39 kwcoco/_helpers.py
--rw-rw-rw-  2.0 unx      717 b- defN 23-Apr-05 02:39 kwcoco/_helpers.pyi
--rw-r--r--  2.0 unx      309 b- defN 23-Apr-05 02:39 kwcoco/abstract_coco_dataset.py
--rw-rw-rw-  2.0 unx       62 b- defN 23-Apr-05 02:39 kwcoco/abstract_coco_dataset.pyi
--rw-r--r--  2.0 unx    27500 b- defN 23-Apr-05 02:39 kwcoco/category_tree.py
--rw-rw-rw-  2.0 unx     2442 b- defN 23-Apr-05 02:39 kwcoco/category_tree.pyi
--rw-r--r--  2.0 unx      364 b- defN 23-Apr-05 02:39 kwcoco/channel_spec.py
--rw-rw-rw-  2.0 unx      104 b- defN 23-Apr-05 02:39 kwcoco/channel_spec.pyi
--rw-r--r--  2.0 unx   249462 b- defN 23-Apr-05 02:39 kwcoco/coco_dataset.py
--rw-rw-rw-  2.0 unx    12926 b- defN 23-Apr-05 02:39 kwcoco/coco_dataset.pyi
--rw-r--r--  2.0 unx    50068 b- defN 23-Apr-05 02:39 kwcoco/coco_evaluator.py
--rw-rw-rw-  2.0 unx     2003 b- defN 23-Apr-05 02:39 kwcoco/coco_evaluator.pyi
--rw-r--r--  2.0 unx    49353 b- defN 23-Apr-05 02:39 kwcoco/coco_image.py
--rw-rw-rw-  2.0 unx     3393 b- defN 23-Apr-05 02:39 kwcoco/coco_image.pyi
--rw-r--r--  2.0 unx    26887 b- defN 23-Apr-05 02:39 kwcoco/coco_objects1d.py
--rw-rw-rw-  2.0 unx     3468 b- defN 23-Apr-05 02:39 kwcoco/coco_objects1d.pyi
--rw-r--r--  2.0 unx    11329 b- defN 23-Apr-05 02:39 kwcoco/coco_schema.py
--rw-rw-rw-  2.0 unx      846 b- defN 23-Apr-05 02:39 kwcoco/coco_schema.pyi
--rw-r--r--  2.0 unx    91530 b- defN 23-Apr-05 02:39 kwcoco/coco_sql_dataset.py
--rw-rw-rw-  2.0 unx     6055 b- defN 23-Apr-05 02:39 kwcoco/coco_sql_dataset.pyi
--rw-r--r--  2.0 unx    16155 b- defN 23-Apr-05 02:39 kwcoco/compat_dataset.py
--rw-rw-rw-  2.0 unx     1793 b- defN 23-Apr-05 02:39 kwcoco/compat_dataset.pyi
--rw-r--r--  2.0 unx      328 b- defN 23-Apr-05 02:39 kwcoco/exceptions.py
--rw-rw-rw-  2.0 unx      128 b- defN 23-Apr-05 02:39 kwcoco/exceptions.pyi
--rw-r--r--  2.0 unx     2639 b- defN 23-Apr-05 02:39 kwcoco/kpf.py
--rw-rw-rw-  2.0 unx       74 b- defN 23-Apr-05 02:39 kwcoco/kpf.pyi
--rw-r--r--  2.0 unx    13342 b- defN 23-Apr-05 02:39 kwcoco/kw18.py
--rw-rw-rw-  2.0 unx      682 b- defN 23-Apr-05 02:39 kwcoco/kw18.pyi
--rw-rw-rw-  2.0 unx        0 b- defN 23-Apr-05 02:39 kwcoco/py.typed
--rw-r--r--  2.0 unx      402 b- defN 23-Apr-05 02:39 kwcoco/sensorchan_spec.py
--rw-rw-rw-  2.0 unx      325 b- defN 23-Apr-05 02:39 kwcoco/sensorchan_spec.pyi
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-05 02:39 kwcoco/cli/__init__.py
--rw-r--r--  2.0 unx     4386 b- defN 23-Apr-05 02:39 kwcoco/cli/__main__.py
--rw-r--r--  2.0 unx     3372 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_conform.py
--rw-r--r--  2.0 unx     5796 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_eval.py
--rw-r--r--  2.0 unx     2293 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_grab.py
--rw-r--r--  2.0 unx     4164 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_modify_categories.py
--rw-r--r--  2.0 unx     6771 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_reroot.py
--rw-r--r--  2.0 unx     4654 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_show.py
--rw-r--r--  2.0 unx     6731 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_split.py
--rw-r--r--  2.0 unx     8473 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_stats.py
--rw-r--r--  2.0 unx    12894 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_subset.py
--rw-r--r--  2.0 unx     4904 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_toydata.py
--rw-r--r--  2.0 unx     2696 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_union.py
--rw-r--r--  2.0 unx     7709 b- defN 23-Apr-05 02:39 kwcoco/cli/coco_validate.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-05 02:39 kwcoco/data/__init__.py
--rw-r--r--  2.0 unx    21744 b- defN 23-Apr-05 02:39 kwcoco/data/grab_camvid.py
--rw-r--r--  2.0 unx     5849 b- defN 23-Apr-05 02:39 kwcoco/data/grab_cifar.py
--rw-r--r--  2.0 unx      720 b- defN 23-Apr-05 02:39 kwcoco/data/grab_datasets.py
--rw-r--r--  2.0 unx     6857 b- defN 23-Apr-05 02:39 kwcoco/data/grab_domainnet.py
--rw-r--r--  2.0 unx     9189 b- defN 23-Apr-05 02:39 kwcoco/data/grab_spacenet.py
--rw-r--r--  2.0 unx     9865 b- defN 23-Apr-05 02:39 kwcoco/data/grab_voc.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-05 02:39 kwcoco/demo/__init__.py
--rw-r--r--  2.0 unx    23050 b- defN 23-Apr-05 02:39 kwcoco/demo/boids.py
--rw-r--r--  2.0 unx    14007 b- defN 23-Apr-05 02:39 kwcoco/demo/perterb.py
--rw-r--r--  2.0 unx      500 b- defN 23-Apr-05 02:39 kwcoco/demo/toydata.py
--rw-r--r--  2.0 unx    20026 b- defN 23-Apr-05 02:39 kwcoco/demo/toydata_image.py
--rw-r--r--  2.0 unx    55274 b- defN 23-Apr-05 02:39 kwcoco/demo/toydata_video.py
--rw-r--r--  2.0 unx    20195 b- defN 23-Apr-05 02:39 kwcoco/demo/toypatterns.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-05 02:39 kwcoco/examples/__init__.py
--rw-r--r--  2.0 unx     5751 b- defN 23-Apr-05 02:39 kwcoco/examples/bench_large_hyperspectral.py
--rw-r--r--  2.0 unx     4911 b- defN 23-Apr-05 02:39 kwcoco/examples/demo_kwcoco_spaces.py
--rw-r--r--  2.0 unx     2882 b- defN 23-Apr-05 02:39 kwcoco/examples/draw_gt_and_predicted_boxes.py
--rw-r--r--  2.0 unx     2692 b- defN 23-Apr-05 02:39 kwcoco/examples/faq.py
--rw-r--r--  2.0 unx     2074 b- defN 23-Apr-05 02:39 kwcoco/examples/getting_started_existing_dataset.py
--rw-r--r--  2.0 unx     2068 b- defN 23-Apr-05 02:39 kwcoco/examples/loading_multispectral_data.py
--rw-r--r--  2.0 unx     1683 b- defN 23-Apr-05 02:39 kwcoco/examples/modification_example.py
--rw-r--r--  2.0 unx     2087 b- defN 23-Apr-05 02:39 kwcoco/examples/shifting_annots.py
--rw-r--r--  2.0 unx     8961 b- defN 23-Apr-05 02:39 kwcoco/examples/simple_kwcoco_torch_dataset.py
--rw-r--r--  2.0 unx     7896 b- defN 23-Apr-05 02:39 kwcoco/examples/vectorized_interface.py
--rw-r--r--  2.0 unx      699 b- defN 23-Apr-05 02:39 kwcoco/metrics/__init__.py
--rw-r--r--  2.0 unx    27687 b- defN 23-Apr-05 02:39 kwcoco/metrics/assignment.py
--rw-r--r--  2.0 unx    22260 b- defN 23-Apr-05 02:39 kwcoco/metrics/clf_report.py
--rw-r--r--  2.0 unx    51923 b- defN 23-Apr-05 02:39 kwcoco/metrics/confusion_measures.py
--rw-r--r--  2.0 unx    43235 b- defN 23-Apr-05 02:39 kwcoco/metrics/confusion_vectors.py
--rw-r--r--  2.0 unx    57007 b- defN 23-Apr-05 02:39 kwcoco/metrics/detect_metrics.py
--rw-r--r--  2.0 unx    22909 b- defN 23-Apr-05 02:39 kwcoco/metrics/drawing.py
--rw-r--r--  2.0 unx     6978 b- defN 23-Apr-05 02:39 kwcoco/metrics/functional.py
--rw-r--r--  2.0 unx     7330 b- defN 23-Apr-05 02:39 kwcoco/metrics/sklearn_alts.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-05 02:39 kwcoco/metrics/util.py
--rw-r--r--  2.0 unx    15267 b- defN 23-Apr-05 02:39 kwcoco/metrics/voc_metrics.py
--rw-r--r--  2.0 unx     5567 b- defN 23-Apr-05 02:39 kwcoco/util/__init__.py
--rw-r--r--  2.0 unx     3765 b- defN 23-Apr-05 02:39 kwcoco/util/dict_like.py
--rw-r--r--  2.0 unx     9344 b- defN 23-Apr-05 02:39 kwcoco/util/dict_proxy2.py
--rw-r--r--  2.0 unx    13052 b- defN 23-Apr-05 02:39 kwcoco/util/jsonschema_elements.py
--rw-r--r--  2.0 unx      211 b- defN 23-Apr-05 02:39 kwcoco/util/lazy_frame_backends.py
--rw-r--r--  2.0 unx    10304 b- defN 23-Apr-05 02:39 kwcoco/util/util_archive.py
--rw-r--r--  2.0 unx      644 b- defN 23-Apr-05 02:39 kwcoco/util/util_deprecate.py
--rw-r--r--  2.0 unx      185 b- defN 23-Apr-05 02:39 kwcoco/util/util_futures.py
--rw-r--r--  2.0 unx     9367 b- defN 23-Apr-05 02:39 kwcoco/util/util_json.py
--rw-r--r--  2.0 unx     3678 b- defN 23-Apr-05 02:39 kwcoco/util/util_monkey.py
--rw-r--r--  2.0 unx     3711 b- defN 23-Apr-05 02:39 kwcoco/util/util_reroot.py
--rw-r--r--  2.0 unx     5654 b- defN 23-Apr-05 02:39 kwcoco/util/util_sklearn.py
--rw-r--r--  2.0 unx     4809 b- defN 23-Apr-05 02:39 kwcoco/util/util_special_json.py
--rw-r--r--  2.0 unx     2720 b- defN 23-Apr-05 02:39 kwcoco/util/util_truncate.py
--rw-r--r--  2.0 unx     1607 b- defN 23-Apr-05 02:39 kwcoco/util/delayed_ops/__init__.py
--rw-rw-rw-  2.0 unx    11343 b- defN 23-Apr-05 02:39 kwcoco-0.6.0.dist-info/LICENSE
--rw-r--r--  2.0 unx    60676 b- defN 23-Apr-05 02:39 kwcoco-0.6.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-05 02:39 kwcoco-0.6.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       52 b- defN 23-Apr-05 02:39 kwcoco-0.6.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        7 b- defN 23-Apr-05 02:39 kwcoco-0.6.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     8717 b- defN 23-Apr-05 02:39 kwcoco-0.6.0.dist-info/RECORD
-105 files, 1316612 bytes uncompressed, 335478 bytes compressed:  74.5%
+Zip file size: 354962 bytes, number of entries: 107
+-rw-r--r--  2.0 unx    21711 b- defN 23-Apr-11 01:20 kwcoco/__init__.py
+-rw-r--r--  2.0 unx      276 b- defN 23-Apr-11 01:20 kwcoco/__main__.py
+-rw-rw-rw-  2.0 unx        1 b- defN 23-Apr-11 01:20 kwcoco/__main__.pyi
+-rw-r--r--  2.0 unx     6161 b- defN 23-Apr-11 01:20 kwcoco/_helpers.py
+-rw-rw-rw-  2.0 unx      717 b- defN 23-Apr-11 01:20 kwcoco/_helpers.pyi
+-rw-r--r--  2.0 unx      309 b- defN 23-Apr-11 01:20 kwcoco/abstract_coco_dataset.py
+-rw-rw-rw-  2.0 unx       62 b- defN 23-Apr-11 01:20 kwcoco/abstract_coco_dataset.pyi
+-rw-r--r--  2.0 unx    27500 b- defN 23-Apr-11 01:20 kwcoco/category_tree.py
+-rw-rw-rw-  2.0 unx     2442 b- defN 23-Apr-11 01:20 kwcoco/category_tree.pyi
+-rw-r--r--  2.0 unx      364 b- defN 23-Apr-11 01:20 kwcoco/channel_spec.py
+-rw-rw-rw-  2.0 unx      104 b- defN 23-Apr-11 01:20 kwcoco/channel_spec.pyi
+-rw-r--r--  2.0 unx   255881 b- defN 23-Apr-11 01:20 kwcoco/coco_dataset.py
+-rw-rw-rw-  2.0 unx    12926 b- defN 23-Apr-11 01:20 kwcoco/coco_dataset.pyi
+-rw-r--r--  2.0 unx    50052 b- defN 23-Apr-11 01:20 kwcoco/coco_evaluator.py
+-rw-rw-rw-  2.0 unx     2003 b- defN 23-Apr-11 01:20 kwcoco/coco_evaluator.pyi
+-rw-r--r--  2.0 unx    49353 b- defN 23-Apr-11 01:20 kwcoco/coco_image.py
+-rw-rw-rw-  2.0 unx     3393 b- defN 23-Apr-11 01:20 kwcoco/coco_image.pyi
+-rw-r--r--  2.0 unx    26887 b- defN 23-Apr-11 01:20 kwcoco/coco_objects1d.py
+-rw-rw-rw-  2.0 unx     3468 b- defN 23-Apr-11 01:20 kwcoco/coco_objects1d.pyi
+-rw-r--r--  2.0 unx    11329 b- defN 23-Apr-11 01:20 kwcoco/coco_schema.py
+-rw-rw-rw-  2.0 unx      846 b- defN 23-Apr-11 01:20 kwcoco/coco_schema.pyi
+-rw-r--r--  2.0 unx    91530 b- defN 23-Apr-11 01:20 kwcoco/coco_sql_dataset.py
+-rw-rw-rw-  2.0 unx     6055 b- defN 23-Apr-11 01:20 kwcoco/coco_sql_dataset.pyi
+-rw-r--r--  2.0 unx    16155 b- defN 23-Apr-11 01:20 kwcoco/compat_dataset.py
+-rw-rw-rw-  2.0 unx     1793 b- defN 23-Apr-11 01:20 kwcoco/compat_dataset.pyi
+-rw-r--r--  2.0 unx      328 b- defN 23-Apr-11 01:20 kwcoco/exceptions.py
+-rw-rw-rw-  2.0 unx      128 b- defN 23-Apr-11 01:20 kwcoco/exceptions.pyi
+-rw-r--r--  2.0 unx     2639 b- defN 23-Apr-11 01:20 kwcoco/kpf.py
+-rw-rw-rw-  2.0 unx       74 b- defN 23-Apr-11 01:20 kwcoco/kpf.pyi
+-rw-r--r--  2.0 unx    13342 b- defN 23-Apr-11 01:20 kwcoco/kw18.py
+-rw-rw-rw-  2.0 unx      682 b- defN 23-Apr-11 01:20 kwcoco/kw18.pyi
+-rw-rw-rw-  2.0 unx        0 b- defN 23-Apr-11 01:20 kwcoco/py.typed
+-rw-r--r--  2.0 unx      402 b- defN 23-Apr-11 01:20 kwcoco/sensorchan_spec.py
+-rw-rw-rw-  2.0 unx      325 b- defN 23-Apr-11 01:20 kwcoco/sensorchan_spec.pyi
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-11 01:20 kwcoco/cli/__init__.py
+-rw-r--r--  2.0 unx     6854 b- defN 23-Apr-11 01:20 kwcoco/cli/__main__.py
+-rw-r--r--  2.0 unx     3372 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_conform.py
+-rw-r--r--  2.0 unx     5725 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_eval.py
+-rw-r--r--  2.0 unx     2293 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_grab.py
+-rw-r--r--  2.0 unx     4164 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_modify_categories.py
+-rw-r--r--  2.0 unx     6771 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_reroot.py
+-rw-r--r--  2.0 unx     4680 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_show.py
+-rw-r--r--  2.0 unx     6731 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_split.py
+-rw-r--r--  2.0 unx     8473 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_stats.py
+-rw-r--r--  2.0 unx    12894 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_subset.py
+-rw-r--r--  2.0 unx     4904 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_toydata.py
+-rw-r--r--  2.0 unx     3566 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_union.py
+-rw-r--r--  2.0 unx     7709 b- defN 23-Apr-11 01:20 kwcoco/cli/coco_validate.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-11 01:20 kwcoco/data/__init__.py
+-rw-r--r--  2.0 unx    21744 b- defN 23-Apr-11 01:20 kwcoco/data/grab_camvid.py
+-rw-r--r--  2.0 unx     5849 b- defN 23-Apr-11 01:20 kwcoco/data/grab_cifar.py
+-rw-r--r--  2.0 unx      720 b- defN 23-Apr-11 01:20 kwcoco/data/grab_datasets.py
+-rw-r--r--  2.0 unx     6857 b- defN 23-Apr-11 01:20 kwcoco/data/grab_domainnet.py
+-rw-r--r--  2.0 unx     9189 b- defN 23-Apr-11 01:20 kwcoco/data/grab_spacenet.py
+-rw-r--r--  2.0 unx     9865 b- defN 23-Apr-11 01:20 kwcoco/data/grab_voc.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-11 01:20 kwcoco/demo/__init__.py
+-rw-r--r--  2.0 unx    23050 b- defN 23-Apr-11 01:20 kwcoco/demo/boids.py
+-rw-r--r--  2.0 unx    14007 b- defN 23-Apr-11 01:20 kwcoco/demo/perterb.py
+-rw-r--r--  2.0 unx      500 b- defN 23-Apr-11 01:20 kwcoco/demo/toydata.py
+-rw-r--r--  2.0 unx    20026 b- defN 23-Apr-11 01:20 kwcoco/demo/toydata_image.py
+-rw-r--r--  2.0 unx    55274 b- defN 23-Apr-11 01:20 kwcoco/demo/toydata_video.py
+-rw-r--r--  2.0 unx    20195 b- defN 23-Apr-11 01:20 kwcoco/demo/toypatterns.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-11 01:20 kwcoco/examples/__init__.py
+-rw-r--r--  2.0 unx     5751 b- defN 23-Apr-11 01:20 kwcoco/examples/bench_large_hyperspectral.py
+-rw-r--r--  2.0 unx     4911 b- defN 23-Apr-11 01:20 kwcoco/examples/demo_kwcoco_spaces.py
+-rw-r--r--  2.0 unx     2882 b- defN 23-Apr-11 01:20 kwcoco/examples/draw_gt_and_predicted_boxes.py
+-rw-r--r--  2.0 unx     2692 b- defN 23-Apr-11 01:20 kwcoco/examples/faq.py
+-rw-r--r--  2.0 unx     2074 b- defN 23-Apr-11 01:20 kwcoco/examples/getting_started_existing_dataset.py
+-rw-r--r--  2.0 unx     2068 b- defN 23-Apr-11 01:20 kwcoco/examples/loading_multispectral_data.py
+-rw-r--r--  2.0 unx     1683 b- defN 23-Apr-11 01:20 kwcoco/examples/modification_example.py
+-rw-r--r--  2.0 unx     2087 b- defN 23-Apr-11 01:20 kwcoco/examples/shifting_annots.py
+-rw-r--r--  2.0 unx     8961 b- defN 23-Apr-11 01:20 kwcoco/examples/simple_kwcoco_torch_dataset.py
+-rw-r--r--  2.0 unx     7896 b- defN 23-Apr-11 01:20 kwcoco/examples/vectorized_interface.py
+-rw-r--r--  2.0 unx      699 b- defN 23-Apr-11 01:20 kwcoco/metrics/__init__.py
+-rw-r--r--  2.0 unx    27823 b- defN 23-Apr-11 01:20 kwcoco/metrics/assignment.py
+-rw-r--r--  2.0 unx    22260 b- defN 23-Apr-11 01:20 kwcoco/metrics/clf_report.py
+-rw-r--r--  2.0 unx    52248 b- defN 23-Apr-11 01:20 kwcoco/metrics/confusion_measures.py
+-rw-r--r--  2.0 unx    43271 b- defN 23-Apr-11 01:20 kwcoco/metrics/confusion_vectors.py
+-rw-r--r--  2.0 unx    60057 b- defN 23-Apr-11 01:20 kwcoco/metrics/detect_metrics.py
+-rw-r--r--  2.0 unx    22909 b- defN 23-Apr-11 01:20 kwcoco/metrics/drawing.py
+-rw-r--r--  2.0 unx     6978 b- defN 23-Apr-11 01:20 kwcoco/metrics/functional.py
+-rw-r--r--  2.0 unx     7330 b- defN 23-Apr-11 01:20 kwcoco/metrics/sklearn_alts.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Apr-11 01:20 kwcoco/metrics/util.py
+-rw-r--r--  2.0 unx    15348 b- defN 23-Apr-11 01:20 kwcoco/metrics/voc_metrics.py
+-rw-r--r--  2.0 unx     5567 b- defN 23-Apr-11 01:20 kwcoco/util/__init__.py
+-rw-r--r--  2.0 unx     3765 b- defN 23-Apr-11 01:20 kwcoco/util/dict_like.py
+-rw-r--r--  2.0 unx     9344 b- defN 23-Apr-11 01:20 kwcoco/util/dict_proxy2.py
+-rw-r--r--  2.0 unx    13052 b- defN 23-Apr-11 01:20 kwcoco/util/jsonschema_elements.py
+-rw-r--r--  2.0 unx      211 b- defN 23-Apr-11 01:20 kwcoco/util/lazy_frame_backends.py
+-rw-r--r--  2.0 unx    10304 b- defN 23-Apr-11 01:20 kwcoco/util/util_archive.py
+-rw-r--r--  2.0 unx      644 b- defN 23-Apr-11 01:20 kwcoco/util/util_deprecate.py
+-rw-r--r--  2.0 unx     2733 b- defN 23-Apr-11 01:20 kwcoco/util/util_eval.py
+-rw-r--r--  2.0 unx      185 b- defN 23-Apr-11 01:20 kwcoco/util/util_futures.py
+-rw-r--r--  2.0 unx     9367 b- defN 23-Apr-11 01:20 kwcoco/util/util_json.py
+-rw-r--r--  2.0 unx     3678 b- defN 23-Apr-11 01:20 kwcoco/util/util_monkey.py
+-rw-r--r--  2.0 unx     2988 b- defN 23-Apr-11 01:20 kwcoco/util/util_parallel.py
+-rw-r--r--  2.0 unx     3711 b- defN 23-Apr-11 01:20 kwcoco/util/util_reroot.py
+-rw-r--r--  2.0 unx     5654 b- defN 23-Apr-11 01:20 kwcoco/util/util_sklearn.py
+-rw-r--r--  2.0 unx     4809 b- defN 23-Apr-11 01:20 kwcoco/util/util_special_json.py
+-rw-r--r--  2.0 unx     2720 b- defN 23-Apr-11 01:20 kwcoco/util/util_truncate.py
+-rw-r--r--  2.0 unx     1607 b- defN 23-Apr-11 01:20 kwcoco/util/delayed_ops/__init__.py
+-rw-rw-rw-  2.0 unx    11343 b- defN 23-Apr-11 01:21 kwcoco-0.6.1.dist-info/LICENSE
+-rw-r--r--  2.0 unx    64330 b- defN 23-Apr-11 01:21 kwcoco-0.6.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-11 01:21 kwcoco-0.6.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx       52 b- defN 23-Apr-11 01:21 kwcoco-0.6.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        7 b- defN 23-Apr-11 01:21 kwcoco-0.6.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     8883 b- defN 23-Apr-11 01:21 kwcoco-0.6.1.dist-info/RECORD
+107 files, 1339701 bytes uncompressed, 341096 bytes compressed:  74.5%
```

## zipnote {}

```diff
@@ -267,23 +267,29 @@
 
 Filename: kwcoco/util/util_archive.py
 Comment: 
 
 Filename: kwcoco/util/util_deprecate.py
 Comment: 
 
+Filename: kwcoco/util/util_eval.py
+Comment: 
+
 Filename: kwcoco/util/util_futures.py
 Comment: 
 
 Filename: kwcoco/util/util_json.py
 Comment: 
 
 Filename: kwcoco/util/util_monkey.py
 Comment: 
 
+Filename: kwcoco/util/util_parallel.py
+Comment: 
+
 Filename: kwcoco/util/util_reroot.py
 Comment: 
 
 Filename: kwcoco/util/util_sklearn.py
 Comment: 
 
 Filename: kwcoco/util/util_special_json.py
@@ -291,26 +297,26 @@
 
 Filename: kwcoco/util/util_truncate.py
 Comment: 
 
 Filename: kwcoco/util/delayed_ops/__init__.py
 Comment: 
 
-Filename: kwcoco-0.6.0.dist-info/LICENSE
+Filename: kwcoco-0.6.1.dist-info/LICENSE
 Comment: 
 
-Filename: kwcoco-0.6.0.dist-info/METADATA
+Filename: kwcoco-0.6.1.dist-info/METADATA
 Comment: 
 
-Filename: kwcoco-0.6.0.dist-info/WHEEL
+Filename: kwcoco-0.6.1.dist-info/WHEEL
 Comment: 
 
-Filename: kwcoco-0.6.0.dist-info/entry_points.txt
+Filename: kwcoco-0.6.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: kwcoco-0.6.0.dist-info/top_level.txt
+Filename: kwcoco-0.6.1.dist-info/top_level.txt
 Comment: 
 
-Filename: kwcoco-0.6.0.dist-info/RECORD
+Filename: kwcoco-0.6.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## kwcoco/__init__.py

```diff
@@ -265,15 +265,15 @@
 Testing:
 
     EAGER_IMPORT=1 python -c "import kwcoco"
     python -c "import kwcoco; print(kwcoco.CocoSqlDatabase)"
 
 """
 
-__version__ = '0.6.0'
+__version__ = '0.6.1'
 
 
 __submodules__ = {
     'abstract_coco_dataset': ['AbstractCocoDataset'],
     'coco_dataset': ['CocoDataset'],
     'coco_image': ['CocoImage'],
     'category_tree': ['CategoryTree'],
```

## kwcoco/_helpers.py

```diff
@@ -183,7 +183,15 @@
         keep_idxs = sorted(set(range(len(items))) - set(remove_idxs))
         newlist = [items[idx] for idx in keep_idxs]
         items[:] = newlist
     else:
         # However, when there are a few hundred items to remove, del is faster.
         for idx in sorted(remove_idxs, reverse=True):
             del items[idx]
+
+
+def _load_and_postprocess(data, loader, postprocess, **loadkw):
+    # Helper for CocoDataset.load_multiple
+    dset = loader(data, **loadkw)
+    if postprocess is not None:
+        dset = postprocess(dset)
+    return dset
```

## kwcoco/coco_dataset.py

```diff
@@ -68,15 +68,16 @@
 # Vectorized ORM-Like containers
 from kwcoco.coco_objects1d import Categories, Videos, Images, Annots
 from kwcoco.abstract_coco_dataset import AbstractCocoDataset
 from kwcoco import exceptions
 
 from kwcoco._helpers import (
     SortedSet, UniqueNameRemapper, _ID_Remapper, _NextId,
-    _delitems, _lut_image_frame_index, _lut_annot_frame_index
+    _delitems, _lut_image_frame_index, _lut_annot_frame_index,
+    _load_and_postprocess,
 )
 
 import json as pjson
 from types import ModuleType
 # The ujson library is faster than Python's json, but the API has some
 # limitations and requires a minimum version. Currently we only use it to read,
 # we have to wait for https://github.com/ultrajson/ultrajson/pull/518 to land
@@ -981,14 +982,15 @@
             >>> assert len(dset.index.name_to_img) == len(dset.index.imgs) == 5
             >>> dset.remove_images([1])
             >>> assert len(dset.index.name_to_img) == len(dset.index.imgs) == 4
             >>> dset.remove_videos([1])
             >>> assert len(dset.index.name_to_img) == len(dset.index.imgs) == 0
         """
         import parse
+        kwargs.pop('autobuild', None)
 
         if key.startswith('special:'):
             key = key.split(':')[1]
 
         if key.startswith('shapes'):
             from kwcoco.demo import toydata_image
             res = parse.parse('shapes{num_imgs:d}', key)
@@ -5274,14 +5276,163 @@
         """
         coco_dset = CocoDataset(bundle_dpath=bundle_dpath, img_root=img_root)
         for gpath in gpaths:
             coco_dset.add_image(gpath)
         return coco_dset
 
     @classmethod
+    def coerce_multiple(cls, datas, workers=0, mode='process', verbose=1,
+                        postprocess=None, ordered=True, **kwargs):
+        """
+        Coerce multiple CocoDataset objects in parallel.
+
+        Args:
+            datas (List): list of kwcoco coercables to load
+
+            workers (int | str): number of worker threads / processes.
+                Can also accept coerceable workers.
+
+            mode (str): thread, process, or serial. Defaults to process.
+
+            verbose (int): verbosity level
+
+            postprocess (Callable | None):
+                A function taking one arg (the loaded dataset) to run on the
+                loaded kwcoco dataset in background workers. This can be more
+                efficient when postprocessing is independent per kwcoco file.
+
+            ordered (bool):
+                if True yields datasets in the same order as given. Otherwise
+                results are yielded as they become available. Defaults to True.
+
+            **kwargs:
+                arguments passed to the constructor
+
+        Yields:
+            CocoDataset
+
+        SeeAlso:
+            * load_multiple - like this function but is a strict file-path-only loader
+
+        CommandLine:
+            xdoctest -m kwcoco.coco_dataset CocoDataset.coerce_multiple
+
+        Example:
+            >>> import kwcoco
+            >>> dset1 = kwcoco.CocoDataset.demo('shapes1')
+            >>> dset2 = kwcoco.CocoDataset.demo('shapes2')
+            >>> dset3 = kwcoco.CocoDataset.demo('vidshapes8')
+            >>> dsets = [dset1, dset2, dset3]
+            >>> input_fpaths = [d.fpath for d in dsets]
+            >>> results = list(kwcoco.CocoDataset.coerce_multiple(input_fpaths, ordered=True))
+            >>> result_fpaths = [r.fpath for r in results]
+            >>> assert result_fpaths == input_fpaths
+            >>> # Test unordered
+            >>> results1 = list(kwcoco.CocoDataset.coerce_multiple(input_fpaths, ordered=False))
+            >>> result_fpaths = [r.fpath for r in results]
+            >>> assert set(result_fpaths) == set(input_fpaths)
+            >>> #
+            >>> # Coerce from existing datasets
+            >>> results2 = list(kwcoco.CocoDataset.coerce_multiple(dsets, ordered=True, workers=0))
+            >>> assert results2[0] is dsets[0]
+        """
+        import kwcoco
+        from kwcoco.util.util_parallel import coerce_num_workers
+        _loader = kwcoco.CocoDataset.coerce
+        workers = coerce_num_workers(workers)
+        workers = min(workers, len(datas))
+        # Reuse coerce_multiple logic but overload the loader function.
+        yield from cls._load_multiple(_loader, datas, workers=workers,
+                                      mode=mode, verbose=verbose,
+                                      postprocess=postprocess, ordered=ordered,
+                                      **kwargs)
+
+    @classmethod
+    def load_multiple(cls, fpaths, workers=0, mode='process', verbose=1,
+                      postprocess=None, ordered=True, **kwargs):
+        """
+        Load multiple CocoDataset objects in parallel.
+
+        Args:
+            fpaths (List[str | PathLike]):
+                list of paths to multiple coco files to be loaded
+
+            workers (int): number of worker threads / processes
+
+            mode (str): thread, process, or serial. Defaults to process.
+
+            verbose (int): verbosity level
+
+            postprocess (Callable | None):
+                A function taking one arg (the loaded dataset) to run on the
+                loaded kwcoco dataset in background workers and returns the
+                modified dataset. This can be more efficient when
+                postprocessing is independent per kwcoco file.
+
+            ordered (bool):
+                if True yields datasets in the same order as given. Otherwise
+                results are yielded as they become available. Defaults to True.
+
+            **kwargs:
+                arguments passed to the constructor
+
+        Yields:
+            CocoDataset
+
+        SeeAlso:
+            * coerce_multiple - like this function but accepts general
+                coercable inputs.
+        """
+        import kwcoco
+        _loader = kwcoco.CocoDataset
+        # Reuse coerce_multiple logic but overload the loader function.
+        yield from cls._load_multiple(_loader, fpaths, workers=workers,
+                                      mode=mode, verbose=verbose,
+                                      postprocess=postprocess, ordered=ordered,
+                                      **kwargs)
+
+    @classmethod
+    def _load_multiple(cls, _loader, inputs, workers=0, mode='process',
+                       verbose=1, postprocess=None, ordered=True, **kwargs):
+        """
+        Shared logic for multiprocessing loaders.
+
+        SeeAlso:
+            * coerce_multiple
+            * load_multiple
+        """
+        _submit_prog = ub.ProgIter(inputs, desc='submit load kwcoco jobs',
+                                   enabled=workers > 0, verbose=verbose)
+        executor = ub.Executor(mode=mode, max_workers=workers)
+        with executor:
+            jobs = []
+            for job_idx, data in enumerate(_submit_prog):
+                job = executor.submit(
+                    _load_and_postprocess,
+                    data=data,
+                    loader=_loader,
+                    postprocess=postprocess, **kwargs)
+                job.job_idx = job_idx
+                jobs.append(job)
+
+            if ordered:
+                _jobiter = jobs
+            else:
+                from concurrent.futures import as_completed
+                _jobiter = as_completed(jobs)
+
+            _collect_prog = ub.ProgIter(_jobiter, total=len(jobs),
+                                        desc='loading kwcoco files',
+                                        verbose=verbose)
+            for job in _collect_prog:
+                # Clear the reference to this job
+                jobs[job.job_idx] = None
+                yield job.result()
+
+    @classmethod
     def from_coco_paths(CocoDataset, fpaths, max_workers=0, verbose=1,
                         mode='thread', union='try'):
         """
         Constructor from multiple coco file paths.
 
         Loads multiple coco datasets and unions the result
 
@@ -5299,23 +5450,24 @@
 
             mode (str): thread, process, or serial
 
             union (str | bool): If True, unions the result
                 datasets after loading. If False, just returns the result list.
                 If 'try', then try to preform the union, but return the result
                 list if it fails. Default='try'
+
+        Note:
+            This may be deprecated. Use load_multiple or coerce_multiple and
+            then manually perform the union.
         """
-        # Can this be done better with asyncio?
-        jobs = ub.JobPool(mode, max_workers=max_workers)
-        for fpath in ub.ProgIter(fpaths, desc='submit load coco jobs', verbose=verbose):
-            jobs.submit(CocoDataset, fpath, autobuild=False)
-
-        results = [f.result()
-                   for f in jobs.as_completed(desc='collect load coco jobs',
-                                              progkw=dict(verbose=verbose))]
+        results = CocoDataset.load_multiple(
+            fpaths, workers=max_workers, verbose=verbose, mode=mode,
+            ordered=False, autobuild=False)
+
+        results = list(results)
 
         if union:
             try:
                 if verbose:
                     # TODO: it would be nice if we had a way to combine results
                     # on the fly, so we can work while the remaining io jobs
                     # are loading
@@ -5682,15 +5834,15 @@
         elif verbose:
             print('Pointers are consistent')
         return True
 
     def _build_index(self):
         self.index.build(self)
 
-    def union(*others, disjoint_tracks=True, **kwargs):
+    def union(*others, disjoint_tracks=True, remember_parent=False, **kwargs):
         """
         Merges multiple :class:`CocoDataset` items into one. Names and
         associations are retained, but ids may be different.
 
         Args:
             *others : a series of CocoDatasets that we will merge.
                 Note, if called as an instance method, the "self" instance
@@ -5698,14 +5850,18 @@
                 like a classmethod, "others" will be empty by default.
 
             disjoint_tracks (bool):
                 if True, we will assume track-ids are disjoint and if two
                 datasets share the same track-id, we will disambiguate them.
                 Otherwise they will be copied over as-is. Defaults to True.
 
+            remember_parent (bool):
+                if True, videos and images will save information about their
+                parent in the "union_parent" field.
+
             **kwargs : constructor options for the new merged CocoDataset
 
         Returns:
             kwcoco.CocoDataset: a new merged coco dataset
 
         CommandLine:
             xdoctest -m kwcoco.coco_dataset CocoDataset.union
@@ -5838,30 +5994,30 @@
                 for item in items:
                     if item in seen:
                         return True
                     seen.add(item)
                 return False
 
             # Check if the image-ids are unique and can be preserved
-            _all_imgs = (img for _, d in relative_dsets for img in d['images'])
+            _all_imgs = (img for _, _, d in relative_dsets for img in d['images'])
             _all_gids = (img['id'] for img in _all_imgs)
             preserve_gids = not _has_duplicates(_all_gids)
 
             # Check if the video-ids are unique and can be preserved
-            _all_videos = (video for _, d in relative_dsets
+            _all_videos = (video for _, _, d in relative_dsets
                            for video in (d.get('videos', None) or []))
             _all_vidids = (video['id'] for video in _all_videos)
             preserve_vidids = not _has_duplicates(_all_vidids)
 
             # If disjoint_tracks is True keep track of track-ids we've seen in
             # so far in previous datasets and ensure we dont reuse them.
             # TODO: do this Remapper class with other ids?
             track_id_map = _ID_Remapper(reuse=False)
 
-            for subdir, old_dset in relative_dsets:
+            for subdir, old_fpath, old_dset in relative_dsets:
                 # Create temporary indexes to map from old to new
                 cat_id_map = {None: None}
                 img_id_map = {}
                 video_id_map = {}
                 kpcat_id_map = {}
 
                 # Add the licenses / info into the merged dataset
@@ -5933,14 +6089,16 @@
                     new_video = _dict([
                         ('id', new_id),
                         ('name', new_vidname),
                     ])
                     # copy over other metadata
                     update_ifnotin(new_video, old_video)
                     video_id_map[old_video['id']] = new_video['id']
+                    if remember_parent:
+                        new_video['union_parent'] = old_fpath
                     merged['videos'].append(new_video)
 
                 # Add the images into the merged dataset
                 for old_img in old_dset['images']:
                     if preserve_gids:
                         new_id = old_img['id']
                     else:
@@ -5974,14 +6132,16 @@
 
                     video_img_id = video_id_map.get(old_img.get('video_id'), None)
                     if video_img_id is not None:
                         new_img['video_id'] = video_img_id
                     # copy over other metadata
                     update_ifnotin(new_img, old_img)
                     img_id_map[old_img['id']] = new_img['id']
+                    if remember_parent:
+                        new_img['union_parent'] = old_fpath
                     merged['images'].append(new_img)
 
                 # Add the annotations into the merged dataset
                 for old_annot in old_dset['annotations']:
                     old_cat_id = old_annot['category_id']
                     old_img_id = old_annot['image_id']
                     new_cat_id = cat_id_map.get(old_cat_id, ub.NoParam)
@@ -6055,16 +6215,18 @@
 
         dset_roots = [dset.bundle_dpath for dset in others]
         dset_roots = [normpath(r) if r is not None else None
                       for r in dset_roots]
         items = [join('.', p) for p in dset_roots]
         common_root = longest_common_prefix(items, sep=os.path.sep)
 
-        relative_dsets = [(relpath(normpath(d.bundle_dpath), common_root),
-                           d.dataset) for d in others]
+        relative_dsets = [
+            (relpath(normpath(d.bundle_dpath), common_root),
+             str(d.fpath),
+             d.dataset) for d in others]
 
         merged = _coco_union(relative_dsets, common_root)
 
         kwargs['bundle_dpath'] = common_root
         new_dset = cls(merged, **kwargs)
         return new_dset
```

## kwcoco/coco_evaluator.py

```diff
@@ -76,15 +76,15 @@
 
 try:
     from xdev import profile
 except Exception:
     profile = ub.identity
 
 
-class CocoEvalConfig(scfg.Config):
+class CocoEvalConfig(scfg.DataConfig):
     """
     Evaluate and score predicted versus truth detections / classifications in a COCO dataset
     """
     __default__ = {
         'true_dataset': scfg.Value(None, type=str, help='coercable true detections', position=1),
         'pred_dataset': scfg.Value(None, type=str, help='coercable predicted detections', position=2),
 
@@ -96,15 +96,15 @@
         'implicit_ignore_classes': scfg.Value(['ignore']),
 
         'fp_cutoff': scfg.Value(float('inf'), help='False positive cutoff for ROC'),
 
         'iou_thresh': scfg.Value(
             value=0.5,
             help='One or more IoU overlap threshold for detection assignment',
-            # alias=['ovthresh']
+            alias=['ovthresh']
         ),
 
         'compat': scfg.Value(
             value='mutex',
             choices=['all', 'mutex', 'ancestors'],
             help=ub.paragraph(
                 '''
@@ -167,28 +167,28 @@
 
         # 'discard_classes': scfg.Value(None, type=list, help='classes to completely remove'),  # TODO
 
         'assign_workers': scfg.Value(8, help='number of background workers for assignment'),
 
         'load_workers': scfg.Value(0, help='number of workers to load cached detections'),
 
-        'ovthresh': scfg.Value(None, help='deprecated, alias for iou_thresh'),
+        # 'ovthresh': scfg.Value(None, help='deprecated, alias for iou_thresh'),
 
         'classes_of_interest': scfg.Value(
             None, type=list,
             help='if specified only these classes are given weight'),
 
         'use_image_names': scfg.Value(
             False, help='if True use image file_name to associate images instead of ids'),
     }
 
     def normalize(self):
-        if self['ovthresh'] is not None:
-            warnings.warn('ovthresh is deprecated use iou_thresh')
-            self['iou_thresh'] = self['ovthresh']
+        # if self['ovthresh'] is not None:
+        #     warnings.warn('ovthresh is deprecated use iou_thresh')
+        #     self['iou_thresh'] = self['ovthresh']
 
         if self['area_range'] is not None:
             parsed = []
             code = self['area_range']
 
             parts = []
             if ub.iterable(code):
@@ -237,18 +237,17 @@
         >>>     'true_dataset': true_dset,
         >>>     'pred_dataset': pred_dset,
         >>>     'classes_of_interest': [],
         >>> }
         >>> coco_eval = CocoEvaluator(config)
         >>> results = coco_eval.evaluate()
     """
-    Config = CocoEvalConfig
 
     def __init__(coco_eval, config):
-        coco_eval.config = CocoEvalConfig(config)
+        coco_eval.config = CocoEvalConfig(**config)
         coco_eval._is_init = False
         coco_eval._logs = []
         coco_eval._verbose = 1
 
     def log(coco_eval, msg, level='INFO'):
         if coco_eval._verbose:
             print(msg)
```

## kwcoco/cli/__main__.py

```diff
@@ -31,120 +31,176 @@
         module_lut[name] = mod
 
     # Create a list of all submodules with CLI interfaces
     cli_modules = list(module_lut.values())
 
     # Create a subparser that uses the first positional argument to run one of
     # the previous CLI interfaces.
+    import os
+    KWCOCO_LOOSE_CLI = os.environ.get('KWCOCO_LOOSE_CLI', '')
 
-    class RawDescriptionDefaultsHelpFormatter(
-            argparse.RawDescriptionHelpFormatter,
-            argparse.ArgumentDefaultsHelpFormatter):
-        pass
-
-    parser = argparse.ArgumentParser(
-        description='The Kitware COCO CLI',
-        formatter_class=RawDescriptionDefaultsHelpFormatter,
-    )
-    parser.add_argument('--version', action='store_true',
-                        help='show version number and exit')
-    subparsers = parser.add_subparsers(help='specify a command to run')
-
-    for cli_module in cli_modules:
-        cli_cls = cli_module._CLI
-        subconfig = cli_cls.CLIConfig()
-
-        # TODO: make subparser.add_parser args consistent with what
-        # scriptconfig generates when parser=None
-        if hasattr(subconfig, '_parserkw'):
-            parserkw = subconfig._parserkw()
-        else:
-            # for older versions of scriptconfig
-            parserkw = dict(
-                description=subconfig.__class__.__doc__
-            )
-        parserkw['help'] = parserkw['description'].split('\n')[0]
-        subparser = subparsers.add_parser(cli_cls.name, **parserkw)
-        subparser = subconfig.argparse(subparser)
-        subparser.set_defaults(main=cli_cls.main)
-
-    if 0:
-        """
-        Debugging positional or keyword args
-
-            python -m kwcoco.cli.coco_stats special:shapes8
-
-            python -m kwcoco.cli.coco_stats --src=special:shapes8
-
-            >>> kw = {'src': 'special:shapes8'}
-            >>> cmdline = False
-            >>> cls = CocoStatsCLI
-
-            python -c "from kwcoco.cli.coco_stats import *; print(CocoStatsCLI.CLIConfig()._read_argv())" --src foo bar
-            python -c "from kwcoco.cli.coco_stats import *; print(CocoStatsCLI.CLIConfig()._read_argv())" a --basic=True baz biz --src f a a
-
-        """
-        for action in parser._actions:
-            print('action = {!r}'.format(action))
-            pass
-        for sub in parser._subparsers:
-            parser._subparsers._actions
+    NEW_MODAL_CLI = 1
+    if NEW_MODAL_CLI:
+        from scriptconfig.modal import ModalCLI
+        modal = ModalCLI(description=ub.codeblock(
+            '''
+            The Kitware COCO CLI
+            '''))
+
+        def get_version(self):
+            import kwcoco
+            return kwcoco.__version__
+        modal.__class__.version = property(get_version)
+
+        for cli_module in cli_modules:
+
+            cli_subconfig = None
+            cli_cls = cli_module._CLI
+            cli_cls.CLIConfig.__command__ = cli_cls.name
+
+            assert hasattr(cli_cls, 'CLIConfig'), (
+                'We are only supporting scriptconfig CLIs')
+            # scriptconfig cli pattern
+            cli_subconfig = cli_cls.CLIConfig
+
+            if not hasattr(cli_subconfig, 'main'):
+                if hasattr(cli_cls, 'main'):
+                    main_func = cli_cls.main
+                    # Hack the main function into the config
+                    cli_subconfig.main = main_func
+                else:
+                    raise AssertionError(f'No main function for {cli_module}')
+
+            # Update configs to have aliases / commands attributes
+            # cli_modname = cli_module.__name__
+            # cli_rel_modname = cli_modname.split('.')[-1]
+
+            cmdname_aliases = ub.oset()
+            alias = getattr(cli_module, '__alias__', [])
+            if isinstance(alias, str):
+                alias = [alias]
+            command = getattr(cli_module, '__command__', None)
+            if command is not None:
+                cmdname_aliases.add(command)
+            cmdname_aliases.update(alias)
+            # cmdname_aliases.update(cmd_alias.get(cli_modname, []) )
+            cmdname_aliases.add(cli_cls.CLIConfig.__command__)
+            parserkw = {}
+            primary_cmdname = cmdname_aliases[0]
+            secondary_cmdnames = cmdname_aliases[1:]
+            cli_subconfig.__command__ = primary_cmdname
+            cli_subconfig.__alias__ = secondary_cmdnames
+            modal.register(cli_subconfig)
+
+        ret = modal.run(strict=not KWCOCO_LOOSE_CLI)
+        return ret
+    else:
+        class RawDescriptionDefaultsHelpFormatter(
+                argparse.RawDescriptionHelpFormatter,
+                argparse.ArgumentDefaultsHelpFormatter):
             pass
 
-    try:
-        import argcomplete
-        # Need to run: "$(register-python-argcomplete xdev)"
-        # or activate-global-python-argcomplete --dest=-
-        # mkdir -p ~/.bash_completion.d
-        # activate-global-python-argcomplete --dest ~/.bash_completion.d
-        # To enable this.
-    except ImportError:
-        argcomplete = None
-
-    if argcomplete is not None:
-        argcomplete.autocomplete(parser)
-
-    EASTER = 1
-    if EASTER:
-        if len(sys.argv) == 2 and sys.argv[1] == 'boid':
-            from kwcoco.demo.boids import _yeah_boid
-            _yeah_boid()
+        parser = argparse.ArgumentParser(
+            description='The Kitware COCO CLI',
+            formatter_class=RawDescriptionDefaultsHelpFormatter,
+        )
+        parser.add_argument('--version', action='store_true',
+                            help='show version number and exit')
+        subparsers = parser.add_subparsers(help='specify a command to run')
+
+        for cli_module in cli_modules:
+            cli_cls = cli_module._CLI
+            subconfig = cli_cls.CLIConfig()
+
+            # TODO: make subparser.add_parser args consistent with what
+            # scriptconfig generates when parser=None
+            if hasattr(subconfig, '_parserkw'):
+                parserkw = subconfig._parserkw()
+            else:
+                # for older versions of scriptconfig
+                parserkw = dict(
+                    description=subconfig.__class__.__doc__
+                )
+            parserkw['help'] = parserkw['description'].split('\n')[0]
+            subparser = subparsers.add_parser(cli_cls.name, **parserkw)
+            subparser = subconfig.argparse(subparser)
+            subparser.set_defaults(main=cli_cls.main)
+
+        if 0:
+            """
+            Debugging positional or keyword args
+
+                python -m kwcoco.cli.coco_stats special:shapes8
+
+                python -m kwcoco.cli.coco_stats --src=special:shapes8
+
+                >>> kw = {'src': 'special:shapes8'}
+                >>> cmdline = False
+                >>> cls = CocoStatsCLI
+
+                python -c "from kwcoco.cli.coco_stats import *; print(CocoStatsCLI.CLIConfig()._read_argv())" --src foo bar
+                python -c "from kwcoco.cli.coco_stats import *; print(CocoStatsCLI.CLIConfig()._read_argv())" a --basic=True baz biz --src f a a
+
+            """
+            for action in parser._actions:
+                print('action = {!r}'.format(action))
+                pass
+            for sub in parser._subparsers:
+                parser._subparsers._actions
+                pass
+
+        try:
+            import argcomplete
+            # Need to run: "$(register-python-argcomplete xdev)"
+            # or activate-global-python-argcomplete --dest=-
+            # mkdir -p ~/.bash_completion.d
+            # activate-global-python-argcomplete --dest ~/.bash_completion.d
+            # To enable this.
+        except ImportError:
+            argcomplete = None
+
+        if argcomplete is not None:
+            argcomplete.autocomplete(parser)
+
+        EASTER = 1
+        if EASTER:
+            if len(sys.argv) == 2 and sys.argv[1] in {'boid', 'boids'}:
+                from kwcoco.demo.boids import _yeah_boid
+                _yeah_boid()
 
-    import os
-    KWCOCO_LOOSE_CLI = os.environ.get('KWCOCO_LOOSE_CLI', '')
-    if KWCOCO_LOOSE_CLI:
-        ns = parser.parse_known_args()[0]
-    else:
-        ns = parser.parse_args()
-    # print('ns = {!r}'.format(ns))
+        if KWCOCO_LOOSE_CLI:
+            ns = parser.parse_known_args()[0]
+        else:
+            ns = parser.parse_args()
+        # print('ns = {!r}'.format(ns))
 
-    # Execute the subcommand without additional CLI parsing
-    kw = ns.__dict__
+        # Execute the subcommand without additional CLI parsing
+        kw = ns.__dict__
 
-    if kw.pop('version'):
-        import kwcoco
-        print(kwcoco.__version__)
-        return 0
-
-    main = kw.pop('main', None)
-    if main is None:
-        parser.print_help()
-        raise ValueError('no command given')
-        return 1
-
-    try:
-        ret = main(cmdline=False, **kw)
-    except Exception as ex:
-        print('ERROR ex = {!r}'.format(ex))
-        raise
-        return 1
-    else:
-        if ret is None:
-            ret = 0
-        return ret
+        if kw.pop('version'):
+            import kwcoco
+            print(kwcoco.__version__)
+            return 0
+
+        main = kw.pop('main', None)
+        if main is None:
+            parser.print_help()
+            raise ValueError('no command given')
+            return 1
+
+        try:
+            ret = main(cmdline=False, **kw)
+        except Exception as ex:
+            print('ERROR ex = {!r}'.format(ex))
+            raise
+            return 1
+        else:
+            if ret is None:
+                ret = 0
+            return ret
 
 
 if __name__ == '__main__':
     """
     CommandLine:
         python -m kwcoco --help
         python -m kwcoco.coco_stats
```

## kwcoco/cli/coco_eval.py

```diff
@@ -4,23 +4,21 @@
 """
 from kwcoco import coco_evaluator
 import scriptconfig as scfg
 import ubelt as ub
 from os.path import join
 
 
-class CocoEvalCLIConfig(scfg.Config):
-    __doc__ = coco_evaluator.CocoEvalConfig.__doc__
-
-    __default__ = ub.dict_union(coco_evaluator.CocoEvalConfig.__default__, {
+class CocoEvalCLIConfig(coco_evaluator.CocoEvalConfig):
+    __default__ = {
         # These should go into the CLI args, not the class config args
         'expt_title': scfg.Value('', type=str, help='title for plots'),
         'draw': scfg.Value(True, isflag=1, help='draw metric plots'),
-        'out_dpath': scfg.Value('./coco_metrics', type=str),
-    })
+        'out_dpath': scfg.Value('./coco_metrics', type=str, help='where to dump results'),
+    }
 
 
 class CocoEvalCLI:
     name = 'eval'
 
     CLIConfig = CocoEvalCLIConfig
 
@@ -75,17 +73,17 @@
             --area_range=all,0-4096,4096-inf
 
         nautilus $HOME/.cache/kwcoco/tests/eval/out
     """
     import kwimage
     import kwarray
     cli_config = CocoEvalCLIConfig.cli(cmdline=cmdline, default=kw)
-    print('cli_config = {}'.format(ub.urepr(dict(cli_config), nl=1)))
+    print('cli_config = {}'.format(ub.urepr(cli_config, nl=1)))
 
-    eval_config = ub.dict_subset(cli_config, coco_evaluator.CocoEvaluator.Config.default)
+    eval_config = ub.dict_subset(cli_config, coco_evaluator.CocoEvalConfig.__default__)
 
     coco_eval = coco_evaluator.CocoEvaluator(eval_config)
     coco_eval._init()
 
     results = coco_eval.evaluate()
 
     ub.ensuredir(cli_config['out_dpath'])
```

## kwcoco/cli/coco_show.py

```diff
@@ -37,17 +37,17 @@
                 None, type=str, help=ub.paragraph(
                     '''
                     By default uses the default channels (usually this is rgb),
                     otherwise specify the name of an auxiliary channels
                     ''')
             ),
 
-            'show_annots': scfg.Value(True, help=(
-                'Overlay annotations on dispaly')),
-            'show_labels': scfg.Value(False, help=(
+            'show_annots': scfg.Value(True, isflag=True, help=(
+                'Overlay annotations on display')),
+            'show_labels': scfg.Value(False, isflag=True, help=(
                 'Overlay labels on annotations')),
         }
 
     @classmethod
     def main(cls, cmdline=True, **kw):
         """
         TODO:
```

## kwcoco/cli/coco_union.py

```diff
@@ -2,24 +2,41 @@
 import ubelt as ub
 import scriptconfig as scfg
 
 
 class CocoUnionCLI(object):
     name = 'union'
 
-    class CLIConfig(scfg.Config):
+    class CLIConfig(scfg.DataConfig):
         """
         Combine multiple COCO datasets into a single merged dataset.
         """
-        __default__ = {
-            'src': scfg.Value([], nargs='+', help='path to multiple input datasets', position=1),
-            'dst': scfg.Value('combo.kwcoco.json', help='path to output dataset'),
-            'absolute': scfg.Value(False, isflag=1, help='if True, converts paths to absolute paths before doing union'),
-            'compress': scfg.Value('auto', help='if True writes results with compression'),
-        }
+        src = scfg.Value([], position=1, help='path to multiple input datasets', nargs='+')
+
+        dst = scfg.Value('combo.kwcoco.json', help='path to output dataset')
+
+        absolute = scfg.Value(False, isflag=1, help=ub.paragraph(
+                '''
+                if True, converts paths to absolute paths before doing union
+                '''))
+
+        remember_parent = scfg.Value(False, isflag=True, help=ub.paragraph(
+                '''
+                if True adds a union_parent item to each coco image and
+                video that indicate which file it is from
+                '''))
+
+        io_workers = scfg.Value('avail-2', help=ub.paragraph(
+            '''
+            number of workers to load input datasets. By default will use
+            available CPUs minus 2.
+            '''))
+
+        compress = scfg.Value('auto', help='if True writes results with compression')
+
         __epilog__ = """
         Example Usage:
             kwcoco union --src special:shapes8 special:shapes1 --dst=combo.kwcoco.json
         """
 
     @classmethod
     def main(cls, cmdline=True, **kw):
@@ -33,49 +50,62 @@
             >>>     'src': ['special:shapes8', 'special:shapes1'],
             >>>     'dst': dst_fpath
             >>> }
             >>> cmdline = False
             >>> cls = CocoUnionCLI
             >>> cls.main(cmdline, **kw)
         """
+        config = cls.CLIConfig.cli(data=kw, cmdline=cmdline)
         import kwcoco
-        config = cls.CLIConfig(kw, cmdline=cmdline)
-        print('config = {}'.format(ub.urepr(dict(config), nl=1)))
+        print('config = {}'.format(ub.urepr(config, nl=1)))
 
-        if config['src'] is None:
-            raise Exception('must specify sources: {}'.format(config['src']))
+        if config.src is None:
+            raise Exception('must specify sources: {}'.format(config.src))
 
-        if len(config['src']) == 0:
+        if len(config.src) == 0:
             raise ValueError('Must provide at least one input dataset')
 
-        datasets = []
-        for fpath in ub.ProgIter(config['src'], desc='reading datasets',
-                                 verbose=1):
-            print('reading fpath = {!r}'.format(fpath))
-            dset = kwcoco.CocoDataset.coerce(fpath)
+        from kwcoco.util.util_parallel import coerce_num_workers
+        io_workers = config.io_workers
+        io_workers = coerce_num_workers(io_workers)
+        io_workers = min(io_workers, len(config.src))
+        if io_workers == 1:
+            io_workers = 0
+
+        if config.absolute:
+            postprocess = _postprocess_absolute
+        else:
+            postprocess = None
+
+        datasets = list(kwcoco.CocoDataset.coerce_multiple(
+            config.src, postprocess=postprocess, ordered=True,
+            workers=io_workers, mode='process', autobuild=False,
+        ))
+
+        print('Finished loading. Starting union.')
+        combo = kwcoco.CocoDataset.union(
+            *datasets,
+            remember_parent=config.remember_parent)
 
-            if config['absolute']:
-                dset.reroot(absolute=True)
-
-            datasets.append(dset)
-
-        combo = kwcoco.CocoDataset.union(*datasets)
-
-        out_fpath = config['dst']
+        out_fpath = config.dst
         out_dpath = ub.Path(out_fpath).parent
         if out_dpath:
             ub.ensuredir(out_dpath)
         print('Writing to out_fpath = {!r}'.format(out_fpath))
         combo.fpath = out_fpath
         dumpkw = {
             'newlines': True,
-            'compress': config['compress'],
+            'compress': config.compress,
         }
         combo.dump(combo.fpath, **dumpkw)
 
+
+def _postprocess_absolute(dset):
+    dset.reroot(absolute=True)
+
 _CLI = CocoUnionCLI
 
 if __name__ == '__main__':
     """
     CommandLine:
         python -m kwcoco.cli.coco_union
     """
```

## kwcoco/metrics/assignment.py

```diff
@@ -144,21 +144,23 @@
         4     0    -1 0.5000  1.0000 -1.0000   -1    1
         5     0     0 0.5000  0.0000  0.6061    1    0
         6    -1     0 0.0000  1.0000 -1.0000    0   -1
         7    -1     1 0.0000  0.9000 -1.0000    2   -1
 
     Example:
         >>> # xdoctest: +REQUIRES(module:pandas)
+        >>> from kwcoco.metrics.assignment import _assign_confusion_vectors
         >>> import pandas as pd
+        >>> import ubelt as ub
         >>> from kwcoco.metrics import DetectionMetrics
         >>> dmet = DetectionMetrics.demo(nimgs=1, nclasses=8,
         >>>                              nboxes=(0, 20), n_fp=20,
         >>>                              box_noise=.2, cls_noise=.3)
         >>> classes = dmet.classes
-        >>> gid = 0
+        >>> gid = ub.peek(dmet.gid_to_pred_dets)
         >>> true_dets = dmet.true_detections(gid)
         >>> pred_dets = dmet.pred_detections(gid)
         >>> y = _assign_confusion_vectors(true_dets, pred_dets,
         >>>                               classes=dmet.classes,
         >>>                               compat='all', prioritize='class')
         >>> y = pd.DataFrame(y)
         >>> print(y)  # xdoc: +IGNORE_WANT
```

## kwcoco/metrics/confusion_measures.py

```diff
@@ -883,27 +883,32 @@
 def populate_info(info):
     """
     Given raw accumulated confusion counts, populated secondary measures like
     AP, AUC, F1, MCC, etc..
     """
     info['tp_count'] = tp = np.array(info['tp_count'])
     info['fp_count'] = fp = np.array(info['fp_count'])
-    info['tn_count'] = tn = np.array(info['tn_count'])
+
+    has_tn = 'tn_count' in info
+    if has_tn:
+        info['tn_count'] = tn = np.array(info['tn_count'])
+
     info['fn_count'] = fn = np.array(info['fn_count'])
     info['thresholds'] = thresh = np.array(info['thresholds'])
 
     realpos_total = info.get('realpos_total', None)
     if realpos_total is None:
         realpos_total = info['tp_count'][-1] + info['fn_count'][-1]
         info['realpos_total'] = realpos_total
 
     realneg_total = info.get('realneg_total', None)
     if realneg_total is None:
-        realneg_total = info['tn_count'][-1] + info['fp_count'][-1]
-        info['realneg_total'] = realneg_total
+        if has_tn:
+            realneg_total = info['tn_count'][-1] + info['fp_count'][-1]
+            info['realneg_total'] = realneg_total
 
     nsupport = info.get('nsupport', None)
     if nsupport is None:
         info['nsupport'] = nsupport = realneg_total + realpos_total
 
     monotonic_ppv = info.get('monotonic_ppv', True)
     info['monotonic_ppv'] = monotonic_ppv
@@ -993,97 +998,99 @@
         debug = 0
         if debug:
             assert ub.allsame(tpr_denom), 'tpr denom should be constant'
             # tpr_denom should be equal to info['realpos_total']
             if np.any(tpr_denom != info['realpos_total']):
                 warnings.warn('realpos_total is inconsistent')
 
-        tnr_denom = (tn + fp)
-        tnr_denom[tnr_denom == 0] = 1
-        tnr = tn / tnr_denom
-
-        pnv_denom = (tn + fn)
-        pnv_denom[pnv_denom == 0] = 1
-        npv = tn / pnv_denom
+        if has_tn:
+            tnr_denom = (tn + fp)
+            tnr_denom[tnr_denom == 0] = 1
+            tnr = tn / tnr_denom
+
+            pnv_denom = (tn + fn)
+            pnv_denom[pnv_denom == 0] = 1
+            npv = tn / pnv_denom
 
         info['ppv'] = ppv
         info['tpr'] = tpr
+        ppv_mul_tpr = ppv * tpr
 
         # fpr_denom is a proxy for fp + tn as tn is generally unknown in
         # the case where all negatives are specified in the confusion
         # vectors fpr_denom will be exactly (fp + tn)
         # fpr = fp / (fp + tn)
         finite_fp = fp[np.isfinite(fp)]
         fpr_denom = finite_fp[-1] if len(finite_fp) else 0
         if fpr_denom == 0:
             fpr_denom = 1
         fpr = info['fp_count'] / fpr_denom
         info['fpr'] = fpr
 
-        info['bm'] = tpr + tnr - 1  # informedness
-        info['mk'] = ppv + npv - 1  # markedness
-
-        tp_add_tn = tp + tn
-        # info['acc'] = (tp + tn) / (tp + tn + fp + fn)
-        info['acc'] = (tp_add_tn) / (tp_add_tn + fp + fn)
-
-        # https://en.wikipedia.org/wiki/Matthews_correlation_coefficient
-        # mcc_numer = (tp * tn) - (fp * fn)
-        # mcc_denom = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
-        # mcc_denom[np.isnan(mcc_denom) | (mcc_denom == 0)] = 1
-        # info['mcc'] = mcc_numer / mcc_denom
-
-        real_pos = fn + tp  # number of real positives
-        p_denom = real_pos.copy()
-        p_denom[p_denom == 0] = 1
-        fnr = fn / p_denom  # miss-rate
-        fdr  = 1 - ppv  # false discovery rate
-        fmr  = 1 - npv  # false ommision rate (for)
-
-        ppv_mul_tpr = ppv * tpr
-
-        info['tnr'] = tnr
-        info['npv'] = npv
-        # info['mcc'] = np.sqrt(ppv * tpr * tnr * npv) - np.sqrt(fdr * fnr * fpr * fmr)
-        info['mcc'] = np.sqrt(ppv_mul_tpr * tnr * npv) - np.sqrt(fdr * fnr * fpr * fmr)
+        if has_tn:
+            info['bm'] = tpr + tnr - 1  # informedness
+            info['mk'] = ppv + npv - 1  # markedness
+
+            tp_add_tn = tp + tn
+            # info['acc'] = (tp + tn) / (tp + tn + fp + fn)
+            info['acc'] = (tp_add_tn) / (tp_add_tn + fp + fn)
+
+            # https://en.wikipedia.org/wiki/Matthews_correlation_coefficient
+            # mcc_numer = (tp * tn) - (fp * fn)
+            # mcc_denom = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
+            # mcc_denom[np.isnan(mcc_denom) | (mcc_denom == 0)] = 1
+            # info['mcc'] = mcc_numer / mcc_denom
+
+            real_pos = fn + tp  # number of real positives
+            p_denom = real_pos.copy()
+            p_denom[p_denom == 0] = 1
+            fnr = fn / p_denom  # miss-rate
+            fdr  = 1 - ppv  # false discovery rate
+            fmr  = 1 - npv  # false ommision rate (for)
+
+            info['tnr'] = tnr
+            info['npv'] = npv
+            # info['mcc'] = np.sqrt(ppv * tpr * tnr * npv) - np.sqrt(fdr * fnr * fpr * fmr)
+            info['mcc'] = np.sqrt(ppv_mul_tpr * tnr * npv) - np.sqrt(fdr * fnr * fpr * fmr)
 
         # f1_numer = (2 * ppv * tpr)
         f1_numer = (2 * ppv_mul_tpr)
         f1_denom = (ppv + tpr)
         f1_denom[f1_denom == 0] = 1
         info['f1'] =  f1_numer / f1_denom
 
         # https://erotemic.wordpress.com/2019/10/23/closed-form-of-the-mcc-when-tn-inf/
         # info['g1'] = np.sqrt(ppv * tpr)
         info['g1'] = np.sqrt(ppv_mul_tpr)
 
         keys = ['mcc', 'g1', 'f1', 'acc']
         finite_thresh = thresh[finite_flags]
         for key in keys:
-            measure = info[key][finite_flags]
-            try:
-                max_idx = np.nanargmax(measure)
-            except ValueError:
-                best_thresh = np.nan
-                best_measure = np.nan
-            else:
-                best_thresh = float(finite_thresh[max_idx])
-                best_measure = float(measure[max_idx])
-
-            best_label = '{}={:0.2f}@{:0.2f}'.format(key, best_measure, best_thresh)
-
-            # if np.isinf(best_thresh) or np.isnan(best_measure):
-            #     print('key = {!r}'.format(key))
-            #     print('finite_flags = {!r}'.format(finite_flags))
-            #     print('measure = {!r}'.format(measure))
-            #     print('best_label = {!r}'.format(best_label))
-            #     import xdev
-            #     xdev.embed()
-            info['max_{}'.format(key)] = best_label
-            info['_max_{}'.format(key)] = (best_measure, best_thresh)
+            if key in info:
+                measure = info[key][finite_flags]
+                try:
+                    max_idx = np.nanargmax(measure)
+                except ValueError:
+                    best_thresh = np.nan
+                    best_measure = np.nan
+                else:
+                    best_thresh = float(finite_thresh[max_idx])
+                    best_measure = float(measure[max_idx])
+
+                best_label = '{}={:0.2f}@{:0.2f}'.format(key, best_measure, best_thresh)
+
+                # if np.isinf(best_thresh) or np.isnan(best_measure):
+                #     print('key = {!r}'.format(key))
+                #     print('finite_flags = {!r}'.format(finite_flags))
+                #     print('measure = {!r}'.format(measure))
+                #     print('best_label = {!r}'.format(best_label))
+                #     import xdev
+                #     xdev.embed()
+                info['max_{}'.format(key)] = best_label
+                info['_max_{}'.format(key)] = (best_measure, best_thresh)
 
         import sklearn.metrics  # NOQA
         finite_trunc_fp = info['trunc_fp_count']
         finite_trunc_fp = finite_trunc_fp[np.isfinite(finite_trunc_fp)]
         trunc_fpr_denom = finite_trunc_fp[-1] if len(finite_trunc_fp) else 0
         if trunc_fpr_denom == 0:
             trunc_fpr_denom = 1
```

## kwcoco/metrics/confusion_vectors.py

```diff
@@ -214,15 +214,16 @@
         CommandLine:
             xdoctest -m kwcoco.metrics.confusion_vectors ConfusionVectors.confusion_matrix
 
         Example:
             >>> # xdoctest: +REQUIRES(module:pandas)
             >>> from kwcoco.metrics import DetectionMetrics
             >>> dmet = DetectionMetrics.demo(
-            >>>     nimgs=10, nboxes=(0, 10), n_fp=(0, 1), n_fn=(0, 1), classes=3, cls_noise=.2)
+            >>>     nimgs=10, nboxes=(0, 10), n_fp=(0, 1), n_fn=(0, 1),
+            >>>     classes=3, cls_noise=.2, newstyle=False)
             >>> cfsn_vecs = dmet.confusion_vectors()
             >>> cm = cfsn_vecs.confusion_matrix()
             ...
             >>> print(cm.to_string(float_format=lambda x: '%.2f' % x))
             pred        background  cat_1  cat_2  cat_3
             real
             background        0.00   1.00   2.00   3.00
```

## kwcoco/metrics/detect_metrics.py

```diff
@@ -14,17 +14,50 @@
 
 class DetectionMetrics(ub.NiceRepr):
     """
     Object that computes associations between detections and can convert them
     into sklearn-compatible representations for scoring.
 
     Attributes:
-        gid_to_true_dets (Dict): maps image ids to truth
-        gid_to_pred_dets (Dict): maps image ids to predictions
-        classes (kwcoco.CategoryTree): category coder
+        gid_to_true_dets (Dict[int, kwimage.Detections]):
+            maps image ids to truth
+
+        gid_to_pred_dets (Dict[int, kwimage.Detections]):
+            maps image ids to predictions
+
+        classes (kwcoco.CategoryTree | None):
+            the categories to be scored, if unspecified attempts to
+            determine these from the truth detections
+
+    Example:
+        >>> # Demo how to use detection metrics directly given detections only
+        >>> # (no kwcoco file required)
+        >>> from kwcoco.metrics import detect_metrics
+        >>> import kwimage
+        >>> # Setup random true detections (these are just boxes and scores)
+        >>> true_dets = kwimage.Detections.random(3)
+        >>> # Peek at the simple internals of a detections object
+        >>> print('true_dets.data = {}'.format(ub.urepr(true_dets.data, nl=1)))
+        >>> # Create similar but different predictions
+        >>> true_subset = true_dets.take([1, 2]).warp(kwimage.Affine.coerce({'scale': 1.1}))
+        >>> false_positive = kwimage.Detections.random(3)
+        >>> pred_dets = kwimage.Detections.concatenate([true_subset, false_positive])
+        >>> dmet = DetectionMetrics()
+        >>> dmet.add_predictions(pred_dets, imgname='image1')
+        >>> dmet.add_truth(true_dets, imgname='image1')
+        >>> # Raw confusion vectors
+        >>> cfsn_vecs = dmet.confusion_vectors()
+        >>> print(cfsn_vecs.data.pandas().to_string())
+        >>> # Our scoring definition (derived from confusion vectors)
+        >>> print(dmet.score_kwcoco())
+        >>> # VOC scoring
+        >>> print(dmet.score_voc(bias=0))
+        >>> # Original pycocotools scoring
+        >>> # xdoctest: +REQUIRES(module:pycocotools)
+        >>> print(dmet.score_pycocotools())
 
     Example:
         >>> dmet = DetectionMetrics.demo(
         >>>     nimgs=100, nboxes=(0, 3), n_fp=(0, 1), classes=8, score_noise=0.9, hacked=False)
         >>> print(dmet.score_kwcoco(bias=0, compat='mutex', prioritize='iou')['mAP'])
         ...
         >>> # NOTE: IN GENERAL NETHARN AND VOC ARE NOT THE SAME
@@ -102,16 +135,16 @@
     @classmethod
     def from_coco(DetectionMetrics, true_coco, pred_coco, gids=None, verbose=0):
         """
         Create detection metrics from two coco files representing the truth and
         predictions.
 
         Args:
-            true_coco (kwcoco.CocoDataset):
-            pred_coco (kwcoco.CocoDataset):
+            true_coco (kwcoco.CocoDataset): coco dataset with ground truth
+            pred_coco (kwcoco.CocoDataset): coco dataset with predictions
 
         Example:
             >>> import kwcoco
             >>> from kwcoco.demo.perterb import perterb_coco
             >>> true_coco = kwcoco.CocoDataset.demo('shapes')
             >>> perterbkw = dict(box_noise=0.5, cls_noise=0.5, score_noise=0.5)
             >>> pred_coco = perterb_coco(true_coco, **perterbkw)
@@ -188,14 +221,34 @@
         """ gets Detections representation for groundtruth in an image """
         return dmet.gid_to_true_dets[gid]
 
     def pred_detections(dmet, gid):
         """ gets Detections representation for predictions in an image """
         return dmet.gid_to_pred_dets[gid]
 
+    @property
+    def classes(dmet):
+        if dmet._classes is not None:
+            return dmet._classes
+        # If the detection metrics object doest have a top-level class
+        # list, then try to extract one from the ground truth.
+        # Try to grab classes from the truth if they exist
+        for dets in dmet.gid_to_true_dets.values():
+            if dets.classes is not None:
+                import kwcoco
+                classes = kwcoco.CategoryTree.coerce(dets.classes)
+                return classes
+
+    @classes.setter
+    def classes(dmet, classes):
+        import kwcoco
+        if classes is not None:
+            classes = kwcoco.CategoryTree.coerce(classes)
+        dmet._classes = classes
+
     def confusion_vectors(dmet, iou_thresh=0.5, bias=0, gids=None, compat='mutex',
                           prioritize='iou', ignore_classes='ignore',
                           background_class=ub.NoParam, verbose='auto',
                           workers=0, track_probs='try', max_dets=None):
         """
         Assigns predicted boxes to the true boxes so we can transform the
         detection problem into a classification problem for scoring.
@@ -283,38 +336,39 @@
 
         if gids is None:
             gids = sorted(dmet._imgname_to_gid.values())
 
         if verbose == 'auto':
             verbose = 1 if len(gids) > 10 else 0
 
+        classes = dmet.classes
+
         if background_class is ub.NoParam:
             # Try to autodetermine background class name,
             # otherwise fallback to None
             background_class = None
-            if dmet.classes is not None:
-                lower_classes = [c.lower() for c in dmet.classes]
+            if classes is not None:
+                lower_classes = [c.lower() for c in classes]
                 try:
                     idx = lower_classes.index('background')
-                    background_class = dmet.classes[idx]
+                    background_class = classes[idx]
                     # TODO: if we know the background class name should we
                     # change bg_cidx in assignment?
                 except ValueError:
                     pass
 
-        workers = 0
         jobs = ub.JobPool(mode='process', max_workers=workers)
         for gid in ub.ProgIter(gids, desc='submit assign jobs',
                                verbose=verbose):
             true_dets = dmet.true_detections(gid)
             pred_dets = dmet.pred_detections(gid)
             job = jobs.submit(
                 _assign_confusion_vectors, true_dets, pred_dets,
                 bg_weight=1, iou_thresh=iou_thresh_list, bg_cidx=-1, bias=bias,
-                classes=dmet.classes, compat=compat, prioritize=prioritize,
+                classes=classes, compat=compat, prioritize=prioritize,
                 ignore_classes=ignore_classes, max_dets=max_dets)
             job.gid = gid
 
         for job in ub.ProgIter(jobs.jobs, desc='assign detections',
                                verbose=verbose):
             iou_thresh_to_y = job.result()
             gid = job.gid
@@ -343,15 +397,15 @@
 
                         # For unassigned truths, we need to create dummy probs
                         # where a background class has probability 1.
                         flags = pxs > -1
                         probs = np.zeros((len(pxs), pred_probs.shape[1]),
                                          dtype=np.float32)
                         if background_class is not None:
-                            bg_idx = dmet.classes.index(background_class)
+                            bg_idx = classes.index(background_class)
                             probs[:, bg_idx] = 1
                         probs[flags] = pred_probs[pxs[flags]]
                         prob_accum.append(probs)
 
                 y['gid'] = [gid] * len(y['pred'])
                 for k, v in y.items():
                     y_accum[k].extend(v)
@@ -383,15 +437,15 @@
                 print(xdev.byte_str(nbytes))
 
             if _tracking_probs:
                 prob_accum = iou_to_probaccum[t]
                 y_prob = np.vstack(prob_accum)
             else:
                 y_prob = None
-            cfsn_vecs = ConfusionVectors(cfsn_data, classes=dmet.classes,
+            cfsn_vecs = ConfusionVectors(cfsn_data, classes=classes,
                                          probs=y_prob)
             iou_to_cfsn[t] = cfsn_vecs
 
         if ub.iterable(iou_thresh):
             return iou_to_cfsn
         else:
             cfsn_vecs = iou_to_cfsn[t]
@@ -512,15 +566,16 @@
         """
         # from . import voc_metrics
         from kwcoco.metrics.assignment import _filter_ignore_regions
         from kwcoco.metrics import voc_metrics
         if gids is None:
             gids = sorted(dmet._imgname_to_gid.values())
         # Convert true/pred detections into VOC format
-        vmet = voc_metrics.VOC_Metrics(classes=dmet.classes)
+        classes = dmet.classes
+        vmet = voc_metrics.VOC_Metrics(classes=classes)
         for gid in gids:
             true_dets = dmet.true_detections(gid)
             pred_dets = dmet.pred_detections(gid)
 
             if ignore_classes is not None:
                 true_ignore_flags, pred_ignore_flags = _filter_ignore_regions(
                     true_dets, pred_dets, ioaa_thresh=iou_thresh,
@@ -541,34 +596,35 @@
         """
         import kwcoco
         true = kwcoco.CocoDataset()
         pred = kwcoco.CocoDataset()
 
         gt_aid_to_tx = {}
         dt_aid_to_px = {}
+        classes = dmet.classes
 
-        for node in dmet.classes:
-            # cid = dmet.classes.graph.node[node]['id']
-            cid = dmet.classes.index(node)
-            supercategory = list(dmet.classes.graph.pred[node])
+        for node in classes:
+            # cid = classes.graph.node[node]['id']
+            cid = classes.index(node)
+            supercategory = list(classes.graph.pred[node])
             if len(supercategory) == 0:
                 supercategory = None
             else:
                 assert len(supercategory) == 1
                 supercategory = supercategory[0]
             true.add_category(node, id=cid, supercategory=supercategory)
             pred.add_category(node, id=cid, supercategory=supercategory)
 
         for imgname, gid in dmet._imgname_to_gid.items():
             true.add_image(imgname, id=gid)
             pred.add_image(imgname, id=gid)
 
         idx_to_id = {
-            idx: dmet.classes.index(node)
-            for idx, node in enumerate(dmet.classes.idx_to_node)
+            idx: classes.index(node)
+            for idx, node in enumerate(classes.idx_to_node)
         }
 
         for gid, pred_dets in dmet.gid_to_pred_dets.items():
             pred_boxes = pred_dets.boxes
             if 'scores' in pred_dets.data:
                 pred_scores = pred_dets.scores
             else:
@@ -692,24 +748,24 @@
                     modified_params = True
 
             print('evaler.params.iouThrs = {!r}'.format(evaler.params.iouThrs))
 
             evaler.evaluate()
             evaler.accumulate()
 
-            if 0:
-                # Get curves at a specific pycocoutils param
-                Tx = np.where(evaler.params.iouThrs == 0.5)[0]
-                Rx = slice(0, len(evaler.params.recThrs))
-                Kx = slice(0, len(evaler.params.catIds))
-                Ax = evaler.params.areaRng.index([0, 10000000000.0])
-                Mx = evaler.params.maxDets.index(100)
-                perclass_prec = evaler.eval['precision'][Tx, Rx, Kx, Ax, Mx]
-                perclass_rec = evaler.eval['recall'][Tx, Kx, Ax, Mx]
-                perclass_score = evaler.eval['scores'][Tx, Rx, Kx, Ax, Mx]
+            # if 0:
+            #     # Get curves at a specific pycocoutils param
+            #     Tx = np.where(evaler.params.iouThrs == 0.5)[0]
+            #     Rx = slice(0, len(evaler.params.recThrs))
+            #     Kx = slice(0, len(evaler.params.catIds))
+            #     Ax = evaler.params.areaRng.index([0, 10000000000.0])
+            #     Mx = evaler.params.maxDets.index(100)
+            #     perclass_prec = evaler.eval['precision'][Tx, Rx, Kx, Ax, Mx]
+            #     perclass_rec = evaler.eval['recall'][Tx, Kx, Ax, Mx]
+            #     perclass_score = evaler.eval['scores'][Tx, Rx, Kx, Ax, Mx]
 
             pct_info = {}
 
             if modified_params:
                 print('modified params')
                 stats = pct_summarize2(evaler)
                 evaler.stats = stats
@@ -776,14 +832,16 @@
                 if True, predicted classes are returned as null, which means
                 only localization scoring is suitable. Defaults to 0.
 
             with_probs (bool):
                 if True, includes per-class probabilities with predictions
                 Defaults to 1.
 
+            rng (int | None | RandomState): random seed / state
+
         CommandLine:
             xdoctest -m kwcoco.metrics.detect_metrics DetectionMetrics.demo:2 --show
 
         Example:
             >>> kwargs = {}
             >>> # Seed the RNG
             >>> kwargs['rng'] = 0
@@ -857,34 +915,47 @@
 
         # specify an amount of overlap between true and false scores
         score_noise = kwargs.get('score_noise', 0.2)
 
         anchors = kwargs.get('anchors', None)
         scale = 100.0
 
-        if kwargs.get('newstyle'):
+        # TODO: make newstyle False
+        newstyle = kwargs.get('newstyle', False)
+
+        if newstyle:
             perterbkw = ub.dict_isect(kwargs, {
                 'rng': 0,
                 'box_noise': 0,
                 'cls_noise': 0,
                 'null_pred': False,
                 'with_probs': False,
                 'score_noise': 0.2,
                 'n_fp': 0,
                 'n_fn': 0,
                 'hacked': 1})
 
             # TODO: use kwcoco.demo.perterb instead of rolling the logic here
             from kwcoco.demo import perterb
-            # TODO
+            # TODO: don't do any rendering
             # true_dset = kwcoco.CocoDataset.random()  # TODO
             true_dset = kwcoco.CocoDataset.demo('shapes{}'.format(nimgs))  # FIXME
+            # true_dset = kwcoco.CocoDataset.demo(
+            #     'vidshapes', num_frames=1, num_videos=nimgs, render=False)
             pred_dset = perterb.perterb_coco(true_dset, **perterbkw)
             dmet = cls.from_coco(true_dset, pred_dset)
         else:
+            # Unfortunately this is not ready for deprecation, the above case
+            # does not handle everything yet.
+            # ub.schedule_deprecation(
+            #     'kwcoco', 'newstyle=False', 'kwarg to DetectionMetrics.demo',
+            #     migration='adapt to newstyle=True instead',
+            #     deprecate='0.6.1', error='0.7.0', remove='0.7.1'
+            # )
+
             # Build random variables
             from kwarray import distributions
             DiscreteUniform = distributions.DiscreteUniform.seeded(rng=rng)
             def _parse_arg(key, default):
                 value = kwargs.get(key, default)
                 try:
                     low, high = value
@@ -1248,16 +1319,16 @@
         # Avoid pandas when possible
         cfsn_data = kwarray.DataFrameArray(_data)
 
         # if _tracking_probs:
         #     y_prob = np.vstack(prob_accum)
         # else:
         y_prob = None
-        cfsn_vecs = ConfusionVectors(cfsn_data, classes=dmet.classes,
-                                     probs=y_prob)
+        cfsn_vecs = ConfusionVectors(
+            cfsn_data, classes=dmet.classes, probs=y_prob)
     return cfsn_vecs
 
 
 def eval_detections_cli(**kw):
     """
     DEPRECATED USE `kwcoco eval` instead
```

## kwcoco/metrics/voc_metrics.py

```diff
@@ -66,24 +66,25 @@
         """
         Compute VOC scores for every category
 
         Example:
             >>> from kwcoco.metrics.detect_metrics import DetectionMetrics
             >>> from kwcoco.metrics.voc_metrics import *  # NOQA
             >>> dmet = DetectionMetrics.demo(
-            >>>     nimgs=1, nboxes=(0, 100), n_fp=(0, 30), n_fn=(0, 30), classes=2, score_noise=0.9)
+            >>>     nimgs=1, nboxes=(0, 100), n_fp=(0, 30), n_fn=(0, 30), classes=2, score_noise=0.9, newstyle=0)
+            >>> gid = ub.peek(dmet.gid_to_pred_dets)
             >>> self = VOC_Metrics(classes=dmet.classes)
-            >>> self.add_truth(dmet.true_detections(0), 0)
-            >>> self.add_predictions(dmet.pred_detections(0), 0)
+            >>> self.add_truth(dmet.true_detections(gid), gid)
+            >>> self.add_predictions(dmet.pred_detections(gid), gid)
             >>> voc_scores = self.score()
             >>> # xdoctest: +REQUIRES(--show)
             >>> import kwplot
             >>> kwplot.autompl()
             >>> kwplot.figure(fnum=1, doclf=True)
-            >>> voc_scores['perclass'].draw()
+            >>> voc_scores['perclass'].draw(key='pr')
 
             kwplot.figure(fnum=2)
             dmet.true_detections(0).draw(color='green', labels=None)
             dmet.pred_detections(0).draw(color='blue', labels=None)
             kwplot.autoplt().gca().set_xlim(0, 100)
             kwplot.autoplt().gca().set_ylim(0, 100)
         """
```

## Comparing `kwcoco-0.6.0.dist-info/LICENSE` & `kwcoco-0.6.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `kwcoco-0.6.0.dist-info/METADATA` & `kwcoco-0.6.1.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: kwcoco
-Version: 0.6.0
+Version: 0.6.1
 Summary: The kwcoco module and cli for image datasets
 Home-page: https://gitlab.kitware.com/computer-vision/kwcoco
 Author: Jon Crall
 Author-email: jon.crall@kitware.com
 License: Apache 2
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers
@@ -23,56 +23,62 @@
 Requires-Dist: delayed-image (>=0.2.4)
 Requires-Dist: jsonschema (>=3.2.0)
 Requires-Dist: kwarray (>=0.6.7)
 Requires-Dist: kwimage (>=0.9.12)
 Requires-Dist: packaging (>=21.3)
 Requires-Dist: parse (>=1.14.0)
 Requires-Dist: safer (>=4.4.1)
-Requires-Dist: scriptconfig (>=0.7.5)
+Requires-Dist: scriptconfig (>=0.7.7)
 Requires-Dist: sortedcontainers (>=2.3.0)
 Requires-Dist: ubelt (>=1.2.4)
 Requires-Dist: uritools (>=3.0.0)
 Requires-Dist: xarray (>=0.16.0)
 Requires-Dist: numpy (>=1.19.3) ; python_version < "3.10" and python_version >= "3.9"
 Requires-Dist: pandas (>=1.4.0) ; python_version < "3.10" and python_version >= "3.9"
 Requires-Dist: scikit-learn (>=1.0.2) ; python_version < "3.10" and python_version >= "3.9"
 Requires-Dist: scipy (>=1.8.0) ; python_version < "3.10" and python_version >= "3.9"
+Requires-Dist: psutil (>=5.7.3) ; python_version < "3.10" and python_version >= "3.9"
 Requires-Dist: numpy (>=1.21.6) ; python_version < "3.11" and python_version >= "3.10"
 Requires-Dist: pandas (>=1.3.5) ; python_version < "3.11" and python_version >= "3.10"
 Requires-Dist: scikit-learn (>=1.1.0) ; python_version < "3.11" and python_version >= "3.10"
 Requires-Dist: scipy (>=1.8.0) ; python_version < "3.11" and python_version >= "3.10"
+Requires-Dist: psutil (>=5.9.0) ; python_version < "3.11" and python_version >= "3.10"
 Requires-Dist: networkx (>=2.7) ; python_version < "3.11" and python_version >= "3.8"
 Requires-Dist: numpy (>=1.19.2) ; python_version < "3.7" and python_version >= "3.6"
 Requires-Dist: pandas (>=1.1.4) ; python_version < "3.7" and python_version >= "3.6"
 Requires-Dist: scikit-learn (>=0.24.1) ; python_version < "3.7" and python_version >= "3.6"
 Requires-Dist: scipy (>=1.5.4) ; python_version < "3.7" and python_version >= "3.6"
+Requires-Dist: psutil (>=5.0.1) ; python_version < "3.7" and python_version >= "3.6"
 Requires-Dist: networkx (<=2.5.1,>=2.2.0) ; python_version < "3.7.0" and python_version >= "3.6.0"
 Requires-Dist: networkx (>=2.6.2) ; python_version < "3.8" and python_version >= "3.7"
 Requires-Dist: numpy (>=1.19.2) ; python_version < "3.8" and python_version >= "3.7"
 Requires-Dist: pandas (>=1.2.0) ; python_version < "3.8" and python_version >= "3.7"
 Requires-Dist: scikit-learn (>=0.24.1) ; python_version < "3.8" and python_version >= "3.7"
 Requires-Dist: scipy (>=1.6.0) ; python_version < "3.8" and python_version >= "3.7"
+Requires-Dist: psutil (>=5.4.6) ; python_version < "3.8" and python_version >= "3.7"
 Requires-Dist: numpy (>=1.19.2) ; python_version < "3.9" and python_version >= "3.8"
 Requires-Dist: pandas (>=1.4.0) ; python_version < "3.9" and python_version >= "3.8"
 Requires-Dist: scikit-learn (>=1.0.2) ; python_version < "3.9" and python_version >= "3.8"
 Requires-Dist: scipy (>=1.8.0) ; python_version < "3.9" and python_version >= "3.8"
+Requires-Dist: psutil (>=5.6.3) ; python_version < "3.9" and python_version >= "3.8"
 Requires-Dist: networkx (>=2.8) ; python_version < "4.0" and python_version >= "3.11"
 Requires-Dist: numpy (>=1.23.2) ; python_version < "4.0" and python_version >= "3.11"
 Requires-Dist: pandas (>=1.5.0) ; python_version < "4.0" and python_version >= "3.11"
 Requires-Dist: scikit-learn (>=1.1.3) ; python_version < "4.0" and python_version >= "3.11"
 Requires-Dist: scipy (>=1.9.2) ; python_version < "4.0" and python_version >= "3.11"
+Requires-Dist: psutil (>=5.9.0) ; python_version < "4.0" and python_version >= "3.11"
 Provides-Extra: all
 Requires-Dist: delayed-image (>=0.2.4) ; extra == 'all'
 Requires-Dist: jsonschema (>=3.2.0) ; extra == 'all'
 Requires-Dist: kwarray (>=0.6.7) ; extra == 'all'
 Requires-Dist: kwimage (>=0.9.12) ; extra == 'all'
 Requires-Dist: packaging (>=21.3) ; extra == 'all'
 Requires-Dist: parse (>=1.14.0) ; extra == 'all'
 Requires-Dist: safer (>=4.4.1) ; extra == 'all'
-Requires-Dist: scriptconfig (>=0.7.5) ; extra == 'all'
+Requires-Dist: scriptconfig (>=0.7.7) ; extra == 'all'
 Requires-Dist: sortedcontainers (>=2.3.0) ; extra == 'all'
 Requires-Dist: ubelt (>=1.2.4) ; extra == 'all'
 Requires-Dist: uritools (>=3.0.0) ; extra == 'all'
 Requires-Dist: xarray (>=0.16.0) ; extra == 'all'
 Requires-Dist: coverage (>=5.2.1) ; extra == 'all'
 Requires-Dist: xdoctest (>=0.15.6) ; extra == 'all'
 Requires-Dist: timerit (>=0.3.0) ; extra == 'all'
@@ -88,15 +94,15 @@
 Requires-Dist: delayed-image (==0.2.4) ; extra == 'all-strict'
 Requires-Dist: jsonschema (==3.2.0) ; extra == 'all-strict'
 Requires-Dist: kwarray (==0.6.7) ; extra == 'all-strict'
 Requires-Dist: kwimage (==0.9.12) ; extra == 'all-strict'
 Requires-Dist: packaging (==21.3) ; extra == 'all-strict'
 Requires-Dist: parse (==1.14.0) ; extra == 'all-strict'
 Requires-Dist: safer (==4.4.1) ; extra == 'all-strict'
-Requires-Dist: scriptconfig (==0.7.5) ; extra == 'all-strict'
+Requires-Dist: scriptconfig (==0.7.7) ; extra == 'all-strict'
 Requires-Dist: sortedcontainers (==2.3.0) ; extra == 'all-strict'
 Requires-Dist: ubelt (==1.2.4) ; extra == 'all-strict'
 Requires-Dist: uritools (==3.0.0) ; extra == 'all-strict'
 Requires-Dist: xarray (==0.16.0) ; extra == 'all-strict'
 Requires-Dist: coverage (==5.2.1) ; extra == 'all-strict'
 Requires-Dist: xdoctest (==0.15.6) ; extra == 'all-strict'
 Requires-Dist: timerit (==0.3.0) ; extra == 'all-strict'
@@ -108,94 +114,106 @@
 Requires-Dist: lark (==1.1.2) ; extra == 'all-strict'
 Requires-Dist: lark-cython (==0.0.12) ; extra == 'all-strict'
 Requires-Dist: seaborn (==0.9.0) ; extra == 'all-strict'
 Requires-Dist: numpy (==1.19.3) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all-strict'
 Requires-Dist: pandas (==1.4.0) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all-strict'
 Requires-Dist: scikit-learn (==1.0.2) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all-strict'
 Requires-Dist: scipy (==1.8.0) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all-strict'
+Requires-Dist: psutil (==5.7.3) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all-strict'
 Requires-Dist: sqlalchemy (==1.4.0) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all-strict'
 Requires-Dist: jq (==1.2.2) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all-strict'
 Requires-Dist: numpy (==1.21.6) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'all-strict'
 Requires-Dist: pandas (==1.3.5) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'all-strict'
 Requires-Dist: scikit-learn (==1.1.0) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'all-strict'
 Requires-Dist: scipy (==1.8.0) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'all-strict'
+Requires-Dist: psutil (==5.9.0) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'all-strict'
 Requires-Dist: networkx (==2.7) ; (python_version < "3.11" and python_version >= "3.8") and extra == 'all-strict'
 Requires-Dist: jq (==1.1.3) ; (python_version < "3.5" and python_version >= "2.7") and extra == 'all-strict'
 Requires-Dist: sqlalchemy (==1.4.0) ; (python_version < "3.6" and python_version >= "3.5") and extra == 'all-strict'
 Requires-Dist: jq (==1.1.3) ; (python_version < "3.6" and python_version >= "3.5") and extra == 'all-strict'
 Requires-Dist: pytest-cov (<2.6.0,==2.0.0) ; (python_version < "3.6.0") and extra == 'all-strict'
 Requires-Dist: numpy (==1.19.2) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all-strict'
 Requires-Dist: pandas (==1.1.4) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all-strict'
 Requires-Dist: scikit-learn (==0.24.1) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all-strict'
 Requires-Dist: scipy (==1.5.4) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all-strict'
+Requires-Dist: psutil (==5.0.1) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all-strict'
 Requires-Dist: sqlalchemy (==1.4.0) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all-strict'
 Requires-Dist: jq (==1.2.2) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all-strict'
 Requires-Dist: networkx (<=2.5.1,==2.2.0) ; (python_version < "3.7.0" and python_version >= "3.6.0") and extra == 'all-strict'
 Requires-Dist: networkx (==2.6.2) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all-strict'
 Requires-Dist: numpy (==1.19.2) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all-strict'
 Requires-Dist: pandas (==1.2.0) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all-strict'
 Requires-Dist: scikit-learn (==0.24.1) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all-strict'
 Requires-Dist: scipy (==1.6.0) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all-strict'
+Requires-Dist: psutil (==5.4.6) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all-strict'
 Requires-Dist: sqlalchemy (==1.4.0) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all-strict'
 Requires-Dist: jq (==1.2.2) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all-strict'
 Requires-Dist: numpy (==1.19.2) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all-strict'
 Requires-Dist: pandas (==1.4.0) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all-strict'
 Requires-Dist: scikit-learn (==1.0.2) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all-strict'
 Requires-Dist: scipy (==1.8.0) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all-strict'
+Requires-Dist: psutil (==5.6.3) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all-strict'
 Requires-Dist: sqlalchemy (==1.4.0) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all-strict'
 Requires-Dist: jq (==1.2.2) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all-strict'
 Requires-Dist: networkx (==2.8) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all-strict'
 Requires-Dist: numpy (==1.23.2) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all-strict'
 Requires-Dist: pandas (==1.5.0) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all-strict'
 Requires-Dist: scikit-learn (==1.1.3) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all-strict'
 Requires-Dist: scipy (==1.9.2) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all-strict'
+Requires-Dist: psutil (==5.9.0) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all-strict'
 Requires-Dist: sqlalchemy (==1.4.26) ; (python_version >= "3.10") and extra == 'all-strict'
 Requires-Dist: jq (==1.2.2) ; (python_version >= "3.10") and extra == 'all-strict'
 Requires-Dist: pytest-cov (==2.12.1) ; (python_version >= "3.6.0") and extra == 'all-strict'
 Requires-Dist: ujson (==5.2.0) ; (python_version >= "3.7") and extra == 'all-strict'
 Requires-Dist: numpy (>=1.19.3) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all'
 Requires-Dist: pandas (>=1.4.0) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all'
 Requires-Dist: scikit-learn (>=1.0.2) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all'
 Requires-Dist: scipy (>=1.8.0) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all'
+Requires-Dist: psutil (>=5.7.3) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all'
 Requires-Dist: sqlalchemy (>=1.4.0) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all'
 Requires-Dist: jq (>=1.2.2) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'all'
 Requires-Dist: numpy (>=1.21.6) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'all'
 Requires-Dist: pandas (>=1.3.5) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'all'
 Requires-Dist: scikit-learn (>=1.1.0) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'all'
 Requires-Dist: scipy (>=1.8.0) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'all'
+Requires-Dist: psutil (>=5.9.0) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'all'
 Requires-Dist: networkx (>=2.7) ; (python_version < "3.11" and python_version >= "3.8") and extra == 'all'
 Requires-Dist: jq (>=1.1.3) ; (python_version < "3.5" and python_version >= "2.7") and extra == 'all'
 Requires-Dist: sqlalchemy (>=1.4.0) ; (python_version < "3.6" and python_version >= "3.5") and extra == 'all'
 Requires-Dist: jq (>=1.1.3) ; (python_version < "3.6" and python_version >= "3.5") and extra == 'all'
 Requires-Dist: pytest-cov (<2.6.0,>=2.0.0) ; (python_version < "3.6.0") and extra == 'all'
 Requires-Dist: numpy (>=1.19.2) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all'
 Requires-Dist: pandas (>=1.1.4) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all'
 Requires-Dist: scikit-learn (>=0.24.1) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all'
 Requires-Dist: scipy (>=1.5.4) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all'
+Requires-Dist: psutil (>=5.0.1) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all'
 Requires-Dist: sqlalchemy (>=1.4.0) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all'
 Requires-Dist: jq (>=1.2.2) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'all'
 Requires-Dist: networkx (<=2.5.1,>=2.2.0) ; (python_version < "3.7.0" and python_version >= "3.6.0") and extra == 'all'
 Requires-Dist: networkx (>=2.6.2) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all'
 Requires-Dist: numpy (>=1.19.2) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all'
 Requires-Dist: pandas (>=1.2.0) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all'
 Requires-Dist: scikit-learn (>=0.24.1) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all'
 Requires-Dist: scipy (>=1.6.0) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all'
+Requires-Dist: psutil (>=5.4.6) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all'
 Requires-Dist: sqlalchemy (>=1.4.0) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all'
 Requires-Dist: jq (>=1.2.2) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'all'
 Requires-Dist: numpy (>=1.19.2) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all'
 Requires-Dist: pandas (>=1.4.0) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all'
 Requires-Dist: scikit-learn (>=1.0.2) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all'
 Requires-Dist: scipy (>=1.8.0) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all'
+Requires-Dist: psutil (>=5.6.3) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all'
 Requires-Dist: sqlalchemy (>=1.4.0) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all'
 Requires-Dist: jq (>=1.2.2) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'all'
 Requires-Dist: networkx (>=2.8) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all'
 Requires-Dist: numpy (>=1.23.2) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all'
 Requires-Dist: pandas (>=1.5.0) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all'
 Requires-Dist: scikit-learn (>=1.1.3) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all'
 Requires-Dist: scipy (>=1.9.2) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all'
+Requires-Dist: psutil (>=5.9.0) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'all'
 Requires-Dist: sqlalchemy (>=1.4.26) ; (python_version >= "3.10") and extra == 'all'
 Requires-Dist: jq (>=1.2.2) ; (python_version >= "3.10") and extra == 'all'
 Requires-Dist: pytest-cov (>=2.12.1) ; (python_version >= "3.6.0") and extra == 'all'
 Requires-Dist: ujson (>=5.2.0) ; (python_version >= "3.7") and extra == 'all'
 Provides-Extra: graphics
 Provides-Extra: graphics-strict
 Requires-Dist: opencv-python (==3.4.15.55) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'graphics-strict'
@@ -300,47 +318,53 @@
 Requires-Dist: delayed-image (==0.2.4) ; extra == 'runtime-strict'
 Requires-Dist: jsonschema (==3.2.0) ; extra == 'runtime-strict'
 Requires-Dist: kwarray (==0.6.7) ; extra == 'runtime-strict'
 Requires-Dist: kwimage (==0.9.12) ; extra == 'runtime-strict'
 Requires-Dist: packaging (==21.3) ; extra == 'runtime-strict'
 Requires-Dist: parse (==1.14.0) ; extra == 'runtime-strict'
 Requires-Dist: safer (==4.4.1) ; extra == 'runtime-strict'
-Requires-Dist: scriptconfig (==0.7.5) ; extra == 'runtime-strict'
+Requires-Dist: scriptconfig (==0.7.7) ; extra == 'runtime-strict'
 Requires-Dist: sortedcontainers (==2.3.0) ; extra == 'runtime-strict'
 Requires-Dist: ubelt (==1.2.4) ; extra == 'runtime-strict'
 Requires-Dist: uritools (==3.0.0) ; extra == 'runtime-strict'
 Requires-Dist: xarray (==0.16.0) ; extra == 'runtime-strict'
 Requires-Dist: numpy (==1.19.3) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'runtime-strict'
 Requires-Dist: pandas (==1.4.0) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'runtime-strict'
 Requires-Dist: scikit-learn (==1.0.2) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'runtime-strict'
 Requires-Dist: scipy (==1.8.0) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'runtime-strict'
+Requires-Dist: psutil (==5.7.3) ; (python_version < "3.10" and python_version >= "3.9") and extra == 'runtime-strict'
 Requires-Dist: numpy (==1.21.6) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'runtime-strict'
 Requires-Dist: pandas (==1.3.5) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'runtime-strict'
 Requires-Dist: scikit-learn (==1.1.0) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'runtime-strict'
 Requires-Dist: scipy (==1.8.0) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'runtime-strict'
+Requires-Dist: psutil (==5.9.0) ; (python_version < "3.11" and python_version >= "3.10") and extra == 'runtime-strict'
 Requires-Dist: networkx (==2.7) ; (python_version < "3.11" and python_version >= "3.8") and extra == 'runtime-strict'
 Requires-Dist: numpy (==1.19.2) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'runtime-strict'
 Requires-Dist: pandas (==1.1.4) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'runtime-strict'
 Requires-Dist: scikit-learn (==0.24.1) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'runtime-strict'
 Requires-Dist: scipy (==1.5.4) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'runtime-strict'
+Requires-Dist: psutil (==5.0.1) ; (python_version < "3.7" and python_version >= "3.6") and extra == 'runtime-strict'
 Requires-Dist: networkx (<=2.5.1,==2.2.0) ; (python_version < "3.7.0" and python_version >= "3.6.0") and extra == 'runtime-strict'
 Requires-Dist: networkx (==2.6.2) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'runtime-strict'
 Requires-Dist: numpy (==1.19.2) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'runtime-strict'
 Requires-Dist: pandas (==1.2.0) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'runtime-strict'
 Requires-Dist: scikit-learn (==0.24.1) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'runtime-strict'
 Requires-Dist: scipy (==1.6.0) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'runtime-strict'
+Requires-Dist: psutil (==5.4.6) ; (python_version < "3.8" and python_version >= "3.7") and extra == 'runtime-strict'
 Requires-Dist: numpy (==1.19.2) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'runtime-strict'
 Requires-Dist: pandas (==1.4.0) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'runtime-strict'
 Requires-Dist: scikit-learn (==1.0.2) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'runtime-strict'
 Requires-Dist: scipy (==1.8.0) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'runtime-strict'
+Requires-Dist: psutil (==5.6.3) ; (python_version < "3.9" and python_version >= "3.8") and extra == 'runtime-strict'
 Requires-Dist: networkx (==2.8) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'runtime-strict'
 Requires-Dist: numpy (==1.23.2) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'runtime-strict'
 Requires-Dist: pandas (==1.5.0) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'runtime-strict'
 Requires-Dist: scikit-learn (==1.1.3) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'runtime-strict'
 Requires-Dist: scipy (==1.9.2) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'runtime-strict'
+Requires-Dist: psutil (==5.9.0) ; (python_version < "4.0" and python_version >= "3.11") and extra == 'runtime-strict'
 Provides-Extra: tests
 Requires-Dist: coverage (>=5.2.1) ; extra == 'tests'
 Requires-Dist: xdoctest (>=0.15.6) ; extra == 'tests'
 Requires-Dist: timerit (>=0.3.0) ; extra == 'tests'
 Requires-Dist: pytest (>=6.2.4) ; extra == 'tests'
 Provides-Extra: tests-strict
 Requires-Dist: coverage (==5.2.1) ; extra == 'tests-strict'
@@ -351,15 +375,15 @@
 Requires-Dist: pytest-cov (==2.12.1) ; (python_version >= "3.6.0") and extra == 'tests-strict'
 Requires-Dist: pytest-cov (<2.6.0,>=2.0.0) ; (python_version < "3.6.0") and extra == 'tests'
 Requires-Dist: pytest-cov (>=2.12.1) ; (python_version >= "3.6.0") and extra == 'tests'
 
 KWCOCO - The Kitware COCO Module
 ================================
 
-.. # TODO Get CI services running on gitlab 
+.. # TODO Get CI services running on gitlab
 
 |GitlabCIPipeline| |GitlabCICoverage| |Appveyor| |Pypi| |Downloads| |ReadTheDocs|
 
 +------------------+------------------------------------------------------+
 | Read the docs    | https://kwcoco.readthedocs.io                        |
 +------------------+------------------------------------------------------+
 | Gitlab (main)    | https://gitlab.kitware.com/computer-vision/kwcoco    |
@@ -396,42 +420,70 @@
 file itself.
 
 The main data structure in this model is largely based on the implementation in
 https://github.com/cocodataset/cocoapi It uses the same efficient core indexing
 data structures, but in our implementation the indexing can be optionally
 turned off, functions are silent by default (with the exception of long running
 processes, which optionally show progress by default). We support helper
-functions that add and remove images, categories, and annotations. 
+functions that add and remove images, categories, and annotations.
 
 We have reimplemented the object detection scoring code in the ``kwcoco.metrics``
-submodule.  
+submodule.
 
 The original ``pycocoutils`` API is exposed via the ``kwcoco.compat_dataset.COCO``
-class for drop-in replacement with existing tools that use ``pycocoutils``. 
+class for drop-in replacement with existing tools that use ``pycocoutils``.
 
 There is some support for kw18 files in the ``kwcoco.kw18`` module.
 
 Installation
 ------------
 
 The `kwcoco <https://pypi.org/project/kwcoco/>`_.  package can be installed via pip:
 
 .. code-block:: bash
 
     pip install kwcoco
 
 
+Feature Overview
+----------------
+
+At its core kwcoco's goal is to make it easy to organize, query, manipulate,
+and distribute image and video datasets. To accomplish this goal it offers
+several features.
+
+* An fast in-memory dictionary-based backend data structure with random access and indexed lookups.
+
+* An `sqlalchemy <https://www.sqlalchemy.org/>`_ backend that supports sqlite3 or postgresql (currently read-only).
+
+* Efficient random sampling of image subregions using `delayed_image <https://gitlab.kitware.com/computer-vision/delayed_image>`_.
+
+* A Command Line Interface (CLI) for manipulating / inspecting coco files using `scriptconfig <https://gitlab.kitware.com/utils/scriptconfig>`_.
+
+* Transparent coco file compression (e.g. i.e. read from / write to zipfiles)
+
+* Support for videos as lists of image frames
+
+* Support for multispectral imagery via image assets
+
+* Metrics for classification and bounding box object detection (segmentation and polygon object detection coming soon).
+
+* Toydata generation for easy CI testing and demos.
+
+* Backwards compatability with the original `cocoapi <https://github.com/cocodataset/cocoapi>`_.
+
+
 The KWCOCO CLI
 --------------
 
-After installing KWCOCO, you will also have the ``kwcoco`` command line tool. 
+After installing KWCOCO, you will also have the ``kwcoco`` command line tool.
 This uses a ``scriptconfig`` / ``argparse`` CLI interface. Running ``kwcoco
 --help`` should provide a good starting point.
 
-.. code-block:: 
+.. code-block::
 
     usage: kwcoco [-h] [--version] {stats,union,split,show,toydata,eval,conform,modify_categories,reroot,validate,subset,grab} ...
 
     The Kitware COCO CLI
 
     positional arguments:
       {stats,union,split,show,toydata,eval,conform,modify_categories,reroot,validate,subset,grab}
@@ -453,28 +505,28 @@
       -h, --help            show this help message and exit
       --version             show version number and exit (default: False)
 
 
 This should help you inspect (via stats and show), combine (via union), and
 make training splits (via split) using the command line. Also ships with
 toydata, which generates a COCO file you can use for testing. The kwcoco CLI
-has tab-complete features, but requires 
+has tab-complete features, but requires
 `enabling argcomplete <docs/source/on_autocomplete.rst>`_.
 
 
 Toy Data
 --------
 
 Don't have a dataset with you, but you still want to test out your algorithms?
 Try the KWCOCO shapes demo dataset, and generate an arbitrarily large dataset.
 
 The toydata submodule renders simple objects on a noisy background ---
 optionally with auxiliary channels --- and provides bounding boxes,
 segmentations, and keypoint annotations. The following example illustrates a
-generated toy image with and without overlaid annotations. 
+generated toy image with and without overlaid annotations.
 
 
 ..  ..image:: https://i.imgur.com/2K17R2U.png
 
 .. image:: https://i.imgur.com/Vk0zUH1.png
    :height: 100px
    :align: left
@@ -514,23 +566,23 @@
         >>> # Add data
         >>> cid = self.add_category('Cat')
         >>> gid = self.add_image('new-img.jpg')
         >>> aid = self.add_annotation(image_id=gid, category_id=cid, bbox=[0, 0, 100, 100])
 
         >>> # Remove data
         >>> self.remove_annotations([aid])
-        >>> self.remove_images([gid])  
+        >>> self.remove_images([gid])
         >>> self.remove_categories([cid])
 
         >>> # Look at data
         >>> print(ub.urepr(self.basic_stats(), nl=1))
         >>> print(ub.urepr(self.extended_stats(), nl=2))
         >>> print(ub.urepr(self.boxsize_stats(), nl=3))
         >>> print(ub.urepr(self.category_annotation_frequency()))
-        
+
 
         >>> # Inspect data
         >>> import kwplot
         >>> kwplot.autompl()
         >>> self.show_image(gid=1)
 
         >>> # Access single-item data via imgs, cats, anns
@@ -565,15 +617,15 @@
             'boxes': <Boxes(xywh,
                          array([[ 37.,   6., 230., 240.],
                                 [124.,  96.,  45.,  18.]], dtype=float32))>,
             'class_idxs': np.array([5, 3], dtype=np.int64),
             'keypoints': <PointsList(n=2) at 0x7f07eda33220>,
             'segmentations': <PolygonList(n=2) at 0x7f086365aa60>,
         }
-        
+
         >>> gids = list(self.imgs.keys())
         >>> images = self.images(gids)
         >>> print('images = {}'.format(ub.urepr(images, nl=1, sv=1)))
         images = <Images(num=3)>
 
         >>> images.lookup('file_name')
         ['astro.png', 'carl.png', 'stars.png']
@@ -602,15 +654,15 @@
 
 Dataset Spec:
 
 An informal description of the spec given in: `kwcoco/coco_schema_informal.rst <kwcoco/coco_schema_informal.rst>`_.
 
 For a formal description of the spec see the  `kwcoco/coco_schema.json <kwcoco/coco_schema.json>`_.
 
-For more information on the "warp" transforms see `warping_and_spaces <docs/source/concepts/warping_and_spaces.rst>`_. 
+For more information on the "warp" transforms see `warping_and_spaces <docs/source/concepts/warping_and_spaces.rst>`_.
 
 
 The CocoDatset API Grouped by Functinoality
 -------------------------------------------
 
 The following are grouped attribute/method names of a ``kwcoco.CocoDataset``.
 See the in-code documentation for further details.
@@ -726,15 +778,15 @@
 ----------------------------------
 
 Assuming you have programmatic access to your dataset you can easily convert to
 a coco file using process similar to the following code:
 
 .. code-block:: python
 
-    # ASSUME INPUTS 
+    # ASSUME INPUTS
     # my_classes: a list of category names
     # my_annots: a list of annotation objects with bounding boxes, images, and categories
     # my_images: a list of image files.
 
     my_images = [
         'image1.png',
         'image2.png',
@@ -845,28 +897,28 @@
 files do not need to have the same resolution. However, the channels
 within a single image currently must be unique.
 
 Because images can be in different resolutions, we need to bring up the topic
 of "KWCOCO spaces". For full info on this, see the discussion on "KWCOCO
 spaces", but briefly, there are 3 spaces that a user of kwcoco needs to be
 concerned with: (1) video space, (2) image space, and (3) asset/auxiliary
-space, and KWCOCO will want to know how. 
+space, and KWCOCO will want to know how.
 
 As a simple example, lets assume you have a dataset containing sequences of RGB
 images, corresponding infrared images, depth estimations, and optical flow
 estimations. The infrared images are stored in half-resolution of the RGB
 images, but the depth and flow data is at the same resolution as the RGB data.
 The RGB images have 3 channels the flow images have 2 channels, and depth and
 ir have 1 channel.
 
 
 If our images on disk look like:
 
 
-.. code-block:: 
+.. code-block::
 
     - video1/vid1_frame1_rgb.tif
     - video1/vid1_frame1_ir.tif
     - video1/vid1_frame1_depth.tif
     - video1/vid1_frame1_flow.tif
     - video1/vid1_frame2_rgb.tif
     - video1/vid1_frame2_ir.tif
@@ -923,15 +975,15 @@
        'depth': 'depth',
     }
 
     for video_dpath in bundle_dpath.glob('video*'):
        # Add a video and give it a name.
        vidid = dset.add_video(name=video_dpath.name)
 
-       # Parse out information that we need from the filenames. 
+       # Parse out information that we need from the filenames.
        # Lots of different ways to do this depending on the use case.
        assets = []
        for fpath in video_dpath.glob('*.tif'):
            _, frame_part, chan_part = fpath.stem.split('_')
            frame_index = int(frame_part[5:])
            assets.append({
                'frame_num': frame_index,
@@ -949,24 +1001,24 @@
 
            # Use the prefix for the image name
            name = rgbdata['fpath'].stem.split('_rgb')[0]
 
            height, width = kwimage.load_image_shape(rgbdata['fpath'])[0:2]
 
            # First add the base image. We will add this image as
-           # without a file_name because all of its data will be stored 
+           # without a file_name because all of its data will be stored
            # in its auxiliary list. We will assume all images in the
            # video are aligned, so we set `warp_img_to_vid` to be the
            # identity matrix.
            gid = dset.add_image(
                name=name, width=width, height=height,
                warp_img_to_vid=kwimage.Affine.eye().concise())
 
            # We could have constructed the auxiliary item dictionaries
-           # explicitly and added them in the previous step, but we 
+           # explicitly and added them in the previous step, but we
            # will use the CocoImage api to do this instead.
            coco_img = dset.coco_image(gid)
 
            for item in group:
                fpath = item['fpath']
                height, width = kwimage.load_image_shape(fpath)[0:2]
                file_name = os.fspath(fpath.relative_to(bundle_dpath))
@@ -985,18 +1037,18 @@
 .. code-block:: python
 
 
     # Get a coco image.
     gid = 1
     coco_img = dset.coco_image(gid)
 
-    # Tell delayed load what channels we want. We can 
+    # Tell delayed load what channels we want. We can
     # also specify which "space" we want to load it in.
     # Note: that when specifying channels from multiple asset items
-    # it is not possible to sample in the the auxiliary / asset space 
+    # it is not possible to sample in the the auxiliary / asset space
     # so only image and video are allowed there.
     delayed_img = coco_img.imdelay('fx|depth|red', space='image')
 
     # We finalize the data to load it
     imdata = delayed_img.finalize()
 
     # We can show it if we want, but it's just random data.
@@ -1069,15 +1121,15 @@
 To summarize ``kwcoco.ChannelSpec`` and ``kwcoco.FusedChannelSpec`` represent a
 set of channels or bands in an image.  A FusedChannelSpec could be as simple as
 ``red|green|blue``, or more complex like: ``red|green|blue|nir|swir16|swir22``
 and a ChannelSpec can be a collection of one or more FusedChannelSpecs
 separated by a comma.
 
 
-The home of the channel specification has moved to 
+The home of the channel specification has moved to
 `delayed_image <https://gitlab.kitware.com/computer-vision/delayed_image>`_.
 See the `delayed image channel spec docs <https://delayed-image.readthedocs.io/en/latest/delayed_image.channel_spec.html#>`_ for more details.
 
 
 Related Work
 ------------
 
@@ -1094,15 +1146,15 @@
 * https://voxel51.com/docs/fiftyone/
 
 
 
 .. [1] http://cocodataset.org/#format-data
 
 .. [2] https://github.com/nightrome/cocostuffapi/blob/master/PythonAPI/pycocotools/mask.py
-      
+
 
 .. |Pypi| image:: https://img.shields.io/pypi/v/kwcoco.svg
    :target: https://pypi.python.org/pypi/kwcoco
 
 .. |Downloads| image:: https://img.shields.io/pypi/dm/kwcoco.svg
    :target: https://pypistats.org/packages/kwcoco
```

## Comparing `kwcoco-0.6.0.dist-info/RECORD` & `kwcoco-0.6.1.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-kwcoco/__init__.py,sha256=0Jo2XDk9bccjIHSUT7DuOZE4uUlTG8yuVR74sIopU-4,21711
+kwcoco/__init__.py,sha256=PpLKkaTHdOMEYbhC00oqUcJBz_-iaFK25Tn6J5U-WFc,21711
 kwcoco/__main__.py,sha256=VP_IimX_6QlcDY0Y8iPG0Od3RVGeEN7k96vuo6KcWK0,276
 kwcoco/__main__.pyi,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
-kwcoco/_helpers.py,sha256=c0R2yhoAfW6oCH4yudDv3fFC-E-t6Gel-cdXkvfct3M,5937
+kwcoco/_helpers.py,sha256=cgKWHy1_9WqLS0ZOVxOmIx0MgSjQn_6srukyk1YRIx4,6161
 kwcoco/_helpers.pyi,sha256=2WSCjz_Q9shjKZ86cx5_hguuJS_YJRGRDOM2sCBjptw,717
 kwcoco/abstract_coco_dataset.py,sha256=um-DQBEOq9v0vUFH8fM5o_OYoe1GI2BfAwzKxDjBijU,309
 kwcoco/abstract_coco_dataset.pyi,sha256=yw-OIinDDAHh_CXYFsbTShHxnth-jVrsDyMigkmNS8s,62
 kwcoco/category_tree.py,sha256=bYwaDHdZWL-KXCjslvu6t7TxhiUP3JGGY-OE1_nrA5o,27500
 kwcoco/category_tree.pyi,sha256=J46p9dBr5VmiYCXX5SKGjD2JVIHSsH6ARxU3CFqvDmU,2442
 kwcoco/channel_spec.py,sha256=Pq-G7p9gAZBrQsTVPVLJs5bE29DUE8loDmSgRQLvfQQ,364
 kwcoco/channel_spec.pyi,sha256=-kBG0y-qCPkMPSUxBaKJOdSND-dME4owPDFSaHO40iY,104
-kwcoco/coco_dataset.py,sha256=L9z8PXsIJPoWOzgBpKtM9T906FCNf14s8u4fG8kBf7k,249462
+kwcoco/coco_dataset.py,sha256=54ExhW0sh1OClnJbJS8rvTWwzwwLLXdg2mAkzAAOwlU,255881
 kwcoco/coco_dataset.pyi,sha256=Ufxu1E0mXpZdmErOUlCd2RupTXCzSbUwOlXeVGWTMmQ,12926
-kwcoco/coco_evaluator.py,sha256=vBZRAKp44MjChg26HQC8y5VscjMrhkzhaimca0Oyepw,50068
+kwcoco/coco_evaluator.py,sha256=dB4tXl82xlOsH4tGPIBAlHba1xNKnTFwnpjGLwRIvtM,50052
 kwcoco/coco_evaluator.pyi,sha256=mvNburnxx_QU7B-EZjc7xNLnx0UNuauJ-JKb4G__sqw,2003
 kwcoco/coco_image.py,sha256=YNR549Q-RGmopClitNOvbUNlYgfFZkJ86Pr0JUBrE4o,49353
 kwcoco/coco_image.pyi,sha256=hEtZQ7sKth8xp_QIFV_DM5cynL2Xkr1hs84MhGCB-4A,3393
 kwcoco/coco_objects1d.py,sha256=0iyy8hzS4p3-1A3DvwMrRoYaVzWbiZ-IvNsOoNFItOw,26887
 kwcoco/coco_objects1d.pyi,sha256=CE3xQYRvPx2UumGypRGIFsCjD75HJEk66mcAaLmI_VA,3468
 kwcoco/coco_schema.py,sha256=gxZfMVz3XGH7JOPZzFIsZXHnGzNHsAfJM-X8VF-gDOc,11329
 kwcoco/coco_schema.pyi,sha256=BVmCKDizmsHeffS3WvfXmi-_wqKhkrgzSJMT-SX6rOc,846
@@ -29,26 +29,26 @@
 kwcoco/kpf.pyi,sha256=4Hf7mAmqCIWnKIld7Ng6BAwuC3OHCisBRUjgAsdMY1U,74
 kwcoco/kw18.py,sha256=-_T2KpOFltRP3eXt0kqfiW8QTY4AOORoIJw_sDIh4DE,13342
 kwcoco/kw18.pyi,sha256=cGcBIzQDFlsTYzCRmoVhC4LXAsGuu9hs0K1Wd1yQGJI,682
 kwcoco/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kwcoco/sensorchan_spec.py,sha256=OEi6WWnbKGMLr415BGjwXpJl8ME8J5K6xOI0q4uZFW4,402
 kwcoco/sensorchan_spec.pyi,sha256=WW3lxJX-M6IONo1fm3uSsscd1Iv52d6TjIGiSoTi5WU,325
 kwcoco/cli/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-kwcoco/cli/__main__.py,sha256=9tkNWnxmutqTlSnB0SqleHvP1bSL6CxSLA7UrZaerqs,4386
+kwcoco/cli/__main__.py,sha256=S8_NHA7EwMUwmo3ZANtI7qsHQicx12j_NCeOvtlqifw,6854
 kwcoco/cli/coco_conform.py,sha256=5zFzwNAfpc1IDhJ4zsMftM1MOSRGqMC93vb7UqLs5zo,3372
-kwcoco/cli/coco_eval.py,sha256=2vWf2orwCJMTccn8SJt2mQyoeFRDpW9IRjL43BdjFGc,5796
+kwcoco/cli/coco_eval.py,sha256=jUmTvvhMo2zJelZjXNDikwACqn626msXrX6RBs9crm8,5725
 kwcoco/cli/coco_grab.py,sha256=TDhaw4gXpJ3Z69y5zR1FFoR4rhv2jKesQUrJThTt1I8,2293
 kwcoco/cli/coco_modify_categories.py,sha256=iItumiGYFCZkSt08o3PSmbGEle8V9NgP_42cxfAcbT0,4164
 kwcoco/cli/coco_reroot.py,sha256=Cl6FOrkkOa0sYu0LLa12bJqGXqvMyZScr0VekU_KiFE,6771
-kwcoco/cli/coco_show.py,sha256=vPeZFYe2UEMl9yGRdscM_-pKK7ffctkcKY3R-_IyoMM,4654
+kwcoco/cli/coco_show.py,sha256=5Lj_EqG_JZqozRENxJIrQ9J6N2g2QVTDwTxeEFvTTjs,4680
 kwcoco/cli/coco_split.py,sha256=Y7LPgnLGzD47DC1X1ZVG3gyDK0N6mDJJjFM2zG7Rf6M,6731
 kwcoco/cli/coco_stats.py,sha256=LcPfslOTRoQTERMobYZhiQ7-8E_N2_sxblfKmg42YLM,8473
 kwcoco/cli/coco_subset.py,sha256=5L_L3fyC7j9WtP_5UtsJdwykT8oUMvme_296eGuprz4,12894
 kwcoco/cli/coco_toydata.py,sha256=ullrW9SPmFXs7EO6nt6MBESydmLpG62aXIkpMcYy6RI,4904
-kwcoco/cli/coco_union.py,sha256=ryhBSrwASlMTZyw9hdiqKMO3jm4e_U2QCYfibrr56Y0,2696
+kwcoco/cli/coco_union.py,sha256=4rvj3l25CNoNNBx7QcqmuyuZi-37t1JNZisbEa0keSw,3566
 kwcoco/cli/coco_validate.py,sha256=_3ArmqdcE1jEZH3SZB7il80bOxgWpBgwOk9LvCUoVVo,7709
 kwcoco/data/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 kwcoco/data/grab_camvid.py,sha256=f4hjW85BGJsHyLKSvwJPQ7eKbHzf-Yr6pLgi4KjOTm4,21744
 kwcoco/data/grab_cifar.py,sha256=zx6DpuwvQcfLQlOnBljZBEpXdkDrHfCMC8diZOKnM5s,5849
 kwcoco/data/grab_datasets.py,sha256=cUiIBJQAFFHuABd6-BBIerUJCZQNSpWxnUoNXsLwths,720
 kwcoco/data/grab_domainnet.py,sha256=aMI2q1XOAkQG9en2ylybIPzbBdxVn-0nKkN2BVpf6dY,6857
 kwcoco/data/grab_spacenet.py,sha256=YTuFs8pSPai2juxLmw7EgpTPe0LW1SXt7xeSsI9GSNQ,9189
@@ -68,38 +68,40 @@
 kwcoco/examples/getting_started_existing_dataset.py,sha256=x2sVovfTjaIpkp3PNa4ydvgPZt93UdmrpVVEz3WQACc,2074
 kwcoco/examples/loading_multispectral_data.py,sha256=4fwLcOUdk_0g1ZnqzA1EgNl98NT3DO56PYsmbff9ruQ,2068
 kwcoco/examples/modification_example.py,sha256=_yFRtnF_jIzXC2XT_5b6viatZ03cxumo5wy77fbbwsg,1683
 kwcoco/examples/shifting_annots.py,sha256=o-xcM_1irjyh4OQ6TvqX0hJndk162Js_V46iqASSbxs,2087
 kwcoco/examples/simple_kwcoco_torch_dataset.py,sha256=H8wNs3NUU7QT8OlzmQ0Xqq9E0HkQt7yXN549erfon3A,8961
 kwcoco/examples/vectorized_interface.py,sha256=lwlORAWZokXFye1Fg1-9xoF5EAZG7MyZGSktSv3fr-4,7896
 kwcoco/metrics/__init__.py,sha256=ePLCT1SFSyrqCXGiIcYnuB7cITfBCn0eK3sPUgUsy-8,699
-kwcoco/metrics/assignment.py,sha256=nQjcKgPlQxrTnjuzSckc0_zeQeihsT5ZFJ_dGtzu8UE,27687
+kwcoco/metrics/assignment.py,sha256=nDXo6ii9yHVyLOR8t8GNBiQLZ84bt_pel2QSQbxd0Og,27823
 kwcoco/metrics/clf_report.py,sha256=_i0m86dPl3kVQZq55OhfVlYSLTHF1UoUZ4dA_st5L4M,22260
-kwcoco/metrics/confusion_measures.py,sha256=uxrIWMFRl02LY-LD-urvDI1LucL2QwyHdFnTE24HTqM,51923
-kwcoco/metrics/confusion_vectors.py,sha256=NysDv7RbqPtqiQige1OHIL0qwAdywJnMncfLJ97Scs4,43235
-kwcoco/metrics/detect_metrics.py,sha256=iS9guWyT-nAmQ828PInXl62mv0uq98197v9_qw0M5EY,57007
+kwcoco/metrics/confusion_measures.py,sha256=fCADMo0JGE4698ZzlQLZ4SaLRoQ-POBim2RcojxNGDA,52248
+kwcoco/metrics/confusion_vectors.py,sha256=T05Wy016-fr0uX_nODFO92dq72b2e2z-oqeAK0b-IqE,43271
+kwcoco/metrics/detect_metrics.py,sha256=cc6v9j4rJagfr_NvRk7mrVouBaCPBDYFxy0L3wk_d18,60057
 kwcoco/metrics/drawing.py,sha256=8vJO7k9lJOvqB17mt5NesteKPnB6PkKM2qWHPqZ4li0,22909
 kwcoco/metrics/functional.py,sha256=88XTgisNDmUTYbuxhabGJTUXJmp-608kqxCq-_fi26M,6978
 kwcoco/metrics/sklearn_alts.py,sha256=fSCyD9MwD3cRoUWLq5n_IJ-xAhlVAZNIkBXri2xRJQc,7330
 kwcoco/metrics/util.py,sha256=ycowZjJyRIDKosxZeoNloxtfiYshuYyRMbEOS-G6YfE,77
-kwcoco/metrics/voc_metrics.py,sha256=8dl3g4Thw7FY6_afNiZUSE8tYdz5Aopkyd6LhqFLHxo,15267
+kwcoco/metrics/voc_metrics.py,sha256=5onslXrMXDWSvHRn1HBKT7AmeXs_lU_R7M5T-duoBWk,15348
 kwcoco/util/__init__.py,sha256=ckjdFBLwaEv976ou5_1235pGInUyvBKvwpdXE6biX-w,5567
 kwcoco/util/dict_like.py,sha256=izT5L6dhpdLRZ1H7ef_d96ELPgiTGoYqsgMDiFIFm3w,3765
 kwcoco/util/dict_proxy2.py,sha256=CJeauso2Nmg5jSp94zJ0u5OhaMwZaaYFMBgIz1GAr64,9344
 kwcoco/util/jsonschema_elements.py,sha256=JxM2FGvcOIsgsjPjK0UfezTHsmcqgF7JOkPHGkJlB0M,13052
 kwcoco/util/lazy_frame_backends.py,sha256=VQx6rGmyIVsQm-EIJjQ1lHZ_qWFeZ61qMU54s8_za2s,211
 kwcoco/util/util_archive.py,sha256=2AJiiYibnfIUM3WVA3UpKNLKY-U4t_Y4XH-VH8Bt0f0,10304
 kwcoco/util/util_deprecate.py,sha256=o0DDvzOTrk2WDKYdGA-jmKjG223eiLWqWNvE2ii9gAc,644
+kwcoco/util/util_eval.py,sha256=hxt7m6VrojLcTHnJtFY1DWLfpl15X3fQQSv0IFpStY8,2733
 kwcoco/util/util_futures.py,sha256=T6s8zykO4Ve1_8XSlXsDfS6ehq-ZYuY3zVPl2RL2XAc,185
 kwcoco/util/util_json.py,sha256=xP_3t6cJrFrAlmlGoUSkdrStq9m_5m_7P2bEPjBX17w,9367
 kwcoco/util/util_monkey.py,sha256=RNnW4m9dgH7O0lUlg8T2TPkd-e8kxL4lRSL1xLtZn00,3678
+kwcoco/util/util_parallel.py,sha256=XaXUuq65z-LQjc0VOAf63dEGAPDiAUNihgzPgvVdNzY,2988
 kwcoco/util/util_reroot.py,sha256=5fup37Z0MFG-A5g5ePezLg6JYQOHZLRESd_qiyepEhg,3711
 kwcoco/util/util_sklearn.py,sha256=IIsxsBAlIKnE48Ytk5AretHEf5IS65r2nZih-lXollw,5654
 kwcoco/util/util_special_json.py,sha256=ogijRKL5BgqAdCaD86LtN9hjHOlctyKLc65rzaTF6zs,4809
 kwcoco/util/util_truncate.py,sha256=9rmAKKEhN7ZTj7RdkYrOzqiza6nBkUK1AeQEuNj9XAk,2720
 kwcoco/util/delayed_ops/__init__.py,sha256=qa5XUk87V7_v90-TcLhDCBL4mJOQQaPtPP6-awoBfPk,1607
-kwcoco-0.6.0.dist-info/LICENSE,sha256=o6jcFk_bwjiPUz6vHK0Ju7RwbFp9eXMwAS2BDnwER-4,11343
-kwcoco-0.6.0.dist-info/METADATA,sha256=a0xL3ktu5UHUPLLDX5vRo0a2Vt7da_iaSPMCh9DY08g,60676
-kwcoco-0.6.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-kwcoco-0.6.0.dist-info/entry_points.txt,sha256=jB-l1KixdMXKAU4nAKhNHuptveF45EacEn1DfAPMtVY,52
-kwcoco-0.6.0.dist-info/top_level.txt,sha256=FF5fjYq6LQmz4M65lprxFeIIvSFc4sVuVqGqyrpjyjo,7
-kwcoco-0.6.0.dist-info/RECORD,,
+kwcoco-0.6.1.dist-info/LICENSE,sha256=o6jcFk_bwjiPUz6vHK0Ju7RwbFp9eXMwAS2BDnwER-4,11343
+kwcoco-0.6.1.dist-info/METADATA,sha256=j-t32-kVZ-59SWNEU9Ue1NwywOthDWpA-vxD_cjHhQ8,64330
+kwcoco-0.6.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+kwcoco-0.6.1.dist-info/entry_points.txt,sha256=jB-l1KixdMXKAU4nAKhNHuptveF45EacEn1DfAPMtVY,52
+kwcoco-0.6.1.dist-info/top_level.txt,sha256=FF5fjYq6LQmz4M65lprxFeIIvSFc4sVuVqGqyrpjyjo,7
+kwcoco-0.6.1.dist-info/RECORD,,
```


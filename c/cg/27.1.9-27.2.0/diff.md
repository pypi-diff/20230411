# Comparing `tmp/cg-27.1.9.tar.gz` & `tmp/cg-27.2.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/cg-27.1.9.tar", last modified: Tue Mar 21 08:21:35 2023, max compression
+gzip compressed data, was "dist/cg-27.2.0.tar", last modified: Tue Apr 11 10:43:38 2023, max compression
```

## Comparing `cg-27.1.9.tar` & `cg-27.2.0.tar`

### file list

```diff
@@ -1,1217 +1,1235 @@
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/
--rw-r--r--   0 runner    (1001) docker     (123)      354 2023-03-21 08:21:26.000000 cg-27.1.9/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (123)     3857 2023-03-21 08:21:35.000000 cg-27.1.9/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)     2802 2023-03-21 08:21:26.000000 cg-27.1.9/README.md
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/
--rw-r--r--   0 runner    (1001) docker     (123)       62 2023-03-21 08:21:26.000000 cg-27.1.9/cg/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/
--rw-r--r--   0 runner    (1001) docker     (123)      315 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/cgstats/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/cgstats/crud/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/crud/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    14071 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/crud/create.py
--rw-r--r--   0 runner    (1001) docker     (123)      707 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/crud/delete.py
--rw-r--r--   0 runner    (1001) docker     (123)     3849 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/crud/find.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/cgstats/db/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/cgstats/db/models/
--rw-r--r--   0 runner    (1001) docker     (123)      338 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1926 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/backup.py
--rw-r--r--   0 runner    (1001) docker     (123)      724 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/backup_tape.py
--rw-r--r--   0 runner    (1001) docker     (123)      646 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     1298 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/datasource.py
--rw-r--r--   0 runner    (1001) docker     (123)     1488 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/demux.py
--rw-r--r--   0 runner    (1001) docker     (123)      870 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/flowcell.py
--rw-r--r--   0 runner    (1001) docker     (123)      909 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/project.py
--rw-r--r--   0 runner    (1001) docker     (123)     1258 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/sample.py
--rw-r--r--   0 runner    (1001) docker     (123)     1227 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/support_params.py
--rw-r--r--   0 runner    (1001) docker     (123)     1312 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/unaligned.py
--rw-r--r--   0 runner    (1001) docker     (123)     1183 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/db/models/version.py
--rw-r--r--   0 runner    (1001) docker     (123)     9370 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/demux_sample.py
--rw-r--r--   0 runner    (1001) docker     (123)      545 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/dragen_demux_sample.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/cgstats/parsers/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/parsers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1919 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/parsers/adapter_metrics.py
--rw-r--r--   0 runner    (1001) docker     (123)    11457 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/parsers/conversion_stats.py
--rw-r--r--   0 runner    (1001) docker     (123)     5375 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/parsers/demux_stats.py
--rw-r--r--   0 runner    (1001) docker     (123)     1608 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/parsers/dragen_demultiplexing_stats.py
--rw-r--r--   0 runner    (1001) docker     (123)     2492 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/parsers/quality_metrics.py
--rw-r--r--   0 runner    (1001) docker     (123)     1068 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/parsers/run_info.py
--rw-r--r--   0 runner    (1001) docker     (123)     7557 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/cgstats/stats.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/coverage/
--rw-r--r--   0 runner    (1001) docker     (123)       27 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/coverage/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2977 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/coverage/api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/crunchy/
--rw-r--r--   0 runner    (1001) docker     (123)       56 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/crunchy/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    12884 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/crunchy/crunchy.py
--rw-r--r--   0 runner    (1001) docker     (123)     4552 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/crunchy/files.py
--rw-r--r--   0 runner    (1001) docker     (123)      910 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/crunchy/sbatch.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/demultiplex/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/demultiplex/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    12296 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/demultiplex/demultiplex_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     3180 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/demultiplex/demux_report.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/demultiplex/sample_sheet/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/demultiplex/sample_sheet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1334 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/demultiplex/sample_sheet/create.py
--rw-r--r--   0 runner    (1001) docker     (123)      983 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/demultiplex/sample_sheet/dummy_sample.py
--rw-r--r--   0 runner    (1001) docker     (123)     5181 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/demultiplex/sample_sheet/index.py
--rw-r--r--   0 runner    (1001) docker     (123)     5882 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/demultiplex/sample_sheet/novaseq_sample_sheet.py
--rw-r--r--   0 runner    (1001) docker     (123)     1839 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/demultiplex/sbatch.py
--rw-r--r--   0 runner    (1001) docker     (123)      297 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/environ.py
--rw-r--r--   0 runner    (1001) docker     (123)     1630 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/gens.py
--rw-r--r--   0 runner    (1001) docker     (123)     3426 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/gt.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/hermes/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/hermes/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2260 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/hermes/hermes_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     1009 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/hermes/models.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/housekeeper/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/housekeeper/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    16187 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/housekeeper/hk.py
--rw-r--r--   0 runner    (1001) docker     (123)      355 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/housekeeper/models.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/invoice/
--rw-r--r--   0 runner    (1001) docker     (123)       32 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/invoice/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4804 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/invoice/render.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/invoice/templates/
--rw-r--r--   0 runner    (1001) docker     (123)   113439 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/invoice/templates/KI_pool_invoice.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)    81032 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/invoice/templates/KI_sample_invoice.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)   113363 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/invoice/templates/KTH_pool_invoice.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)    80886 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/invoice/templates/KTH_sample_invoice.xlsx
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/lims/
--rw-r--r--   0 runner    (1001) docker     (123)       25 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/lims/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    16820 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/lims/api.py
--rw-r--r--   0 runner    (1001) docker     (123)     2699 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/lims/batch.py
--rw-r--r--   0 runner    (1001) docker     (123)     8241 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/lims/order.py
--rw-r--r--   0 runner    (1001) docker     (123)     3989 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/lims/samplesheet.py
--rw-r--r--   0 runner    (1001) docker     (123)     4818 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/loqus.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/madeline/
--rw-r--r--   0 runner    (1001) docker     (123)       35 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/madeline/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3219 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/madeline/api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/mip/
--rw-r--r--   0 runner    (1001) docker     (123)       23 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/mip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3550 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/mip/confighandler.py
--rw-r--r--   0 runner    (1001) docker     (123)     2211 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/mutacc_auto.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/orderform/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/orderform/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     9233 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/orderform/excel_orderform_parser.py
--rw-r--r--   0 runner    (1001) docker     (123)     3068 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/orderform/json_orderform_parser.py
--rw-r--r--   0 runner    (1001) docker     (123)     6441 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/orderform/orderform_parser.py
--rw-r--r--   0 runner    (1001) docker     (123)     2542 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/osticket.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/scout/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/scout/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2845 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/scout/scout_export.py
--rw-r--r--   0 runner    (1001) docker     (123)    11733 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/scout/scoutapi.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/slurm/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/slurm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1277 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/slurm/sbatch.py
--rw-r--r--   0 runner    (1001) docker     (123)     3586 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/slurm/slurm_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/apps/tb/
--rw-r--r--   0 runner    (1001) docker     (123)       32 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/tb/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     7973 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/tb/api.py
--rw-r--r--   0 runner    (1001) docker     (123)     1346 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/tb/models.py
--rw-r--r--   0 runner    (1001) docker     (123)     4867 2023-03-21 08:21:26.000000 cg-27.1.9/cg/apps/vogue.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/
--rw-r--r--   0 runner    (1001) docker     (123)       23 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     9858 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/add.py
--rw-r--r--   0 runner    (1001) docker     (123)     7039 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/backup.py
--rw-r--r--   0 runner    (1001) docker     (123)     3590 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/base.py
--rw-r--r--   0 runner    (1001) docker     (123)    19165 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/clean.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/compress/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/compress/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2081 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/compress/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     6665 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/compress/fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)     8457 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/compress/helpers.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/delete/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/delete/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      494 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/delete/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     4499 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/delete/case.py
--rw-r--r--   0 runner    (1001) docker     (123)     1843 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/delete/cases.py
--rw-r--r--   0 runner    (1001) docker     (123)     2567 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/delete/observations.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/deliver/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/deliver/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     6092 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/deliver/base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/demultiplex/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/demultiplex/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2825 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/demultiplex/add.py
--rw-r--r--   0 runner    (1001) docker     (123)      883 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/demultiplex/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     7354 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/demultiplex/demux.py
--rw-r--r--   0 runner    (1001) docker     (123)     2289 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/demultiplex/finish.py
--rw-r--r--   0 runner    (1001) docker     (123)     1463 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/demultiplex/report.py
--rw-r--r--   0 runner    (1001) docker     (123)     5437 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/demultiplex/sample_sheet.py
--rw-r--r--   0 runner    (1001) docker     (123)      682 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/export.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/generate/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/generate/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      307 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/generate/base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/generate/report/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/generate/report/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4475 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/generate/report/base.py
--rw-r--r--   0 runner    (1001) docker     (123)      855 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/generate/report/options.py
--rw-r--r--   0 runner    (1001) docker     (123)     4386 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/generate/report/utils.py
--rw-r--r--   0 runner    (1001) docker     (123)     8163 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/get.py
--rw-r--r--   0 runner    (1001) docker     (123)     4413 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/import_cmd.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/set/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/set/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     9695 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/set/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     2538 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/set/families.py
--rw-r--r--   0 runner    (1001) docker     (123)     4373 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/set/family.py
--rw-r--r--   0 runner    (1001) docker     (123)    14321 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/status.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/store/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/store/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     5340 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/store/fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)     1021 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/store/store.py
--rw-r--r--   0 runner    (1001) docker     (123)     3018 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/transfer.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/upload/
--rw-r--r--   0 runner    (1001) docker     (123)       57 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     5382 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     4665 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/clinical_delivery.py
--rw-r--r--   0 runner    (1001) docker     (123)     1181 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/coverage.py
--rw-r--r--   0 runner    (1001) docker     (123)     1124 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/delivery_report.py
--rw-r--r--   0 runner    (1001) docker     (123)     4077 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/fohm.py
--rw-r--r--   0 runner    (1001) docker     (123)     1443 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/genotype.py
--rw-r--r--   0 runner    (1001) docker     (123)     1898 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/gens.py
--rw-r--r--   0 runner    (1001) docker     (123)      566 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/gisaid.py
--rw-r--r--   0 runner    (1001) docker     (123)     2693 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/mutacc.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/upload/nipt/
--rw-r--r--   0 runner    (1001) docker     (123)       23 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/nipt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2888 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/nipt/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     2217 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/nipt/ftp.py
--rw-r--r--   0 runner    (1001) docker     (123)     1597 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/nipt/statina.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/upload/observations/
--rw-r--r--   0 runner    (1001) docker     (123)       63 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/observations/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2605 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/observations/observations.py
--rw-r--r--   0 runner    (1001) docker     (123)     2905 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/observations/utils.py
--rw-r--r--   0 runner    (1001) docker     (123)    10282 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/scout.py
--rw-r--r--   0 runner    (1001) docker     (123)      664 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/utils.py
--rw-r--r--   0 runner    (1001) docker     (123)     1668 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/validate.py
--rw-r--r--   0 runner    (1001) docker     (123)    11276 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/upload/vogue.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/
--rw-r--r--   0 runner    (1001) docker     (123)       18 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/balsamic/
--rw-r--r--   0 runner    (1001) docker     (123)       22 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/balsamic/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     8799 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/balsamic/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     1905 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/balsamic/options.py
--rw-r--r--   0 runner    (1001) docker     (123)      882 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/balsamic/pon.py
--rw-r--r--   0 runner    (1001) docker     (123)     1177 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/balsamic/qc.py
--rw-r--r--   0 runner    (1001) docker     (123)     1192 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/balsamic/umi.py
--rw-r--r--   0 runner    (1001) docker     (123)     1015 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/base.py
--rw-r--r--   0 runner    (1001) docker     (123)    12604 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/commands.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/fastq/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/fastq/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1669 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/fastq/base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/fluffy/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/fluffy/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4077 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/fluffy/base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/microsalt/
--rw-r--r--   0 runner    (1001) docker     (123)       22 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/microsalt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    10892 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/microsalt/base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/mip/
--rw-r--r--   0 runner    (1001) docker     (123)       22 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/mip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     6164 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/mip/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     1268 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/mip/options.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/mip_dna/
--rw-r--r--   0 runner    (1001) docker     (123)       22 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/mip_dna/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      942 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/mip_dna/base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/mip_rna/
--rw-r--r--   0 runner    (1001) docker     (123)       22 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/mip_rna/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      915 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/mip_rna/base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/mutant/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/mutant/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3351 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/mutant/base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/nextflow/
--rw-r--r--   0 runner    (1001) docker     (123)       22 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/nextflow/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1857 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/nextflow/options.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/rnafusion/
--rw-r--r--   0 runner    (1001) docker     (123)       22 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/rnafusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     9740 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/rnafusion/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     1991 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/rnafusion/options.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/cli/workflow/tower/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/tower/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      227 2023-03-21 08:21:26.000000 cg-27.1.9/cg/cli/workflow/tower/options.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/constants/
--rw-r--r--   0 runner    (1001) docker     (123)      955 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)       35 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/backup.py
--rw-r--r--   0 runner    (1001) docker     (123)      210 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/cgstats.py
--rw-r--r--   0 runner    (1001) docker     (123)     5290 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/compression.py
--rw-r--r--   0 runner    (1001) docker     (123)     4338 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/constants.py
--rw-r--r--   0 runner    (1001) docker     (123)     4239 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/delivery.py
--rw-r--r--   0 runner    (1001) docker     (123)     2352 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/demultiplexing.py
--rw-r--r--   0 runner    (1001) docker     (123)     1349 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/encryption.py
--rw-r--r--   0 runner    (1001) docker     (123)      371 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/extraction.py
--rw-r--r--   0 runner    (1001) docker     (123)     1252 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/gene_panel.py
--rw-r--r--   0 runner    (1001) docker     (123)     4766 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/housekeeper_tags.py
--rw-r--r--   0 runner    (1001) docker     (123)      194 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/indexes.py
--rw-r--r--   0 runner    (1001) docker     (123)      253 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/invoice.py
--rw-r--r--   0 runner    (1001) docker     (123)     5255 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/lims.py
--rw-r--r--   0 runner    (1001) docker     (123)      403 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/nextflow.py
--rw-r--r--   0 runner    (1001) docker     (123)       21 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/nipt.py
--rw-r--r--   0 runner    (1001) docker     (123)     2233 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/observations.py
--rw-r--r--   0 runner    (1001) docker     (123)      985 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/orderforms.py
--rw-r--r--   0 runner    (1001) docker     (123)       96 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/paths.py
--rw-r--r--   0 runner    (1001) docker     (123)      367 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/pdc.py
--rw-r--r--   0 runner    (1001) docker     (123)      159 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/pedigree.py
--rw-r--r--   0 runner    (1001) docker     (123)      930 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/priority.py
--rw-r--r--   0 runner    (1001) docker     (123)      100 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/process.py
--rw-r--r--   0 runner    (1001) docker     (123)     3460 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/report.py
--rw-r--r--   0 runner    (1001) docker     (123)      660 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/rnafusion.py
--rw-r--r--   0 runner    (1001) docker     (123)      485 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/sample_sources.py
--rw-r--r--   0 runner    (1001) docker     (123)     2239 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/scout_upload.py
--rw-r--r--   0 runner    (1001) docker     (123)     1301 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/sequencing.py
--rw-r--r--   0 runner    (1001) docker     (123)      107 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/slurm.py
--rw-r--r--   0 runner    (1001) docker     (123)      626 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/subject.py
--rw-r--r--   0 runner    (1001) docker     (123)      166 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/symbols.py
--rw-r--r--   0 runner    (1001) docker     (123)      227 2023-03-21 08:21:26.000000 cg-27.1.9/cg/constants/tb.py
--rw-r--r--   0 runner    (1001) docker     (123)     5596 2023-03-21 08:21:26.000000 cg-27.1.9/cg/exc.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/io/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/io/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      856 2023-03-21 08:21:26.000000 cg-27.1.9/cg/io/api.py
--rw-r--r--   0 runner    (1001) docker     (123)     2397 2023-03-21 08:21:26.000000 cg-27.1.9/cg/io/controller.py
--rw-r--r--   0 runner    (1001) docker     (123)      607 2023-03-21 08:21:26.000000 cg-27.1.9/cg/io/json.py
--rw-r--r--   0 runner    (1001) docker     (123)      907 2023-03-21 08:21:26.000000 cg-27.1.9/cg/io/yaml.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/
--rw-r--r--   0 runner    (1001) docker     (123)      281 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/backup/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/backup/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    18585 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/backup/backup.py
--rw-r--r--   0 runner    (1001) docker     (123)     1694 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/backup/pdc.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/clean/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/clean/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3930 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/clean/api.py
--rw-r--r--   0 runner    (1001) docker     (123)    14278 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/clean/demultiplexed_flow_cells.py
--rw-r--r--   0 runner    (1001) docker     (123)     4907 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/clean/flow_cell_run_directories.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/compress/
--rw-r--r--   0 runner    (1001) docker     (123)       34 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/compress/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    12289 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/compress/compress.py
--rw-r--r--   0 runner    (1001) docker     (123)     4947 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/compress/files.py
--rw-r--r--   0 runner    (1001) docker     (123)    13041 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/deliver.py
--rw-r--r--   0 runner    (1001) docker     (123)     8007 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/deliver_ticket.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/demultiplex/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/demultiplex/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    11086 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/demultiplex/delete_demultiplex_api.py
--rw-r--r--   0 runner    (1001) docker     (123)    15575 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/demultiplex/demux_post_processing.py
--rw-r--r--   0 runner    (1001) docker     (123)     4868 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/demultiplex/files.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/encryption/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/encryption/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    10827 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/encryption/encryption.py
--rw-r--r--   0 runner    (1001) docker     (123)    10945 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/invoice.py
--rw-r--r--   0 runner    (1001) docker     (123)     2557 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/meta.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/observations/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/observations/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     5374 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/observations/balsamic_observations_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     5242 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/observations/mip_dna_observations_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     5455 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/observations/observations_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/orders/
--rw-r--r--   0 runner    (1001) docker     (123)       27 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3547 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/api.py
--rw-r--r--   0 runner    (1001) docker     (123)      121 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/balsamic_qc_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)      107 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/balsamic_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)      122 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/balsamic_umi_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)    14999 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/case_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)     5793 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/fastq_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)      105 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/fluffy_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)     1278 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/lims.py
--rw-r--r--   0 runner    (1001) docker     (123)     5320 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/metagenome_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)     5848 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/microbial_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)      123 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/microsalt_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)      105 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/mip_dna_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)      105 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/mip_rna_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)     7471 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/pool_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)      102 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/rml_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)     1200 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/sars_cov_2_submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)     1774 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/submitter.py
--rw-r--r--   0 runner    (1001) docker     (123)     7886 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/orders/ticket_handler.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/report/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/report/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     8966 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/report/balsamic.py
--rw-r--r--   0 runner    (1001) docker     (123)      705 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/report/balsamic_umi.py
--rw-r--r--   0 runner    (1001) docker     (123)     3586 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/report/field_validators.py
--rw-r--r--   0 runner    (1001) docker     (123)     6116 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/report/mip_dna.py
--rw-r--r--   0 runner    (1001) docker     (123)    18056 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/report/report_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/report/templates/
--rw-r--r--   0 runner    (1001) docker     (123)    78958 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/report/templates/balsamic_report.html
--rw-r--r--   0 runner    (1001) docker     (123)   151463 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/report/templates/bootstrap.html
--rw-r--r--   0 runner    (1001) docker     (123)    77789 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/report/templates/mip-dna_report.html
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/rsync/
--rw-r--r--   0 runner    (1001) docker     (123)       32 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/rsync/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    11938 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/rsync/rsync_api.py
--rw-r--r--   0 runner    (1001) docker     (123)      387 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/rsync/sbatch.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/tar/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/tar/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1475 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/tar/tar.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/transfer/
--rw-r--r--   0 runner    (1001) docker     (123)      110 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/transfer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     9935 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/transfer/external_data.py
--rw-r--r--   0 runner    (1001) docker     (123)     8422 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/transfer/flowcell.py
--rw-r--r--   0 runner    (1001) docker     (123)     6282 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/transfer/lims.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/upload/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/upload/balsamic/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/balsamic/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2649 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/balsamic/balsamic.py
--rw-r--r--   0 runner    (1001) docker     (123)     2225 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/coverage.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/upload/fohm/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/fohm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    12066 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/fohm/fohm.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/upload/gisaid/
--rw-r--r--   0 runner    (1001) docker     (123)       30 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/gisaid/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      992 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/gisaid/constants.py
--rw-r--r--   0 runner    (1001) docker     (123)    13572 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/gisaid/gisaid.py
--rw-r--r--   0 runner    (1001) docker     (123)     2284 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/gisaid/models.py
--rw-r--r--   0 runner    (1001) docker     (123)     5671 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/gt.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/upload/mip/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/mip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2444 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/mip/mip_dna.py
--rw-r--r--   0 runner    (1001) docker     (123)     1777 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/mip/mip_rna.py
--rw-r--r--   0 runner    (1001) docker     (123)     7491 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/mutacc.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/upload/nipt/
--rw-r--r--   0 runner    (1001) docker     (123)       32 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/nipt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      213 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/nipt/models.py
--rw-r--r--   0 runner    (1001) docker     (123)     7591 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/nipt/nipt.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/upload/rnafusion/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/rnafusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      990 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/rnafusion/rnafusion.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/upload/scout/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/scout/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3929 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/scout/balsamic_config_builder.py
--rw-r--r--   0 runner    (1001) docker     (123)     1304 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/scout/balsamic_umi_config_builder.py
--rw-r--r--   0 runner    (1001) docker     (123)     3188 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/scout/hk_tags.py
--rw-r--r--   0 runner    (1001) docker     (123)     8799 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/scout/mip_config_builder.py
--rw-r--r--   0 runner    (1001) docker     (123)     2721 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/scout/rnafusion_config_builder.py
--rw-r--r--   0 runner    (1001) docker     (123)     7904 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/scout/scout_config_builder.py
--rw-r--r--   0 runner    (1001) docker     (123)    19466 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/scout/uploadscoutapi.py
--rw-r--r--   0 runner    (1001) docker     (123)     3065 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/upload_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     2571 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/upload/vogue.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/meta/workflow/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    19582 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)    29347 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/balsamic.py
--rw-r--r--   0 runner    (1001) docker     (123)     2613 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/balsamic_pon.py
--rw-r--r--   0 runner    (1001) docker     (123)      549 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/balsamic_qc.py
--rw-r--r--   0 runner    (1001) docker     (123)      551 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/balsamic_umi.py
--rw-r--r--   0 runner    (1001) docker     (123)    10995 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)    13270 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/fluffy.py
--rw-r--r--   0 runner    (1001) docker     (123)    18075 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/microsalt.py
--rw-r--r--   0 runner    (1001) docker     (123)    14256 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/mip.py
--rw-r--r--   0 runner    (1001) docker     (123)     2727 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/mip_dna.py
--rw-r--r--   0 runner    (1001) docker     (123)     2237 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/mip_rna.py
--rw-r--r--   0 runner    (1001) docker     (123)    10704 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/mutant.py
--rw-r--r--   0 runner    (1001) docker     (123)     9545 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/nextflow_common.py
--rw-r--r--   0 runner    (1001) docker     (123)     4469 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/prepare_fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)    11417 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/rnafusion.py
--rw-r--r--   0 runner    (1001) docker     (123)     1043 2023-03-21 08:21:26.000000 cg-27.1.9/cg/meta/workflow/tower_common.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/
--rw-r--r--   0 runner    (1001) docker     (123)      113 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)       99 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/analysis.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/balsamic/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/balsamic/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      484 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/balsamic/analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)     4840 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/balsamic/config.py
--rw-r--r--   0 runner    (1001) docker     (123)     2109 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/balsamic/metrics.py
--rw-r--r--   0 runner    (1001) docker     (123)    12684 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/cg_config.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/cgstats/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/cgstats/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      339 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/cgstats/flowcell.py
--rw-r--r--   0 runner    (1001) docker     (123)     1582 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/cgstats/stats_sample.py
--rw-r--r--   0 runner    (1001) docker     (123)     4482 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/compression_data.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/deliverables/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/deliverables/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3328 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/deliverables/metric_deliverables.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/demultiplex/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/demultiplex/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    10905 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/demultiplex/demux_results.py
--rw-r--r--   0 runner    (1001) docker     (123)     8181 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/demultiplex/flow_cell.py
--rw-r--r--   0 runner    (1001) docker     (123)     4817 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/demultiplex/run_parameters.py
--rw-r--r--   0 runner    (1001) docker     (123)      525 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/demultiplex/sbatch.py
--rw-r--r--   0 runner    (1001) docker     (123)      317 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/email.py
--rw-r--r--   0 runner    (1001) docker     (123)     2157 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/file_data.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/invoice/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/invoice/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1295 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/invoice/invoice.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/lims/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/lims/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2098 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/lims/sample.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/mip/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/mip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      362 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/mip/mip_analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)     1585 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/mip/mip_config.py
--rw-r--r--   0 runner    (1001) docker     (123)     4754 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/mip/mip_metrics_deliverables.py
--rw-r--r--   0 runner    (1001) docker     (123)     2581 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/mip/mip_sample_info.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/nextflow/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/nextflow/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1161 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/nextflow/deliverables.py
--rw-r--r--   0 runner    (1001) docker     (123)      745 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/nextflow/sample.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/observations/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/observations/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1264 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/observations/input_files.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/orders/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/orders/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      529 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/orders/constants.py
--rw-r--r--   0 runner    (1001) docker     (123)     6001 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/orders/excel_sample.py
--rw-r--r--   0 runner    (1001) docker     (123)     1008 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/orders/json_sample.py
--rw-r--r--   0 runner    (1001) docker     (123)     1245 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/orders/order.py
--rw-r--r--   0 runner    (1001) docker     (123)      838 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/orders/orderform_schema.py
--rw-r--r--   0 runner    (1001) docker     (123)     3802 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/orders/sample_base.py
--rw-r--r--   0 runner    (1001) docker     (123)     9830 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/orders/samples.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/report/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/report/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4311 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/report/metadata.py
--rw-r--r--   0 runner    (1001) docker     (123)     5173 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/report/report.py
--rw-r--r--   0 runner    (1001) docker     (123)     4396 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/report/sample.py
--rw-r--r--   0 runner    (1001) docker     (123)     3407 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/report/validators.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/rnafusion/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/rnafusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      573 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/rnafusion/rnafusion_sample.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/scout/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/scout/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4924 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/scout/scout_load_config.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/slurm/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/slurm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      640 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/slurm/sbatch.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/models/workflow/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/workflow/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      611 2023-03-21 08:21:26.000000 cg-27.1.9/cg/models/workflow/mutant.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/resources/
--rw-r--r--   0 runner    (1001) docker     (123)    25590 2023-03-21 08:21:26.000000 cg-27.1.9/cg/resources/20181012_Indices.csv
--rw-r--r--   0 runner    (1001) docker     (123)      436 2023-03-21 08:21:26.000000 cg-27.1.9/cg/resources/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1836 2023-03-21 08:21:26.000000 cg-27.1.9/cg/resources/rnafusion_bundle_filenames.csv
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/server/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    16608 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/admin.py
--rw-r--r--   0 runner    (1001) docker     (123)    15946 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/api.py
--rw-r--r--   0 runner    (1001) docker     (123)     3850 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/app.py
--rw-r--r--   0 runner    (1001) docker     (123)       48 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/auto.py
--rw-r--r--   0 runner    (1001) docker     (123)      935 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/config.py
--rw-r--r--   0 runner    (1001) docker     (123)      914 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/ext.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/server/invoices/
--rw-r--r--   0 runner    (1001) docker     (123)       29 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/invoices/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/server/invoices/templates/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/server/invoices/templates/invoices/
--rw-r--r--   0 runner    (1001) docker     (123)     4793 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/invoices/templates/invoices/index.html
--rw-r--r--   0 runner    (1001) docker     (123)     8171 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/invoices/templates/invoices/invoice.html
--rw-r--r--   0 runner    (1001) docker     (123)     2838 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/invoices/templates/invoices/layout.html
--rw-r--r--   0 runner    (1001) docker     (123)     4956 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/invoices/templates/invoices/new.html
--rw-r--r--   0 runner    (1001) docker     (123)     7418 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/invoices/views.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/server/templates/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/server/templates/admin/
--rw-r--r--   0 runner    (1001) docker     (123)      354 2023-03-21 08:21:26.000000 cg-27.1.9/cg/server/templates/admin/index.html
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/store/
--rw-r--r--   0 runner    (1001) docker     (123)       23 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/store/api/
--rw-r--r--   0 runner    (1001) docker     (123)       37 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/api/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    10586 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/api/add.py
--rw-r--r--   0 runner    (1001) docker     (123)     3235 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/api/base.py
--rw-r--r--   0 runner    (1001) docker     (123)      771 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/api/core.py
--rw-r--r--   0 runner    (1001) docker     (123)     1249 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/api/delete.py
--rw-r--r--   0 runner    (1001) docker     (123)     8756 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/api/find_basic_data.py
--rw-r--r--   0 runner    (1001) docker     (123)    22402 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/api/find_business_data.py
--rw-r--r--   0 runner    (1001) docker     (123)    12722 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/api/import_func.py
--rw-r--r--   0 runner    (1001) docker     (123)     1500 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/api/models.py
--rw-r--r--   0 runner    (1001) docker     (123)    39270 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/api/status.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/store/filters/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3868 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_analysis_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     2540 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_application_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     1122 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_bed_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)      947 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_bed_version_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     4605 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_case_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     1720 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_case_sample_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)      929 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_collaboration_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)      904 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_customer_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     1847 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_flow_cell_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     1293 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_invoice_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)      876 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_organism_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)      807 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_panel_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     3963 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_pool_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     7350 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_sample_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)      755 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/filters/status_user_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)    27621 2023-03-21 08:21:26.000000 cg-27.1.9/cg/store/models.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/utils/
--rw-r--r--   0 runner    (1001) docker     (123)       30 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/utils/checksum/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/checksum/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1579 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/checksum/checksum.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/utils/click/
--rw-r--r--   0 runner    (1001) docker     (123)     2056 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/click/EnumChoice.py
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/click/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4688 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/commands.py
--rw-r--r--   0 runner    (1001) docker     (123)     2250 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/date.py
--rw-r--r--   0 runner    (1001) docker     (123)      666 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/dict.py
--rw-r--r--   0 runner    (1001) docker     (123)     1251 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/email.py
--rw-r--r--   0 runner    (1001) docker     (123)      315 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/enums.py
--rw-r--r--   0 runner    (1001) docker     (123)       51 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/files.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg/utils/flask/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/flask/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1138 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/flask/enum.py
--rw-r--r--   0 runner    (1001) docker     (123)      289 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/time.py
--rw-r--r--   0 runner    (1001) docker     (123)      888 2023-03-21 08:21:26.000000 cg-27.1.9/cg/utils/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/cg.egg-info/
--rw-r--r--   0 runner    (1001) docker     (123)     3857 2023-03-21 08:21:35.000000 cg-27.1.9/cg.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)    38454 2023-03-21 08:21:35.000000 cg-27.1.9/cg.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-03-21 08:21:35.000000 cg-27.1.9/cg.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (123)       36 2023-03-21 08:21:35.000000 cg-27.1.9/cg.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-03-21 08:21:35.000000 cg-27.1.9/cg.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (123)      491 2023-03-21 08:21:35.000000 cg-27.1.9/cg.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (123)        3 2023-03-21 08:21:35.000000 cg-27.1.9/cg.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (123)      147 2023-03-21 08:21:26.000000 cg-27.1.9/pyproject.toml
--rw-r--r--   0 runner    (1001) docker     (123)      916 2023-03-21 08:21:26.000000 cg-27.1.9/requirements.txt
--rw-r--r--   0 runner    (1001) docker     (123)       38 2023-03-21 08:21:35.000000 cg-27.1.9/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (123)     2076 2023-03-21 08:21:26.000000 cg-27.1.9/setup.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/cgstats/
--rw-r--r--   0 runner    (1001) docker     (123)     5981 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/cgstats/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/cgstats/crud/
--rw-r--r--   0 runner    (1001) docker     (123)      805 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/cgstats/crud/test_create_novaseq.py
--rw-r--r--   0 runner    (1001) docker     (123)      753 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/cgstats/crud/test_delete.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/cgstats/parsers/
--rw-r--r--   0 runner    (1001) docker     (123)      475 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/cgstats/parsers/test_adapter_metrics.py
--rw-r--r--   0 runner    (1001) docker     (123)      595 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/cgstats/parsers/test_conversion_stats.py
--rw-r--r--   0 runner    (1001) docker     (123)      585 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/cgstats/parsers/test_demux_stats.py
--rw-r--r--   0 runner    (1001) docker     (123)      475 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/cgstats/parsers/test_quality_metrics.py
--rw-r--r--   0 runner    (1001) docker     (123)      913 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/cgstats/parsers/test_run_info.py
--rw-r--r--   0 runner    (1001) docker     (123)     4372 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/cgstats/test_cgstats_create.py
--rw-r--r--   0 runner    (1001) docker     (123)     1229 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/cgstats/test_stats.py
--rw-r--r--   0 runner    (1001) docker     (123)     1184 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/coverage/
--rw-r--r--   0 runner    (1001) docker     (123)      309 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/coverage/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     6211 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/coverage/test_coverage.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/crunchy/
--rw-r--r--   0 runner    (1001) docker     (123)     3058 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/crunchy/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     5469 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/crunchy/test_compress_fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)     2274 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/crunchy/test_config.py
--rw-r--r--   0 runner    (1001) docker     (123)    14590 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/crunchy/test_crunchy.py
--rw-r--r--   0 runner    (1001) docker     (123)     9107 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/crunchy/test_spring_decompression.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/demultiplex/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/demultiplex/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     5867 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/demultiplex/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     1518 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/demultiplex/test_convert_to_sample_sheet.py
--rw-r--r--   0 runner    (1001) docker     (123)     1323 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/demultiplex/test_demultiplex_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     2061 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/demultiplex/test_parse_run_parameters.py
--rw-r--r--   0 runner    (1001) docker     (123)     1743 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/demultiplex/test_sample_sheet.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/gens/
--rw-r--r--   0 runner    (1001) docker     (123)       66 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/gens/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     1740 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/gens/test_gens_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/gt/
--rw-r--r--   0 runner    (1001) docker     (123)     2060 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/gt/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     4276 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/gt/test_gt_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/hk/
--rw-r--r--   0 runner    (1001) docker     (123)     1955 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/hk/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)      680 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/hk/test__getattr__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1598 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/hk/test_add_file.py
--rw-r--r--   0 runner    (1001) docker     (123)     3529 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/hk/test_bundles.py
--rw-r--r--   0 runner    (1001) docker     (123)      871 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/hk/test_core.py
--rw-r--r--   0 runner    (1001) docker     (123)    21809 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/hk/test_file.py
--rw-r--r--   0 runner    (1001) docker     (123)     5884 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/hk/test_version.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/lims/
--rw-r--r--   0 runner    (1001) docker     (123)      920 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/lims/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     6263 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/lims/test_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/loqus/
--rw-r--r--   0 runner    (1001) docker     (123)     9785 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/loqus/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     8994 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/loqus/test_loqusdb_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/madeline/
--rw-r--r--   0 runner    (1001) docker     (123)     3010 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/madeline/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     4653 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/madeline/test_madeline.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/mip/
--rw-r--r--   0 runner    (1001) docker     (123)     5200 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/mip/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     2487 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/mip/test_config_mip.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/mutacc_auto/
--rw-r--r--   0 runner    (1001) docker     (123)      882 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/mutacc_auto/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     2472 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/mutacc_auto/test_mutacc_auto.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/orderform/
--rw-r--r--   0 runner    (1001) docker     (123)    11900 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/orderform/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     8899 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/orderform/test_excel_orderform_parser.py
--rw-r--r--   0 runner    (1001) docker     (123)     4368 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/orderform/test_excel_sample_schema.py
--rw-r--r--   0 runner    (1001) docker     (123)     1032 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/orderform/test_json_orderform_parser.py
--rw-r--r--   0 runner    (1001) docker     (123)     2474 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/orderform/test_orderform_parser.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/scout/
--rw-r--r--   0 runner    (1001) docker     (123)     4005 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/scout/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     2269 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/scout/test_get_causative_variants.py
--rw-r--r--   0 runner    (1001) docker     (123)     1376 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/scout/test_get_scout_cases.py
--rw-r--r--   0 runner    (1001) docker     (123)     1725 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/scout/test_scout_load_config.py
--rw-r--r--   0 runner    (1001) docker     (123)     3447 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/scout/test_scout_models.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/slurm/
--rw-r--r--   0 runner    (1001) docker     (123)     1242 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/slurm/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     4412 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/slurm/test_slurm_api.py
--rw-r--r--   0 runner    (1001) docker     (123)      831 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/test_apps_environ.py
--rw-r--r--   0 runner    (1001) docker     (123)      957 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/test_osticket.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/apps/vogue/
--rw-r--r--   0 runner    (1001) docker     (123)      988 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/vogue/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     6421 2023-03-21 08:21:26.000000 cg-27.1.9/tests/apps/vogue/test_vogue_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/add/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/add/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1072 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/add/test_cli_add.py
--rw-r--r--   0 runner    (1001) docker     (123)     2456 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/add/test_cli_add_customer.py
--rw-r--r--   0 runner    (1001) docker     (123)     6627 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/add/test_cli_add_family.py
--rw-r--r--   0 runner    (1001) docker     (123)     7329 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/add/test_cli_add_relationship.py
--rw-r--r--   0 runner    (1001) docker     (123)     7546 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/add/test_cli_add_sample.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/backup/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/backup/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      768 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/backup/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     2925 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/backup/test_backup_command.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/clean/
--rw-r--r--   0 runner    (1001) docker     (123)     6099 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/clean/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     5432 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/clean/test_balsamic_clean.py
--rw-r--r--   0 runner    (1001) docker     (123)     1829 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/clean/test_clean_hk_bundle_files.py
--rw-r--r--   0 runner    (1001) docker     (123)     2073 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/clean/test_hk_bundle_files.py
--rw-r--r--   0 runner    (1001) docker     (123)     4597 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/clean/test_hk_case_bundle_files.py
--rw-r--r--   0 runner    (1001) docker     (123)     3558 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/clean/test_microbial_clean.py
--rw-r--r--   0 runner    (1001) docker     (123)     1881 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/clean/test_rsync_past_run_dirs.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/compress/
--rw-r--r--   0 runner    (1001) docker     (123)    10804 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/compress/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     6885 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/compress/test_cli_compress_fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)     1495 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/compress/test_cli_decompress_spring.py
--rw-r--r--   0 runner    (1001) docker     (123)     5243 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/compress/test_compress_helpers.py
--rw-r--r--   0 runner    (1001) docker     (123)     1238 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/compress/test_store_fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)     5671 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/delete/
--rw-r--r--   0 runner    (1001) docker     (123)    11850 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/delete/test_case.py
--rw-r--r--   0 runner    (1001) docker     (123)     1839 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/delete/test_cases.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/deliver/
--rw-r--r--   0 runner    (1001) docker     (123)     4125 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/deliver/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     3659 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/deliver/test_deliver_base.py
--rw-r--r--   0 runner    (1001) docker     (123)     1165 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/deliver/test_rsync_base.py
--rw-r--r--   0 runner    (1001) docker     (123)     8426 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/deliver/test_run_deliver_cmd.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/demultiplex/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/demultiplex/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    11711 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/demultiplex/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     1214 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/demultiplex/test_add_flowcell.py
--rw-r--r--   0 runner    (1001) docker     (123)     3802 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/demultiplex/test_create_sample_sheet.py
--rw-r--r--   0 runner    (1001) docker     (123)    11252 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/demultiplex/test_demultiplex_flowcell.py
--rw-r--r--   0 runner    (1001) docker     (123)     4163 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/demultiplex/test_finish_demux.py
--rw-r--r--   0 runner    (1001) docker     (123)     1475 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/demultiplex/test_stats_command.py
--rw-r--r--   0 runner    (1001) docker     (123)     2992 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/demultiplex/test_validate_sample_sheet.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/generate/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/generate/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/generate/report/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/generate/report/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1716 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/generate/report/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     2148 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/generate/report/test_cli_delivery_report.py
--rw-r--r--   0 runner    (1001) docker     (123)     2767 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/generate/report/test_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)      564 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/generate/test_cli_base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/get/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/get/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      857 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/get/test_cli_get.py
--rw-r--r--   0 runner    (1001) docker     (123)     1515 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/get/test_cli_get_analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)     1240 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/get/test_cli_get_case.py
--rw-r--r--   0 runner    (1001) docker     (123)     6217 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/get/test_cli_get_flow_cell.py
--rw-r--r--   0 runner    (1001) docker     (123)     8796 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/get/test_cli_get_sample.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/set/
--rw-r--r--   0 runner    (1001) docker     (123)     1363 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/set/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     1213 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/set/test_families.py
--rw-r--r--   0 runner    (1001) docker     (123)     6665 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/set/test_family.py
--rw-r--r--   0 runner    (1001) docker     (123)     1918 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/set/test_flowcell.py
--rw-r--r--   0 runner    (1001) docker     (123)     1744 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/set/test_list_keys.py
--rw-r--r--   0 runner    (1001) docker     (123)    12280 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/set/test_sample.py
--rw-r--r--   0 runner    (1001) docker     (123)     6087 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/set/test_samples.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/store/
--rw-r--r--   0 runner    (1001) docker     (123)     6918 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/store/test_fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)     2359 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/test_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      513 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/test_clean.py
--rw-r--r--   0 runner    (1001) docker     (123)     2195 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/test_cli_status_cases.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/tests/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/tests/fixtures/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/tests/fixtures/data/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/tests/fixtures/data/fastq.fastq.gz
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/upload/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    12178 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     2295 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_scout.py
--rw-r--r--   0 runner    (1001) docker     (123)     1844 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload.py
--rw-r--r--   0 runner    (1001) docker     (123)      935 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload_auto.py
--rw-r--r--   0 runner    (1001) docker     (123)     1472 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload_delivery_report.py
--rw-r--r--   0 runner    (1001) docker     (123)      889 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload_fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)     1156 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload_genotype.py
--rw-r--r--   0 runner    (1001) docker     (123)      683 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload_gens.py
--rw-r--r--   0 runner    (1001) docker     (123)     8408 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload_nipt.py
--rw-r--r--   0 runner    (1001) docker     (123)     4686 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload_nipt_ftp.py
--rw-r--r--   0 runner    (1001) docker     (123)     1839 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload_nipt_statina.py
--rw-r--r--   0 runner    (1001) docker     (123)     5913 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload_observations.py
--rw-r--r--   0 runner    (1001) docker     (123)     3107 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/upload/test_cli_upload_vogue.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/workflow/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/workflow/balsamic/
--rw-r--r--   0 runner    (1001) docker     (123)    30975 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/balsamic/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)    15350 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/balsamic/test_cli_balsamic_config_case.py
--rw-r--r--   0 runner    (1001) docker     (123)     7468 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/balsamic/test_compound_commands.py
--rw-r--r--   0 runner    (1001) docker     (123)     2330 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/balsamic/test_link.py
--rw-r--r--   0 runner    (1001) docker     (123)     3525 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/balsamic/test_report_deliver.py
--rw-r--r--   0 runner    (1001) docker     (123)     6340 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/balsamic/test_run.py
--rw-r--r--   0 runner    (1001) docker     (123)     6936 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/balsamic/test_store_housekeeper.py
--rw-r--r--   0 runner    (1001) docker     (123)     7941 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/workflow/fastq/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/fastq/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1656 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/fastq/test_fastq_base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/workflow/fluffy/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/fluffy/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4918 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/fluffy/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     3908 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/fluffy/test_cli_create_samplesheet.py
--rw-r--r--   0 runner    (1001) docker     (123)     3242 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/fluffy/test_cli_link.py
--rw-r--r--   0 runner    (1001) docker     (123)     1895 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/fluffy/test_cli_run.py
--rw-r--r--   0 runner    (1001) docker     (123)     2952 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/fluffy/test_cli_start.py
--rw-r--r--   0 runner    (1001) docker     (123)     7741 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/fluffy/test_cli_store.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/workflow/microsalt/
--rw-r--r--   0 runner    (1001) docker     (123)     2976 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/microsalt/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/workflow/microsalt/snapshots/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/microsalt/snapshots/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1451 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/microsalt/snapshots/snap_test_microsalt_case_config.py
--rw-r--r--   0 runner    (1001) docker     (123)     7251 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/microsalt/test_microsalt_case_config.py
--rw-r--r--   0 runner    (1001) docker     (123)      992 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/microsalt/test_microsalt_run.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/workflow/mip/
--rw-r--r--   0 runner    (1001) docker     (123)     6940 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     6997 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_base.py
--rw-r--r--   0 runner    (1001) docker     (123)     1540 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_dna_config_case.py
--rw-r--r--   0 runner    (1001) docker     (123)      430 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_dna_link.py
--rw-r--r--   0 runner    (1001) docker     (123)      450 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_dna_panel.py
--rw-r--r--   0 runner    (1001) docker     (123)     3691 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_dna_run.py
--rw-r--r--   0 runner    (1001) docker     (123)     3885 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_dna_start.py
--rw-r--r--   0 runner    (1001) docker     (123)     1003 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_rna_config_case.py
--rw-r--r--   0 runner    (1001) docker     (123)      526 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_rna_link.py
--rw-r--r--   0 runner    (1001) docker     (123)      713 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_rna_run.py
--rw-r--r--   0 runner    (1001) docker     (123)     8446 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_store.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/cli/workflow/rnafusion/
--rw-r--r--   0 runner    (1001) docker     (123)     8555 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/rnafusion/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     7809 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/rnafusion/test_cli_rnafusion_compound_commands.py
--rw-r--r--   0 runner    (1001) docker     (123)     4346 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/rnafusion/test_cli_rnafusion_config_case.py
--rw-r--r--   0 runner    (1001) docker     (123)     2873 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/rnafusion/test_cli_rnafusion_report_deliver.py
--rw-r--r--   0 runner    (1001) docker     (123)     5060 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/rnafusion/test_cli_rnafusion_run.py
--rw-r--r--   0 runner    (1001) docker     (123)     8366 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/rnafusion/test_cli_rnafusion_store_housekeeper.py
--rw-r--r--   0 runner    (1001) docker     (123)      836 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/test_cli_workflow.py
--rw-r--r--   0 runner    (1001) docker     (123)     4310 2023-03-21 08:21:26.000000 cg-27.1.9/tests/cli/workflow/test_cli_workflow_clean.py
--rw-r--r--   0 runner    (1001) docker     (123)    57730 2023-03-21 08:21:26.000000 cg-27.1.9/tests/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/DEMUX/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/Sample_ADM1136A3_XTC08/
--rw-r--r--   0 runner    (1001) docker     (123)        4 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/Sample_ADM1136A3_XTC08/ADM1136A3_XTC08_AGTGGTCA_L001_R1_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/Sample_ADM1136A3_XTC08/ADM1136A3_XTC08_AGTGGTCA_L001_R2_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/Sample_ADM1136A3_XTC08/ADM1136A3_XTC08_AGTGGTCA_L002_R1_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/Sample_ADM1136A3_XTC08/ADM1136A3_XTC08_AGTGGTCA_L002_R2_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)     6666 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/runParameters.xml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/analysis/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/analysis/balsamic/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/analysis/balsamic/tn_wgs/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/balsamic/tn_wgs/adm1.cram
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/balsamic/tn_wgs/ascat.output.pdf
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/balsamic/tn_wgs/snv.vcf
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/balsamic/tn_wgs/sv.vcf
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/analysis/microsalt/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/analysis/microsalt/ACC11111_qc_fail/
--rw-r--r--   0 runner    (1001) docker     (123)    14644 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/microsalt/ACC11111_qc_fail/ACC11111_qc_fail.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/analysis/microsalt/ACC22222_qc_pass/
--rw-r--r--   0 runner    (1001) docker     (123)    15713 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/microsalt/ACC22222_qc_pass/ACC22222_qc_pass.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/analysis/mip/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/ADM1.baf.bed.gz
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/ADM1.cov.bed.gz
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/ADM2.cram
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/ADM3.cram
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/adm1.cram
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/adm1.mt.bam
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/multiqc.html
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/report.pdf
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/smn.vcf
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/snv.vcf
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/snv_research.vcf
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/str.vcf
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/sv.vcf
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/sv_research.vcf
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/mip/dna/vcf2cytosure.txt
--rw-r--r--   0 runner    (1001) docker     (123)     2873 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/analysis/sample_coverage.bed
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/balsamic/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/balsamic/case/
--rw-r--r--   0 runner    (1001) docker     (123)     9948 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/balsamic/case/config.json
--rw-r--r--   0 runner    (1001) docker     (123)     3465 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/balsamic/case/metadata.yml
--rw-r--r--   0 runner    (1001) docker     (123)       63 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/balsamic/case/metadata_directory.yml
--rw-r--r--   0 runner    (1001) docker     (123)      165 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/balsamic/case/metadata_file_tags.yml
--rw-r--r--   0 runner    (1001) docker     (123)     2338 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/balsamic/case/metrics_deliverables.yaml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/crunchy/
--rw-r--r--   0 runner    (1001) docker     (123)      692 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/crunchy/spring_metadata.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/201203_A00689_0200_AHVKJCDRXX/
--rw-r--r--   0 runner    (1001) docker     (123)     6666 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml
--rw-r--r--   0 runner    (1001) docker     (123)    53877 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/201203_A00689_0200_AHVKJCDRXX/SampleSheet.csv
--rw-r--r--   0 runner    (1001) docker     (123)     1076 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/SampleSheetS2_Bcl2Fastq.csv
--rw-r--r--   0 runner    (1001) docker     (123)     1084 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/SampleSheetS2_Dragen.csv
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/
--rw-r--r--   0 runner    (1001) docker     (123)     1757 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Project_150392/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Project_150392/Sample_ACC7769A10/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Project_150392/Sample_ACC7769A10/HN3FKDSXY_AL-P-00425491-N-03103120-KH20210330-PN20210331_S1_L001_R1_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Project_150392/Sample_ACC7769A10/HN3FKDSXY_AL-P-00425491-N-03103120-KH20210330-PN20210331_S1_L001_R2_001.fastq.gz
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/
--rw-r--r--   0 runner    (1001) docker     (123)     6034 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/ConversionStats.xml
--rw-r--r--   0 runner    (1001) docker     (123)     1172 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/DemultiplexingStats.xml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/Reports/
--rw-r--r--   0 runner    (1001) docker     (123)      315 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/Reports/Adapter_Metrics.csv
--rw-r--r--   0 runner    (1001) docker     (123)      434 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/Reports/Quality_Metrics.csv
--rw-r--r--   0 runner    (1001) docker     (123)     8624 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/Reports/RunInfo.xml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/
--rw-r--r--   0 runner    (1001) docker     (123)       43 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/dummy_run_R1_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)       67 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/dummy_run_R1_001.fastq.gz.md5
--rw-r--r--   0 runner    (1001) docker     (123)   338370 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/fastq_run_R1_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)       67 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/fastq_run_R1_001.fastq.gz.md5
--rw-r--r--   0 runner    (1001) docker     (123)   338349 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/fastq_run_R2_001.fastq.gz
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/150392/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/150392/ACC7769A10/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/150392/ACC7769A10/AL-P-00425491-N-03103120-KH20210330-PN20210331_S1_L001_R1_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/150392/ACC7769A10/AL-P-00425491-N-03103120-KH20210330-PN20210331_S1_L001_R2_001.fastq.gz
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/
--rw-r--r--   0 runner    (1001) docker     (123)     4439 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/ConversionStats.xml
--rw-r--r--   0 runner    (1001) docker     (123)     1172 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/DemultiplexingStats.xml
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Undetermined_S0_L001_R1_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Undetermined_S0_L001_R2_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Undetermined_S0_L002_R1_001.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Undetermined_S0_L002_R2_001.fastq.gz
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/CopyComplete.txt
--rw-r--r--   0 runner    (1001) docker     (123)     1757 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/RTAComplete.txt
--rw-r--r--   0 runner    (1001) docker     (123)     6666 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml
--rw-r--r--   0 runner    (1001) docker     (123)      324 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/SampleSheet.csv
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/copycomplete.txt
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/demuxstarted.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/CopyComplete.txt
--rw-r--r--   0 runner    (1001) docker     (123)      509 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/HLG5GDRXY_demultiplex.stderr
--rw-r--r--   0 runner    (1001) docker     (123)     2229 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/HLG5GDRXY_demultiplex.stdout
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/RTAComplete.txt
--rw-r--r--   0 runner    (1001) docker     (123)     6665 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/RunParameters.xml
--rw-r--r--   0 runner    (1001) docker     (123)      407 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/SampleSheet.csv
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/demuxstarted.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/CopyComplete.txt
--rw-r--r--   0 runner    (1001) docker     (123)     1757 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/RTAComplete.txt
--rw-r--r--   0 runner    (1001) docker     (123)     6666 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml
--rw-r--r--   0 runner    (1001) docker     (123)      324 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/SampleSheet.csv
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/demuxstarted.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/CopyComplete.txt
--rw-r--r--   0 runner    (1001) docker     (123)     1757 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/RTAComplete.txt
--rw-r--r--   0 runner    (1001) docker     (123)     6666 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml
--rw-r--r--   0 runner    (1001) docker     (123)      332 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/SampleSheet.csv
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/demuxstarted.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/hiseq_run/
--rw-r--r--   0 runner    (1001) docker     (123)     5367 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/hiseq_run/runParameters.xml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/raw_lims_samples/
--rw-r--r--   0 runner    (1001) docker     (123)    92887 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/raw_lims_samples/raw_samplesheet_novaseq.json
--rw-r--r--   0 runner    (1001) docker     (123)     5304 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/runParameters_missing_flowcell_run_field.xml
--rw-r--r--   0 runner    (1001) docker     (123)     5370 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/demultiplexing/unknown_run_parameters.xml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/fluffy/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/fluffy/2020-23219-05/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/fluffy/2020-23219-05/2020-23219-05.WCXpredict_aberrations.filt.bed
--rw-r--r--   0 runner    (1001) docker     (123)     5554 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/fluffy/SampleSheet.csv
--rw-r--r--   0 runner    (1001) docker     (123)      901 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/fluffy/deliverables.yaml
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/fluffy/fluffy_fastq.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/fluffy/multiqc_report.html
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/fluffy/summary.csv
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/gt/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/gt/yellowhog.bcf
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/madeline/
--rw-r--r--   0 runner    (1001) docker     (123)     5114 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/madeline/madeline.xml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/mip/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/case_file.txt
--rw-r--r--   0 runner    (1001) docker     (123)     3241 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/case_metrics_deliverables.yaml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/mip/dna/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/mip/dna/store/
--rw-r--r--   0 runner    (1001) docker     (123)    21811 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/dna/store/case_config.yaml
--rw-r--r--   0 runner    (1001) docker     (123)    23364 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/dna/store/case_id_deliverables.yaml
--rw-r--r--   0 runner    (1001) docker     (123)    37367 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/dna/store/case_qc_sample_info.yaml
--rw-r--r--   0 runner    (1001) docker     (123)       16 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/dna/store/empty_case_config.yaml
--rw-r--r--   0 runner    (1001) docker     (123)       16 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/dna/store/empty_case_metrics_deliverables.yaml
--rw-r--r--   0 runner    (1001) docker     (123)       16 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/dna/store/empty_case_qc_sample_info.yaml
--rw-r--r--   0 runner    (1001) docker     (123)      123 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/dna/store/empty_delivery_report.html
--rw-r--r--   0 runner    (1001) docker     (123)    62741 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/dna/store/yellowhog_clinical_selected.vcf
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/mip/rna/
--rw-r--r--   0 runner    (1001) docker     (123)    11242 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/rna/case_config.yaml
--rw-r--r--   0 runner    (1001) docker     (123)    12164 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/rna/case_qc_sampleinfo.yaml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/mip/rna/store/
--rw-r--r--   0 runner    (1001) docker     (123)     5231 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/rna/store/bundle_data.yaml
--rw-r--r--   0 runner    (1001) docker     (123)     9774 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/rna/store/case_config.yaml
--rw-r--r--   0 runner    (1001) docker     (123)     4624 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/rna/store/case_id_deliverables.yaml
--rw-r--r--   0 runner    (1001) docker     (123)    13666 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/rna/store/case_qc_sample_info.yaml
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/mip/sample_file.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/scout/
--rw-r--r--   0 runner    (1001) docker     (123)     1885 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/scout/643594.config.yaml
--rw-r--r--   0 runner    (1001) docker     (123)     6027 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/scout/case_export.json
--rw-r--r--   0 runner    (1001) docker     (123)     9349 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/scout/export_causatives.json
--rw-r--r--   0 runner    (1001) docker     (123)     1315 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/scout/none_case_export.json
--rw-r--r--   0 runner    (1001) docker     (123)     3518 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/scout/other_sex_case.json
--rw-r--r--   0 runner    (1001) docker     (123)     8874 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/scout/panel_export.bed
--rw-r--r--   0 runner    (1001) docker     (123)     4169 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/scout/panel_export.csv
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/apps/shipping/
--rw-r--r--   0 runner    (1001) docker     (123)       42 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/apps/shipping/scout-deploy.yaml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/cgweb_orders/
--rw-r--r--   0 runner    (1001) docker     (123)     1001 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/cgweb_orders/balsamic.json
--rw-r--r--   0 runner    (1001) docker     (123)     1104 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/cgweb_orders/fastq.json
--rw-r--r--   0 runner    (1001) docker     (123)     1312 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/cgweb_orders/metagenome.json
--rw-r--r--   0 runner    (1001) docker     (123)     3033 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/cgweb_orders/microsalt.json
--rw-r--r--   0 runner    (1001) docker     (123)     3705 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/cgweb_orders/mip.json
--rw-r--r--   0 runner    (1001) docker     (123)     1364 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/cgweb_orders/mip_rna.json
--rw-r--r--   0 runner    (1001) docker     (123)     2125 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/cgweb_orders/rml.json
--rw-r--r--   0 runner    (1001) docker     (123)     4699 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/cgweb_orders/sarscov2.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/data/
--rw-r--r--   0 runner    (1001) docker     (123)     5609 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/data/SampleSheet.csv
--rw-r--r--   0 runner    (1001) docker     (123)   258048 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/data/cgfixture.db
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/data/fastq.fastq.gz
--rw-r--r--   0 runner    (1001) docker     (123)    49152 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/data/hkstore.db
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/data/yellowhog/
--rw-r--r--   0 runner    (1001) docker     (123)       73 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/data/yellowhog/pedigree.yaml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/io/
--rw-r--r--   0 runner    (1001) docker     (123)      582 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/io/example_json.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/orderforms/
--rw-r--r--   0 runner    (1001) docker     (123)   267284 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/1508.27.balsamic.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)   258613 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/1508.27.balsamic_qc.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)   266876 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/1508.27.balsamic_umi.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)   266141 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/1508.27.fastq.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)   266967 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/1508.27.mip.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)   266759 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/1508.27.mip_rna.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)    95878 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/1603.11.microbial.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)   163548 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/1604.15.rml.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)    88463 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/1605.10.metagenome.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)   227684 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/2184.7.sarscov2.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)    18594 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/NIPT-json.json
--rw-r--r--   0 runner    (1001) docker     (123)     6028 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/balsamic_uploaded_json_orderform.json
--rw-r--r--   0 runner    (1001) docker     (123)     6587 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/orderforms/mip_uploaded_json_orderform.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/report/
--rw-r--r--   0 runner    (1001) docker     (123)     1417 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/report/case_data.json
--rw-r--r--   0 runner    (1001) docker     (123)     1109 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/report/lims_exported_samples.json
--rw-r--r--   0 runner    (1001) docker     (123)     1562 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/report/lims_family.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/store/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/fixtures/store/api/
--rw-r--r--   0 runner    (1001) docker     (123)    10462 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/store/api/application_versions.xlsx
--rw-r--r--   0 runner    (1001) docker     (123)    12914 2023-03-21 08:21:26.000000 cg-27.1.9/tests/fixtures/store/api/applications.xlsx
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/io/
--rw-r--r--   0 runner    (1001) docker     (123)     1145 2023-03-21 08:21:26.000000 cg-27.1.9/tests/io/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     4968 2023-03-21 08:21:26.000000 cg-27.1.9/tests/io/test_io_controller.py
--rw-r--r--   0 runner    (1001) docker     (123)     1779 2023-03-21 08:21:26.000000 cg-27.1.9/tests/io/test_io_json.py
--rw-r--r--   0 runner    (1001) docker     (123)     2861 2023-03-21 08:21:26.000000 cg-27.1.9/tests/io/test_io_yaml.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/backup/
--rw-r--r--   0 runner    (1001) docker     (123)     1930 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/backup/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)    24842 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/backup/test_meta_backup.py
--rw-r--r--   0 runner    (1001) docker     (123)     1821 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/backup/test_meta_pdc.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/clean/
--rw-r--r--   0 runner    (1001) docker     (123)     2448 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/clean/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     4099 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/clean/test_clean_demultiplexed_runs.py
--rw-r--r--   0 runner    (1001) docker     (123)     3407 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/clean/test_clean_flow_cell_run_directories.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/compress/
--rw-r--r--   0 runner    (1001) docker     (123)     8954 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/compress/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     6574 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/compress/test_clean_fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)     1846 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/compress/test_compress_files.py
--rw-r--r--   0 runner    (1001) docker     (123)     2350 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/compress/test_compress_meta_fastq.py
--rw-r--r--   0 runner    (1001) docker     (123)     1179 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/compress/test_decompress_spring_meta.py
--rw-r--r--   0 runner    (1001) docker     (123)     4847 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/compress/test_meta_compress_update_hk.py
--rw-r--r--   0 runner    (1001) docker     (123)     9914 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/deliver/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/deliver/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3372 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/deliver/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     8742 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/deliver/test_deliver_ticket.py
--rw-r--r--   0 runner    (1001) docker     (123)    10041 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/deliver/test_delivery_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/demultiplex/
--rw-r--r--   0 runner    (1001) docker     (123)    10998 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/demultiplex/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)    13287 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/demultiplex/test_delete_demultiplex_api.py
--rw-r--r--   0 runner    (1001) docker     (123)    13707 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/demultiplex/test_demux_post_processing.py
--rw-r--r--   0 runner    (1001) docker     (123)     1346 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/demultiplex/test_rename_files.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/encryption/
--rw-r--r--   0 runner    (1001) docker     (123)     6011 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/encryption/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)    12882 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/encryption/test_encryption.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/observations/
--rw-r--r--   0 runner    (1001) docker     (123)     2955 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/observations/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)    16192 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/observations/test_meta_upload_observations.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/orders/
--rw-r--r--   0 runner    (1001) docker     (123)     5052 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/orders/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     1769 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/orders/test_PoolSubmitter_validate_order.py
--rw-r--r--   0 runner    (1001) docker     (123)     1464 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/orders/test_SarsCov2Submitter_order_to_status.py
--rw-r--r--   0 runner    (1001) docker     (123)     1818 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/orders/test_SarsCov2Submitter_store_order.py
--rw-r--r--   0 runner    (1001) docker     (123)     2026 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/orders/test_SarsCov2Submitter_validate_order.py
--rw-r--r--   0 runner    (1001) docker     (123)    19464 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/orders/test_meta_orders_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     7123 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/orders/test_meta_orders_lims.py
--rw-r--r--   0 runner    (1001) docker     (123)    28955 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/orders/test_meta_orders_status.py
--rw-r--r--   0 runner    (1001) docker     (123)     1059 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/orders/test_ticket_handler.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/report/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/report/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3968 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/report/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)      434 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/report/helper.py
--rw-r--r--   0 runner    (1001) docker     (123)     3477 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/report/test_balsamic_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     4056 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/report/test_field_validators.py
--rw-r--r--   0 runner    (1001) docker     (123)     2794 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/report/test_mip_dna_api.py
--rw-r--r--   0 runner    (1001) docker     (123)    13304 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/report/test_report_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/rsync/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/rsync/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1005 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/rsync/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     8768 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/rsync/test_rsync.py
--rw-r--r--   0 runner    (1001) docker     (123)     3150 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/test_invoice.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/transfer/
--rw-r--r--   0 runner    (1001) docker     (123)     2302 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/transfer/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)    10152 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/transfer/test_external_data.py
--rw-r--r--   0 runner    (1001) docker     (123)    16228 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/transfer/test_meta_transfer_flowcell.py
--rw-r--r--   0 runner    (1001) docker     (123)     4366 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/transfer/test_meta_transfer_lims.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/upload/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/upload/balsamic/
--rw-r--r--   0 runner    (1001) docker     (123)     2213 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/balsamic/test_balsamic.py
--rw-r--r--   0 runner    (1001) docker     (123)     4582 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/upload/gisaid/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/gisaid/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4181 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/gisaid/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/upload/gisaid/fixtures/
--rw-r--r--   0 runner    (1001) docker     (123)     2557 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/gisaid/fixtures/four_samples.csv
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/gisaid/fixtures/invalid_housekeeper.fasta
--rw-r--r--   0 runner    (1001) docker     (123)      211 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/gisaid/fixtures/valid_gisaid.fasta
--rw-r--r--   0 runner    (1001) docker     (123)      371 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/gisaid/fixtures/valid_housekeeper.fasta
--rw-r--r--   0 runner    (1001) docker     (123)     4052 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/gisaid/test_gisaid_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/upload/mutacc/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/mutacc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3695 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/mutacc/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     4167 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/mutacc/test_meta_upload_mutacc.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/upload/nipt/
--rw-r--r--   0 runner    (1001) docker     (123)     1747 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/nipt/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     1234 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/nipt/test_nipt_upload_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/upload/scout/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/scout/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    23301 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/scout/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     4810 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/scout/test_generate_load_config.py
--rw-r--r--   0 runner    (1001) docker     (123)     3994 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/scout/test_meta_upload_scoutapi.py
--rw-r--r--   0 runner    (1001) docker     (123)    24712 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/scout/test_meta_upload_scoutapi_rna.py
--rw-r--r--   0 runner    (1001) docker     (123)     7857 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/scout/test_scout_config_builder.py
--rw-r--r--   0 runner    (1001) docker     (123)     2140 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/test_meta_upload_coverage.py
--rw-r--r--   0 runner    (1001) docker     (123)     1476 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/test_upload_api.py
--rw-r--r--   0 runner    (1001) docker     (123)     2551 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/test_upload_genotypes_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/upload/vogue/
--rw-r--r--   0 runner    (1001) docker     (123)     2512 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/vogue/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     3763 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/upload/vogue/test_upload_vogue.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/meta/workflow/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/workflow/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     8231 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/workflow/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     2552 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/workflow/test_analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)     6340 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/workflow/test_balsamic.py
--rw-r--r--   0 runner    (1001) docker     (123)     7333 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/workflow/test_microsalt.py
--rw-r--r--   0 runner    (1001) docker     (123)     5038 2023-03-21 08:21:26.000000 cg-27.1.9/tests/meta/workflow/test_prepare_fastq_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/mocks/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1186 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/balsamic_analysis_mock.py
--rw-r--r--   0 runner    (1001) docker     (123)     3500 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/crunchy.py
--rw-r--r--   0 runner    (1001) docker     (123)    19583 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/hk_mock.py
--rw-r--r--   0 runner    (1001) docker     (123)     3352 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/limsmock.py
--rw-r--r--   0 runner    (1001) docker     (123)      572 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/madeline.py
--rw-r--r--   0 runner    (1001) docker     (123)     1489 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/mip_analysis_mock.py
--rw-r--r--   0 runner    (1001) docker     (123)     1557 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/osticket.py
--rw-r--r--   0 runner    (1001) docker     (123)     3279 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/process_mock.py
--rw-r--r--   0 runner    (1001) docker     (123)     3920 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/report.py
--rw-r--r--   0 runner    (1001) docker     (123)     4033 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/scout.py
--rw-r--r--   0 runner    (1001) docker     (123)      785 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/store_model.py
--rw-r--r--   0 runner    (1001) docker     (123)     1344 2023-03-21 08:21:26.000000 cg-27.1.9/tests/mocks/tb_mock.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/models/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/models/balsamic/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/balsamic/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1226 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/balsamic/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     1030 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/balsamic/test_balsamic_analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)     1100 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/models/demultiplexing/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/demultiplexing/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2124 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/demultiplexing/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     1075 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/demultiplexing/test_demux_results.py
--rw-r--r--   0 runner    (1001) docker     (123)     2902 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/demultiplexing/test_flowcell_model.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/models/mip/
--rw-r--r--   0 runner    (1001) docker     (123)     7184 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/mip/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     1239 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/mip/test_mip_analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)     2348 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/mip/test_mip_config.py
--rw-r--r--   0 runner    (1001) docker     (123)     6401 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/mip/test_mip_metrics_deliverables.py
--rw-r--r--   0 runner    (1001) docker     (123)     3959 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/mip/test_mip_sample_info.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/models/nextflow/
--rw-r--r--   0 runner    (1001) docker     (123)     1168 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/nextflow/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     1523 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/nextflow/test_nextflow_deliver.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/models/observations/
--rw-r--r--   0 runner    (1001) docker     (123)     1625 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/observations/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     3323 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/observations/test_observations_input_files.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/models/report/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/report/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     5073 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/report/test_validators.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/models/rnafusion/
--rw-r--r--   0 runner    (1001) docker     (123)     1888 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/rnafusion/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     2915 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/rnafusion/test_rnafusion_sample.py
--rw-r--r--   0 runner    (1001) docker     (123)     1368 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/test_cg_models.py
--rw-r--r--   0 runner    (1001) docker     (123)     2352 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/test_compression_data.py
--rw-r--r--   0 runner    (1001) docker     (123)     2859 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/test_file_data.py
--rw-r--r--   0 runner    (1001) docker     (123)      755 2023-03-21 08:21:26.000000 cg-27.1.9/tests/models/test_flowcell_class.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/server/
--rw-r--r--   0 runner    (1001) docker     (123)      520 2023-03-21 08:21:26.000000 cg-27.1.9/tests/server/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)      299 2023-03-21 08:21:26.000000 cg-27.1.9/tests/server/test_server_app.py
--rw-r--r--   0 runner    (1001) docker     (123)      271 2023-03-21 08:21:26.000000 cg-27.1.9/tests/server/test_server_auto.py
--rw-r--r--   0 runner    (1001) docker     (123)      318 2023-03-21 08:21:26.000000 cg-27.1.9/tests/small_helpers.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/store/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/store/api/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/store/api/add/
--rw-r--r--   0 runner    (1001) docker     (123)     3504 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/add/test_store_add_base.py
--rw-r--r--   0 runner    (1001) docker     (123)     2442 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/add/test_store_add_customer.py
--rw-r--r--   0 runner    (1001) docker     (123)     1590 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/add/test_store_add_flow_celll.py
--rw-r--r--   0 runner    (1001) docker     (123)    12103 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/store/api/delete/
--rw-r--r--   0 runner    (1001) docker     (123)     4441 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/delete/test_store_api_delete.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/store/api/status/
--rw-r--r--   0 runner    (1001) docker     (123)     4726 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/status/test_analyses_to_clean.py
--rw-r--r--   0 runner    (1001) docker     (123)     3335 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/status/test_analyses_to_delivery_report.py
--rw-r--r--   0 runner    (1001) docker     (123)      471 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/test_base.py
--rw-r--r--   0 runner    (1001) docker     (123)    10911 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/test_find_basic_data.py
--rw-r--r--   0 runner    (1001) docker     (123)    26734 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/test_find_business_data.py
--rw-r--r--   0 runner    (1001) docker     (123)    12956 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/test_store_api_status.py
--rw-r--r--   0 runner    (1001) docker     (123)    12246 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/test_store_api_status_analysis.py
--rw-r--r--   0 runner    (1001) docker     (123)    54133 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/test_store_api_status_cases.py
--rw-r--r--   0 runner    (1001) docker     (123)    11972 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/api/test_store_import_func.py
--rw-r--r--   0 runner    (1001) docker     (123)     9726 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/conftest.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/store/filters/
--rw-r--r--   0 runner    (1001) docker     (123)     9530 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/filters/test_status_analyses_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     5990 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/filters/test_status_application_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     1603 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/filters/test_status_bed_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     1298 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/filters/test_status_bed_version_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)    19283 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/filters/test_status_cases_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     1330 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/filters/test_status_collaboration_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     4082 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/filters/test_status_flow_cell_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     2222 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/filters/test_status_invoice_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     9864 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/filters/test_status_pool_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)    19508 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/filters/test_status_samples_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     2153 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/test_delivery.py
--rw-r--r--   0 runner    (1001) docker     (123)     2431 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/test_organism_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     1807 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/test_panel_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)      701 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/test_status_customer_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)     3173 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/test_store_models.py
--rw-r--r--   0 runner    (1001) docker     (123)     1579 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store/test_user_filters.py
--rw-r--r--   0 runner    (1001) docker     (123)    28575 2023-03-21 08:21:26.000000 cg-27.1.9/tests/store_helpers.py
--rw-r--r--   0 runner    (1001) docker     (123)      998 2023-03-21 08:21:26.000000 cg-27.1.9/tests/test_store_helpers.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/tests/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/tests/fixtures/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/tests/fixtures/apps/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/tests/fixtures/apps/demultiplexing/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/tests/fixtures/apps/demultiplexing/flowcell-runs/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/copycomplete.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/tests/fixtures/data/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/tests/fixtures/data/fastq.fastq.gz
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:35.000000 cg-27.1.9/tests/utils/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-03-21 08:21:26.000000 cg-27.1.9/tests/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      829 2023-03-21 08:21:26.000000 cg-27.1.9/tests/utils/conftest.py
--rw-r--r--   0 runner    (1001) docker     (123)     2919 2023-03-21 08:21:26.000000 cg-27.1.9/tests/utils/test_commands.py
--rw-r--r--   0 runner    (1001) docker     (123)      953 2023-03-21 08:21:26.000000 cg-27.1.9/tests/utils/test_date.py
--rw-r--r--   0 runner    (1001) docker     (123)     1574 2023-03-21 08:21:26.000000 cg-27.1.9/tests/utils/test_dict.py
--rw-r--r--   0 runner    (1001) docker     (123)     1147 2023-03-21 08:21:26.000000 cg-27.1.9/tests/utils/test_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/
+-rw-r--r--   0 runner    (1001) docker     (123)      354 2023-04-11 10:43:26.000000 cg-27.2.0/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (123)     3857 2023-04-11 10:43:38.000000 cg-27.2.0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     2802 2023-04-11 10:43:26.000000 cg-27.2.0/README.md
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/
+-rw-r--r--   0 runner    (1001) docker     (123)       62 2023-04-11 10:43:26.000000 cg-27.2.0/cg/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/
+-rw-r--r--   0 runner    (1001) docker     (123)      315 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/cgstats/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/cgstats/crud/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/crud/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14071 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/crud/create.py
+-rw-r--r--   0 runner    (1001) docker     (123)      707 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/crud/delete.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3849 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/crud/find.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/cgstats/db/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/cgstats/db/models/
+-rw-r--r--   0 runner    (1001) docker     (123)      338 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1926 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/backup.py
+-rw-r--r--   0 runner    (1001) docker     (123)      724 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/backup_tape.py
+-rw-r--r--   0 runner    (1001) docker     (123)      646 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1298 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/datasource.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1488 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/demux.py
+-rw-r--r--   0 runner    (1001) docker     (123)      870 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/flowcell.py
+-rw-r--r--   0 runner    (1001) docker     (123)      879 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/project.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1258 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1227 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/support_params.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1312 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/unaligned.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1183 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/db/models/version.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9370 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/demux_sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)      545 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/dragen_demux_sample.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/cgstats/parsers/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/parsers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1919 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/parsers/adapter_metrics.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11317 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/parsers/conversion_stats.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5375 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/parsers/demux_stats.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1608 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/parsers/dragen_demultiplexing_stats.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2492 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/parsers/quality_metrics.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1068 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/parsers/run_info.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7557 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/cgstats/stats.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/coverage/
+-rw-r--r--   0 runner    (1001) docker     (123)       27 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/coverage/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2977 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/coverage/api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/crunchy/
+-rw-r--r--   0 runner    (1001) docker     (123)       56 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/crunchy/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12884 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/crunchy/crunchy.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4552 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/crunchy/files.py
+-rw-r--r--   0 runner    (1001) docker     (123)      910 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/crunchy/sbatch.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/demultiplex/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/demultiplex/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11473 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/demultiplex/demultiplex_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3180 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/demultiplex/demux_report.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/demultiplex/sample_sheet/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/demultiplex/sample_sheet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1334 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/demultiplex/sample_sheet/create.py
+-rw-r--r--   0 runner    (1001) docker     (123)      983 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/demultiplex/sample_sheet/dummy_sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5181 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/demultiplex/sample_sheet/index.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5722 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/demultiplex/sample_sheet/novaseq_sample_sheet.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1833 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/demultiplex/sbatch.py
+-rw-r--r--   0 runner    (1001) docker     (123)      297 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/environ.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1430 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/gens.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3426 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/gt.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/hermes/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/hermes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2260 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/hermes/hermes_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1009 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/hermes/models.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/housekeeper/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/housekeeper/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17462 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/housekeeper/hk.py
+-rw-r--r--   0 runner    (1001) docker     (123)      355 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/housekeeper/models.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/invoice/
+-rw-r--r--   0 runner    (1001) docker     (123)       32 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/invoice/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4804 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/invoice/render.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/invoice/templates/
+-rw-r--r--   0 runner    (1001) docker     (123)   113439 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/invoice/templates/KI_pool_invoice.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)    81032 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/invoice/templates/KI_sample_invoice.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)   113363 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/invoice/templates/KTH_pool_invoice.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)    80886 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/invoice/templates/KTH_sample_invoice.xlsx
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/lims/
+-rw-r--r--   0 runner    (1001) docker     (123)       25 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/lims/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14682 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/lims/api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2664 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/lims/batch.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8241 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/lims/order.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3989 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/lims/samplesheet.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4818 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/loqus.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/madeline/
+-rw-r--r--   0 runner    (1001) docker     (123)       35 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/madeline/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3219 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/madeline/api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/mip/
+-rw-r--r--   0 runner    (1001) docker     (123)       23 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/mip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3550 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/mip/confighandler.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2211 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/mutacc_auto.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/orderform/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/orderform/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9233 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/orderform/excel_orderform_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3068 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/orderform/json_orderform_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6441 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/orderform/orderform_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2542 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/osticket.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/scout/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/scout/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2845 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/scout/scout_export.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11713 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/scout/scoutapi.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/slurm/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/slurm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1277 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/slurm/sbatch.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3586 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/slurm/slurm_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/apps/tb/
+-rw-r--r--   0 runner    (1001) docker     (123)       32 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/tb/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7957 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/tb/api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1346 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/tb/models.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4867 2023-04-11 10:43:26.000000 cg-27.2.0/cg/apps/vogue.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/
+-rw-r--r--   0 runner    (1001) docker     (123)       23 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10050 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/add.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7039 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/backup.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3590 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19747 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/clean.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/compress/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/compress/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2081 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/compress/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6665 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/compress/fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8507 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/compress/helpers.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/delete/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/delete/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      494 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/delete/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4528 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/delete/case.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1843 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/delete/cases.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2567 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/delete/observations.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/deliver/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/deliver/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6119 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/deliver/base.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/demultiplex/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/demultiplex/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2825 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/demultiplex/add.py
+-rw-r--r--   0 runner    (1001) docker     (123)      883 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/demultiplex/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7354 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/demultiplex/demux.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2289 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/demultiplex/finish.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1463 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/demultiplex/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5437 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/demultiplex/sample_sheet.py
+-rw-r--r--   0 runner    (1001) docker     (123)      682 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/export.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/generate/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/generate/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      307 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/generate/base.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/generate/report/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/generate/report/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4475 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/generate/report/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      855 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/generate/report/options.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4515 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/generate/report/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8275 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/get.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4413 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/import_cmd.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/set/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/set/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9823 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/set/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2538 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/set/families.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4411 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/set/family.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14281 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/status.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/store/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/store/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5340 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/store/fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1021 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/store/store.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3018 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/transfer.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/upload/
+-rw-r--r--   0 runner    (1001) docker     (123)       57 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5405 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4694 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/clinical_delivery.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1155 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/coverage.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1124 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/delivery_report.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4077 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/fohm.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1472 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/genotype.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1910 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/gens.py
+-rw-r--r--   0 runner    (1001) docker     (123)      566 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/gisaid.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2693 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/mutacc.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/upload/nipt/
+-rw-r--r--   0 runner    (1001) docker     (123)       23 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/nipt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2888 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/nipt/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2217 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/nipt/ftp.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1597 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/nipt/statina.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/upload/observations/
+-rw-r--r--   0 runner    (1001) docker     (123)       63 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/observations/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2605 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/observations/observations.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2934 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/observations/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10325 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/scout.py
+-rw-r--r--   0 runner    (1001) docker     (123)      604 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1697 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/validate.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11334 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/upload/vogue.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/
+-rw-r--r--   0 runner    (1001) docker     (123)       18 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/balsamic/
+-rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/balsamic/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8799 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/balsamic/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1905 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/balsamic/options.py
+-rw-r--r--   0 runner    (1001) docker     (123)      882 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/balsamic/pon.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1177 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/balsamic/qc.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1192 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/balsamic/umi.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1015 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12561 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/commands.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/fastq/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/fastq/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1686 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/fastq/base.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/fluffy/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/fluffy/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4067 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/fluffy/base.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/microsalt/
+-rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/microsalt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10875 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/microsalt/base.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/mip/
+-rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/mip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6164 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/mip/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1268 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/mip/options.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/mip_dna/
+-rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/mip_dna/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      942 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/mip_dna/base.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/mip_rna/
+-rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/mip_rna/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      915 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/mip_rna/base.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/mutant/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/mutant/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3351 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/mutant/base.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/nextflow/
+-rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/nextflow/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1857 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/nextflow/options.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/rnafusion/
+-rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/rnafusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9734 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/rnafusion/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1991 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/rnafusion/options.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/cli/workflow/tower/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/tower/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      227 2023-04-11 10:43:26.000000 cg-27.2.0/cg/cli/workflow/tower/options.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/constants/
+-rw-r--r--   0 runner    (1001) docker     (123)      955 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)       35 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/backup.py
+-rw-r--r--   0 runner    (1001) docker     (123)      210 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/cgstats.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5367 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/compression.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4316 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4239 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/delivery.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2352 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/demultiplexing.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1349 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/encryption.py
+-rw-r--r--   0 runner    (1001) docker     (123)      371 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/extraction.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1252 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/gene_panel.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4744 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/housekeeper_tags.py
+-rw-r--r--   0 runner    (1001) docker     (123)      194 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/indexes.py
+-rw-r--r--   0 runner    (1001) docker     (123)      295 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/invoice.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5255 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/lims.py
+-rw-r--r--   0 runner    (1001) docker     (123)      649 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/nextflow.py
+-rw-r--r--   0 runner    (1001) docker     (123)       21 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/nipt.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2233 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/observations.py
+-rw-r--r--   0 runner    (1001) docker     (123)      985 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/orderforms.py
+-rw-r--r--   0 runner    (1001) docker     (123)       96 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/paths.py
+-rw-r--r--   0 runner    (1001) docker     (123)      367 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/pdc.py
+-rw-r--r--   0 runner    (1001) docker     (123)      159 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/pedigree.py
+-rw-r--r--   0 runner    (1001) docker     (123)      930 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/priority.py
+-rw-r--r--   0 runner    (1001) docker     (123)      100 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/process.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3460 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)      618 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/rnafusion.py
+-rw-r--r--   0 runner    (1001) docker     (123)      485 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/sample_sources.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2239 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/scout_upload.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1301 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/sequencing.py
+-rw-r--r--   0 runner    (1001) docker     (123)      107 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/slurm.py
+-rw-r--r--   0 runner    (1001) docker     (123)      626 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/subject.py
+-rw-r--r--   0 runner    (1001) docker     (123)      166 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/symbols.py
+-rw-r--r--   0 runner    (1001) docker     (123)      227 2023-04-11 10:43:26.000000 cg-27.2.0/cg/constants/tb.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3780 2023-04-11 10:43:26.000000 cg-27.2.0/cg/exc.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/io/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/io/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      856 2023-04-11 10:43:26.000000 cg-27.2.0/cg/io/api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2397 2023-04-11 10:43:26.000000 cg-27.2.0/cg/io/controller.py
+-rw-r--r--   0 runner    (1001) docker     (123)      607 2023-04-11 10:43:26.000000 cg-27.2.0/cg/io/json.py
+-rw-r--r--   0 runner    (1001) docker     (123)      907 2023-04-11 10:43:26.000000 cg-27.2.0/cg/io/yaml.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/
+-rw-r--r--   0 runner    (1001) docker     (123)      281 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/archive/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/archive/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8717 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/archive/ddn_dataflow.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/backup/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/backup/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18846 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/backup/backup.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1694 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/backup/pdc.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/clean/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/clean/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4009 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/clean/api.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14279 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/clean/demultiplexed_flow_cells.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4997 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/clean/flow_cell_run_directories.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/compress/
+-rw-r--r--   0 runner    (1001) docker     (123)       34 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/compress/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12451 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/compress/compress.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4995 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/compress/files.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13024 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/deliver.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8032 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/deliver_ticket.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/demultiplex/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/demultiplex/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11100 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/demultiplex/delete_demultiplex_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15575 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/demultiplex/demux_post_processing.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4868 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/demultiplex/files.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/encryption/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/encryption/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10747 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/encryption/encryption.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10954 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/invoice.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2557 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/meta.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/observations/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/observations/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5374 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/observations/balsamic_observations_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5242 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/observations/mip_dna_observations_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5455 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/observations/observations_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/orders/
+-rw-r--r--   0 runner    (1001) docker     (123)       27 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3547 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/api.py
+-rw-r--r--   0 runner    (1001) docker     (123)      121 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/balsamic_qc_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      107 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/balsamic_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      122 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/balsamic_umi_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15229 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/case_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6098 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/fastq_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      105 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/fluffy_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1278 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/lims.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5680 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/metagenome_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6087 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/microbial_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      123 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/microsalt_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      105 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/mip_dna_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      105 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/mip_rna_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7626 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/pool_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      102 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/rml_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1293 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/sars_cov_2_submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1774 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/submitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7917 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/orders/ticket_handler.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/report/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/report/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9732 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/report/balsamic.py
+-rw-r--r--   0 runner    (1001) docker     (123)      705 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/report/balsamic_umi.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3586 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/report/field_validators.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6937 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/report/mip_dna.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17738 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/report/report_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/report/templates/
+-rw-r--r--   0 runner    (1001) docker     (123)    78964 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/report/templates/balsamic_report.html
+-rw-r--r--   0 runner    (1001) docker     (123)   151463 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/report/templates/bootstrap.html
+-rw-r--r--   0 runner    (1001) docker     (123)    77831 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/report/templates/mip-dna_report.html
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/rsync/
+-rw-r--r--   0 runner    (1001) docker     (123)       32 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/rsync/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11965 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/rsync/rsync_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)      387 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/rsync/sbatch.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/tar/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/tar/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1475 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/tar/tar.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/transfer/
+-rw-r--r--   0 runner    (1001) docker     (123)      110 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/transfer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10007 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/transfer/external_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8405 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/transfer/flowcell.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6270 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/transfer/lims.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/upload/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/upload/balsamic/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/balsamic/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2649 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/balsamic/balsamic.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2225 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/coverage.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/upload/fohm/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/fohm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12124 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/fohm/fohm.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/upload/gisaid/
+-rw-r--r--   0 runner    (1001) docker     (123)       30 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/gisaid/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      992 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/gisaid/constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13572 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/gisaid/gisaid.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2278 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/gisaid/models.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5671 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/gt.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/upload/mip/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/mip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2406 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/mip/mip_dna.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1777 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/mip/mip_rna.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7491 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/mutacc.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/upload/nipt/
+-rw-r--r--   0 runner    (1001) docker     (123)       32 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/nipt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      188 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/nipt/models.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7508 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/nipt/nipt.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/upload/rnafusion/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/rnafusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      990 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/rnafusion/rnafusion.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/upload/scout/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/scout/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4009 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/scout/balsamic_config_builder.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1304 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/scout/balsamic_umi_config_builder.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3188 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/scout/hk_tags.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8759 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/scout/mip_config_builder.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2719 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/scout/rnafusion_config_builder.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8081 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/scout/scout_config_builder.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19581 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/scout/uploadscoutapi.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3065 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/upload_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2571 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/upload/vogue.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/meta/workflow/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19831 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)    28514 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/balsamic.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2642 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/balsamic_pon.py
+-rw-r--r--   0 runner    (1001) docker     (123)      549 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/balsamic_qc.py
+-rw-r--r--   0 runner    (1001) docker     (123)      551 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/balsamic_umi.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10959 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13352 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/fluffy.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18187 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/microsalt.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14337 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/mip.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2764 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/mip_dna.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2266 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/mip_rna.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10762 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/mutant.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10955 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/nextflow_common.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4527 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/prepare_fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11913 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/rnafusion.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1043 2023-04-11 10:43:26.000000 cg-27.2.0/cg/meta/workflow/tower_common.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/
+-rw-r--r--   0 runner    (1001) docker     (123)      113 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)       99 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/analysis.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/balsamic/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/balsamic/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      484 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/balsamic/analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4840 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/balsamic/config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2109 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/balsamic/metrics.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12885 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/cg_config.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/cgstats/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/cgstats/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      339 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/cgstats/flowcell.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1572 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/cgstats/stats_sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4278 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/compression_data.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/deliverables/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/deliverables/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3328 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/deliverables/metric_deliverables.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/demultiplex/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/demultiplex/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10905 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/demultiplex/demux_results.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8181 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/demultiplex/flow_cell.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4817 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/demultiplex/run_parameters.py
+-rw-r--r--   0 runner    (1001) docker     (123)      525 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/demultiplex/sbatch.py
+-rw-r--r--   0 runner    (1001) docker     (123)      287 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/email.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2157 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/file_data.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/invoice/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/invoice/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1285 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/invoice/invoice.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/lims/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/lims/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2068 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/lims/sample.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/mip/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/mip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      362 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/mip/mip_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1585 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/mip/mip_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4754 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/mip/mip_metrics_deliverables.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2581 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/mip/mip_sample_info.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/nextflow/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/nextflow/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1161 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/nextflow/deliverables.py
+-rw-r--r--   0 runner    (1001) docker     (123)      745 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/nextflow/sample.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/observations/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/observations/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1264 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/observations/input_files.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/orders/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/orders/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      529 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/orders/constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6001 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/orders/excel_sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1008 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/orders/json_sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1245 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/orders/order.py
+-rw-r--r--   0 runner    (1001) docker     (123)      838 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/orders/orderform_schema.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3786 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/orders/sample_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9804 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/orders/samples.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/report/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/report/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4311 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/report/metadata.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5173 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/report/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4396 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/report/sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3407 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/report/validators.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/rnafusion/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/rnafusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      573 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/rnafusion/rnafusion_sample.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/scout/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/scout/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4924 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/scout/scout_load_config.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/slurm/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/slurm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      640 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/slurm/sbatch.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/models/workflow/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/workflow/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      611 2023-04-11 10:43:26.000000 cg-27.2.0/cg/models/workflow/mutant.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/resources/
+-rw-r--r--   0 runner    (1001) docker     (123)    25590 2023-04-11 10:43:26.000000 cg-27.2.0/cg/resources/20181012_Indices.csv
+-rw-r--r--   0 runner    (1001) docker     (123)      436 2023-04-11 10:43:26.000000 cg-27.2.0/cg/resources/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1836 2023-04-11 10:43:26.000000 cg-27.2.0/cg/resources/rnafusion_bundle_filenames.csv
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/server/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16677 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/admin.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16756 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3850 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/app.py
+-rw-r--r--   0 runner    (1001) docker     (123)       48 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/auto.py
+-rw-r--r--   0 runner    (1001) docker     (123)      935 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/config.py
+-rw-r--r--   0 runner    (1001) docker     (123)      914 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/ext.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/server/invoices/
+-rw-r--r--   0 runner    (1001) docker     (123)       29 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/invoices/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/server/invoices/templates/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/server/invoices/templates/invoices/
+-rw-r--r--   0 runner    (1001) docker     (123)     4793 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/invoices/templates/invoices/index.html
+-rw-r--r--   0 runner    (1001) docker     (123)     8171 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/invoices/templates/invoices/invoice.html
+-rw-r--r--   0 runner    (1001) docker     (123)     2838 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/invoices/templates/invoices/layout.html
+-rw-r--r--   0 runner    (1001) docker     (123)     4956 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/invoices/templates/invoices/new.html
+-rw-r--r--   0 runner    (1001) docker     (123)     7751 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/invoices/views.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/server/templates/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/server/templates/admin/
+-rw-r--r--   0 runner    (1001) docker     (123)      354 2023-04-11 10:43:26.000000 cg-27.2.0/cg/server/templates/admin/index.html
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/store/
+-rw-r--r--   0 runner    (1001) docker     (123)       23 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/store/api/
+-rw-r--r--   0 runner    (1001) docker     (123)       37 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/api/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10615 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/api/add.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3230 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/api/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      771 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/api/core.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1271 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/api/delete.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9114 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/api/find_basic_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29738 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/api/find_business_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12759 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/api/import_func.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1500 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/api/models.py
+-rw-r--r--   0 runner    (1001) docker     (123)    40457 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/api/status.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/store/filters/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6705 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_analysis_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2540 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_application_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2308 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_application_version_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1122 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_bed_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)      947 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_bed_version_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8747 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_case_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1720 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_case_sample_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)      929 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_collaboration_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)      955 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_customer_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1840 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_flow_cell_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1293 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_invoice_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)      876 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_organism_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)      807 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_panel_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4280 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_pool_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9383 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_sample_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)      755 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/filters/status_user_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27621 2023-04-11 10:43:26.000000 cg-27.2.0/cg/store/models.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)       30 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/utils/checksum/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/checksum/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1579 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/checksum/checksum.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/utils/click/
+-rw-r--r--   0 runner    (1001) docker     (123)     2056 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/click/EnumChoice.py
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/click/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4946 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/commands.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2250 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/date.py
+-rw-r--r--   0 runner    (1001) docker     (123)      666 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/dict.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2151 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/dispatcher.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1251 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/email.py
+-rw-r--r--   0 runner    (1001) docker     (123)      315 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/enums.py
+-rw-r--r--   0 runner    (1001) docker     (123)       51 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/files.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg/utils/flask/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/flask/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1138 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/flask/enum.py
+-rw-r--r--   0 runner    (1001) docker     (123)      289 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/time.py
+-rw-r--r--   0 runner    (1001) docker     (123)      888 2023-04-11 10:43:26.000000 cg-27.2.0/cg/utils/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/cg.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)     3857 2023-04-11 10:43:38.000000 cg-27.2.0/cg.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    39247 2023-04-11 10:43:38.000000 cg-27.2.0/cg.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-11 10:43:38.000000 cg-27.2.0/cg.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       36 2023-04-11 10:43:38.000000 cg-27.2.0/cg.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-11 10:43:38.000000 cg-27.2.0/cg.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (123)      491 2023-04-11 10:43:38.000000 cg-27.2.0/cg.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        3 2023-04-11 10:43:38.000000 cg-27.2.0/cg.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      147 2023-04-11 10:43:26.000000 cg-27.2.0/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (123)      916 2023-04-11 10:43:26.000000 cg-27.2.0/requirements.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       38 2023-04-11 10:43:38.000000 cg-27.2.0/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (123)     2076 2023-04-11 10:43:26.000000 cg-27.2.0/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/cgstats/
+-rw-r--r--   0 runner    (1001) docker     (123)     5987 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/cgstats/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/cgstats/crud/
+-rw-r--r--   0 runner    (1001) docker     (123)      805 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/cgstats/crud/test_create_novaseq.py
+-rw-r--r--   0 runner    (1001) docker     (123)      753 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/cgstats/crud/test_delete.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/cgstats/parsers/
+-rw-r--r--   0 runner    (1001) docker     (123)      475 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/cgstats/parsers/test_adapter_metrics.py
+-rw-r--r--   0 runner    (1001) docker     (123)      595 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/cgstats/parsers/test_conversion_stats.py
+-rw-r--r--   0 runner    (1001) docker     (123)      585 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/cgstats/parsers/test_demux_stats.py
+-rw-r--r--   0 runner    (1001) docker     (123)      475 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/cgstats/parsers/test_quality_metrics.py
+-rw-r--r--   0 runner    (1001) docker     (123)      913 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/cgstats/parsers/test_run_info.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4372 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/cgstats/test_cgstats_create.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1229 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/cgstats/test_stats.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1159 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/coverage/
+-rw-r--r--   0 runner    (1001) docker     (123)      309 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/coverage/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6211 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/coverage/test_coverage.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/crunchy/
+-rw-r--r--   0 runner    (1001) docker     (123)     3058 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/crunchy/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5469 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/crunchy/test_compress_fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2274 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/crunchy/test_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14590 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/crunchy/test_crunchy.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9107 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/crunchy/test_spring_decompression.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/demultiplex/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/demultiplex/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5867 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/demultiplex/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1518 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/demultiplex/test_convert_to_sample_sheet.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1323 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/demultiplex/test_demultiplex_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2061 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/demultiplex/test_parse_run_parameters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1471 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/demultiplex/test_sample_sheet.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/gens/
+-rw-r--r--   0 runner    (1001) docker     (123)       41 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/gens/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1740 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/gens/test_gens_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/gt/
+-rw-r--r--   0 runner    (1001) docker     (123)     2060 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/gt/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4276 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/gt/test_gt_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/hk/
+-rw-r--r--   0 runner    (1001) docker     (123)     1955 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/hk/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)      684 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/hk/test__getattr__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1598 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/hk/test_add_file.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3529 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/hk/test_bundles.py
+-rw-r--r--   0 runner    (1001) docker     (123)      871 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/hk/test_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24046 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/hk/test_file.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5884 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/hk/test_version.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/lims/
+-rw-r--r--   0 runner    (1001) docker     (123)      920 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/lims/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3235 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/lims/test_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/loqus/
+-rw-r--r--   0 runner    (1001) docker     (123)     9785 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/loqus/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8994 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/loqus/test_loqusdb_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/madeline/
+-rw-r--r--   0 runner    (1001) docker     (123)     3010 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/madeline/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4653 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/madeline/test_madeline.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/mip/
+-rw-r--r--   0 runner    (1001) docker     (123)     5200 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/mip/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2487 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/mip/test_config_mip.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/mutacc_auto/
+-rw-r--r--   0 runner    (1001) docker     (123)      882 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/mutacc_auto/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2472 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/mutacc_auto/test_mutacc_auto.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/orderform/
+-rw-r--r--   0 runner    (1001) docker     (123)    11900 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/orderform/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8899 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/orderform/test_excel_orderform_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4351 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/orderform/test_excel_sample_schema.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1032 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/orderform/test_json_orderform_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2474 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/orderform/test_orderform_parser.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/scout/
+-rw-r--r--   0 runner    (1001) docker     (123)     4005 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/scout/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2269 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/scout/test_get_causative_variants.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1376 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/scout/test_get_scout_cases.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1700 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/scout/test_scout_load_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3447 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/scout/test_scout_models.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/slurm/
+-rw-r--r--   0 runner    (1001) docker     (123)     1242 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/slurm/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4412 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/slurm/test_slurm_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)      831 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/test_apps_environ.py
+-rw-r--r--   0 runner    (1001) docker     (123)      957 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/test_osticket.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/apps/vogue/
+-rw-r--r--   0 runner    (1001) docker     (123)      988 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/vogue/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6421 2023-04-11 10:43:26.000000 cg-27.2.0/tests/apps/vogue/test_vogue_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/add/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/add/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1072 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/add/test_cli_add.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2465 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/add/test_cli_add_customer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6657 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/add/test_cli_add_family.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7329 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/add/test_cli_add_relationship.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7529 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/add/test_cli_add_sample.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/backup/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/backup/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      768 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/backup/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2925 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/backup/test_backup_command.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/clean/
+-rw-r--r--   0 runner    (1001) docker     (123)     6099 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/clean/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5531 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/clean/test_balsamic_clean.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1829 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/clean/test_clean_hk_bundle_files.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2116 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/clean/test_hk_bundle_files.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4608 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/clean/test_hk_case_bundle_files.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3578 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/clean/test_microbial_clean.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1881 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/clean/test_rsync_past_run_dirs.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/compress/
+-rw-r--r--   0 runner    (1001) docker     (123)    10804 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/compress/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6913 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/compress/test_cli_compress_fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1424 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/compress/test_cli_decompress_spring.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5196 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/compress/test_compress_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1238 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/compress/test_store_fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5671 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/delete/
+-rw-r--r--   0 runner    (1001) docker     (123)    11850 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/delete/test_case.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1845 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/delete/test_cases.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/deliver/
+-rw-r--r--   0 runner    (1001) docker     (123)     4137 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/deliver/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3671 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/deliver/test_deliver_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1165 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/deliver/test_rsync_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8562 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/deliver/test_run_deliver_cmd.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/demultiplex/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/demultiplex/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11711 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/demultiplex/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1214 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/demultiplex/test_add_flowcell.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3778 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/demultiplex/test_create_sample_sheet.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11252 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/demultiplex/test_demultiplex_flowcell.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4163 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/demultiplex/test_finish_demux.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1475 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/demultiplex/test_stats_command.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2992 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/demultiplex/test_validate_sample_sheet.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/generate/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/generate/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/generate/report/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/generate/report/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1716 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/generate/report/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2148 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/generate/report/test_cli_delivery_report.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2767 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/generate/report/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)      564 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/generate/test_cli_base.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/get/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/get/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      857 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/get/test_cli_get.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1515 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/get/test_cli_get_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1240 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/get/test_cli_get_case.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6217 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/get/test_cli_get_flow_cell.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8782 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/get/test_cli_get_sample.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/set/
+-rw-r--r--   0 runner    (1001) docker     (123)     1363 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/set/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1219 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/set/test_families.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6665 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/set/test_family.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1918 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/set/test_flowcell.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1720 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/set/test_list_keys.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12265 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/set/test_sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6116 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/set/test_samples.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/store/
+-rw-r--r--   0 runner    (1001) docker     (123)     6874 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/store/test_fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2359 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/test_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      513 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/test_clean.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2195 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/test_cli_status_cases.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/tests/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/tests/fixtures/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/tests/fixtures/data/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/tests/fixtures/data/fastq.fastq.gz
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/upload/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12187 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2295 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_scout.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1786 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload.py
+-rw-r--r--   0 runner    (1001) docker     (123)      935 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload_auto.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1472 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload_delivery_report.py
+-rw-r--r--   0 runner    (1001) docker     (123)      889 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload_fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1185 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload_genotype.py
+-rw-r--r--   0 runner    (1001) docker     (123)      683 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload_gens.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8408 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload_nipt.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4686 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload_nipt_ftp.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1839 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload_nipt_statina.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5913 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload_observations.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3107 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/upload/test_cli_upload_vogue.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/workflow/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/workflow/balsamic/
+-rw-r--r--   0 runner    (1001) docker     (123)    30975 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/balsamic/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15327 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/balsamic/test_cli_balsamic_config_case.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7611 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/balsamic/test_compound_commands.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2334 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/balsamic/test_link.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3554 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/balsamic/test_report_deliver.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6369 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/balsamic/test_run.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7052 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/balsamic/test_store_housekeeper.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8061 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/workflow/fastq/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/fastq/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1715 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/fastq/test_fastq_base.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/workflow/fluffy/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/fluffy/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4918 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/fluffy/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3908 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/fluffy/test_cli_create_samplesheet.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3242 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/fluffy/test_cli_link.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1895 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/fluffy/test_cli_run.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2926 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/fluffy/test_cli_start.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7870 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/fluffy/test_cli_store.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/workflow/microsalt/
+-rw-r--r--   0 runner    (1001) docker     (123)     2951 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/microsalt/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/workflow/microsalt/snapshots/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/microsalt/snapshots/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1451 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/microsalt/snapshots/snap_test_microsalt_case_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7257 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/microsalt/test_microsalt_case_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)      998 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/microsalt/test_microsalt_run.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/workflow/mip/
+-rw-r--r--   0 runner    (1001) docker     (123)     6965 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6997 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1540 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_dna_config_case.py
+-rw-r--r--   0 runner    (1001) docker     (123)      430 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_dna_link.py
+-rw-r--r--   0 runner    (1001) docker     (123)      435 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_dna_panel.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3650 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_dna_run.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3878 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_dna_start.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1003 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_rna_config_case.py
+-rw-r--r--   0 runner    (1001) docker     (123)      526 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_rna_link.py
+-rw-r--r--   0 runner    (1001) docker     (123)      713 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_rna_run.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8550 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_store.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/cli/workflow/rnafusion/
+-rw-r--r--   0 runner    (1001) docker     (123)     8555 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/rnafusion/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7876 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/rnafusion/test_cli_rnafusion_compound_commands.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4375 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/rnafusion/test_cli_rnafusion_config_case.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2877 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/rnafusion/test_cli_rnafusion_report_deliver.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5064 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/rnafusion/test_cli_rnafusion_run.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8511 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/rnafusion/test_cli_rnafusion_store_housekeeper.py
+-rw-r--r--   0 runner    (1001) docker     (123)      836 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/test_cli_workflow.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4310 2023-04-11 10:43:26.000000 cg-27.2.0/tests/cli/workflow/test_cli_workflow_clean.py
+-rw-r--r--   0 runner    (1001) docker     (123)    60642 2023-04-11 10:43:26.000000 cg-27.2.0/tests/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/DEMUX/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/Sample_ADM1136A3_XTC08/
+-rw-r--r--   0 runner    (1001) docker     (123)        4 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/Sample_ADM1136A3_XTC08/ADM1136A3_XTC08_AGTGGTCA_L001_R1_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/Sample_ADM1136A3_XTC08/ADM1136A3_XTC08_AGTGGTCA_L001_R2_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/Sample_ADM1136A3_XTC08/ADM1136A3_XTC08_AGTGGTCA_L002_R1_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/Unaligned5/Project_337334/Sample_ADM1136A3_XTC08/ADM1136A3_XTC08_AGTGGTCA_L002_R2_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)     6666 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/runParameters.xml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/analysis/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/analysis/balsamic/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/analysis/balsamic/tn_wgs/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/balsamic/tn_wgs/adm1.cram
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/balsamic/tn_wgs/ascat.output.pdf
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/balsamic/tn_wgs/snv.vcf
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/balsamic/tn_wgs/sv.vcf
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/analysis/microsalt/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/analysis/microsalt/ACC11111_qc_fail/
+-rw-r--r--   0 runner    (1001) docker     (123)    14644 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/microsalt/ACC11111_qc_fail/ACC11111_qc_fail.json
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/analysis/microsalt/ACC22222_qc_pass/
+-rw-r--r--   0 runner    (1001) docker     (123)    15713 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/microsalt/ACC22222_qc_pass/ACC22222_qc_pass.json
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/analysis/mip/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/ADM1.baf.bed.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/ADM1.cov.bed.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/ADM2.cram
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/ADM3.cram
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/adm1.cram
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/adm1.mt.bam
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/multiqc.html
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/report.pdf
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/smn.vcf
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/snv.vcf
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/snv_research.vcf
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/str.vcf
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/sv.vcf
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/sv_research.vcf
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/mip/dna/vcf2cytosure.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     2873 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/analysis/sample_coverage.bed
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/balsamic/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/balsamic/case/
+-rw-r--r--   0 runner    (1001) docker     (123)     9948 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/balsamic/case/config.json
+-rw-r--r--   0 runner    (1001) docker     (123)     3465 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/balsamic/case/metadata.yml
+-rw-r--r--   0 runner    (1001) docker     (123)       63 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/balsamic/case/metadata_directory.yml
+-rw-r--r--   0 runner    (1001) docker     (123)      165 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/balsamic/case/metadata_file_tags.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     2338 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/balsamic/case/metrics_deliverables.yaml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/crunchy/
+-rw-r--r--   0 runner    (1001) docker     (123)      692 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/crunchy/spring_metadata.json
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/201203_A00689_0200_AHVKJCDRXX/
+-rw-r--r--   0 runner    (1001) docker     (123)     6666 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml
+-rw-r--r--   0 runner    (1001) docker     (123)    53877 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/201203_A00689_0200_AHVKJCDRXX/SampleSheet.csv
+-rw-r--r--   0 runner    (1001) docker     (123)     1076 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/SampleSheetS2_Bcl2Fastq.csv
+-rw-r--r--   0 runner    (1001) docker     (123)     1084 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/SampleSheetS2_Dragen.csv
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/
+-rw-r--r--   0 runner    (1001) docker     (123)     1757 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Project_150392/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Project_150392/Sample_ACC7769A10/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Project_150392/Sample_ACC7769A10/HN3FKDSXY_AL-P-00425491-N-03103120-KH20210330-PN20210331_S1_L001_R1_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Project_150392/Sample_ACC7769A10/HN3FKDSXY_AL-P-00425491-N-03103120-KH20210330-PN20210331_S1_L001_R2_001.fastq.gz
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/
+-rw-r--r--   0 runner    (1001) docker     (123)     6034 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/ConversionStats.xml
+-rw-r--r--   0 runner    (1001) docker     (123)     1172 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/DemultiplexingStats.xml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/Reports/
+-rw-r--r--   0 runner    (1001) docker     (123)      315 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/Reports/Adapter_Metrics.csv
+-rw-r--r--   0 runner    (1001) docker     (123)      434 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/Reports/Quality_Metrics.csv
+-rw-r--r--   0 runner    (1001) docker     (123)     8624 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/Reports/RunInfo.xml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/
+-rw-r--r--   0 runner    (1001) docker     (123)       43 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/dummy_run_R1_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)       67 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/dummy_run_R1_001.fastq.gz.md5
+-rw-r--r--   0 runner    (1001) docker     (123)   338370 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/fastq_run_R1_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)       67 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/fastq_run_R1_001.fastq.gz.md5
+-rw-r--r--   0 runner    (1001) docker     (123)   338349 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/fastq_run_R2_001.fastq.gz
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/150392/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/150392/ACC7769A10/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/150392/ACC7769A10/AL-P-00425491-N-03103120-KH20210330-PN20210331_S1_L001_R1_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/150392/ACC7769A10/AL-P-00425491-N-03103120-KH20210330-PN20210331_S1_L001_R2_001.fastq.gz
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/
+-rw-r--r--   0 runner    (1001) docker     (123)     4439 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/ConversionStats.xml
+-rw-r--r--   0 runner    (1001) docker     (123)     1172 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/DemultiplexingStats.xml
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Undetermined_S0_L001_R1_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Undetermined_S0_L001_R2_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Undetermined_S0_L002_R1_001.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Undetermined_S0_L002_R2_001.fastq.gz
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/CopyComplete.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     1757 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/RTAComplete.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     6666 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml
+-rw-r--r--   0 runner    (1001) docker     (123)      324 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/SampleSheet.csv
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/copycomplete.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/demuxstarted.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/CopyComplete.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      509 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/HLG5GDRXY_demultiplex.stderr
+-rw-r--r--   0 runner    (1001) docker     (123)     2229 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/HLG5GDRXY_demultiplex.stdout
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/RTAComplete.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     6665 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/RunParameters.xml
+-rw-r--r--   0 runner    (1001) docker     (123)      407 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/SampleSheet.csv
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/demuxstarted.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/CopyComplete.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     1757 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/RTAComplete.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     6666 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml
+-rw-r--r--   0 runner    (1001) docker     (123)      324 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/SampleSheet.csv
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/demuxstarted.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/CopyComplete.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     1757 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/RTAComplete.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     6666 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml
+-rw-r--r--   0 runner    (1001) docker     (123)      332 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/SampleSheet.csv
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/demuxstarted.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/hiseq_run/
+-rw-r--r--   0 runner    (1001) docker     (123)     5367 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/hiseq_run/runParameters.xml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/raw_lims_samples/
+-rw-r--r--   0 runner    (1001) docker     (123)    92887 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/raw_lims_samples/raw_samplesheet_novaseq.json
+-rw-r--r--   0 runner    (1001) docker     (123)     5304 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/runParameters_missing_flowcell_run_field.xml
+-rw-r--r--   0 runner    (1001) docker     (123)     5370 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/demultiplexing/unknown_run_parameters.xml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/fluffy/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/fluffy/2020-23219-05/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/fluffy/2020-23219-05/2020-23219-05.WCXpredict_aberrations.filt.bed
+-rw-r--r--   0 runner    (1001) docker     (123)     5554 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/fluffy/SampleSheet.csv
+-rw-r--r--   0 runner    (1001) docker     (123)      901 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/fluffy/deliverables.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/fluffy/fluffy_fastq.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/fluffy/multiqc_report.html
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/fluffy/summary.csv
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/gt/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/gt/yellowhog.bcf
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/madeline/
+-rw-r--r--   0 runner    (1001) docker     (123)     5114 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/madeline/madeline.xml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/mip/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/case_file.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     3241 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/case_metrics_deliverables.yaml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/mip/dna/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/mip/dna/store/
+-rw-r--r--   0 runner    (1001) docker     (123)    21811 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/dna/store/case_config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    23364 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/dna/store/case_id_deliverables.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    37367 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/dna/store/case_qc_sample_info.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)       16 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/dna/store/empty_case_config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)       16 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/dna/store/empty_case_metrics_deliverables.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)       16 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/dna/store/empty_case_qc_sample_info.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)      123 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/dna/store/empty_delivery_report.html
+-rw-r--r--   0 runner    (1001) docker     (123)    62741 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/dna/store/yellowhog_clinical_selected.vcf
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/mip/rna/
+-rw-r--r--   0 runner    (1001) docker     (123)    11242 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/rna/case_config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    12164 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/rna/case_qc_sampleinfo.yaml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/mip/rna/store/
+-rw-r--r--   0 runner    (1001) docker     (123)     5231 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/rna/store/bundle_data.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     9774 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/rna/store/case_config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     4624 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/rna/store/case_id_deliverables.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)    13666 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/rna/store/case_qc_sample_info.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/mip/sample_file.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/scout/
+-rw-r--r--   0 runner    (1001) docker     (123)     1885 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/scout/643594.config.yaml
+-rw-r--r--   0 runner    (1001) docker     (123)     6027 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/scout/case_export.json
+-rw-r--r--   0 runner    (1001) docker     (123)     9349 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/scout/export_causatives.json
+-rw-r--r--   0 runner    (1001) docker     (123)     1315 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/scout/none_case_export.json
+-rw-r--r--   0 runner    (1001) docker     (123)     3518 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/scout/other_sex_case.json
+-rw-r--r--   0 runner    (1001) docker     (123)     8874 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/scout/panel_export.bed
+-rw-r--r--   0 runner    (1001) docker     (123)     4169 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/scout/panel_export.csv
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/apps/shipping/
+-rw-r--r--   0 runner    (1001) docker     (123)       42 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/apps/shipping/scout-deploy.yaml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/cgweb_orders/
+-rw-r--r--   0 runner    (1001) docker     (123)     1001 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/cgweb_orders/balsamic.json
+-rw-r--r--   0 runner    (1001) docker     (123)     1104 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/cgweb_orders/fastq.json
+-rw-r--r--   0 runner    (1001) docker     (123)     1312 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/cgweb_orders/metagenome.json
+-rw-r--r--   0 runner    (1001) docker     (123)     3033 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/cgweb_orders/microsalt.json
+-rw-r--r--   0 runner    (1001) docker     (123)     3705 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/cgweb_orders/mip.json
+-rw-r--r--   0 runner    (1001) docker     (123)     1364 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/cgweb_orders/mip_rna.json
+-rw-r--r--   0 runner    (1001) docker     (123)     2125 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/cgweb_orders/rml.json
+-rw-r--r--   0 runner    (1001) docker     (123)     4699 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/cgweb_orders/sarscov2.json
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/data/
+-rw-r--r--   0 runner    (1001) docker     (123)     5609 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/data/SampleSheet.csv
+-rw-r--r--   0 runner    (1001) docker     (123)   258048 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/data/cgfixture.db
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/data/fastq.fastq.gz
+-rw-r--r--   0 runner    (1001) docker     (123)    49152 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/data/hkstore.db
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/data/yellowhog/
+-rw-r--r--   0 runner    (1001) docker     (123)       73 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/data/yellowhog/pedigree.yaml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/io/
+-rw-r--r--   0 runner    (1001) docker     (123)      582 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/io/example_json.json
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/orderforms/
+-rw-r--r--   0 runner    (1001) docker     (123)   267284 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/1508.27.balsamic.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)   258613 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/1508.27.balsamic_qc.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)   266876 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/1508.27.balsamic_umi.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)   266141 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/1508.27.fastq.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)   266967 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/1508.27.mip.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)   266759 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/1508.27.mip_rna.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)    95878 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/1603.11.microbial.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)   163548 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/1604.15.rml.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)    88463 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/1605.10.metagenome.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)   227684 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/2184.7.sarscov2.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)    18594 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/NIPT-json.json
+-rw-r--r--   0 runner    (1001) docker     (123)     6028 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/balsamic_uploaded_json_orderform.json
+-rw-r--r--   0 runner    (1001) docker     (123)     6587 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/orderforms/mip_uploaded_json_orderform.json
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/report/
+-rw-r--r--   0 runner    (1001) docker     (123)     1417 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/report/case_data.json
+-rw-r--r--   0 runner    (1001) docker     (123)     1109 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/report/lims_exported_samples.json
+-rw-r--r--   0 runner    (1001) docker     (123)     1562 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/report/lims_family.json
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/store/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/fixtures/store/api/
+-rw-r--r--   0 runner    (1001) docker     (123)    10462 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/store/api/application_versions.xlsx
+-rw-r--r--   0 runner    (1001) docker     (123)    12914 2023-04-11 10:43:26.000000 cg-27.2.0/tests/fixtures/store/api/applications.xlsx
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/io/
+-rw-r--r--   0 runner    (1001) docker     (123)     1145 2023-04-11 10:43:26.000000 cg-27.2.0/tests/io/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4968 2023-04-11 10:43:26.000000 cg-27.2.0/tests/io/test_io_controller.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1779 2023-04-11 10:43:26.000000 cg-27.2.0/tests/io/test_io_json.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2861 2023-04-11 10:43:26.000000 cg-27.2.0/tests/io/test_io_yaml.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/archive/
+-rw-r--r--   0 runner    (1001) docker     (123)     3723 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/archive/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12929 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/archive/test_archiving.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/backup/
+-rw-r--r--   0 runner    (1001) docker     (123)     1930 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/backup/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24823 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/backup/test_meta_backup.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1821 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/backup/test_meta_pdc.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/clean/
+-rw-r--r--   0 runner    (1001) docker     (123)     2448 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/clean/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4099 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/clean/test_clean_demultiplexed_runs.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4293 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/clean/test_clean_flow_cell_run_directories.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/compress/
+-rw-r--r--   0 runner    (1001) docker     (123)     8954 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/compress/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7339 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/compress/test_clean_fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1846 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/compress/test_compress_files.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2350 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/compress/test_compress_meta_fastq.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1179 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/compress/test_decompress_spring_meta.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5391 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/compress/test_meta_compress_update_hk.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9914 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/deliver/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/deliver/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3384 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/deliver/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8874 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/deliver/test_deliver_ticket.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10121 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/deliver/test_delivery_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/demultiplex/
+-rw-r--r--   0 runner    (1001) docker     (123)    10998 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/demultiplex/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13315 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/demultiplex/test_delete_demultiplex_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13707 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/demultiplex/test_demux_post_processing.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1346 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/demultiplex/test_rename_files.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/encryption/
+-rw-r--r--   0 runner    (1001) docker     (123)     6011 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/encryption/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12857 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/encryption/test_encryption.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/observations/
+-rw-r--r--   0 runner    (1001) docker     (123)     2955 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/observations/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16540 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/observations/test_meta_upload_observations.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/orders/
+-rw-r--r--   0 runner    (1001) docker     (123)     5052 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/orders/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1774 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/orders/test_PoolSubmitter_validate_order.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1464 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/orders/test_SarsCov2Submitter_order_to_status.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1881 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/orders/test_SarsCov2Submitter_store_order.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2026 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/orders/test_SarsCov2Submitter_validate_order.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19702 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/orders/test_meta_orders_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7123 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/orders/test_meta_orders_lims.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29074 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/orders/test_meta_orders_status.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1068 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/orders/test_ticket_handler.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/report/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/report/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4027 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/report/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)      434 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/report/helper.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3477 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/report/test_balsamic_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4056 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/report/test_field_validators.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2794 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/report/test_mip_dna_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13304 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/report/test_report_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/rsync/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/rsync/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1017 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/rsync/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8834 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/rsync/test_rsync.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3150 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/test_invoice.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/transfer/
+-rw-r--r--   0 runner    (1001) docker     (123)     2308 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/transfer/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10246 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/transfer/test_external_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16220 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/transfer/test_meta_transfer_flowcell.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4362 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/transfer/test_meta_transfer_lims.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/upload/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/upload/balsamic/
+-rw-r--r--   0 runner    (1001) docker     (123)     2306 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/balsamic/test_balsamic.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4686 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/upload/gisaid/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/gisaid/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4145 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/gisaid/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/upload/gisaid/fixtures/
+-rw-r--r--   0 runner    (1001) docker     (123)     2557 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/gisaid/fixtures/four_samples.csv
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/gisaid/fixtures/invalid_housekeeper.fasta
+-rw-r--r--   0 runner    (1001) docker     (123)      211 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/gisaid/fixtures/valid_gisaid.fasta
+-rw-r--r--   0 runner    (1001) docker     (123)      371 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/gisaid/fixtures/valid_housekeeper.fasta
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/upload/mutacc/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/mutacc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3695 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/mutacc/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4167 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/mutacc/test_meta_upload_mutacc.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/upload/nipt/
+-rw-r--r--   0 runner    (1001) docker     (123)     1747 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/nipt/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1234 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/nipt/test_nipt_upload_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/upload/scout/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/scout/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    23340 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/scout/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4810 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/scout/test_generate_load_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3994 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/scout/test_meta_upload_scoutapi.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24928 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/scout/test_meta_upload_scoutapi_rna.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7857 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/scout/test_scout_config_builder.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2172 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/test_meta_upload_coverage.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1476 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/test_upload_api.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2551 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/test_upload_genotypes_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/upload/vogue/
+-rw-r--r--   0 runner    (1001) docker     (123)     2512 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/vogue/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3739 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/upload/vogue/test_upload_vogue.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/meta/workflow/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/workflow/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8231 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/workflow/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2552 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/workflow/test_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6301 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/workflow/test_balsamic.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7478 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/workflow/test_microsalt.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5125 2023-04-11 10:43:26.000000 cg-27.2.0/tests/meta/workflow/test_prepare_fastq_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/mocks/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1186 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/balsamic_analysis_mock.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3500 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/crunchy.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19780 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/hk_mock.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3352 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/limsmock.py
+-rw-r--r--   0 runner    (1001) docker     (123)      572 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/madeline.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1489 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/mip_analysis_mock.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1557 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/osticket.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3279 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/process_mock.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3920 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3973 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/scout.py
+-rw-r--r--   0 runner    (1001) docker     (123)      785 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/store_model.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1344 2023-04-11 10:43:26.000000 cg-27.2.0/tests/mocks/tb_mock.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/models/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/models/balsamic/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/balsamic/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1226 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/balsamic/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1030 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/balsamic/test_balsamic_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1100 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/models/demultiplexing/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/demultiplexing/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2124 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/demultiplexing/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1075 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/demultiplexing/test_demux_results.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2835 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/demultiplexing/test_flowcell_model.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/models/mip/
+-rw-r--r--   0 runner    (1001) docker     (123)     7184 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/mip/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1239 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/mip/test_mip_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2348 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/mip/test_mip_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6401 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/mip/test_mip_metrics_deliverables.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3959 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/mip/test_mip_sample_info.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/models/nextflow/
+-rw-r--r--   0 runner    (1001) docker     (123)     1168 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/nextflow/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1523 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/nextflow/test_nextflow_deliver.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/models/observations/
+-rw-r--r--   0 runner    (1001) docker     (123)     1625 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/observations/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3323 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/observations/test_observations_input_files.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/models/report/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/report/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5073 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/report/test_validators.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/models/rnafusion/
+-rw-r--r--   0 runner    (1001) docker     (123)     1888 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/rnafusion/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2915 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/rnafusion/test_rnafusion_sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1368 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/test_cg_models.py
+-rw-r--r--   0 runner    (1001) docker     (123)      999 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/test_compression_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2859 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/test_file_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)      755 2023-04-11 10:43:26.000000 cg-27.2.0/tests/models/test_flowcell_class.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/server/
+-rw-r--r--   0 runner    (1001) docker     (123)      520 2023-04-11 10:43:26.000000 cg-27.2.0/tests/server/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)      299 2023-04-11 10:43:26.000000 cg-27.2.0/tests/server/test_server_app.py
+-rw-r--r--   0 runner    (1001) docker     (123)      271 2023-04-11 10:43:26.000000 cg-27.2.0/tests/server/test_server_auto.py
+-rw-r--r--   0 runner    (1001) docker     (123)      318 2023-04-11 10:43:26.000000 cg-27.2.0/tests/small_helpers.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/store/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/store/api/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/store/api/add/
+-rw-r--r--   0 runner    (1001) docker     (123)     1368 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/add/test_store_add_application_version.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3548 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/add/test_store_add_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2451 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/add/test_store_add_customer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1590 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/add/test_store_add_flow_celll.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20991 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/store/api/delete/
+-rw-r--r--   0 runner    (1001) docker     (123)     4485 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/delete/test_store_api_delete.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/store/api/find/
+-rw-r--r--   0 runner    (1001) docker     (123)    10953 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/find/test_find_basic_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4344 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/find/test_find_basic_data_application_version.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24265 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/find/test_find_business_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2342 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/find/test_find_business_data_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3040 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/find/test_find_business_data_case.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11860 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/find/test_find_business_data_sample.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/store/api/status/
+-rw-r--r--   0 runner    (1001) docker     (123)     4726 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/status/test_analyses_to_clean.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3294 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/status/test_analyses_to_delivery_report.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10792 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/status/test_store_api_status.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15264 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/status/test_store_api_status_analysis.py
+-rw-r--r--   0 runner    (1001) docker     (123)    54207 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/status/test_store_api_status_cases.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1134 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/status/test_store_api_status_customer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1548 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/status/test_store_api_status_pool.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8308 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/status/test_store_api_status_sample.py
+-rw-r--r--   0 runner    (1001) docker     (123)      471 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/test_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11972 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/api/test_store_import_func.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13302 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/conftest.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/store/filters/
+-rw-r--r--   0 runner    (1001) docker     (123)    15427 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_analyses_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5921 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_application_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11177 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_application_version_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1603 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_bed_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1298 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_bed_version_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27931 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_cases_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1330 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_collaboration_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)      710 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_customer_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4082 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_flow_cell_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2222 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_invoice_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2431 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_organism_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1807 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_panel_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9718 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_pool_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)    23340 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_samples_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1579 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/filters/test_status_user_filters.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2141 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/test_delivery.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4044 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store/test_store_models.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29709 2023-04-11 10:43:26.000000 cg-27.2.0/tests/store_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)      911 2023-04-11 10:43:26.000000 cg-27.2.0/tests/test_store_helpers.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/tests/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/tests/fixtures/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/tests/fixtures/apps/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/tests/fixtures/apps/demultiplexing/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/tests/fixtures/apps/demultiplexing/flowcell-runs/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/copycomplete.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/tests/fixtures/data/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/tests/fixtures/data/fastq.fastq.gz
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:38.000000 cg-27.2.0/tests/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-04-11 10:43:26.000000 cg-27.2.0/tests/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      829 2023-04-11 10:43:26.000000 cg-27.2.0/tests/utils/conftest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2919 2023-04-11 10:43:26.000000 cg-27.2.0/tests/utils/test_commands.py
+-rw-r--r--   0 runner    (1001) docker     (123)      953 2023-04-11 10:43:26.000000 cg-27.2.0/tests/utils/test_date.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1508 2023-04-11 10:43:26.000000 cg-27.2.0/tests/utils/test_dict.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7368 2023-04-11 10:43:26.000000 cg-27.2.0/tests/utils/test_dispatcher.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1147 2023-04-11 10:43:26.000000 cg-27.2.0/tests/utils/test_utils.py
```

### Comparing `cg-27.1.9/PKG-INFO` & `cg-27.2.0/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: cg
-Version: 27.1.9
+Version: 27.2.0
 Summary: Clinical Genomics command center
 Home-page: https://github.com/Clinical-Genomics/cg
 Author: Clinical Genomics
 Author-email: support@clinicalgenomics.se
 License: UNKNOWN
 Description: 
         # cg
```

### Comparing `cg-27.1.9/README.md` & `cg-27.2.0/README.md`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/crud/create.py` & `cg-27.2.0/cg/apps/cgstats/crud/create.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/crud/delete.py` & `cg-27.2.0/cg/apps/cgstats/crud/delete.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/crud/find.py` & `cg-27.2.0/cg/apps/cgstats/crud/find.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/backup.py` & `cg-27.2.0/cg/apps/cgstats/db/models/backup.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/backup_tape.py` & `cg-27.2.0/cg/apps/cgstats/db/models/backup_tape.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/base.py` & `cg-27.2.0/cg/apps/cgstats/db/models/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/datasource.py` & `cg-27.2.0/cg/apps/cgstats/db/models/datasource.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/demux.py` & `cg-27.2.0/cg/apps/cgstats/db/models/demux.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/flowcell.py` & `cg-27.2.0/cg/apps/cgstats/db/models/flowcell.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/project.py` & `cg-27.2.0/cg/apps/cgstats/db/models/project.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 from typing import Optional
 
-from sqlalchemy import Column, ForeignKey, UniqueConstraint, orm, types
+from sqlalchemy import Column, orm, types
 from sqlalchemy.orm.exc import NoResultFound
 
 from .base import Model
 
 
 class Project(Model):
     project_id = Column(types.Integer, primary_key=True)
```

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/sample.py` & `cg-27.2.0/cg/apps/cgstats/db/models/sample.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/support_params.py` & `cg-27.2.0/cg/apps/cgstats/db/models/support_params.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/unaligned.py` & `cg-27.2.0/cg/apps/cgstats/db/models/unaligned.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/db/models/version.py` & `cg-27.2.0/cg/apps/cgstats/db/models/version.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/demux_sample.py` & `cg-27.2.0/cg/apps/cgstats/demux_sample.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/dragen_demux_sample.py` & `cg-27.2.0/cg/apps/cgstats/dragen_demux_sample.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/parsers/adapter_metrics.py` & `cg-27.2.0/cg/apps/cgstats/parsers/adapter_metrics.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/parsers/conversion_stats.py` & `cg-27.2.0/cg/apps/cgstats/parsers/conversion_stats.py`

 * *Files 2% similar despite different names*

```diff
@@ -92,15 +92,14 @@
     def parse_file(self) -> None:
         """Parse a file with demux conversion stats information"""
         event: str
         node: Element
         LOG.info("Parsing demux conversion stats file %s", self.conversion_stats_path)
         for event, node in iterparse(str(self.conversion_stats_path), ["start", "end"]):
             # Only search nodes when correct
-            # print("Path", self.current_path, self._current_barcode)
             current_tag: str = self.get_current_tag(node=node)
             if event == "start":
                 self.evaluate_start_event(node=node, current_tag=current_tag)
                 continue
 
             if not self._skip_entry:
                 self.evaluate_end_event(node=node, current_tag=current_tag)
@@ -150,16 +149,14 @@
         LOG.debug("Creating unknown barcode entry for lane %s", self._current_lane)
         lane_results: List[UnknownBarcode] = copy.deepcopy(self.unknown_barcodes)
         self.lanes_to_unknown_barcode[self._current_lane] = lane_results
         self.unknown_barcodes = []
         self.unknown_barcodes_entry = False
 
     def evaluate_start_event(self, node: Element, current_tag: str) -> None:
-        # print("Start!", current_tag, node, node.attrib, node.text)
-
         LOG.debug("Add start event %s to current path", current_tag)
         self.current_path.append(current_tag)
         if current_tag == "Lane":
             self.set_current_lane(lane_nr=int(node.attrib["number"]))
         elif current_tag == "Sample":
             sample_name: str = node.attrib["name"]
             if "indexcheck" in sample_name:
```

### Comparing `cg-27.1.9/cg/apps/cgstats/parsers/demux_stats.py` & `cg-27.2.0/cg/apps/cgstats/parsers/demux_stats.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/parsers/dragen_demultiplexing_stats.py` & `cg-27.2.0/cg/apps/cgstats/parsers/dragen_demultiplexing_stats.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/parsers/quality_metrics.py` & `cg-27.2.0/cg/apps/cgstats/parsers/quality_metrics.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/parsers/run_info.py` & `cg-27.2.0/cg/apps/cgstats/parsers/run_info.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/cgstats/stats.py` & `cg-27.2.0/cg/apps/cgstats/stats.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/coverage/api.py` & `cg-27.2.0/cg/apps/coverage/api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/crunchy/crunchy.py` & `cg-27.2.0/cg/apps/crunchy/crunchy.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/crunchy/files.py` & `cg-27.2.0/cg/apps/crunchy/files.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/crunchy/sbatch.py` & `cg-27.2.0/cg/apps/crunchy/sbatch.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/demultiplex/demultiplex_api.py` & `cg-27.2.0/cg/apps/demultiplex/demultiplex_api.py`

 * *Files 8% similar despite different names*

```diff
@@ -139,32 +139,14 @@
         LOG.info(f"Check if demultiplexing is ready for {flow_cell.path}")
         logfile: Path = self.get_stderr_logfile(flow_cell)
         if not logfile.exists():
             LOG.warning("Could not find logfile!")
             return False
         return self.demultiplexing_completed_path(flow_cell).exists()
 
-    def is_demultiplexing_ongoing(self, flow_cell: FlowCell) -> bool:
-        """Check if demultiplexing is ongoing.
-
-        This is indicated by if the file demuxstarted.txt exists in the flow cell directory
-        AND
-        that the demultiplexing completed file does not exist.
-        """
-        LOG.debug("Check if demultiplexing is ongoing for %s", flow_cell.id)
-        if not flow_cell.demultiplexing_started_path.exists():
-            LOG.debug("Demultiplexing has not been started")
-            return False
-        LOG.debug("Demultiplexing has been started!")
-        if self.is_demultiplexing_completed(flow_cell):
-            LOG.debug(f"Demultiplexing is already completed for flow cell {flow_cell.id}")
-            return False
-        LOG.debug("Demultiplexing is not finished!")
-        return True
-
     def is_demultiplexing_possible(self, flow_cell: FlowCell) -> bool:
         """Check if it is possible to start demultiplexing.
 
         This means that
             - flow cell should be ready for demultiplexing (all files in place)
             - sample sheet needs to exist
             - demultiplexing should not be running
```

### Comparing `cg-27.1.9/cg/apps/demultiplex/demux_report.py` & `cg-27.2.0/cg/apps/demultiplex/demux_report.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/demultiplex/sample_sheet/create.py` & `cg-27.2.0/cg/apps/demultiplex/sample_sheet/create.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/demultiplex/sample_sheet/dummy_sample.py` & `cg-27.2.0/cg/apps/demultiplex/sample_sheet/dummy_sample.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/demultiplex/sample_sheet/index.py` & `cg-27.2.0/cg/apps/demultiplex/sample_sheet/index.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/demultiplex/sample_sheet/novaseq_sample_sheet.py` & `cg-27.2.0/cg/apps/demultiplex/sample_sheet/novaseq_sample_sheet.py`

 * *Files 2% similar despite different names*

```diff
@@ -37,19 +37,14 @@
         self.run_parameters: RunParameters = run_parameters
         self.force = force
 
     @property
     def valid_indexes(self) -> List[Index]:
         return index.get_valid_indexes(dual_indexes_only=True)
 
-    @staticmethod
-    def get_project_name(project: str) -> str:
-        """Only keeps the first part of the project name"""
-        return project.split()[0]
-
     def add_dummy_samples(self) -> None:
         """Add all dummy samples with non existing indexes to samples
 
         dummy samples are added if there are indexes that are not used by the actual samples.
         This means that we will add each dummy sample (that is needed) to each lane
         """
         LOG.info("Adding dummy samples for unused indexes")
```

### Comparing `cg-27.1.9/cg/apps/demultiplex/sbatch.py` & `cg-27.2.0/cg/apps/demultiplex/sbatch.py`

 * *Files 2% similar despite different names*

```diff
@@ -26,22 +26,22 @@
 log "bcl2fastq finished!"
 """,
     "dragen": """
 log "dragen --bcl-conversion-only true \
 --bcl-input-directory {run_dir} \
 --output-directory {unaligned_dir} \
 --bcl-sampleproject-subdirectories true \
---force   
+--force
 touch {demux_completed_file}"
 
 dragen --bcl-conversion-only true \
 --bcl-input-directory {run_dir} \
 --output-directory {unaligned_dir} \
 --bcl-sampleproject-subdirectories true \
---force   
+--force
 touch {demux_completed_file}
 log "Dragen BCL Convert finished!"
 """,
 }
 # This needs flow cell id, email. logfile
 DEMULTIPLEX_ERROR = """
 mail -s 'ERROR demultiplexing of {flow_cell_id}' {email} < '{logfile}'
```

### Comparing `cg-27.1.9/cg/apps/gens.py` & `cg-27.2.0/cg/apps/gens.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,12 @@
 """Module for Gens API."""
 
 import logging
-from pathlib import Path
-from subprocess import CalledProcessError
-from typing import Optional, Dict, List
+from typing import Dict, List
 
-from cg.constants.constants import FileFormat
-from cg.exc import CaseNotFoundError
-from cg.io.controller import ReadStream
 from cg.utils import Process
 from cg.utils.dict import get_list_from_dictionary
 
 LOG = logging.getLogger(__name__)
 
 
 class GensAPI:
```

### Comparing `cg-27.1.9/cg/apps/gt.py` & `cg-27.2.0/cg/apps/gt.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/hermes/hermes_api.py` & `cg-27.2.0/cg/apps/hermes/hermes_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/hermes/models.py` & `cg-27.2.0/cg/apps/hermes/models.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/housekeeper/hk.py` & `cg-27.2.0/cg/apps/housekeeper/hk.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,15 +2,14 @@
 import datetime as dt
 import logging
 import os
 from pathlib import Path
 from typing import Iterable, List, Optional, Set, Tuple, Dict
 
 from alchy import Query
-from housekeeper.exc import VersionIncludedError
 from housekeeper.include import checksum as hk_checksum
 from housekeeper.include import include_version
 from housekeeper.store import Store, models
 from housekeeper.store.models import Bundle, File, Version
 
 from cg.constants import SequencingFileTag
 from cg.exc import HousekeeperBundleVersionMissingError
@@ -35,15 +34,15 @@
 
     def add_bundle(self, bundle_data) -> Tuple[Bundle, Version]:
         """Build a new bundle version of files."""
         return self._store.add_bundle(bundle_data)
 
     def bundle(self, name: str) -> Bundle:
         """Fetch a bundle."""
-        return self._store.bundle(name)
+        return self._store.get_bundle_by_name(bundle_name=name)
 
     def bundles(self) -> List[Bundle]:
         """Fetch bundles."""
         return self._store.bundles()
 
     def create_new_bundle_and_version(self, name: str) -> Bundle:
         """Create new bundle with version."""
@@ -67,15 +66,15 @@
         if tags is None:
             tags = []
         return self._store.new_file(path, checksum, to_archive, tags)
 
     def get_file(self, file_id: int) -> Optional[File]:
         """Get a file based on file id."""
         LOG.info("Fetching file %s", file_id)
-        file_obj: File = self._store.file_(file_id)
+        file_obj: File = self._store.get_file_by_id(file_id=file_id)
         if not file_obj:
             LOG.info("file not found")
             return None
         return file_obj
 
     def delete_file(self, file_id: int) -> Optional[File]:
         """Delete a file both from database and disk (if included)."""
@@ -120,30 +119,43 @@
         *,
         bundle: str = None,
         tags: List[str] = None,
         version: int = None,
         path: str = None,
     ) -> Query:
         """Fetch files."""
-        return self._store.files(bundle=bundle, tags=tags, version=version, path=path)
+        return self._store.get_files(
+            bundle_name=bundle, tag_names=tags, version_id=version, file_path=path
+        )
 
     @staticmethod
-    def fetch_file_from_version(version_obj: Version, tags: Set[str]) -> Optional[File]:
-        """Fetch file that includes at least all tags in 'tags'.
-
-        Return None if no file could be found.
-        """
-        LOG.debug("Fetch files from version with tags %s", tags)
-        for file_obj in version_obj.files:
-            tag: models.Tag
-            file_tags = {tag.name for tag in file_obj.tags}
+    def get_files_from_version(version: Version, tags: Set[str]) -> Optional[List[File]]:
+        """Return a list of files associated with the given version and tags."""
+        LOG.debug(f"Getting files from version with tags {tags}")
+        files: List[File] = []
+        for file in list(version.files):
+            file_tags = {tag.name for tag in file.tags}
             if tags.issubset(file_tags):
-                LOG.debug("Found file %s", file_obj)
-                return file_obj
-        LOG.info("Could not find any files matching the tags")
+                LOG.debug(f"Found file {file}")
+                files.append(file)
+        if not files:
+            LOG.warning(f"Could not find any files matching the tags {tags}")
+        return files
+
+    @staticmethod
+    def get_file_from_version(version: Version, tags: Set[str]) -> Optional[File]:
+        """Return the first file matching the given tags."""
+        files: List[File] = HousekeeperAPI.get_files_from_version(version=version, tags=tags)
+        return files[0] if files else None
+
+    @staticmethod
+    def get_latest_file_from_version(version: Version, tags: Set[str]) -> Optional[File]:
+        """Return the latest file from Housekeeper given its version and tags."""
+        files: List[File] = HousekeeperAPI.get_files_from_version(version=version, tags=tags)
+        return sorted(files, key=lambda file_obj: file_obj.id)[-1] if files else None
 
     def rollback(self):
         """Wrap method in Housekeeper Store."""
         return self._store.rollback()
 
     def session_no_autoflush(self):
         """Wrap property in Housekeeper Store."""
@@ -151,15 +163,22 @@
 
     def get_files(
         self, bundle: str, tags: Optional[list] = None, version: Optional[int] = None
     ) -> Iterable[File]:
         """Get all the files in housekeeper, optionally filtered by bundle and/or tags and/or
         version.
         """
-        return self._store.files(bundle=bundle, tags=tags, version=version)
+        return self._store.get_files(bundle_name=bundle, tag_names=tags, version_id=version)
+
+    def get_latest_file(
+        self, bundle: str, tags: Optional[list] = None, version: Optional[int] = None
+    ) -> Optional[File]:
+        """Return latest file from Housekeeper, filtered by bundle and/or tags and/or version."""
+        files: Query = self._store.get_files(bundle_name=bundle, tag_names=tags, version_id=version)
+        return files.order_by(File.id.desc()).first()
 
     def check_bundle_files(
         self,
         bundle_name: str,
         file_paths: List[Path],
         last_version: Version,
         tags: Optional[list] = None,
@@ -194,29 +213,32 @@
         if file_obj.to_archive:
             # calculate sha1 checksum if file is to be archived
             file_obj.checksum = HousekeeperAPI.checksum(file_obj.path)
         if new_path.exists():
             LOG.warning(
                 f"Another file with identical included file path: {new_path} already exist. Skip linking of: {file_obj.path}"
             )
+            file_obj.path = str(new_path).replace(f"{global_root_dir}/", "", 1)
             return file_obj
         # hardlink file to the internal structure
         os.link(file_obj.path, new_path)
         LOG.info(f"Linked file: {file_obj.path} -> {new_path}")
-        file_obj.path: str = str(new_path).replace(f"{global_root_dir}/", "", 1)
+        file_obj.path = str(new_path).replace(f"{global_root_dir}/", "", 1)
         return file_obj
 
     def new_version(self, created_at: dt.datetime, expires_at: dt.datetime = None) -> Version:
         """Create a new bundle version."""
         return self._store.new_version(created_at, expires_at)
 
     def version(self, bundle: str, date: dt.datetime) -> Version:
         """Fetch a version."""
         LOG.info("Fetch version %s from bundle %s", date, bundle)
-        return self._store.version(bundle, date)
+        return self._store.get_version_by_date_and_bundle_name(
+            bundle_name=bundle, version_date=date
+        )
 
     def last_version(self, bundle: str) -> Version:
         """Gets the latest version of a bundle."""
         LOG.info(f"Fetch latest version from bundle {bundle}")
         return (
             self._store.Version.query.join(Version.bundle)
             .filter(Bundle.name == bundle)
```

### Comparing `cg-27.1.9/cg/apps/invoice/render.py` & `cg-27.2.0/cg/apps/invoice/render.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/invoice/templates/KI_pool_invoice.xlsx` & `cg-27.2.0/cg/apps/invoice/templates/KI_pool_invoice.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/invoice/templates/KI_sample_invoice.xlsx` & `cg-27.2.0/cg/apps/invoice/templates/KI_sample_invoice.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/invoice/templates/KTH_pool_invoice.xlsx` & `cg-27.2.0/cg/apps/invoice/templates/KTH_pool_invoice.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/invoice/templates/KTH_sample_invoice.xlsx` & `cg-27.2.0/cg/apps/invoice/templates/KTH_sample_invoice.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/lims/api.py` & `cg-27.2.0/cg/apps/lims/api.py`

 * *Files 3% similar despite different names*

```diff
@@ -88,19 +88,14 @@
                 int(udfs["Application Tag Version"])
                 if udfs.get("Application Tag Version")
                 else None
             ),
             "comment": udfs.get("comment"),
         }
 
-    @staticmethod
-    def _export_artifact(lims_artifact):
-        """Get data from a LIMS artifact."""
-        return {"id": lims_artifact.id, "name": lims_artifact.name}
-
     def get_received_date(self, lims_id: str) -> dt.date:
         """Get the date when a sample was received."""
 
         sample = Sample(self, id=lims_id)
         try:
             date = sample.udf.get("Received at")
         except HTTPError:
@@ -123,24 +118,14 @@
         sample = Sample(self, id=lims_id)
         try:
             date = sample.udf.get("Delivered at")
         except HTTPError:
             date = None
         return date
 
-    def get_sequenced_date(self, lims_id: str) -> dt.date:
-        """Get the date when a sample was sequenced."""
-
-        sample = Sample(self, id=lims_id)
-        try:
-            date = sample.udf.get("Sequencing Finished")
-        except HTTPError:
-            date = None
-        return date
-
     def capture_kit(self, lims_id: str) -> str:
         """Get capture kit for a LIMS sample."""
 
         step_names_udfs = MASTER_STEPS_UDFS["capture_kit_step"]
         capture_kits = set()
 
         lims_sample = Sample(self, id=lims_id)
@@ -210,21 +195,14 @@
         family_data["panels"] = list(panels)
         return family_data
 
     def process(self, process_id: str) -> Process:
         """Get LIMS process."""
         return Process(self, id=process_id)
 
-    @staticmethod
-    def process_samples(lims_process: Process) -> Generator[str, None, None]:
-        """Retrieve LIMS input samples from a process."""
-        for lims_artifact in lims_process.all_inputs():
-            for lims_sample in lims_artifact.samples:
-                yield lims_sample.id
-
     def update_sample(
         self, lims_id: str, sex=None, target_reads: int = None, name: str = None, **kwargs
     ):
         """Update information about a sample."""
         lims_sample = Sample(self, id=lims_id)
 
         if sex:
@@ -251,80 +229,41 @@
         sample = Sample(self, id=lims_id)
         if not PROP2UDF.get(key):
             raise LimsDataError(
                 f"Unknown how to get {key} from LIMS since it is not defined in " f"{PROP2UDF}"
             )
         return sample.udf[PROP2UDF[key]]
 
-    def update_project(self, lims_id: str, name: str = None) -> None:
-        """Update information about a project."""
-        lims_project = Project(self, id=lims_id)
-        if name:
-            lims_project.name = name
-            lims_project.put()
-
     def get_prep_method(self, lims_id: str) -> str:
         """Get the library preparation method."""
 
         step_names_udfs = MASTER_STEPS_UDFS["prep_method_step"]
 
         return self._get_methods(step_names_udfs, lims_id)
 
     def get_sequencing_method(self, lims_id: str) -> str:
         """Get the sequencing method."""
 
         step_names_udfs = MASTER_STEPS_UDFS["sequencing_method_step"]
 
         return self._get_methods(step_names_udfs, lims_id)
 
-    def get_delivery_method(self, lims_id: str) -> str:
-        """Get the delivery method."""
-
-        step_names_udfs = MASTER_STEPS_UDFS["delivery_method_step"]
-
-        return self._get_methods(step_names_udfs, lims_id)
-
-    def get_processing_time(self, lims_id: str) -> Optional[dt.timedelta]:
-        """Get the time it takes to process a sample"""
-        received_at = self.get_received_date(lims_id)
-        delivery_date = self.get_delivery_date(lims_id)
-        if received_at and delivery_date:
-            return delivery_date - received_at
-        return None
-
     @staticmethod
     def _sort_by_date_run(sort_list: list):
         """
         Sort list of tuples by parent process attribute date_run in descending order.
 
         Parameters:
             sort_list (list): a list of tuples in the format (date_run, elem1, elem2, ...)
 
         Returns:
             sorted list of tuples
         """
         return sorted(sort_list, key=lambda sort_tuple: sort_tuple[0], reverse=True)
 
-    def _most_recent_date(self, dates: list):
-        """
-        Gets the most recent date from a list of dates sorted by date_run
-
-        Parameters:
-            dates (list): a list of tuples in the format (date_run, date), sorted by date_run
-                descending
-
-        Returns:
-            The date in the first tuple in dates
-        """
-        sorted_dates = self._sort_by_date_run(dates)
-        date_run_index = 0
-        date_index = 1
-
-        return sorted_dates[date_run_index][date_index] if dates else None
-
     def _get_methods(self, step_names_udfs, lims_id):
         """
         Gets the method, method number and method version for a given list of step names for AM documents.
         Only method name and Atlas version is returned if Atlas documentation instead has been used.
         """
         methods = []
```

### Comparing `cg-27.1.9/cg/apps/lims/batch.py` & `cg-27.2.0/cg/apps/lims/batch.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 from functools import partial
 from typing import Any, Dict, List
 
-from genologics.entities import Artifact, Container, Containertype, Project, Researcher
-from lxml import etree
+from genologics.entities import Artifact, Container, Containertype, Project
 from lxml.objectify import ElementMaker, ObjectifiedElement
 
 SMP_MAKER = ElementMaker(
     namespace="http://genologics.com/ri/sample",
     nsmap={"smp": "http://genologics.com/ri/sample", "udf": "http://genologics.com/ri/userdefined"},
 )
 SMP_DETAILS = partial(SMP_MAKER, "details")
```

### Comparing `cg-27.1.9/cg/apps/lims/order.py` & `cg-27.2.0/cg/apps/lims/order.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/lims/samplesheet.py` & `cg-27.2.0/cg/apps/lims/samplesheet.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/loqus.py` & `cg-27.2.0/cg/apps/loqus.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/madeline/api.py` & `cg-27.2.0/cg/apps/madeline/api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/mip/confighandler.py` & `cg-27.2.0/cg/apps/mip/confighandler.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/mutacc_auto.py` & `cg-27.2.0/cg/apps/mutacc_auto.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/orderform/excel_orderform_parser.py` & `cg-27.2.0/cg/apps/orderform/excel_orderform_parser.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/orderform/json_orderform_parser.py` & `cg-27.2.0/cg/apps/orderform/json_orderform_parser.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/orderform/orderform_parser.py` & `cg-27.2.0/cg/apps/orderform/orderform_parser.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/osticket.py` & `cg-27.2.0/cg/apps/osticket.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/scout/scout_export.py` & `cg-27.2.0/cg/apps/scout/scout_export.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/scout/scoutapi.py` & `cg-27.2.0/cg/apps/scout/scoutapi.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,15 +21,15 @@
     """Interface to Scout."""
 
     def __init__(self, config):
         binary_path = config["scout"]["binary_path"]
         config_path = config["scout"]["config_path"]
         self.process = Process(binary=binary_path, config=config_path)
 
-    def upload(self, scout_load_config: Path, threshold: int = 5, force: bool = False):
+    def upload(self, scout_load_config: Path, force: bool = False):
         """Load analysis of a new family into Scout."""
 
         scout_config: dict = ReadFile.get_content_from_file(
             file_format=FileFormat.YAML, file_path=scout_load_config
         )
         scout_load_config_object: ScoutLoadConfig = ScoutLoadConfig(**scout_config)
         existing_case: Optional[ScoutExportCase] = self.get_case(
```

### Comparing `cg-27.1.9/cg/apps/slurm/sbatch.py` & `cg-27.2.0/cg/apps/slurm/sbatch.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/slurm/slurm_api.py` & `cg-27.2.0/cg/apps/slurm/slurm_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/tb/api.py` & `cg-27.2.0/cg/apps/tb/api.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 """ Trailblazer API for cg """ ""
 import datetime
 import datetime as dt
 import logging
 from typing import Any, Optional
 
-import requests
 from google.auth import jwt
 from google.auth.crypt import RSASigner
 
 from cg.apps.tb.models import TrailblazerAnalysis
 from cg.constants import Pipeline
 from cg.constants.constants import FileFormat, APIMethods
 from cg.constants.priority import SlurmQos
```

### Comparing `cg-27.1.9/cg/apps/tb/models.py` & `cg-27.2.0/cg/apps/tb/models.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/apps/vogue.py` & `cg-27.2.0/cg/apps/vogue.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/add.py` & `cg-27.2.0/cg/cli/add.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,20 +6,21 @@
 from cg.constants.subject import Gender
 from cg.meta.transfer.external_data import ExternalDataAPI
 from cg.models.cg_config import CGConfig
 from cg.store import Store
 from cg.utils.click.EnumChoice import EnumChoice
 from cg.store.models import (
     Family,
+    FamilySample,
     Sample,
-    Customer,
     User,
     Collaboration,
     Customer,
     Application,
+    ApplicationVersion,
     Panel,
 )
 
 from cg.constants import Priority
 
 LOG = logging.getLogger(__name__)
 
@@ -63,15 +64,17 @@
     invoice_address: str,
     invoice_reference: str,
 ):
     """Add a new customer with a unique internal id and name."""
     collaboration_internal_ids = collaboration_internal_ids or []
     status_db: Store = context.status_db
 
-    existing_customer: Customer = status_db.get_customer_by_customer_id(customer_id=internal_id)
+    existing_customer: Customer = status_db.get_customer_by_internal_id(
+        customer_internal_id=internal_id
+    )
     if existing_customer:
         LOG.error(f"{existing_customer.name}: customer already added")
         raise click.Abort
 
     collaborations: List[Collaboration] = [
         status_db.get_collaboration_by_internal_id(internal_id=collaboration_internal_id)
         for collaboration_internal_id in collaboration_internal_ids
@@ -102,15 +105,15 @@
 @click.argument("email")
 @click.argument("name")
 @click.pass_obj
 def user(context: CGConfig, admin: bool, customer_id: str, email: str, name: str):
     """Add a new user with an EMAIL (login) and a NAME (full)."""
     status_db: Store = context.status_db
 
-    customer_obj: Customer = status_db.get_customer_by_customer_id(customer_id=customer_id)
+    customer_obj: Customer = status_db.get_customer_by_internal_id(customer_internal_id=customer_id)
     existing_user: User = status_db.get_user_by_email(email=email)
     if existing_user:
         LOG.error(f"{existing_user.name}: user already added")
         raise click.Abort
 
     new_user: User = status_db.add_user(
         customer=customer_obj, email=email, name=name, is_admin=admin
@@ -153,15 +156,15 @@
     priority: Priority,
     customer_id: str,
     name: str,
 ):
     """Add a sample for CUSTOMER_ID with a NAME (display)."""
     status_db: Store = context.status_db
 
-    customer: Customer = status_db.get_customer_by_customer_id(customer_id=customer_id)
+    customer: Customer = status_db.get_customer_by_internal_id(customer_internal_id=customer_id)
     if not customer:
         LOG.error(f"Customer: {customer_id} not found")
         raise click.Abort
     application: Application = status_db.get_application_by_tag(tag=application_tag)
     if not application:
         LOG.error(f"Application: {application_tag} not found")
 
@@ -170,16 +173,18 @@
         name=name,
         sex=sex,
         downsampled_to=down_sampled,
         internal_id=lims_id,
         order=order,
         priority=priority,
     )
-    new_record.application_version = status_db.current_application_version(application_tag)
-    new_record.customer = customer
+    new_record.application_version: ApplicationVersion = (
+        status_db.get_current_application_version_by_tag(tag=application_tag)
+    )
+    new_record.customer: Customer = customer
     status_db.add_commit(new_record)
     LOG.info(f"{new_record.internal_id}: new sample added")
 
 
 @add.command()
 @click.option(
     "--priority",
@@ -217,15 +222,15 @@
     customer_id: str,
     name: str,
     ticket: str,
 ):
     """Add a case with the given name and associated with the given customer"""
     status_db: Store = context.status_db
 
-    customer: Customer = status_db.get_customer_by_customer_id(customer_id=customer_id)
+    customer: Customer = status_db.get_customer_by_internal_id(customer_internal_id=customer_id)
     if customer is None:
         LOG.error(f"{customer_id}: customer not found")
         raise click.Abort
 
     for panel_abbreviation in panel_abbreviations:
         panel: Panel = status_db.get_panel_by_abbreviation(abbreviation=panel_abbreviation)
 
@@ -238,15 +243,15 @@
         data_delivery=data_delivery,
         name=name,
         panels=list(panel_abbreviations),
         priority=priority,
         ticket=ticket,
     )
 
-    new_case.customer = customer
+    new_case.customer: Customer = customer
     status_db.add_commit(new_case)
     LOG.info(f"{new_case.internal_id}: new case added")
 
 
 @add.command()
 @click.option("-m", "--mother-id", help="Sample ID for mother of sample")
 @click.option("-f", "--father-id", help="Sample ID for father of sample")
@@ -262,15 +267,15 @@
     case_id: str,
     sample_id: str,
 ):
     """Create a link between a case id and a sample id."""
     status_db: Store = context.status_db
     mother: Optional[Sample] = None
     father: Optional[Sample] = None
-    case_obj: Family = status_db.family(case_id)
+    case_obj: Family = status_db.get_case_by_internal_id(internal_id=case_id)
     if case_obj is None:
         LOG.error("%s: family not found", case_id)
         raise click.Abort
 
     sample: Sample = status_db.get_sample_by_internal_id(internal_id=sample_id)
     if sample is None:
         LOG.error("%s: sample not found", sample_id)
@@ -284,15 +289,15 @@
 
     if father_id:
         father: Sample = status_db.get_sample_by_internal_id(internal_id=father_id)
         if father is None:
             LOG.error("%s: father not found", father_id)
             raise click.Abort
 
-    new_record = status_db.relate_sample(
+    new_record: FamilySample = status_db.relate_sample(
         family=case_obj, sample=sample, status=status, mother=mother, father=father
     )
     status_db.add_commit(new_record)
     LOG.info("related %s to %s", case_obj.internal_id, sample.internal_id)
 
 
 @add.command()
```

### Comparing `cg-27.1.9/cg/cli/backup.py` & `cg-27.2.0/cg/cli/backup.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/base.py` & `cg-27.2.0/cg/cli/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/clean.py` & `cg-27.2.0/cg/cli/clean.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 """cg module for cleaning databases and files."""
 import logging
 from datetime import datetime, timedelta
 from pathlib import Path
 from typing import List, Optional
+from cg.utils.dispatcher import Dispatcher
 
 import click
 from alchy import Query
 from cgmodels.cg.constants import Pipeline
 from housekeeper.store.models import File, Version
 from tabulate import tabulate
 
@@ -36,15 +37,15 @@
 from cg.utils.date import get_timedelta_from_date, get_date_days_ago
 from cg.exc import FlowCellError, HousekeeperBundleVersionMissingError
 from cg.meta.clean.api import CleanAPI
 from cg.meta.clean.demultiplexed_flow_cells import DemultiplexedRunsFlowCell
 from cg.meta.clean.flow_cell_run_directories import RunDirFlowCell
 from cg.models.cg_config import CGConfig
 from cg.store import Store
-from cg.store.models import Sample, Flowcell
+from cg.store.models import Sample, Flowcell, Analysis
 
 CHECK_COLOR = {True: "green", False: "red"}
 LOG = logging.getLogger(__name__)
 FLOW_CELL_OUTPUT_HEADERS = [
     "Flow cell run name",
     "Flow cell id",
     "Correct name?",
@@ -194,17 +195,31 @@
     """Remove files found in Housekeeper bundles."""
 
     housekeeper_api: HousekeeperAPI = context.housekeeper_api
     status_db: Store = context.status_db
 
     date_threshold: datetime = get_date_days_ago(days_ago=days_old)
 
-    analyses: Query = status_db.get_analyses_before_date(
-        case_id=case_id, before=date_threshold, pipeline=pipeline
+    function_dispatcher: Dispatcher = Dispatcher(
+        functions=[
+            status_db.get_analyses_started_at_before,
+            status_db.get_analyses_for_case_and_pipeline_started_at_before,
+            status_db.get_analyses_for_pipeline_started_at_before,
+            status_db.get_analyses_for_case_started_at_before,
+        ],
+        input_dict={
+            "case_internal_id": case_id,
+            "pipeline": pipeline,
+            "started_at_before": date_threshold,
+        },
     )
+    analyses: List[Analysis] = function_dispatcher(
+        {"case_internal_id": case_id, "pipeline": pipeline, "started_at_before": date_threshold}
+    )
+
     size_cleaned: int = 0
     for analysis in analyses:
         LOG.info(f"Cleaning analysis {analysis}")
         bundle_name: str = analysis.family.internal_id
         hk_bundle_version: Optional[Version] = housekeeper_api.version(
             bundle=bundle_name, date=analysis.started_at
         )
```

### Comparing `cg-27.1.9/cg/cli/compress/base.py` & `cg-27.2.0/cg/cli/compress/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/compress/fastq.py` & `cg-27.2.0/cg/cli/compress/fastq.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/compress/helpers.py` & `cg-27.2.0/cg/cli/compress/helpers.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,39 +12,39 @@
 from cg.constants.compression import CASES_TO_IGNORE, MAX_READS_PER_GB, CRUNCHY_MIN_GB_PER_PROCESS
 from cg.constants.slurm import Slurm
 from cg.utils.date import get_date_days_ago
 from cg.exc import CaseNotFoundError
 from cg.meta.compress import CompressAPI
 from cg.meta.compress.files import get_spring_paths
 from cg.store import Store
-from cg.store.models import Family, Sample
+from cg.store.models import Family
 
 LOG = logging.getLogger(__name__)
 
 
 def get_cases_to_process(
     days_back: int, store: Store, case_id: Optional[str] = None
 ) -> Optional[List[Family]]:
     """Return cases to process."""
     cases: List[Family] = []
     if case_id:
-        case: Family = store.family(case_id)
+        case: Family = store.get_case_by_internal_id(internal_id=case_id)
         if not case:
             LOG.warning(f"Could not find case {case_id}")
             return
         cases.append(case)
     else:
         date_threshold: dt.datetime = get_date_days_ago(days_ago=days_back)
         cases: List[Family] = store.get_cases_to_compress(date_threshold=date_threshold)
     return cases
 
 
 def get_fastq_individuals(store: Store, case_id: str = None) -> Iterator[str]:
     """Fetch individual ids from cases that are ready for SPRING compression"""
-    case_obj = store.family(case_id)
+    case_obj = store.get_case_by_internal_id(internal_id=case_id)
     if not case_obj:
         LOG.error("Could not find case %s", case_id)
         raise CaseNotFoundError("")
 
     for link_obj in case_obj.links:
         yield link_obj.sample.internal_id
```

### Comparing `cg-27.1.9/cg/cli/delete/case.py` & `cg-27.2.0/cg/cli/delete/case.py`

 * *Files 1% similar despite different names*

```diff
@@ -25,15 +25,15 @@
     The command will ask the user about deleting links between case and samples
     If a sample has its last link removed the command will ask about deleting the sample
     The command will not delete samples that has been processed (received etc.)
     The command will not delete a sample that has been marked as mother or father to another
     sample.
     """
     status_db: Store = context.obj.status_db
-    case: Family = status_db.family(case_id)
+    case: Family = status_db.get_case_by_internal_id(internal_id=case_id)
     if not case:
         LOG.error(f"Could not find case {case_id}")
         raise click.Abort
 
     if case.analyses:
         LOG.error(f"Can NOT delete case with analyses {case.analyses}")
         raise click.Abort
```

### Comparing `cg-27.1.9/cg/cli/delete/cases.py` & `cg-27.2.0/cg/cli/delete/cases.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/delete/observations.py` & `cg-27.2.0/cg/cli/delete/observations.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/deliver/base.py` & `cg-27.2.0/cg/cli/deliver/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -90,21 +90,21 @@
             delivery_type=delivery,
             force_all=force_all,
             ignore_missing_bundles=ignore_missing_bundles,
         )
         deliver_api.set_dry_run(dry_run)
         cases: List[Family] = []
         if case_id:
-            case_obj: Family = status_db.family(case_id)
+            case_obj: Family = status_db.get_case_by_internal_id(internal_id=case_id)
             if not case_obj:
                 LOG.warning("Could not find case %s", case_id)
                 return
             cases.append(case_obj)
         else:
-            cases: List[Family] = status_db.get_cases_from_ticket(ticket=ticket).all()
+            cases: List[Family] = status_db.get_cases_by_ticket_id(ticket_id=ticket)
             if not cases:
                 LOG.warning("Could not find cases for ticket %s", ticket)
                 return
 
         for case_obj in cases:
             deliver_api.deliver_files(case_obj=case_obj)
```

### Comparing `cg-27.1.9/cg/cli/demultiplex/add.py` & `cg-27.2.0/cg/cli/demultiplex/add.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/demultiplex/base.py` & `cg-27.2.0/cg/cli/demultiplex/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/demultiplex/demux.py` & `cg-27.2.0/cg/cli/demultiplex/demux.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/demultiplex/finish.py` & `cg-27.2.0/cg/cli/demultiplex/finish.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/demultiplex/report.py` & `cg-27.2.0/cg/cli/demultiplex/report.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/demultiplex/sample_sheet.py` & `cg-27.2.0/cg/cli/demultiplex/sample_sheet.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/export.py` & `cg-27.2.0/cg/cli/export.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/generate/report/base.py` & `cg-27.2.0/cg/cli/generate/report/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/generate/report/options.py` & `cg-27.2.0/cg/cli/generate/report/options.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/generate/report/utils.py` & `cg-27.2.0/cg/cli/generate/report/utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -26,15 +26,15 @@
     # Default report API (MIP DNA report API)
     report_api: ReportAPI = (
         context.obj.meta_apis.get("report_api")
         if context.obj.meta_apis.get("report_api")
         else MipDNAReportAPI(config=context.obj, analysis_api=MipDNAAnalysisAPI(config=context.obj))
     )
 
-    case: Family = report_api.status_db.family(case_id)
+    case: Family = report_api.status_db.get_case_by_internal_id(internal_id=case_id)
 
     # Missing or not valid internal case ID
     if not case_id or not case:
         LOG.warning("Invalid case ID. Retrieving available cases.")
 
         pipeline = (
             report_api.analysis_api.pipeline if context.obj.meta_apis.get("report_api") else None
@@ -107,17 +107,19 @@
 def get_report_analysis_started(
     case: Family, report_api: ReportAPI, analysis_started_at: Optional[str]
 ) -> datetime:
     """Resolves and returns a valid analysis date."""
 
     if not analysis_started_at:
         analysis_started_at: datetime = (
-            report_api.status_db.family(case.internal_id).analyses[0].started_at
+            report_api.status_db.get_case_by_internal_id(case.internal_id).analyses[0].started_at
         )
 
     # If there is no analysis for the provided date
-    if not report_api.status_db.analysis(case, analysis_started_at):
+    if not report_api.status_db.get_analysis_by_case_entry_id_and_started_at(
+        case_entry_id=case.id, started_at_date=analysis_started_at
+    ):
         LOG.error(f"There is no analysis started at {analysis_started_at}")
         raise click.Abort
 
     LOG.info("Using analysis started at: %s", analysis_started_at)
     return analysis_started_at
```

### Comparing `cg-27.1.9/cg/cli/get.py` & `cg-27.2.0/cg/cli/get.py`

 * *Files 4% similar despite different names*

```diff
@@ -73,15 +73,15 @@
 
 @get.command()
 @click.argument("case-id")
 @click.pass_obj
 def analysis(context: CGConfig, case_id: str):
     """Get information about case analysis."""
     status_db: Store = context.status_db
-    case: Family = status_db.family(case_id)
+    case: Family = status_db.get_case_by_internal_id(internal_id=case_id)
     if case is None:
         LOG.error(f"{case_id}: case doesn't exist")
         raise click.Abort
     LOG.debug(f"{case.internal_id}: get info about case analysis")
 
     for case_analysis in case.analyses:
         row = [
@@ -94,15 +94,15 @@
 
 @get.command()
 @click.argument("case-id")
 @click.pass_obj
 def relations(context: CGConfig, case_id: str):
     """Get information about case relations."""
     status_db: Store = context.status_db
-    case: Family = status_db.family(internal_id=case_id)
+    case: Family = status_db.get_case_by_internal_id(internal_id=case_id)
     if case is None:
         LOG.error(f"{case_id}: case doesn't exist")
         raise click.Abort
 
     LOG.debug(f"{case.internal_id}: get info about case relations")
 
     for case_link in case.links:
@@ -131,24 +131,24 @@
     analyses: bool,
     case_ids: List[str],
 ):
     """Get information about a case."""
     status_db: Store = context.obj.status_db
     status_db_cases: List[Family] = []
     if name:
-        customer: Customer = status_db.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = status_db.get_customer_by_internal_id(customer_internal_id=customer_id)
         if not customer:
             LOG.error(f"{customer_id}: customer not found")
             raise click.Abort
-        status_db_cases: Iterable[Family] = status_db.families(
-            customers=[customer], enquiry=case_ids[-1]
+        status_db_cases: Iterable[Family] = status_db.get_cases_by_customer_and_case_name_search(
+            customer=customer, case_name_search=case_ids[-1]
         )
     else:
         for case_id in case_ids:
-            existing_case: Family = status_db.family(internal_id=case_id)
+            existing_case: Family = status_db.get_case_by_internal_id(internal_id=case_id)
             if not existing_case:
                 LOG.error(f"{case_id}: case doesn't exist")
                 raise click.Abort
             status_db_cases.append(existing_case)
 
     for status_db_case in status_db_cases:
         LOG.debug(f"{status_db_case.internal_id}: get info about case")
```

### Comparing `cg-27.1.9/cg/cli/import_cmd.py` & `cg-27.2.0/cg/cli/import_cmd.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/set/base.py` & `cg-27.2.0/cg/cli/set/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -75,15 +75,15 @@
     kwargs: click.Tuple([str, str]),
     skip_lims: bool,
     yes: bool,
     case_id: str,
 ):
     """Set values on many samples at the same time."""
     store: Store = context.obj.status_db
-    sample_objs = _get_samples(case_id=case_id, identifiers=identifiers, store=store)
+    sample_objs: List[Sample] = _get_samples(case_id=case_id, identifiers=identifiers, store=store)
 
     if not sample_objs:
         LOG.error("No samples to alter!")
         context.abort()
 
     LOG.info("Would alter samples:")
 
@@ -104,15 +104,15 @@
     samples_by_case_id = None
     samples_by_id = None
 
     if case_id:
         samples_by_case_id: List[Sample] = store.get_samples_by_case_id(case_id=case_id)
 
     if identifiers:
-        samples_by_id = _get_samples_by_identifiers(identifiers, store)
+        samples_by_id: List[Sample] = _get_samples_by_identifiers(identifiers, store)
 
     if case_id and identifiers:
         sample_objs = set(set(samples_by_case_id) & set(samples_by_id))
     else:
         sample_objs = samples_by_case_id or samples_by_id
 
     return sample_objs
@@ -219,17 +219,21 @@
             new_value: str = value
 
         if key in ["customer", "application_version", "priority"]:
             if key == "priority":
                 if isinstance(value, str) and not value.isdigit():
                     new_key = "priority_human"
             elif key == "customer":
-                new_value: Customer = status_db.get_customer_by_customer_id(customer_id=value)
+                new_value: Customer = status_db.get_customer_by_internal_id(
+                    customer_internal_id=value
+                )
             elif key == "application_version":
-                new_value: ApplicationVersion = status_db.current_application_version(value)
+                new_value: ApplicationVersion = status_db.get_current_application_version_by_tag(
+                    tag=value
+                )
 
             if not new_value:
                 LOG.error(f"{key} {value} not found, aborting")
                 raise click.Abort
 
         old_value = getattr(sample, new_key)
```

### Comparing `cg-27.1.9/cg/cli/set/families.py` & `cg-27.2.0/cg/cli/set/families.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/set/family.py` & `cg-27.2.0/cg/cli/set/family.py`

 * *Files 2% similar despite different names*

```diff
@@ -86,15 +86,15 @@
 def abort_on_empty_options(options: List[str]) -> None:
     if not any(options):
         LOG.error("Nothing to change")
         raise click.Abort
 
 
 def get_case(case_id: str, status_db: Store) -> Family:
-    case: Family = status_db.family(case_id)
+    case: Family = status_db.get_case_by_internal_id(internal_id=case_id)
 
     if case is None:
         LOG.error(f"Can't find case {case_id}")
         raise click.Abort
 
     return case
 
@@ -102,15 +102,15 @@
 def update_action(case: Family, action: str) -> None:
     """Update case action."""
     LOG.info(f"Update action: {case.action or 'NA'} -> {action}")
     case.action = action
 
 
 def update_customer(case: Family, customer_id: str, status_db: Store) -> None:
-    customer_obj: Customer = status_db.get_customer_by_customer_id(customer_id=customer_id)
+    customer_obj: Customer = status_db.get_customer_by_internal_id(customer_internal_id=customer_id)
 
     if customer_obj is None:
         LOG.error("Unknown customer: %s", customer_id)
         raise click.Abort
 
     LOG.info(f"Update customer: {case.customer.internal_id} -> {customer_id}")
     case.customer = customer_obj
```

### Comparing `cg-27.1.9/cg/cli/status.py` & `cg-27.2.0/cg/cli/status.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,14 @@
-from typing import Iterable, List
+from typing import List
 
 import click
 from cg.constants import CASE_ACTIONS, Pipeline
 from cg.models.cg_config import CGConfig
 from cg.store import Store
-from cg.store.models import Family, Sample, Customer, ApplicationVersion, Analysis
+from cg.store.models import Family, Sample
 from ansi.colour import fg
 from ansi.colour.fx import reset
 from tabulate import tabulate
 
 from cg.constants import Priority
 
 from cg.utils.click.EnumChoice import EnumChoice
@@ -352,15 +352,15 @@
 
 @status.command()
 @click.option("-s", "--skip", default=0, help="skip initial records")
 @click.pass_obj
 def samples(context: CGConfig, skip: int):
     """View status of samples."""
     status_db: Store = context.status_db
-    records: List[Sample] = status_db.get_all_samples()[skip : skip + 30]
+    records: List[Sample] = status_db.get_samples()[skip : skip + 30]
     for record in records:
         message = f"{record.internal_id} ({record.customer.internal_id})"
         if record.sequenced_at:
             color = "green"
             message += f" [SEQUENCED: {record.sequenced_at.date()}]"
         elif record.received_at and record.reads:
             color = "orange"
@@ -377,15 +377,15 @@
 @status.command()
 @click.option("-s", "--skip", default=0, help="skip initial records")
 @click.pass_obj
 def families(context: CGConfig, skip: int):
     """View status of families."""
     click.echo("red: prio > 1, blue: prio = 1, green: completed, yellow: action")
     status_db: Store = context.status_db
-    records: List[Family] = status_db.families().offset(skip).limit(30)
+    records: List[Family] = status_db._get_query(table=Family).offset(skip).limit(30)
     for case_obj in records:
         color = "red" if case_obj.priority_int > 1 else "blue"
         message = f"{case_obj.internal_id} ({case_obj.priority_int})"
         if case_obj.analyses:
             message += f" {case_obj.analyses[0].completed_at.date()}"
             color = "green"
         if case_obj.action:
```

### Comparing `cg-27.1.9/cg/cli/store/fastq.py` & `cg-27.2.0/cg/cli/store/fastq.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/store/store.py` & `cg-27.2.0/cg/cli/store/store.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/transfer.py` & `cg-27.2.0/cg/cli/transfer.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/upload/base.py` & `cg-27.2.0/cg/cli/upload/base.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Code that handles CLI commands to upload"""
 import logging
 import sys
 import traceback
-from typing import Dict, Optional
+from typing import Optional
 
 import click
 
 from cg.cli.upload import vogue
 from cg.cli.upload.clinical_delivery import auto_fastq, clinical_delivery
 from cg.cli.upload.coverage import coverage
 from cg.cli.upload.delivery_report import upload_delivery_report_to_scout
@@ -60,15 +60,15 @@
     LOG.info("----------------- UPLOAD -----------------")
 
     if context.invoked_subcommand is not None:
         context.obj.meta_apis["upload_api"] = upload_api
     elif family_id:  # Provided case ID without a subcommand: upload everything
         try:
             upload_api.analysis_api.verify_case_id_in_statusdb(case_id=family_id)
-            case: Family = upload_api.status_db.family(family_id)
+            case: Family = upload_api.status_db.get_case_by_internal_id(internal_id=family_id)
             upload_api.verify_analysis_upload(case_obj=case, restart=restart)
         except AnalysisAlreadyUploadedError:
             # Analysis being uploaded or it has been already uploaded
             return
 
         # Update the upload API based on the data analysis type (MIP-DNA by default)
         # Upload for balsamic, balsamic-umi and balsamic-qc
```

### Comparing `cg-27.1.9/cg/cli/upload/clinical_delivery.py` & `cg-27.2.0/cg/cli/upload/clinical_delivery.py`

 * *Files 2% similar despite different names*

```diff
@@ -26,15 +26,15 @@
 @DRY_RUN
 def clinical_delivery(context: click.Context, case_id: str, dry_run: bool):
     """Links the appropriate files for a case, based on the data_delivery, to the customer folder
     and subsequently uses rsync to upload it to caesar."""
 
     click.echo(click.style("----------------- Clinical-delivery -----------------"))
 
-    case_obj: Family = context.obj.status_db.family(case_id)
+    case_obj: Family = context.obj.status_db.get_case_by_internal_id(internal_id=case_id)
     delivery_types: Set[str] = case_obj.get_delivery_arguments()
     is_sample_delivery: bool
     is_case_delivery: bool
     is_complete_delivery: bool
     job_id: int
     is_sample_delivery, is_case_delivery = DeliverAPI.get_delivery_scope(
         delivery_arguments=delivery_types
```

### Comparing `cg-27.1.9/cg/cli/upload/coverage.py` & `cg-27.2.0/cg/cli/upload/coverage.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 """Code for uploading coverage reports via CLI"""
 
 import click
 from cg.meta.upload.coverage import UploadCoverageApi
-from cg.meta.workflow.mip_dna import MipDNAAnalysisAPI
 from cg.models.cg_config import CGConfig
 from cg.store import Store
 from cg.store.models import Family
 
 from .utils import suggest_cases_to_upload
 
 
@@ -26,15 +25,15 @@
 
     status_db: Store = context.status_db
 
     if not family_id:
         suggest_cases_to_upload(status_db=status_db)
         raise click.Abort
 
-    case_obj: Family = status_db.family(family_id)
+    case_obj: Family = status_db.get_case_by_internal_id(internal_id=family_id)
     upload_coverage_api = UploadCoverageApi(
         status_api=status_db,
         hk_api=context.housekeeper_api,
         chanjo_api=context.chanjo_api,
     )
     coverage_data = upload_coverage_api.data(case_obj.analyses[0])
     upload_coverage_api.upload(coverage_data, replace=re_upload)
```

### Comparing `cg-27.1.9/cg/cli/upload/delivery_report.py` & `cg-27.2.0/cg/cli/upload/delivery_report.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/upload/fohm.py` & `cg-27.2.0/cg/cli/upload/fohm.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/upload/genotype.py` & `cg-27.2.0/cg/cli/upload/genotype.py`

 * *Files 10% similar despite different names*

```diff
@@ -32,15 +32,15 @@
     genotype_api: GenotypeAPI = context.genotype_api
 
     click.echo(click.style("----------------- GENOTYPES -------------------"))
 
     if not family_id:
         suggest_cases_to_upload(status_db=status_db)
         raise click.Abort
-    case_obj: Family = status_db.family(family_id)
+    case_obj: Family = status_db.get_case_by_internal_id(internal_id=family_id)
     upload_genotypes_api = UploadGenotypesAPI(hk_api=housekeeper_api, gt_api=genotype_api)
     results: dict = upload_genotypes_api.data(case_obj.analyses[0])
 
     if not results:
         LOG.warning("Could not find any results to upload")
         return
     upload_genotypes_api.upload(results, replace=re_upload)
```

### Comparing `cg-27.1.9/cg/cli/upload/gens.py` & `cg-27.2.0/cg/cli/upload/gens.py`

 * *Files 6% similar despite different names*

```diff
@@ -5,16 +5,16 @@
 import click
 from cg.apps.gens import GensAPI
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.constants.gene_panel import GENOME_BUILD_37
 from cg.constants.housekeeper_tags import GensAnalysisTag
 from cg.models.cg_config import CGConfig
 from cg.store import Store
-from cg.store.models import Family, Sample
-from housekeeper.store.models import File, Version
+from cg.store.models import Family
+from housekeeper.store.models import File
 
 from cg.cli.upload.utils import suggest_cases_to_upload
 from cg.cli.workflow.commands import (
     ARGUMENT_CASE_ID,
     OPTION_DRY,
 )
 
@@ -36,15 +36,15 @@
 
     gens_api.set_dry_run(dry_run=dry_run)
 
     if not case_id:
         suggest_cases_to_upload(status_db=status_db)
         raise click.Abort
 
-    family: Family = status_db.family(case_id)
+    family: Family = status_db.get_case_by_internal_id(internal_id=case_id)
 
     for sample in family.samples:
         hk_coverage: File = housekeeper_api.get_file_from_latest_version(
             bundle_name=case_id, tags=[sample.internal_id] + GensAnalysisTag.COVERAGE
         )
         hk_fracsnp: File = housekeeper_api.get_file_from_latest_version(
             bundle_name=case_id, tags=[sample.internal_id] + GensAnalysisTag.FRACSNP
```

### Comparing `cg-27.1.9/cg/cli/upload/gisaid.py` & `cg-27.2.0/cg/cli/upload/gisaid.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/upload/mutacc.py` & `cg-27.2.0/cg/cli/upload/mutacc.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/upload/nipt/base.py` & `cg-27.2.0/cg/cli/upload/nipt/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/upload/nipt/ftp.py` & `cg-27.2.0/cg/cli/upload/nipt/ftp.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/upload/nipt/statina.py` & `cg-27.2.0/cg/cli/upload/nipt/statina.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/upload/observations/observations.py` & `cg-27.2.0/cg/cli/upload/observations/observations.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/upload/observations/utils.py` & `cg-27.2.0/cg/cli/upload/observations/utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 
 LOG = logging.getLogger(__name__)
 
 
 def get_observations_case(context: CGConfig, case_id: str, upload: bool) -> Family:
     """Return a verified Loqusdb case."""
     status_db: Store = context.status_db
-    case: Family = status_db.family(case_id)
+    case: Family = status_db.get_case_by_internal_id(internal_id=case_id)
     if not case or case.data_analysis not in LOQUSDB_SUPPORTED_PIPELINES:
         LOG.error("Invalid case ID. Retrieving available cases for Loqusdb actions.")
         cases_to_process: Query = (
             status_db.observations_to_upload() if upload else status_db.observations_uploaded()
         )
         if not cases_to_process:
             LOG.info("There are no valid cases to be processed by Loqusdb")
```

### Comparing `cg-27.1.9/cg/cli/upload/scout.py` & `cg-27.2.0/cg/cli/upload/scout.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Code for uploading to scout via CLI"""
 import logging
 from pathlib import Path
 from typing import Dict, Optional
 
 import click
-from housekeeper.store.models import File
+from housekeeper.store.models import File, Version
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.apps.scout.scoutapi import ScoutAPI
 from cg.cli.upload.utils import suggest_cases_to_upload
 from cg.constants import Pipeline
 from cg.constants.constants import FileFormat
 from cg.exc import CgDataError, ScoutUploadError
@@ -63,15 +63,15 @@
 @click.pass_obj
 def create_scout_load_config(context: CGConfig, case_id: str, print_console: bool, re_upload: bool):
     """Create a load config for a case in scout and add it to housekeeper"""
 
     status_db: Store = context.status_db
 
     LOG.info("Fetching family object")
-    case_obj: Family = status_db.family(case_id)
+    case_obj: Family = status_db.get_case_by_internal_id(internal_id=case_id)
 
     if not case_obj.analyses:
         LOG.warning("Could not find analyses for %s", case_id)
         raise click.Abort
 
     context.meta_apis["upload_api"]: UploadAPI = get_upload_api(cg_config=context, case=case_obj)
 
@@ -135,29 +135,29 @@
     """Upload variants and case from analysis to Scout."""
 
     LOG.info("----------------- UPLOAD -----------------------")
 
     housekeeper_api: HousekeeperAPI = context.housekeeper_api
     scout_api: ScoutAPI = context.scout_api
 
-    tag_name = UploadScoutAPI.get_load_config_tag()
-    version_obj = housekeeper_api.last_version(bundle=case_id)
-    scout_config_file: Optional[File] = housekeeper_api.fetch_file_from_version(
-        version_obj=version_obj, tags={tag_name}
+    tag_name: str = UploadScoutAPI.get_load_config_tag()
+    version: Version = housekeeper_api.last_version(bundle=case_id)
+    scout_config_file: Optional[File] = housekeeper_api.get_latest_file_from_version(
+        version=version, tags={tag_name}
     )
 
     if scout_config_file is None:
         raise FileNotFoundError(f"No scout load config was found in housekeeper for {case_id}")
 
-    LOG.info("uploading case %s to scout", case_id)
+    LOG.info(f"Uploading case {case_id} to scout")
 
     if not dry_run:
         scout_api.upload(scout_load_config=scout_config_file.full_path, force=re_upload)
 
-    LOG.info("uploaded to scout using load config %s", scout_config_file.full_path)
+    LOG.info(f"Uploaded to scout using load config {scout_config_file.full_path}")
     LOG.info("Case loaded successfully to Scout")
 
 
 @click.command(name="rna-to-scout")
 @click.option("--dry-run", is_flag=True)
 @click.option("-r", "--research", is_flag=True, help="Upload research report instead of clinical")
 @click.option(
```

### Comparing `cg-27.1.9/cg/cli/upload/utils.py` & `cg-27.2.0/cg/cli/upload/utils.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,19 +1,17 @@
 """Utility functions for the upload cli commands."""
 
 import logging
-from pathlib import Path
 from typing import Optional
 
 import click
 
 from cg.constants import Pipeline
 from cg.constants.constants import MAX_ITEMS_TO_RETRIEVE
 from cg.store import Store
-from cg.store.models import Family
 
 LOG = logging.getLogger(__name__)
 
 
 def suggest_cases_to_upload(status_db: Store, pipeline: Optional[Pipeline] = None) -> None:
     """Print a list of suggested cases to upload."""
     LOG.warning("Provide a case, suggestions:")
```

### Comparing `cg-27.1.9/cg/cli/upload/validate.py` & `cg-27.2.0/cg/cli/upload/validate.py`

 * *Files 9% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 
     click.echo(click.style("----------------- VALIDATE --------------------"))
 
     if not family_id:
         suggest_cases_to_upload(status_db=status_db)
         raise click.Abort
 
-    case_obj = status_db.family(family_id)
+    case_obj = status_db.get_case_by_internal_id(internal_id=family_id)
     chanjo_samples: List[dict] = []
     for link_obj in case_obj.links:
         sample_id = link_obj.sample.internal_id
         chanjo_sample = chanjo_api.sample(sample_id)
         if chanjo_sample is None:
             click.echo(click.style(f"upload coverage for {sample_id}", fg="yellow"))
             continue
```

### Comparing `cg-27.1.9/cg/cli/upload/vogue.py` & `cg-27.2.0/cg/cli/upload/vogue.py`

 * *Files 2% similar despite different names*

```diff
@@ -280,29 +280,29 @@
     """Get a sample string for case_name
     Args:
         case_name(str): onemite
     Returns:
         sample_names(str): ACC12345,ACC45679
     """
 
-    link_objs: List[FamilySample] = store.family(case_name).links
+    link_objs: List[FamilySample] = store.get_case_by_internal_id(internal_id=case_name).links
     sample_ids = {link_obj.sample.internal_id for link_obj in link_objs}
     return ",".join(sample_ids)
 
 
 def _get_analysis_workflow_details(status_api: Store, case_name: str) -> Tuple[Any, Optional[Any]]:
     """Get lowercase workflow name for a case_name
     Args:
         case_name(str): onemite
     Returns:
         workflow_name(str): balsamic
         workflow_version(str): v3.14.15
     """
     # Workflow that generated these results
-    case_obj = status_api.family(case_name)
+    case_obj = status_api.get_case_by_internal_id(internal_id=case_name)
     workflow_name = None
     workflow_version = None
     if case_obj.analyses:
         workflow_name = case_obj.analyses[0].pipeline
         workflow_version = case_obj.analyses[0].pipeline_version
 
     return workflow_name, workflow_version
```

### Comparing `cg-27.1.9/cg/cli/workflow/balsamic/base.py` & `cg-27.2.0/cg/cli/workflow/balsamic/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/balsamic/options.py` & `cg-27.2.0/cg/cli/workflow/balsamic/options.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/balsamic/pon.py` & `cg-27.2.0/cg/cli/workflow/balsamic/pon.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/balsamic/qc.py` & `cg-27.2.0/cg/cli/workflow/balsamic/qc.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/balsamic/umi.py` & `cg-27.2.0/cg/cli/workflow/balsamic/umi.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/base.py` & `cg-27.2.0/cg/cli/workflow/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/commands.py` & `cg-27.2.0/cg/cli/workflow/commands.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 import click
 import datetime as dt
 import logging
 import shutil
 
 from pathlib import Path
 
-from cgmodels.cg.constants import Pipeline
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.constants import EXIT_FAIL, EXIT_SUCCESS
 from cg.constants.observations import LOQUSDB_SUPPORTED_PIPELINES
 from cg.exc import FlowCellsNeededError, DecompressionNeededError
 from cg.meta.rsync import RsyncAPI
 from cg.meta.workflow.analysis import AnalysisAPI
```

### Comparing `cg-27.1.9/cg/cli/workflow/fastq/base.py` & `cg-27.2.0/cg/cli/workflow/fastq/base.py`

 * *Files 7% similar despite different names*

```diff
@@ -24,15 +24,15 @@
 @DRY_RUN
 @ARGUMENT_CASE_ID
 @click.pass_context
 def store_fastq_analysis(context: click.Context, case_id: str, dry_run: bool = False):
     """Creates an analysis object in status-db for the given fast case"""
     LOG.info("Creating an analysis for case %s", case_id)
     status_db: Store = context.obj.status_db
-    case_obj: Family = status_db.family(internal_id=case_id)
+    case_obj: Family = status_db.get_case_by_internal_id(internal_id=case_id)
     new_analysis: Analysis = status_db.add_analysis(
         pipeline=Pipeline.FASTQ,
         completed_at=dt.datetime.now(),
         primary=True,
         started_at=dt.datetime.now(),
         family_id=case_obj.id,
     )
```

### Comparing `cg-27.1.9/cg/cli/workflow/fluffy/base.py` & `cg-27.2.0/cg/cli/workflow/fluffy/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 import logging
 
 import click
 from cg.cli.workflow.commands import link, resolve_compression, store, store_available
-from cg.constants import EXIT_FAIL, EXIT_SUCCESS, Pipeline
+from cg.constants import EXIT_FAIL, EXIT_SUCCESS
 from cg.exc import CgError, DecompressionNeededError
 from cg.meta.workflow.fluffy import FluffyAnalysisAPI
 from cg.models.cg_config import CGConfig
 from cg.meta.workflow.analysis import AnalysisAPI
 
 OPTION_DRY = click.option(
     "-d", "--dry-run", "dry_run", help="Print command to console without executing", is_flag=True
```

### Comparing `cg-27.1.9/cg/cli/workflow/microsalt/base.py` & `cg-27.2.0/cg/cli/workflow/microsalt/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -207,29 +207,29 @@
     for case_obj in analysis_api.get_cases_to_analyze():
         try:
             context.invoke(start, unique_id=case_obj.internal_id, dry_run=dry_run)
         except CgError as error:
             LOG.error(error)
             exit_code = EXIT_FAIL
         except Exception as error:
-            LOG.error(f"Unspecified error occurred: %s", error)
+            LOG.error(f"Unspecified error occurred: {error}")
             exit_code = EXIT_FAIL
     if exit_code:
         raise click.Abort
 
 
 @microsalt.command("upload-analysis-vogue")
 @OPTION_DRY_RUN
 @ARGUMENT_UNIQUE_IDENTIFIER
 @click.pass_obj
 def upload_analysis_vogue(context: CGConfig, unique_id: str, dry_run: bool) -> None:
     """Upload the trending report for latest analysis of given case_id to Vogue"""
 
     analysis_api: MicrosaltAnalysisAPI = context.meta_apis["analysis_api"]
-    case_obj = analysis_api.status_db.family(unique_id)
+    case_obj = analysis_api.status_db.get_case_by_internal_id(internal_id=unique_id)
     if not case_obj or not case_obj.analyses:
         LOG.error("No analysis available for %s", unique_id)
         raise click.Abort
 
     samples_string = ",".join(str(link_obj.sample.internal_id) for link_obj in case_obj.links)
     microsalt_version: str = analysis_api.get_pipeline_version(case_id=case_obj.internal_id)
 
@@ -272,19 +272,15 @@
 @OPTION_DRY_RUN
 @click.pass_context
 def upload_vogue_latest(context: click.Context, dry_run: bool) -> None:
     """Upload the trending reports for all un-uploaded latest analyses to Vogue"""
 
     EXIT_CODE: int = EXIT_SUCCESS
     analysis_api: MicrosaltAnalysisAPI = context.obj.meta_apis["analysis_api"]
-    latest_analyses = list(
-        analysis_api.status_db.latest_analyses()
-        .filter(Analysis.pipeline == Pipeline.MICROSALT)
-        .filter(Analysis.uploaded_at.is_(None))
-    )
+    latest_analyses = list(analysis_api.status_db.get_latest_microsalt_analysis_to_upload())
     for analysis in latest_analyses:
         unique_id: str = analysis.family.internal_id
         try:
             context.invoke(upload_analysis_vogue, unique_id=unique_id, dry_run=dry_run)
         except Exception as error:
             LOG.error(
                 "Could not upload data for %s to vogue, exception %s",
@@ -304,12 +300,14 @@
     """Perform QC on a microsalt case."""
     analysis_api: MicrosaltAnalysisAPI = context.obj.meta_apis["analysis_api"]
     try:
         analysis_api.microsalt_qc(
             case_id=unique_id,
             run_dir_path=analysis_api.get_latest_case_path(case_id=unique_id),
             lims_project=analysis_api.get_project(
-                analysis_api.status_db.family(internal_id=unique_id).samples[0].internal_id
+                analysis_api.status_db.get_case_by_internal_id(internal_id=unique_id)
+                .samples[0]
+                .internal_id
             ),
         )
     except IndexError:
         LOG.error(f"No existing analysis directories found for case {unique_id}.")
```

### Comparing `cg-27.1.9/cg/cli/workflow/mip/base.py` & `cg-27.2.0/cg/cli/workflow/mip/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/mip/options.py` & `cg-27.2.0/cg/cli/workflow/mip/options.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/mip_dna/base.py` & `cg-27.2.0/cg/cli/workflow/mip_dna/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/mip_rna/base.py` & `cg-27.2.0/cg/cli/workflow/mip_rna/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/mutant/base.py` & `cg-27.2.0/cg/cli/workflow/mutant/base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/nextflow/options.py` & `cg-27.2.0/cg/cli/workflow/nextflow/options.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/cli/workflow/rnafusion/base.py` & `cg-27.2.0/cg/cli/workflow/rnafusion/base.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 
 import logging
 
 import click
 from pydantic import ValidationError
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
-from cg.cli.workflow.commands import ARGUMENT_CASE_ID, link, resolve_compression
+from cg.cli.workflow.commands import ARGUMENT_CASE_ID, resolve_compression
 from cg.cli.workflow.nextflow.options import (
     OPTION_CONFIG,
     OPTION_LOG,
     OPTION_PARAMS_FILE,
     OPTION_PROFILE,
     OPTION_REVISION,
     OPTION_STUB,
```

### Comparing `cg-27.1.9/cg/cli/workflow/rnafusion/options.py` & `cg-27.2.0/cg/cli/workflow/rnafusion/options.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/__init__.py` & `cg-27.2.0/cg/constants/__init__.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/compression.py` & `cg-27.2.0/cg/constants/compression.py`

 * *Files 7% similar despite different names*

```diff
@@ -48,14 +48,15 @@
     "unitedbeagle",  # BALSAMIC validation case tumor-normal panel
     "eagerox",  # BALSAMIC validation case from cust087, tumor-only panel
     "casualweasel",  # BALSAMIC validation case from cust087, tumor-only panel
     "acetuna",  # BALSAMIC validation case from cust087, tumor-only panel
     "suitedsnake",  # BALSAMIC validation case from cust087, tumor-only panel
     "savinghorse",  # BALSAMIC validation case from cust087, tumor-only panel
     "rightpup",  # BALSAMIC validation case from cust087, tumor-only panel
+    "sureroughy",  # BALSAMIC validation case from cust087, tumor-only panel
 ]
 
 FLUFFY_VALIDATION_CASES = [
     "simplesalmon",  # Chromosome 13, 18, 21 Suspected
 ]
 
 MIP_VALIDATION_CASES = [
```

### Comparing `cg-27.1.9/cg/constants/constants.py` & `cg-27.2.0/cg/constants/constants.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 """Constants for cg."""
-from enum import Enum
 
 import click
 from cgmodels.cg.constants import StrEnum
 
 from cg.constants.sequencing import Sequencers
 from cg.utils.date import get_date
```

### Comparing `cg-27.1.9/cg/constants/delivery.py` & `cg-27.2.0/cg/constants/delivery.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/demultiplexing.py` & `cg-27.2.0/cg/constants/demultiplexing.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/encryption.py` & `cg-27.2.0/cg/constants/encryption.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/gene_panel.py` & `cg-27.2.0/cg/constants/gene_panel.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/housekeeper_tags.py` & `cg-27.2.0/cg/constants/housekeeper_tags.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 """File tags for files in Housekeeper."""
-from enum import Enum
 from typing import List
 
 from cgmodels.cg.constants import Pipeline, StrEnum
 
 
 class AlignmentFileTag(StrEnum):
     """Tags for alignment files."""
```

### Comparing `cg-27.1.9/cg/constants/lims.py` & `cg-27.2.0/cg/constants/lims.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/observations.py` & `cg-27.2.0/cg/constants/observations.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/orderforms.py` & `cg-27.2.0/cg/constants/orderforms.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/priority.py` & `cg-27.2.0/cg/constants/priority.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/report.py` & `cg-27.2.0/cg/constants/report.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/rnafusion.py` & `cg-27.2.0/cg/constants/rnafusion.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 """RNAfusion related constants."""
 
-from cgmodels.cg.constants import StrEnum
 
 from cg.constants.nextflow import NFX_SAMPLESHEET_HEADERS
 
 RNAFUSION_ACCEPTED_STRANDEDNESS = ["forward", "reverse", "unstranded"]
 RNAFUSION_STRANDEDNESS_HEADER = "strandedness"
 RNAFUSION_SAMPLESHEET_HEADERS = NFX_SAMPLESHEET_HEADERS + [RNAFUSION_STRANDEDNESS_HEADER]
```

### Comparing `cg-27.1.9/cg/constants/scout_upload.py` & `cg-27.2.0/cg/constants/scout_upload.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/sequencing.py` & `cg-27.2.0/cg/constants/sequencing.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/constants/subject.py` & `cg-27.2.0/cg/constants/subject.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/exc.py` & `cg-27.2.0/cg/exc.py`

 * *Files 22% similar despite different names*

```diff
@@ -9,31 +9,14 @@
     Base exception for the package.
     """
 
     def __init__(self, message: str = ""):
         super().__init__(message)
 
 
-class AccessionNumerMissingError(CgError):
-    """Raised when accession numers are not found in a gisaid cli log."""
-
-
-class AnalysisDuplicationError(CgError):
-    """
-    Error related to trying to create analysis object that already exists in status-db.
-    """
-
-
-class AnalysisNotFinishedError(CgError):
-    """
-    Exception raised when an adding a MIP analysis to Housekeeper, but the analysis is not
-    finished in MIP, as indicated in the qc sample info file.
-    """
-
-
 class AnalysisUploadError(CgError):
     """
     Error related to trying to upload analysis data.
     """
 
 
 class AnalysisAlreadyUploadedError(CgError):
@@ -58,15 +41,15 @@
     """
     Exception raised when a case is not found.
     """
 
 
 class CgDataError(CgError):
     """
-    Error related to missing/incomplete data in Status DB.
+    Error related to missing or incomplete data in Status DB.
     """
 
 
 class ChecksumFailedError(CgError):
     """
     Exception raised when the checksums of two files are not equal.
     """
@@ -82,36 +65,22 @@
     """
 
 
 class EmailNotSentError(CgError):
     """Raised when email not sent."""
 
 
-class FamilyLinkMissingError(CgError):
-    """Raised when faimly link missing for a sample."""
-
-
-class FastaSequenceMissingError(CgError):
-    """
-    Exception raised when expected sequence in fasta file is missing.
-    """
-
-
 class FlowCellError(CgError):
     """Raised when there is a problem with demultiplexing a flow cell."""
 
 
 class FlowCellsNeededError(CgError):
     """Raised when fetching flow cells still needed to start analysis."""
 
 
-class GisaidUploadFailedError(CgError):
-    """Raised when gisaid upload fails."""
-
-
 class HousekeeperFileMissingError(CgError):
     """
     Exception raised when a file is missing in Housekeeper.
     """
 
     def __init__(self, message: str = "", errors=None):
         super().__init__(message)
@@ -120,43 +89,20 @@
 
 class HousekeeperBundleVersionMissingError(CgError):
     """
     Exception raised when bundle version is missing in Housekeeper.
     """
 
 
-class InvalidFastaError(CgError):
-    """
-    Exception raised when fasta file content is invalid.
-    """
-
-
 class LimsDataError(CgError):
     """
     Error related to missing/incomplete data in LIMS.
     """
 
 
-class MandatoryFilesMissing(CgError):
-    """
-    Exception raised when mandatory files are missing from the deliverables when storing an
-    analysis in Housekeeper.
-    """
-
-
-class MipStartError(CgError):
-    """
-    Exception raised when MIP fails to start a run.
-    """
-
-
-class MultipleFamilyLinksError(CgError):
-    """Raised when only one family was expected but more than one was found."""
-
-
 class OrderError(CgError):
     """
     Exception related to orders.
     """
 
 
 class OrderFormError(CgError):
@@ -171,72 +117,42 @@
     """
 
     def __init__(self, message: str = "", errors=None):
         super().__init__(message)
         self.errors = errors
 
 
-class PipelineUnknownError(CgError):
-    """
-    Exception raised when a sample in a case has no data analysis type.
-    """
-
-
-class RnafusionStartError(CgError):
-    """
-    Exception raised when rnafusion fails to start
-    """
-
-
 class ScoutUploadError(CgError):
     """Raised when uploading to Scout fails."""
 
 
 class StatinaAPIHTTPError(CgError):
     """Raised when Statina REST API response code is not 200."""
 
 
-class StoreError(CgError):
-    """
-    Exception related to storing an analysis.
-    """
-
-
 class TicketCreationError(CgError):
     """
     Exception related to ticket creation.
     """
 
 
 class TrailblazerAPIHTTPError(CgError):
     """Raised when Trailblazer REST API response code is not 200."""
 
 
-class TrailblazerMissingAnalysisError(CgError):
-    """Raised when Trailblazer REST API response code is not 200."""
-
-
 class ValidationError(CgError):
     """
     Exception related to delivery report validation.
     """
 
 
 class DeleteDemuxError(CgError):
     """Raised when there is an issue with wiping a flowcell before start."""
 
 
-class CustomerPermissionError(CgError):
-    """Exception related to the limited permissions of a customer."""
-
-
-class DataIntegrityError(CgError):
-    """Raised when data integrity is not met."""
-
-
 class LoqusdbError(CgError):
     """Exception related to the Loqusdb app."""
 
 
 class LoqusdbUploadCaseError(LoqusdbError):
     """Exception raised when a case could not be uploaded to Loqusdb."""
 
@@ -249,9 +165,13 @@
     """Exception related to duplicate records in Loqusdb."""
 
 
 class PdcNoFilesMatchingSearchError(CgError):
     """Exception raised when PDC API returns no files matching the search criteria."""
 
 
+class DdnDataflowAuthenticationError(CgError):
+    """Exception raised when the DDN Dataflow authentication fails."""
+
+
 class MissingFilesError(CgError):
     """Exception raised when there are missing files."""
```

### Comparing `cg-27.1.9/cg/io/api.py` & `cg-27.2.0/cg/io/api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/io/controller.py` & `cg-27.2.0/cg/io/controller.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/io/json.py` & `cg-27.2.0/cg/io/json.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/io/yaml.py` & `cg-27.2.0/cg/io/yaml.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/backup/backup.py` & `cg-27.2.0/cg/meta/backup/backup.py`

 * *Files 2% similar despite different names*

```diff
@@ -400,31 +400,37 @@
     def mark_file_as_archived(self, spring_file_path: Path) -> None:
         """Set the field 'to_archive' of the file in Housekeeper to mark that it has been
         archived to PDC."""
         if self.dry_run:
             LOG.info(f"Dry run, no changes made to {spring_file_path}")
             return
         hk_spring_file: File = self.hk_api.files(path=str(spring_file_path)).first()
-        LOG.info(f"Setting {spring_file_path} to archived in Housekeeper")
-        self.hk_api.set_to_archive(file=hk_spring_file, value=True)
-
-    def is_to_be_retrieved_and_decrypted(self, spring_file_path: Path) -> bool:
-        """Determines if a spring file is archived on PDC and needs to be retrieved and decrypted."""
-        return (
-            self.hk_api.files(path=str(spring_file_path)).first().to_archive
-            and not spring_file_path.exists()
-        )
+        if hk_spring_file:
+            LOG.info(f"Setting {spring_file_path} to archived in Housekeeper")
+            self.hk_api.set_to_archive(file=hk_spring_file, value=True)
+        else:
+            LOG.warning(f"Could not find {spring_file_path} on disk")
 
     def remove_archived_spring_file(self, spring_file_path: Path) -> None:
         """Removes all files related to spring PDC archiving."""
         if not self.dry_run:
             LOG.info(f"Removing spring file {spring_file_path} from disk")
             spring_file_path.unlink()
 
+    def is_to_be_retrieved_and_decrypted(self, spring_file_path: Path) -> bool:
+        """Determines if a spring file is archived on PDC and needs to be retrieved and decrypted."""
+        spring_file: File = self.hk_api.files(path=str(spring_file_path)).first()
+        if spring_file and not spring_file_path.exists():
+            return spring_file.to_archive
+        return False
+
     def is_spring_file_archived(self, spring_file_path: Path) -> bool:
         """Checks if a spring file is marked as archived in Housekeeper."""
-        return self.hk_api.files(path=str(spring_file_path)).first().to_archive
+        spring_file: File = self.hk_api.files(path=str(spring_file_path)).first()
+        if spring_file:
+            return spring_file.to_archive
+        return False
 
     @staticmethod
     def is_compression_ongoing(spring_file_path: Path) -> bool:
         """Determines if (de)compression of the spring file ongoing."""
         return CompressionData(spring_file_path).pending_exists()
```

### Comparing `cg-27.1.9/cg/meta/backup/pdc.py` & `cg-27.2.0/cg/meta/backup/pdc.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/clean/api.py` & `cg-27.2.0/cg/meta/clean/api.py`

 * *Files 6% similar despite different names*

```diff
@@ -20,18 +20,20 @@
         self.housekeeper_api = housekeeper_api
 
     def get_bundle_files(self, before: datetime, pipeline: Pipeline) -> Iterator[List[File]]:
         """Get any bundle files for a specific version"""
 
         analysis: Analysis
         LOG.debug(
-            f"number of {pipeline} analyses before: {before} : {self.status_db.get_analyses_before_date(pipeline=pipeline, before=before).count()}"
+            f"number of {pipeline} analyses before: {before} : {len(self.status_db.get_analyses_for_pipeline_started_at_before(pipeline=pipeline, started_at_before=before))}"
         )
 
-        for analysis in self.status_db.get_analyses_before_date(pipeline=pipeline, before=before):
+        for analysis in self.status_db.get_analyses_for_pipeline_started_at_before(
+            pipeline=pipeline, started_at_before=before
+        ):
             bundle_name = analysis.family.internal_id
 
             hk_bundle_version: Optional[Version] = self.housekeeper_api.version(
                 bundle=bundle_name, date=analysis.started_at
             )
             if not hk_bundle_version:
                 LOG.warning(
```

### Comparing `cg-27.1.9/cg/meta/clean/demultiplexed_flow_cells.py` & `cg-27.2.0/cg/meta/clean/demultiplexed_flow_cells.py`

 * *Files 0% similar despite different names*

```diff
@@ -254,15 +254,15 @@
         LOG.info(f"Archiving sample sheet for flow cell {self.run_name}")
         globbed_unaligned_paths: Path.glob = Path(self.path).glob(
             DemultiplexingDirsAndFiles.UNALIGNED_DIR_NAME + ASTERISK
         )
         globbed_unaligned_paths_list: list = list(globbed_unaligned_paths)
         if not globbed_unaligned_paths_list:
             LOG.warning(
-                f"No Unaligned directory found for flow cell {self.run_nam}! No sample sheet to archive!"
+                f"No Unaligned directory found for flow cell {self.run_name}! No sample sheet to archive!"
             )
             return
         unaligned_path: Path = globbed_unaligned_paths_list[0]
         original_sample_sheet: Path = (
             Path(
                 unaligned_path,
                 DemultiplexingDirsAndFiles.SAMPLE_SHEET_FILE_NAME,
```

### Comparing `cg-27.1.9/cg/meta/clean/flow_cell_run_directories.py` & `cg-27.2.0/cg/meta/clean/flow_cell_run_directories.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Module that handles deletion of flow cell run directories and their BCL files from
 flow_cell_run_dir/<sequencer>."""
 import logging
 import shutil
 from datetime import datetime, timedelta
 from pathlib import Path
-from typing import Optional
+from typing import Optional, List
 
 from housekeeper.store.models import Bundle
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.constants import FlowCellStatus
 from cg.constants.demultiplexing import DemultiplexingDirsAndFiles
 from cg.constants.symbols import UNDERSCORE
@@ -98,18 +98,19 @@
         """Archives a sample sheet in Housekeeper bundles."""
         LOG.info(f"Start archiving sample sheet {self.sample_sheet_path}")
         if not self.sample_sheet_path.exists():
             LOG.warning("Sample sheet does not exists!")
             return
         LOG.info("Sample sheet found!")
         hk_bundle: Bundle = self.hk.bundle(name=self.id)
+        hk_tags: List[str] = [SequencingFileTag.ARCHIVED_SAMPLE_SHEET, self.id]
         if hk_bundle is None:
             LOG.info(f"Creating bundle with name {self.id}")
             self.hk.create_new_bundle_and_version(name=self.id)
-        try:
-            self.hk.add_and_include_file_to_latest_version(
-                bundle_name=self.id,
-                file=self.sample_sheet_path,
-                tags=[SequencingFileTag.ARCHIVED_SAMPLE_SHEET, self.id],
-            )
-        except FileExistsError:
+        elif self.hk.get_file_from_latest_version(bundle_name=hk_bundle.name, tags=hk_tags):
             LOG.warning("Sample sheet already included!")
+            return
+        self.hk.add_and_include_file_to_latest_version(
+            bundle_name=self.id,
+            file=self.sample_sheet_path,
+            tags=hk_tags,
+        )
```

### Comparing `cg-27.1.9/cg/meta/compress/compress.py` & `cg-27.2.0/cg/meta/compress/compress.py`

 * *Files 2% similar despite different names*

```diff
@@ -111,14 +111,15 @@
         compressions: List[CompressionData] = files.get_spring_paths(version_obj=version)
         for compression in compressions:
             if not self.crunchy_api.is_spring_decompression_possible(compression_obj=compression):
                 LOG.info(f"SPRING to FASTQ decompression not possible for {sample_id}")
                 if not self.backup_api.is_to_be_retrieved_and_decrypted(
                     spring_file_path=compression.spring_path
                 ):
+                    LOG.warning(f"Could not find {compression.spring_path} on disk")
                     return False
                 LOG.info("Until the SPRING file is retrieved from PDC and decrypted")
                 self.backup_api.retrieve_and_decrypt_spring_file(
                     spring_file_path=Path(compression.spring_path)
                 )
 
             LOG.info(
@@ -219,41 +220,42 @@
         sample_id: str,
         compression_obj: CompressionData,
         hk_fastq_first: File,
         hk_fastq_second: File,
     ) -> None:
         """Update Housekeeper with compressed FASTQ files and SPRING metadata file."""
         version: Version = self.hk_api.last_version(sample_id)
-
         spring_tags: List[str] = [sample_id, SequencingFileTag.SPRING]
         spring_metadata_tags: List[str] = [sample_id, SequencingFileTag.SPRING_METADATA]
-        LOG.info(f"Updating FASTQ files in Housekeeper update for {sample_id}:")
+        LOG.info(f"Updating FASTQ files in Housekeeper for {sample_id}")
         LOG.info(
-            f"{compression_obj.fastq_first}, {compression_obj.fastq_second} -> {compression_obj.spring_path}, with tags {spring_tags}"
+            f"{compression_obj.fastq_first}, {compression_obj.fastq_second} -> {compression_obj.spring_path}, "
+            f"with tags {spring_tags}"
         )
         LOG.info(f"Adds {compression_obj.spring_metadata_path}, with tags {spring_metadata_tags}")
         if self.dry_run:
             return
 
         LOG.info("Updating files in Housekeeper...")
         if files.is_file_in_version(version_obj=version, path=compression_obj.spring_path):
             LOG.info("SPRING file is already in Housekeeper")
         else:
             LOG.info("Adding SPRING file to Housekeeper")
-            self.hk_api.add_file(
-                path=compression_obj.spring_path, version_obj=version, tags=spring_tags
+            self.hk_api.add_and_include_file_to_latest_version(
+                bundle_name=sample_id, file=compression_obj.spring_path, tags=spring_tags
             )
             self.hk_api.commit()
 
         if files.is_file_in_version(version_obj=version, path=compression_obj.spring_metadata_path):
-            LOG.info("Spring metadata file is already in Housekeeper")
+            LOG.info("SPRING metadata file is already in Housekeeper")
         else:
-            self.hk_api.add_file(
-                path=compression_obj.spring_metadata_path,
-                version_obj=version,
+            LOG.info("Adding SPRING metadata file to Housekeeper")
+            self.hk_api.add_and_include_file_to_latest_version(
+                bundle_name=sample_id,
+                file=compression_obj.spring_metadata_path,
                 tags=spring_metadata_tags,
             )
             self.hk_api.commit()
 
         self.delete_fastq_housekeeper(
             hk_fastq_first=hk_fastq_first, hk_fastq_second=hk_fastq_second
         )
@@ -262,24 +264,25 @@
         """Add FASTQ files to Housekeeper."""
 
         if not sample_obj.application_version.application.is_external:
             flow_cell_id: str = self.get_flow_cell_id(fastq_path=fastq_first)
             fastq_tags: List[str] = [flow_cell_id, SequencingFileTag.FASTQ]
         else:
             fastq_tags: List[str] = [sample_obj.internal_id, SequencingFileTag.FASTQ]
-        last_version: Version = self.hk_api.last_version(bundle=sample_obj.internal_id)
         LOG.info(
             f"Adds {fastq_first}, {fastq_second} to bundle {sample_obj.internal_id} with tags {fastq_tags}"
         )
         if self.dry_run:
             return
 
         LOG.info("Updating files in Housekeeper...")
-        self.hk_api.add_file(path=fastq_first, version_obj=last_version, tags=fastq_tags)
-        self.hk_api.add_file(path=fastq_second, version_obj=last_version, tags=fastq_tags)
+        for fastq in [fastq_first, fastq_second]:
+            self.hk_api.add_and_include_file_to_latest_version(
+                bundle_name=sample_obj.internal_id, file=fastq, tags=fastq_tags
+            )
         self.hk_api.commit()
 
     # Methods to remove files from disc
     def remove_fastq(self, fastq_first: Path, fastq_second: Path):
         """Remove FASTQ files."""
         LOG.info(f"Will remove {fastq_first} and {fastq_second}")
         if self.dry_run:
```

### Comparing `cg-27.1.9/cg/meta/compress/files.py` & `cg-27.2.0/cg/meta/compress/files.py`

 * *Files 6% similar despite different names*

```diff
@@ -31,16 +31,16 @@
         LOG.info(f"Found file {version_file.path}")
         path_obj: Path = Path(version_file.full_path)
         hk_file[path_obj] = version_file
     return hk_file
 
 
 def is_file_in_version(version_obj: Version, path: Path) -> bool:
-    """Check if a file is in a certain version."""
-    return any(version_file.path == str(path) for version_file in version_obj.files)
+    """Check if a file is in a certain version considering relative path in the database."""
+    return any(version_file.path in path.as_posix() for version_file in version_obj.files)
 
 
 # Functions to get FASTQ like files
 
 
 def get_spring_paths(version_obj: Version) -> List[CompressionData]:
     """Get all SPRING paths for a sample."""
```

### Comparing `cg-27.1.9/cg/meta/deliver.py` & `cg-27.2.0/cg/meta/deliver.py`

 * *Files 0% similar despite different names*

```diff
@@ -232,15 +232,14 @@
 
     def include_file_case(self, file: File, sample_ids: Set[str]) -> bool:
         """Check if file should be included in case bundle.
 
         At least one tag should match between file and tags.
         Do not include files with sample tags.
         """
-        tag: Tag
         file_tags = {tag.name for tag in file.tags}
         if self.all_case_tags.isdisjoint(file_tags):
             LOG.debug("No tags are matching")
             return False
 
         LOG.debug(f"Found file tags {', '.join(file_tags)}")
```

### Comparing `cg-27.1.9/cg/meta/deliver_ticket.py` & `cg-27.2.0/cg/meta/deliver_ticket.py`

 * *Files 3% similar despite different names*

```diff
@@ -21,15 +21,15 @@
 
 class DeliverTicketAPI(MetaAPI):
     def __init__(self, config: CGConfig):
         super().__init__(config)
         self.delivery_path: Path = Path(config.delivery_path)
 
     def get_all_cases_from_ticket(self, ticket: str) -> List[Family]:
-        return self.status_db.get_cases_from_ticket(ticket=ticket).all()
+        return self.status_db.get_cases_by_ticket_id(ticket_id=ticket)
 
     def get_inbox_path(self, ticket: str) -> Path:
         cases: List[Family] = self.get_all_cases_from_ticket(ticket=ticket)
         if not cases:
             raise CgError(
                 f"The customer id was not identified since no cases for ticket {ticket} was found"
             )
@@ -87,26 +87,26 @@
                     shutil.copyfileobj(file_descriptor, write_file_obj)
 
     def remove_files(self, reads: List[Path]) -> None:
         for file in reads:
             LOG.info("Removing file: %s", file)
             file.unlink()
 
-    def get_all_samples_from_ticket(self, ticket: str) -> list:
-        all_samples = []
+    def get_samples_from_ticket(self, ticket: str) -> list:
+        all_samples: List = []
         cases: List[Family] = self.get_all_cases_from_ticket(ticket=ticket)
         for case in cases:
             for link_obj in case.links:
                 all_samples.append(link_obj.sample.name)
         return all_samples
 
     def report_missing_samples(self, ticket: str, dry_run: bool) -> None:
         customer_inbox: Path = self.get_inbox_path(ticket=ticket)
         missing_samples = []
-        all_samples: list = self.get_all_samples_from_ticket(ticket=ticket)
+        all_samples: list = self.get_samples_from_ticket(ticket=ticket)
         if not customer_inbox.exists() and dry_run:
             LOG.info("Dry run, will not search for missing data in: %s", customer_inbox)
             return
         if not customer_inbox.exists():
             LOG.info(
                 "The path %s do not exist, no search for missing data will be done", customer_inbox
             )
@@ -166,15 +166,15 @@
     def get_app_tag(self, samples: list) -> str:
         app_tag = samples[0].application_version.application.tag
         return app_tag
 
     def check_if_concatenation_is_needed(self, ticket: str) -> bool:
         cases: List[Family] = self.get_all_cases_from_ticket(ticket=ticket)
         case_id = cases[0].internal_id
-        case_obj = self.status_db.family(case_id)
+        case_obj = self.status_db.get_case_by_internal_id(internal_id=case_id)
         samples: List[Sample] = [link.sample for link in case_obj.links]
         app_tag = self.get_app_tag(samples=samples)
         for prefix in PREFIX_TO_CONCATENATE:
             if app_tag.startswith(prefix):
                 LOG.info(
                     "Identified %s as application tag, i.e. the fastqs should be concatenated",
                     app_tag,
```

### Comparing `cg-27.1.9/cg/meta/demultiplex/delete_demultiplex_api.py` & `cg-27.2.0/cg/meta/demultiplex/delete_demultiplex_api.py`

 * *Files 0% similar despite different names*

```diff
@@ -69,15 +69,15 @@
         )
 
     def active_samples_on_flow_cell(self) -> Optional[List[str]]:
         """Check if there are any active cases related to samples of a flow cell"""
         active_samples_on_flow_cell: List[str] = [
             sample.internal_id
             for sample in self.samples_on_flow_cell
-            if self.status_db.active_sample(internal_id=sample.internal_id)
+            if self.status_db.has_active_cases_for_sample(internal_id=sample.internal_id)
         ]
         if active_samples_on_flow_cell:
             return active_samples_on_flow_cell
 
     def _delete_sample_sheet_housekeeper(self) -> None:
         """Delete the presence of all sample sheets related to a flow cell in Housekeeper."""
         sample_sheet_files: Iterable[File] = self.housekeeper_api.files(
```

### Comparing `cg-27.1.9/cg/meta/demultiplex/demux_post_processing.py` & `cg-27.2.0/cg/meta/demultiplex/demux_post_processing.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/demultiplex/files.py` & `cg-27.2.0/cg/meta/demultiplex/files.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/encryption/encryption.py` & `cg-27.2.0/cg/meta/encryption/encryption.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,17 @@
 """API for encryption on Hasta"""
-import hashlib
 import logging
 import subprocess
 from io import TextIOWrapper
 from pathlib import Path
 from tempfile import NamedTemporaryFile
 from typing import List
 
 from cg.constants import FileExtensions
 from cg.constants.encryption import GPGParameters
-from cg.constants.extraction import FlowCellExtractionParameters
 from cg.exc import ChecksumFailedError
 from cg.utils import Process
 from cg.utils.checksum.checksum import sha512_checksum
 
 LOG = logging.getLogger(__name__)
```

### Comparing `cg-27.1.9/cg/meta/invoice.py` & `cg-27.2.0/cg/meta/invoice.py`

 * *Files 1% similar despite different names*

```diff
@@ -36,15 +36,15 @@
         elif self.invoice_obj.samples:
             self.record_type = RecordType.Sample
             self.raw_records = self.invoice_obj.samples
 
     def get_customer_by_cost_center(self, cost_center: str) -> Union[Customer, str]:
         """Return the costumer based on cost center."""
         return (
-            self.db.get_customer_by_customer_id(customer_id=CustomerNames.cust999)
+            self.db.get_customer_by_internal_id(customer_internal_id=CustomerNames.cust999)
             if cost_center.lower() == CostCenters.kth
             else self.customer_obj
         )
 
     def get_customer_invoice_contact(self, customer: Customer, msg: str) -> Any:
         """Return the customer invoice contact."""
         if not customer.invoice_contact:
```

### Comparing `cg-27.1.9/cg/meta/meta.py` & `cg-27.2.0/cg/meta/meta.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/observations/balsamic_observations_api.py` & `cg-27.2.0/cg/meta/observations/balsamic_observations_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/observations/mip_dna_observations_api.py` & `cg-27.2.0/cg/meta/observations/mip_dna_observations_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/observations/observations_api.py` & `cg-27.2.0/cg/meta/observations/observations_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/orders/api.py` & `cg-27.2.0/cg/meta/orders/api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/orders/case_submitter.py` & `cg-27.2.0/cg/meta/orders/case_submitter.py`

 * *Files 3% similar despite different names*

```diff
@@ -42,16 +42,16 @@
             subject_id: str = sample.subject_id
             if not subject_id:
                 continue
             new_gender: str = sample.sex
             if new_gender == "unknown":
                 continue
 
-            existing_samples: List[Sample] = self.status.get_samples_by_subject_id(
-                customer_id=customer_id, subject_id=subject_id
+            existing_samples: List[Sample] = self.status.get_samples_by_customer_and_subject_id(
+                customer_internal_id=customer_id, subject_id=subject_id
             )
             existing_sample: Sample
             for existing_sample in existing_samples:
                 previous_gender = existing_sample.sex
                 if previous_gender == "unknown":
                     continue
 
@@ -69,33 +69,37 @@
             if not sample.internal_id:
                 continue
 
             existing_sample: Sample = self.status.get_sample_by_internal_id(
                 internal_id=sample.internal_id
             )
 
-            data_customer: Customer = self.status.get_customer_by_customer_id(
-                customer_id=customer_id
+            data_customer: Customer = self.status.get_customer_by_internal_id(
+                customer_internal_id=customer_id
             )
 
             if existing_sample.customer not in data_customer.collaborators:
                 raise OrderError(f"Sample not available: {sample.name}")
 
     def _validate_case_names_are_unique(
         self, samples: List[OrderInSample], customer_id: str
     ) -> None:
         """Validate that the names of all cases are unused for all samples"""
 
-        customer: Customer = self.status.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = self.status.get_customer_by_internal_id(
+            customer_internal_id=customer_id
+        )
 
         sample: Of1508Sample
         for sample in samples:
             if self._is_rerun_of_existing_case(sample=sample):
                 continue
-            if self.status.find_family(customer=customer, name=sample.family_name):
+            if self.status.get_case_by_name_and_customer(
+                customer=customer, case_name=sample.family_name
+            ):
                 raise OrderError(f"Case name {sample.family_name} already in use")
 
     def submit_order(self, order: OrderIn) -> dict:
         """Submit a batch of samples for sequencing and analysis."""
         result = self._process_case_samples(order=order)
         for case_obj in result["records"]:
             LOG.info(f"{case_obj.name}: submit family samples")
@@ -219,19 +223,23 @@
             status_data["families"].append(case)
         return status_data
 
     def store_items_in_status(
         self, customer_id: str, order: str, ordered: dt.datetime, ticket_id: str, items: List[dict]
     ) -> List[Family]:
         """Store cases, samples and their relationship in the Status database."""
-        customer: Customer = self.status.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = self.status.get_customer_by_internal_id(
+            customer_internal_id=customer_id
+        )
         new_cases: List[Family] = []
 
         for case in items:
-            status_db_case: Family = self.status.family(internal_id=case["internal_id"])
+            status_db_case: Family = self.status.get_case_by_internal_id(
+                internal_id=case["internal_id"]
+            )
             if not status_db_case:
                 new_case: Family = self._create_case(
                     case=case, customer_obj=customer, ticket=ticket_id
                 )
                 new_cases.append(new_case)
                 self._update_case_panel(panels=case["panels"], case=new_case)
                 status_db_case: Family = new_case
@@ -333,16 +341,16 @@
             reference_genome=sample["reference_genome"],
             sex=sample["sex"],
             subject_id=sample["subject_id"],
         )
         sample_obj.customer = customer_obj
         with self.status.session.no_autoflush:
             application_tag = sample["application"]
-            sample_obj.application_version = self.status.current_application_version(
-                application_tag
+            sample_obj.application_version: ApplicationVersion = (
+                self.status.get_current_application_version_by_tag(tag=application_tag)
             )
         self.status.add(sample_obj)
         new_delivery = self.status.add_delivery(destination="caesar", sample=sample_obj)
         self.status.add(new_delivery)
         return sample_obj
 
     def _create_case(self, case: dict, customer_obj: Customer, ticket: str):
```

### Comparing `cg-27.1.9/cg/meta/orders/fastq_submitter.py` & `cg-27.2.0/cg/meta/orders/fastq_submitter.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,21 +1,22 @@
 import datetime as dt
 from typing import List
 
 from cgmodels.cg.constants import Pipeline
 
 from cg.constants import DataDelivery, GenePanelMasterList
 from cg.constants.constants import PrepCategory
+from cg.constants.invoice import CustomerNames
 from cg.exc import OrderError
 from cg.meta.orders.lims import process_lims
 from cg.meta.orders.submitter import Submitter
 from cg.models.orders.order import OrderIn
 from cg.models.orders.sample_base import StatusEnum
 from cg.constants.priority import Priority
-from cg.store.models import Sample, Family, FamilySample, Customer
+from cg.store.models import Sample, Family, FamilySample, Customer, ApplicationVersion
 
 
 class FastqSubmitter(Submitter):
     def submit_order(self, order: OrderIn) -> dict:
         """Submit a batch of samples for FASTQ delivery."""
 
         project_data, lims_map = process_lims(
@@ -63,29 +64,35 @@
             data_analysis=Pipeline(Pipeline.MIP_DNA),
             data_delivery=DataDelivery(DataDelivery.NO_DELIVERY),
             name="_".join([sample_obj.name, "MAF"]),
             panels=[GenePanelMasterList.OMIM_AUTO],
             priority=Priority.research,
             ticket=sample_obj.original_ticket,
         )
-        case.customer: Customer = self.status.get_customer_by_customer_id(customer_id="cust000")
+        case.customer: Customer = self.status.get_customer_by_internal_id(
+            customer_internal_id=CustomerNames.CG_INTERNAL_CUSTOMER
+        )
         relationship: FamilySample = self.status.relate_sample(
             family=case, sample=sample_obj, status=StatusEnum.unknown
         )
         self.status.add(case, relationship)
 
     def store_items_in_status(
         self, customer_id: str, order: str, ordered: dt.datetime, ticket_id: str, items: List[dict]
     ) -> List[Sample]:
         """Store fastq samples in the status database including family connection and delivery"""
-        customer: Customer = self.status.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = self.status.get_customer_by_internal_id(
+            customer_internal_id=customer_id
+        )
         if not customer:
             raise OrderError(f"Unknown customer: {customer_id}")
         new_samples = []
-        case: Family = self.status.find_family(customer=customer, name=ticket_id)
+        case: Family = self.status.get_case_by_name_and_customer(
+            customer=customer, case_name=ticket_id
+        )
         submitted_case: dict = items[0]
         with self.status.session.no_autoflush:
             for sample in items:
                 new_sample = self.status.add_sample(
                     name=sample["name"],
                     sex=sample["sex"] or "unknown",
                     comment=sample["comment"],
@@ -93,20 +100,22 @@
                     order=order,
                     ordered=ordered,
                     original_ticket=ticket_id,
                     priority=sample["priority"],
                     tumour=sample["tumour"],
                     capture_kit=sample["capture_kit"],
                 )
-                new_sample.customer = customer
-                application_tag = sample["application"]
-                application_version = self.status.current_application_version(tag=application_tag)
+                new_sample.customer: Customer = customer
+                application_tag: str = sample["application"]
+                application_version: ApplicationVersion = (
+                    self.status.get_current_application_version_by_tag(tag=application_tag)
+                )
                 if application_version is None:
                     raise OrderError(f"Invalid application: {sample['application']}")
-                new_sample.application_version = application_version
+                new_sample.application_version: ApplicationVersion = application_version
                 new_samples.append(new_sample)
                 if not case:
                     case = self.status.add_case(
                         data_analysis=Pipeline(submitted_case["data_analysis"]),
                         data_delivery=DataDelivery(submitted_case["data_delivery"]),
                         name=ticket_id,
                         panels=None,
```

### Comparing `cg-27.1.9/cg/meta/orders/lims.py` & `cg-27.2.0/cg/meta/orders/lims.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/orders/metagenome_submitter.py` & `cg-27.2.0/cg/meta/orders/metagenome_submitter.py`

 * *Files 11% similar despite different names*

```diff
@@ -6,30 +6,34 @@
 from cg.constants import DataDelivery
 from cg.exc import OrderError
 from cg.meta.orders.lims import process_lims
 from cg.meta.orders.submitter import Submitter
 from cg.models.orders.order import OrderIn
 from cg.models.orders.sample_base import StatusEnum
 from cg.models.orders.samples import MetagenomeSample
-from cg.store.models import Customer, Sample
+from cg.store.models import Customer, Family, FamilySample, Sample, ApplicationVersion
 
 
 class MetagenomeSubmitter(Submitter):
     def validate_order(self, order: OrderIn) -> None:
         self._validate_sample_names_are_unique(samples=order.samples, customer_id=order.customer)
 
     def _validate_sample_names_are_unique(
         self, samples: List[MetagenomeSample], customer_id: str
     ) -> None:
         """Validate that the names of all samples are unused."""
-        customer: Customer = self.status.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = self.status.get_customer_by_internal_id(
+            customer_internal_id=customer_id
+        )
         for sample in samples:
             if sample.control:
                 continue
-            if self.status.find_samples(customer=customer, name=sample.name).first():
+            if self.status.get_sample_by_customer_and_name(
+                customer_entry_id=[customer.id], sample_name=sample.name
+            ):
                 raise OrderError(f"Sample name {sample.name} already in use")
 
     def submit_order(self, order: OrderIn) -> dict:
         """Submit a batch of metagenome samples."""
         project_data, lims_map = process_lims(
             lims_api=self.lims, lims_order=order, new_samples=order.samples
         )
@@ -76,53 +80,59 @@
         customer_id: str,
         order: str,
         ordered: dt.datetime,
         ticket_id: str,
         items: List[dict],
     ) -> List[Sample]:
         """Store samples in the status database."""
-        customer = self.status.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = self.status.get_customer_by_internal_id(
+            customer_internal_id=customer_id
+        )
         if customer is None:
             raise OrderError(f"unknown customer: {customer_id}")
         new_samples = []
-        case_obj = self.status.find_family(customer=customer, name=str(ticket_id))
-        case: dict = items[0]
+        case: Family = self.status.get_case_by_name_and_customer(
+            customer=customer, case_name=str(ticket_id)
+        )
+        case_dict: dict = items[0]
         with self.status.session.no_autoflush:
-            for sample in case["samples"]:
+            for sample in case_dict["samples"]:
                 new_sample = self.status.add_sample(
                     name=sample["name"],
                     sex="unknown",
                     comment=sample["comment"],
                     control=sample["control"],
                     internal_id=sample.get("internal_id"),
                     order=order,
                     ordered=ordered,
                     original_ticket=ticket_id,
                     priority=sample["priority"],
                 )
-                new_sample.customer = customer
-                application_tag = sample["application"]
-                application_version = self.status.current_application_version(tag=application_tag)
+                new_sample.customer: Customer = customer
+                application_tag: str = sample["application"]
+                application_version: ApplicationVersion = (
+                    self.status.get_current_application_version_by_tag(tag=application_tag)
+                )
                 if application_version is None:
                     raise OrderError(f"Invalid application: {sample['application']}")
-                new_sample.application_version = application_version
+                new_sample.application_version: ApplicationVersion = application_version
                 new_samples.append(new_sample)
 
-                if not case_obj:
-                    case_obj = self.status.add_case(
-                        data_analysis=Pipeline(case["data_analysis"]),
-                        data_delivery=DataDelivery(case["data_delivery"]),
+                if not case:
+                    case = self.status.add_case(
+                        data_analysis=Pipeline(case_dict["data_analysis"]),
+                        data_delivery=DataDelivery(case_dict["data_delivery"]),
                         name=str(ticket_id),
                         panels=None,
-                        priority=case["priority"],
+                        priority=case_dict["priority"],
                         ticket=ticket_id,
                     )
-                    case_obj.customer = customer
-                    self.status.add(case_obj)
+                    case.customer: Customer = customer
+                    self.status.add(case)
 
-                new_relationship = self.status.relate_sample(
-                    family=case_obj, sample=new_sample, status=StatusEnum.unknown
+                new_relationship: FamilySample = self.status.relate_sample(
+                    family=case, sample=new_sample, status=StatusEnum.unknown
                 )
                 self.status.add(new_relationship)
 
         self.status.add_commit(new_samples)
         return new_samples
```

### Comparing `cg-27.1.9/cg/meta/orders/microbial_submitter.py` & `cg-27.2.0/cg/meta/orders/microbial_submitter.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,19 +1,18 @@
 import datetime as dt
 from typing import List
 
 from cgmodels.cg.constants import Pipeline
 
 from cg.constants import DataDelivery
-from cg.exc import OrderError
 from cg.meta.orders.lims import process_lims
 from cg.meta.orders.submitter import Submitter
 from cg.models.orders.order import OrderIn
 from cg.models.orders.samples import MicrobialSample
-from cg.store.models import Customer, Family, Organism, Sample
+from cg.store.models import Customer, Family, Organism, Sample, ApplicationVersion
 
 
 class MicrobialSubmitter(Submitter):
     @staticmethod
     def order_to_status(order: OrderIn) -> dict:
         """Convert order input for microbial samples."""
 
@@ -76,46 +75,54 @@
         items: List[dict],
         ticket_id: str,
     ) -> [Sample]:
         """Store microbial samples in the status database."""
 
         sample_objs = []
 
-        customer: Customer = self.status.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = self.status.get_customer_by_internal_id(
+            customer_internal_id=customer_id
+        )
         new_samples = []
 
         with self.status.session.no_autoflush:
             for sample_data in items:
-                case: Family = self.status.find_family(customer=customer, name=ticket_id)
+                case: Family = self.status.get_case_by_name_and_customer(
+                    customer=customer, case_name=ticket_id
+                )
 
                 if not case:
-                    case = self.status.add_case(
+                    case: Family = self.status.add_case(
                         data_analysis=data_analysis,
                         data_delivery=data_delivery,
                         name=ticket_id,
                         panels=None,
                         ticket=ticket_id,
                     )
-                    case.customer = customer
+                    case.customer: Customer = customer
                     self.status.add_commit(case)
 
-                application_tag = sample_data["application"]
-                application_version = self.status.current_application_version(tag=application_tag)
-                organism = self.status.get_organism_by_internal_id(sample_data["organism_id"])
+                application_tag: str = sample_data["application"]
+                application_version: ApplicationVersion = (
+                    self.status.get_current_application_version_by_tag(tag=application_tag)
+                )
+                organism: Organism = self.status.get_organism_by_internal_id(
+                    sample_data["organism_id"]
+                )
 
                 if not organism:
-                    organism = self.status.add_organism(
+                    organism: Organism = self.status.add_organism(
                         internal_id=sample_data["organism_id"],
                         name=sample_data["organism_id"],
                         reference_genome=sample_data["reference_genome"],
                     )
                     self.status.add_commit(organism)
 
                 if comment:
-                    case.comment = f"Order comment: {comment}"
+                    case.comment: str = f"Order comment: {comment}"
 
                 new_sample = self.status.add_sample(
                     name=sample_data["name"],
                     sex="unknown",
                     comment=sample_data["comment"],
                     control=sample_data["control"],
                     internal_id=sample_data.get("internal_id"),
```

### Comparing `cg-27.1.9/cg/meta/orders/pool_submitter.py` & `cg-27.2.0/cg/meta/orders/pool_submitter.py`

 * *Files 3% similar despite different names*

```diff
@@ -105,25 +105,29 @@
             )
         return status_data
 
     def store_items_in_status(
         self, customer_id: str, order: str, ordered: dt.datetime, ticket_id: str, items: List[dict]
     ) -> List[Pool]:
         """Store pools in the status database."""
-        customer: Customer = self.status.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = self.status.get_customer_by_internal_id(
+            customer_internal_id=customer_id
+        )
         new_pools: List[Pool] = []
         new_samples: List[Sample] = []
         for pool in items:
             with self.status.session.no_autoflush:
-                application_version: ApplicationVersion = self.status.current_application_version(
-                    pool["application"]
+                application_version: ApplicationVersion = (
+                    self.status.get_current_application_version_by_tag(tag=pool["application"])
                 )
             priority: str = pool["priority"]
             case_name: str = self.create_case_name(ticket=ticket_id, pool_name=pool["name"])
-            case: Family = self.status.find_family(customer=customer, name=case_name)
+            case: Family = self.status.get_case_by_name_and_customer(
+                customer=customer, case_name=case_name
+            )
             if not case:
                 data_analysis: Pipeline = Pipeline(pool["data_analysis"])
                 data_delivery: DataDelivery = DataDelivery(pool["data_delivery"])
                 case = self.status.add_case(
                     data_analysis=data_analysis,
                     data_delivery=data_delivery,
                     name=case_name,
@@ -167,18 +171,20 @@
 
         return new_pools
 
     def _validate_case_names_are_available(
         self, customer_id: str, samples: List[RmlSample], ticket: str
     ):
         """Validate names of all samples are not already in use."""
-        customer: Customer = self.status.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = self.status.get_customer_by_internal_id(
+            customer_internal_id=customer_id
+        )
         for sample in samples:
             case_name: str = self.create_case_name(pool_name=sample.pool, ticket=ticket)
-            if self.status.find_family(customer=customer, name=case_name):
+            if self.status.get_case_by_name_and_customer(customer=customer, case_name=case_name):
                 raise OrderError(
                     f"Case name {case_name} already in use for customer {customer.name}"
                 )
 
     @staticmethod
     def create_case_name(ticket: str, pool_name: str) -> str:
         return f"{ticket}-{pool_name}"
```

### Comparing `cg-27.1.9/cg/meta/orders/sars_cov_2_submitter.py` & `cg-27.2.0/cg/meta/orders/sars_cov_2_submitter.py`

 * *Files 26% similar despite different names*

```diff
@@ -15,15 +15,19 @@
         super().validate_order(order=order)
         self._validate_sample_names_are_available(samples=order.samples, customer_id=order.customer)
 
     def _validate_sample_names_are_available(
         self, samples: List[SarsCov2Sample], customer_id: str
     ) -> None:
         """Validate names of all samples are not already in use."""
-        customer: Customer = self.status.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = self.status.get_customer_by_internal_id(
+            customer_internal_id=customer_id
+        )
         for sample in samples:
             if sample.control:
                 continue
-            if self.status.find_samples(customer=customer, name=sample.name).first():
+            if self.status.get_sample_by_customer_and_name(
+                customer_entry_id=[customer.id], sample_name=sample.name
+            ):
                 raise OrderError(
                     f"Sample name {sample.name} already in use for customer {customer.name}"
                 )
```

### Comparing `cg-27.1.9/cg/meta/orders/submitter.py` & `cg-27.2.0/cg/meta/orders/submitter.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/orders/ticket_handler.py` & `cg-27.2.0/cg/meta/orders/ticket_handler.py`

 * *Files 1% similar despite different names*

```diff
@@ -151,15 +151,17 @@
     def add_user_name_to_message(self, message: str, name: Optional[str]) -> str:
         if name:
             message += f"{self.NEW_LINE}{name}"
         return message
 
     def add_customer_to_message(self, message: str, customer_id: str) -> str:
         """Add customer info to message and return updated message."""
-        customer: Customer = self.status_db.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = self.status_db.get_customer_by_internal_id(
+            customer_internal_id=customer_id
+        )
         message += f", {customer.name} ({customer_id})"
         return message
 
     @classmethod
     def replace_empty_string_with_none(cls, obj: Any) -> Any:
         """Recursive function that replaces empty string in nested dicts/lists with None"""
         if obj == "":
```

### Comparing `cg-27.1.9/cg/meta/report/balsamic.py` & `cg-27.2.0/cg/meta/report/balsamic.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 import logging
 from typing import List, Union, Optional, Dict
 
 from cgmodels.cg.constants import Pipeline
+from housekeeper.store.models import Version, File
 
 from cg.constants import (
     BALSAMIC_REPORT_ACCREDITED_PANELS,
     REQUIRED_REPORT_FIELDS,
     REQUIRED_CUSTOMER_FIELDS,
     REQUIRED_CASE_FIELDS,
     REQUIRED_APPLICATION_FIELDS,
@@ -206,7 +207,24 @@
 
         return Pipeline.BALSAMIC + "_report.html"
 
     def get_upload_case_tags(self) -> dict:
         """Retrieves BALSAMIC upload case tags."""
 
         return BALSAMIC_CASE_TAGS
+
+    def get_scout_uploaded_file_from_hk(self, case_id: str, scout_tag: str) -> Optional[str]:
+        """Return the file path of the uploaded to Scout file given its tag."""
+
+        version: Version = self.housekeeper_api.last_version(bundle=case_id)
+        tags: list = self.get_hk_scout_file_tags(scout_tag=scout_tag)
+        uploaded_file: File = self.housekeeper_api.get_latest_file(
+            bundle=case_id, tags=tags, version=version.id
+        )
+
+        if not tags or not uploaded_file:
+            LOG.warning(
+                f"No files were found for the following Scout Housekeeper tag: {scout_tag} (case: {case_id})"
+            )
+            return None
+
+        return uploaded_file.full_path
```

### Comparing `cg-27.1.9/cg/meta/report/balsamic_umi.py` & `cg-27.2.0/cg/meta/report/balsamic_umi.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/report/field_validators.py` & `cg-27.2.0/cg/meta/report/field_validators.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/report/mip_dna.py` & `cg-27.2.0/cg/meta/report/mip_dna.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 import logging
-from typing import List, Optional
+from typing import List, Optional, Iterable
 
 from cgmodels.cg.constants import Pipeline
+from housekeeper.store.models import Version, File
+from sqlalchemy.orm import Query
 
 from cg.constants import (
     REQUIRED_REPORT_FIELDS,
     REQUIRED_CUSTOMER_FIELDS,
     REQUIRED_CASE_FIELDS,
     REQUIRED_APPLICATION_FIELDS,
     REQUIRED_DATA_ANALYSIS_MIP_DNA_FIELDS,
@@ -147,7 +149,23 @@
 
         return Pipeline.MIP_DNA + "_report.html"
 
     def get_upload_case_tags(self) -> dict:
         """Retrieves MIP DNA upload case tags."""
 
         return MIP_CASE_TAGS
+
+    def get_scout_uploaded_file_from_hk(self, case_id: str, scout_tag: str) -> Optional[str]:
+        """Returns the file path of the uploaded to Scout file given its tag."""
+
+        version: Version = self.housekeeper_api.last_version(bundle=case_id)
+        tags: list = self.get_hk_scout_file_tags(scout_tag=scout_tag)
+        uploaded_files: Iterable[File] = self.housekeeper_api.get_files(
+            bundle=case_id, tags=tags, version=version.id
+        )
+        if not tags or not any(uploaded_files):
+            LOG.info(
+                f"No files were found for the following Scout Housekeeper tag: {scout_tag} (case: {case_id})"
+            )
+            return None
+
+        return uploaded_files[0].full_path
```

### Comparing `cg-27.1.9/cg/meta/report/report_api.py` & `cg-27.2.0/cg/meta/report/report_api.py`

 * *Files 3% similar despite different names*

```diff
@@ -93,41 +93,28 @@
 
         return None
 
     def get_delivery_report_from_hk(self, case_id: str) -> str:
         """Extracts the delivery reports of a specific case stored in HK."""
 
         version: Version = self.housekeeper_api.last_version(case_id)
-        delivery_report_files: Query = self.housekeeper_api.get_files(
+        delivery_report: File = self.housekeeper_api.get_latest_file(
             bundle=case_id, tags=[HK_DELIVERY_REPORT_TAG], version=version.id
         )
 
-        if delivery_report_files.count() == 0:
+        if not delivery_report:
             LOG.warning(f"No existing delivery report found in housekeeper for {case_id}")
             raise FileNotFoundError
 
-        return delivery_report_files[0].full_path
+        return delivery_report.full_path
 
     def get_scout_uploaded_file_from_hk(self, case_id: str, scout_tag: str) -> Optional[str]:
-        """Returns the file path of the uploaded to Scout file given its tag."""
+        """Return the file path of the uploaded to Scout file given its tag."""
 
-        version: Version = self.housekeeper_api.last_version(bundle=case_id)
-        tags: list = self.get_hk_scout_file_tags(scout_tag)
-        uploaded_files: Query = self.housekeeper_api.get_files(
-            bundle=case_id, tags=tags, version=version.id
-        )
-
-        if not tags or uploaded_files.count() == 0:
-            LOG.info(
-                f"No files were found for the following Scout Housekeeper tag: {scout_tag} (case: {case_id})"
-            )
-
-            return None
-
-        return uploaded_files[0].full_path
+        raise NotImplementedError
 
     def render_delivery_report(self, report_data: dict) -> str:
         """Renders the report on the Jinja template."""
 
         env = Environment(
             loader=PackageLoader("cg", "meta/report/templates"),
             autoescape=select_autoescape(["html", "xml"]),
@@ -168,23 +155,27 @@
         ]
 
         return [analysis_obj.family for analysis_obj in analyses]
 
     def update_delivery_report_date(self, case: Family, analysis_date: datetime) -> None:
         """Updates the date when delivery report was created."""
 
-        analysis: Analysis = self.status_db.analysis(case, analysis_date)
+        analysis: Analysis = self.status_db.get_analysis_by_case_entry_id_and_started_at(
+            case_entry_id=case.id, started_at_date=analysis_date
+        )
         analysis.delivery_report_created_at = datetime.now()
         self.status_db.commit()
 
     def get_report_data(self, case_id: str, analysis_date: datetime) -> ReportModel:
         """Fetches all the data needed to generate a delivery report."""
 
-        case: Family = self.status_db.family(case_id)
-        analysis: Analysis = self.status_db.analysis(case, analysis_date)
+        case: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
+        analysis: Analysis = self.status_db.get_analysis_by_case_entry_id_and_started_at(
+            case_entry_id=case.id, started_at_date=analysis_date
+        )
         analysis_metadata: AnalysisModel = self.analysis_api.get_latest_metadata(case.internal_id)
         case_model: CaseModel = self.get_case_data(case, analysis, analysis_metadata)
 
         return ReportModel(
             customer=self.get_customer_data(case),
             version=self.get_report_version(analysis),
             date=datetime.today(),
```

### Comparing `cg-27.1.9/cg/meta/report/templates/balsamic_report.html` & `cg-27.2.0/cg/meta/report/templates/balsamic_report.html`

 * *Files 3% similar despite different names*

```diff
@@ -226,24 +226,24 @@
         {% if customer.scout_access and "scout" in case.data_analysis.data_delivery %}
           <div class="card-block">
             <h4 class="card-title">Scout</h4>
             <div class="card-text">
               <p>Varianter finns uppladdade i Scout: <a href="https://scout.scilifelab.se/{{ customer.id }}/{{ case.name }}">scout.scilifelab.se/{{ customer.id }}/{{ case.name }}</a></p>
               <ul>
                 {% if case.data_analysis.scout_files.snv_vcf != 'N/A' %}
-                  <li><strong>Clinical somatic SNV and INDELs fil</strong> : <em>{{ case.data_analysis.scout_files.snv_vcf.replace(case.id, case.name) }}</em></li>
+                  <li><strong>Kliniskt relevanta frvrvade SNVs och INDELs</strong> : <em>{{ case.data_analysis.scout_files.snv_vcf.replace(case.id, case.name) }}</em></li>
                 {% endif %}
                 {% if case.data_analysis.scout_files.snv_research_vcf != 'N/A' %}
-                  <li><strong>Research somatic SNV and INDELs fil</strong>: <em>{{ case.data_analysis.scout_files.snv_research_vcf.replace(case.id, case.name) }}</em></li>
+                  <li><strong>Frvrvade SNVs och INDELs fr forskning</strong>: <em>{{ case.data_analysis.scout_files.snv_research_vcf.replace(case.id, case.name) }}</em></li>
                 {% endif %}
                 {% if case.data_analysis.scout_files.sv_vcf != 'N/A' %}
-                  <li><strong>Clinical somatic structural variants fil</strong>: <em>{{ case.data_analysis.scout_files.sv_vcf.replace(case.id, case.name) }}</em></li>
+                  <li><strong>Kliniskt relevanta frvrvade SVs</strong>: <em>{{ case.data_analysis.scout_files.sv_vcf.replace(case.id, case.name) }}</em></li>
                 {% endif %}
                 {% if case.data_analysis.scout_files.sv_research_vcf != 'N/A' %}
-                  <li><strong>Research somatic structural variants fil</strong>: <em>{{ case.data_analysis.scout_files.sv_research_vcf.replace(case.id, case.name) }}</em></li>
+                  <li><strong>Frvrvade SVs fr forskning</strong>: <em>{{ case.data_analysis.scout_files.sv_research_vcf.replace(case.id, case.name) }}</em></li>
                 {% endif %}
                 </ul>
             </div>
           </div>
         {% endif %}
 
         {% for application in case.applications %}
```

#### html2text {}

```diff
@@ -48,27 +48,27 @@
 }}*         }}                                 }}                              }}                      }}                      }}                      }}                                     }}                       }}                       }}                         }}                               }}
 * Information given av kund
 {% if customer.scout_access and "scout" in case.data_analysis.data_delivery %}
 *** Scout ***
 Varianter finns uppladdade i Scout: scout.scilifelab.se/{{_customer.id_}}/{
 {_case.name_}}
     * {% if case.data_analysis.scout_files.snv_vcf != 'N/A' %}
-    * Clinical somatic SNV and INDELs fil : {
+    * Kliniskt relevanta frvrvade SNVs och INDELs : {
       { case.data_analysis.scout_files.snv_vcf.replace(case.id, case.name) }}
     * {% endif %} {% if case.data_analysis.scout_files.snv_research_vcf != 'N/
       A' %}
-    * Research somatic SNV and INDELs fil: {
+    * Frvrvade SNVs och INDELs fr forskning: {
       { case.data_analysis.scout_files.snv_research_vcf.replace(case.id,
       case.name) }}
     * {% endif %} {% if case.data_analysis.scout_files.sv_vcf != 'N/A' %}
-    * Clinical somatic structural variants fil: {
+    * Kliniskt relevanta frvrvade SVs: {
       { case.data_analysis.scout_files.sv_vcf.replace(case.id, case.name) }}
     * {% endif %} {% if case.data_analysis.scout_files.sv_research_vcf != 'N/A'
       %}
-    * Research somatic structural variants fil: {
+    * Frvrvade SVs fr forskning: {
       { case.data_analysis.scout_files.sv_research_vcf.replace(case.id,
       case.name) }}
     * {% endif %}
 {% endif %} {% for application in case.applications %}
 *** Teknisk beskrivning av analysen: {{ application.tag }} ***
 {{ application.description }}
 {% if application.limitations %}
```

### Comparing `cg-27.1.9/cg/meta/report/templates/bootstrap.html` & `cg-27.2.0/cg/meta/report/templates/bootstrap.html`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/report/templates/mip-dna_report.html` & `cg-27.2.0/cg/meta/report/templates/mip-dna_report.html`

 * *Files 2% similar despite different names*

```diff
@@ -200,30 +200,30 @@
         {% if customer.scout_access and "scout" in case.data_analysis.data_delivery %}
           <div class="card-block">
             <h4 class="card-title">Scout</h4>
             <div class="card-text">
               <p>Varianter finns uppladdade i Scout: <a href="https://scout.scilifelab.se/{{ customer.id }}/{{ case.name }}">scout.scilifelab.se/{{ customer.id }}/{{ case.name }}</a></p>
               <ul>
                 {% if case.data_analysis.scout_files.snv_vcf != 'N/A' %}
-                  <li><strong>Clinical SNV and INDELs fil</strong>: <em>{{ case.data_analysis.scout_files.snv_vcf.replace(case.id, case.name) }}</em></li>
+                  <li><strong>Kliniskt relevanta frvrvade SNVs och INDELs</strong>: <em>{{ case.data_analysis.scout_files.snv_vcf.replace(case.id, case.name) }}</em></li>
                 {% endif %}
                 {% if case.data_analysis.scout_files.snv_research_vcf != 'N/A' %}
-                  <li><strong>Research SNV and INDELs fil</strong>: <em>{{ case.data_analysis.scout_files.snv_research_vcf.replace(case.id, case.name) }}</em></li>
+                  <li><strong>Frvrvade SNVs och INDELs fr forskning</strong>: <em>{{ case.data_analysis.scout_files.snv_research_vcf.replace(case.id, case.name) }}</em></li>
                 {% endif %}
                 {% if case.data_analysis.scout_files.sv_vcf != 'N/A' %}
-                  <li><strong>Clinical structural variants fil</strong>: <em>{{ case.data_analysis.scout_files.sv_vcf.replace(case.id, case.name) }}</em></li>
+                  <li><strong>Kliniskt relevanta frvrvade SVs</strong>: <em>{{ case.data_analysis.scout_files.sv_vcf.replace(case.id, case.name) }}</em></li>
                 {% endif %}
                 {% if case.data_analysis.scout_files.sv_research_vcf != 'N/A' %}
-                  <li><strong>Research structural variants fil</strong>: <em>{{ case.data_analysis.scout_files.sv_research_vcf.replace(case.id, case.name) }}</em></li>
+                  <li><strong>Frvrvade SVs fr forskning</strong>: <em>{{ case.data_analysis.scout_files.sv_research_vcf.replace(case.id, case.name) }}</em></li>
                 {% endif %}
                 {% if case.data_analysis.scout_files.vcf_str != 'N/A' %}
-                  <li><strong>Clinical STR variants fil</strong>: <em>{{ case.data_analysis.scout_files.vcf_str.replace(case.id, case.name) }}</em></li>
+                  <li><strong>Kliniskt relevanta STRs</strong>: <em>{{ case.data_analysis.scout_files.vcf_str.replace(case.id, case.name) }}</em></li>
                 {% endif %}
                 {% if case.data_analysis.scout_files.smn_tsv != 'N/A' %}
-                  <li><strong>SMN CN fil</strong>: <em>{{ case.data_analysis.scout_files.smn_tsv.replace(case.id, case.name) }}</em></li>
+                  <li><strong>SMN CN varianter</strong>: <em>{{ case.data_analysis.scout_files.smn_tsv.replace(case.id, case.name) }}</em></li>
                 {% endif %}
                 </ul>
             </div>
           </div>
         {% endif %}
 
         {% for application in case.applications %}
```

#### html2text {}

```diff
@@ -51,35 +51,35 @@
 }}*         }}                                 }}                           }}                                   }}                      }}
 * Information given av kund
 {% if customer.scout_access and "scout" in case.data_analysis.data_delivery %}
 *** Scout ***
 Varianter finns uppladdade i Scout: scout.scilifelab.se/{{_customer.id_}}/{
 {_case.name_}}
     * {% if case.data_analysis.scout_files.snv_vcf != 'N/A' %}
-    * Clinical SNV and INDELs fil: {
+    * Kliniskt relevanta frvrvade SNVs och INDELs: {
       { case.data_analysis.scout_files.snv_vcf.replace(case.id, case.name) }}
     * {% endif %} {% if case.data_analysis.scout_files.snv_research_vcf != 'N/
       A' %}
-    * Research SNV and INDELs fil: {
+    * Frvrvade SNVs och INDELs fr forskning: {
       { case.data_analysis.scout_files.snv_research_vcf.replace(case.id,
       case.name) }}
     * {% endif %} {% if case.data_analysis.scout_files.sv_vcf != 'N/A' %}
-    * Clinical structural variants fil: {
+    * Kliniskt relevanta frvrvade SVs: {
       { case.data_analysis.scout_files.sv_vcf.replace(case.id, case.name) }}
     * {% endif %} {% if case.data_analysis.scout_files.sv_research_vcf != 'N/A'
       %}
-    * Research structural variants fil: {
+    * Frvrvade SVs fr forskning: {
       { case.data_analysis.scout_files.sv_research_vcf.replace(case.id,
       case.name) }}
     * {% endif %} {% if case.data_analysis.scout_files.vcf_str != 'N/A' %}
-    * Clinical STR variants fil: {
+    * Kliniskt relevanta STRs: {
       { case.data_analysis.scout_files.vcf_str.replace(case.id, case.name) }}
     * {% endif %} {% if case.data_analysis.scout_files.smn_tsv != 'N/A' %}
-    * SMN CN fil: {{ case.data_analysis.scout_files.smn_tsv.replace(case.id,
-      case.name) }}
+    * SMN CN varianter: {{ case.data_analysis.scout_files.smn_tsv.replace
+      (case.id, case.name) }}
     * {% endif %}
 {% endif %} {% for application in case.applications %}
 *** Teknisk beskrivning av analysen: {{ application.tag }} ***
 {{ application.description }}
 {% if application.limitations %}
 *** Begrnsningar av analysen: {{ application.tag }} ***
 {{ application.limitations }}
```

### Comparing `cg-27.1.9/cg/meta/rsync/rsync_api.py` & `cg-27.2.0/cg/meta/rsync/rsync_api.py`

 * *Files 0% similar despite different names*

```diff
@@ -94,15 +94,15 @@
             timestamp = dt.datetime.now()
             timestamp_str = timestamp.strftime("%y%m%d_%H_%M_%S_%f")
             folder_name = Path("_".join([folder_prefix, timestamp_str]))
             LOG.info(f"Setting log dir to: {self.base_path / folder_name}")
             self.log_dir: Path = self.base_path / folder_name
 
     def get_all_cases_from_ticket(self, ticket: str) -> List[Family]:
-        return self.status_db.get_cases_from_ticket(ticket=ticket).all()
+        return self.status_db.get_cases_by_ticket_id(ticket_id=ticket)
 
     def get_source_and_destination_paths(self, ticket: str) -> Dict[str, Path]:
         cases: List[Family] = self.get_all_cases_from_ticket(ticket=ticket)
         source_and_destination_paths: Dict[str, Path] = {}
         if not cases:
             LOG.warning("Could not find any cases for ticket %s", ticket)
             raise CgError()
@@ -171,15 +171,15 @@
             )
         folder_list: List[str] = []
         if sample_files_present:
             folder_list.extend(
                 [sample.name for sample in self.status_db.get_samples_by_case_id(case_id=case_id)]
             )
         if case_files_present:
-            folder_list.append(self.status_db.family(case_id).name)
+            folder_list.append(self.status_db.get_case_by_internal_id(internal_id=case_id).name)
         return folder_list
 
     def slurm_rsync_single_case(
         self,
         case_id: str,
         dry_run: bool,
         sample_files_present: bool = False,
```

### Comparing `cg-27.1.9/cg/meta/tar/tar.py` & `cg-27.2.0/cg/meta/tar/tar.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/transfer/external_data.py` & `cg-27.2.0/cg/meta/transfer/external_data.py`

 * *Files 2% similar despite different names*

```diff
@@ -147,19 +147,21 @@
             last_version=hk_version,
             tags=HK_FASTQ_TAGS,
         )
         return fastq_paths_to_add
 
     def curate_sample_folder(self, cust_name: str, force: bool, sample_folder: Path) -> None:
         """Changes the name of the folder to the internal_id. If force is true replaces any previous folder."""
-        customer: Customer = self.status_db.get_customer_by_customer_id(customer_id=cust_name)
+        customer: Customer = self.status_db.get_customer_by_internal_id(
+            customer_internal_id=cust_name
+        )
         customer_folder: Path = sample_folder.parent
-        sample: Sample = self.status_db.find_samples(
-            customer=customer, name=sample_folder.name
-        ).first()
+        sample: Sample = self.status_db.get_sample_by_customer_and_name(
+            customer_entry_id=[customer.id], sample_name=sample_folder.name
+        )
         if (sample and not customer_folder.joinpath(sample.internal_id).exists()) or (
             sample and force
         ):
             sample_folder.rename(customer_folder.joinpath(sample.internal_id))
         elif not sample and not self.status_db.get_sample_by_internal_id(sample_folder.name):
             raise Exception(
                 f"{sample_folder} is not a sample present in statusdb. Move or remove it to continue"
@@ -203,8 +205,8 @@
             LOG.info("Changes in housekeeper will not be committed and no cases will be added")
             return
         if dry_run:
             LOG.info("No changes will be committed since this is a dry-run")
             return
         self.housekeeper_api.commit()
         for case in cases_to_start:
-            self.status_db.set_case_action(case_id=case["internal_id"], action="analyze")
+            self.status_db.set_case_action(case_internal_id=case["internal_id"], action="analyze")
```

### Comparing `cg-27.1.9/cg/meta/transfer/flowcell.py` & `cg-27.2.0/cg/meta/transfer/flowcell.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """API for transfer a flow cell."""
 
 import logging
 from datetime import datetime
 from pathlib import Path
-from typing import List, Dict, Optional
+from typing import List, Optional
 
-from housekeeper.store.models import Bundle, Version, Tag, File
+from housekeeper.store.models import Bundle, Version
 from cg.apps.cgstats.stats import StatsAPI
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.constants import FlowCellStatus
 from cg.constants.demultiplexing import DemultiplexingDirsAndFiles
 from cg.constants.housekeeper_tags import SequencingFileTag
 from cg.models.cgstats.flowcell import StatsFlowcell
 from cg.store import Store
```

### Comparing `cg-27.1.9/cg/meta/transfer/lims.py` & `cg-27.2.0/cg/meta/transfer/lims.py`

 * *Files 2% similar despite different names*

```diff
@@ -36,16 +36,16 @@
 
 class TransferLims(object):
     def __init__(self, status: Store, lims: LimsAPI):
         self.status = status
         self.lims = lims
 
         self._sample_functions = {
-            SampleState.RECEIVED: self.status.get_all_samples_to_receive,
-            SampleState.PREPARED: self.status.get_all_samples_to_prepare,
+            SampleState.RECEIVED: self.status.get_samples_to_receive,
+            SampleState.PREPARED: self.status.get_samples_to_prepare,
             SampleState.DELIVERED: self.status.get_samples_to_deliver,
         }
 
         self._pool_functions = {
             PoolState.RECEIVED: self.status.get_pools_to_receive,
             PoolState.DELIVERED: self.status.get_all_pools_to_deliver,
         }
@@ -54,15 +54,15 @@
             SampleState.RECEIVED: self.lims.get_received_date,
             SampleState.PREPARED: self.lims.get_prepared_date,
             SampleState.DELIVERED: self.lims.get_delivery_date,
             PoolState.RECEIVED: self.lims.get_received_date,
             PoolState.DELIVERED: self.lims.get_delivery_date,
         }
 
-    def _get_all_samples_not_yet_delivered(self):
+    def _get_samples_not_yet_delivered(self):
         return self.status.get_samples_not_delivered()
 
     def transfer_samples(
         self, status_type: SampleState, include: str = "unset", sample_id: str = None
     ):
         """Transfer information about samples."""
```

### Comparing `cg-27.1.9/cg/meta/upload/balsamic/balsamic.py` & `cg-27.2.0/cg/meta/upload/balsamic/balsamic.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/coverage.py` & `cg-27.2.0/cg/meta/upload/coverage.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/fohm/fohm.py` & `cg-27.2.0/cg/meta/upload/fohm/fohm.py`

 * *Files 2% similar despite different names*

```diff
@@ -276,18 +276,18 @@
         if os.listdir(self.daily_rawdata_path) == []:
             self.daily_rawdata_path.rmdir()
 
     def update_upload_started_at(self, case_id: str) -> None:
         """Update timestamp for cases which started being processed as batch"""
         if self._dry_run:
             return
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         case_obj.analyses[0].upload_started_at = dt.datetime.now()
         self.status_db.commit()
 
     def update_uploaded_at(self, case_id: str) -> None:
         """Update timestamp for cases which uploaded successfully"""
         if self._dry_run:
             return
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         case_obj.analyses[0].uploaded_at = dt.datetime.now()
         self.status_db.commit()
```

### Comparing `cg-27.1.9/cg/meta/upload/gisaid/constants.py` & `cg-27.2.0/cg/meta/upload/gisaid/constants.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/gisaid/gisaid.py` & `cg-27.2.0/cg/meta/upload/gisaid/gisaid.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/gisaid/models.py` & `cg-27.2.0/cg/meta/upload/gisaid/models.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from pathlib import Path
 from typing import Optional
 from pydantic import BaseModel, validator
-from datetime import date, datetime
+from datetime import datetime
 
 from cg.meta.upload.gisaid.constants import AUTHORS
 
 
 class FastaFile(BaseModel):
     header: str
     sequence: str
```

### Comparing `cg-27.1.9/cg/meta/upload/gt.py` & `cg-27.2.0/cg/meta/upload/gt.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/mip/mip_dna.py` & `cg-27.2.0/cg/meta/upload/mip/mip_dna.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 """MIP-DNA upload API"""
 
 import datetime as dt
 import logging
 
 import click
 
-from cg.apps.tb import TrailblazerAPI
 from cg.cli.generate.report.base import delivery_report
 from cg.cli.upload.clinical_delivery import clinical_delivery
 from cg.cli.upload.coverage import coverage
 from cg.cli.upload.genotype import genotypes
 from cg.cli.upload.gens import gens
 from cg.cli.upload.observations import observations
 from cg.cli.upload.scout import scout
```

### Comparing `cg-27.1.9/cg/meta/upload/mip/mip_rna.py` & `cg-27.2.0/cg/meta/upload/mip/mip_rna.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/mutacc.py` & `cg-27.2.0/cg/meta/upload/mutacc.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/nipt/nipt.py` & `cg-27.2.0/cg/meta/upload/nipt/nipt.py`

 * *Files 3% similar despite different names*

```diff
@@ -89,20 +89,15 @@
         if not results_file.exists():
             raise FileNotFoundError(f"Results file {results_file} not found on hasta!")
 
         return results_file
 
     def get_all_upload_analyses(self) -> Iterable[Analysis]:
         """Gets all nipt analyses that are ready to be uploaded"""
-
-        latest_nipt_analyses = self.status_db.latest_analyses().filter(
-            Analysis.pipeline == Pipeline.FLUFFY
-        )
-
-        return latest_nipt_analyses.filter(Analysis.uploaded_at.is_(None))
+        return self.status_db.get_latest_nipt_analysis_to_upload()
 
     def upload_to_ftp_server(self, results_file: Path) -> None:
         """Upload the result file to the ftp server"""
         if self.dry_run:
             LOG.info(f"Would upload results file to ftp server: {results_file}")
             return
         transport: paramiko.Transport = paramiko.Transport((self.sftp_host, self.sftp_port))
@@ -120,30 +115,30 @@
         )
         sftp.close()
         transport.close()
 
     def update_analysis_uploaded_at_date(self, case_id: str) -> Analysis:
         """Updates analysis_uploaded_at for the uploaded analysis"""
 
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         analysis_obj: Analysis = case_obj.analyses[0]
 
         if not self.dry_run:
             analysis_obj.uploaded_at = dt.datetime.now()
             self.status_db.commit()
             self.trailblazer_api.set_analysis_uploaded(
                 case_id=case_id, uploaded_at=analysis_obj.uploaded_at
             )
 
         return analysis_obj
 
     def update_analysis_upload_started_date(self, case_id: str) -> Analysis:
         """Updates analysis_upload_started_at for the uploaded analysis"""
 
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         analysis_obj: Analysis = case_obj.analyses[0]
 
         if not self.dry_run:
             analysis_obj.upload_started_at = dt.datetime.now()
             self.status_db.commit()
 
         return analysis_obj
```

### Comparing `cg-27.1.9/cg/meta/upload/rnafusion/rnafusion.py` & `cg-27.2.0/cg/meta/upload/rnafusion/rnafusion.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/scout/balsamic_config_builder.py` & `cg-27.2.0/cg/meta/upload/scout/balsamic_config_builder.py`

 * *Files 7% similar despite different names*

```diff
@@ -22,31 +22,35 @@
         )
         self.case_tags: CaseTags = CaseTags(**BALSAMIC_CASE_TAGS)
         self.sample_tags: SampleTags = SampleTags(**BALSAMIC_SAMPLE_TAGS)
         self.load_config: BalsamicLoadConfig = BalsamicLoadConfig(track="cancer")
 
     def include_case_files(self):
         LOG.info("Including BALSAMIC specific case level files")
-        self.load_config.vcf_cancer = self.fetch_file_from_hk(self.case_tags.snv_vcf)
-        self.load_config.vcf_cancer_sv = self.fetch_file_from_hk(self.case_tags.sv_vcf)
+        self.load_config.vcf_cancer = self.get_file_from_hk(
+            hk_tags=self.case_tags.snv_vcf, latest=True
+        )
+        self.load_config.vcf_cancer_sv = self.get_file_from_hk(
+            hk_tags=self.case_tags.sv_vcf, latest=True
+        )
         self.include_cnv_report()
         self.include_multiqc_report()
         self.include_delivery_report()
 
     def include_sample_files(self, config_sample: ScoutCancerIndividual) -> None:
         LOG.info("Including BALSAMIC specific sample level files.")
 
         sample_id: str = config_sample.sample_id
         if config_sample.alignment_path:
             if SampleType.TUMOR in config_sample.alignment_path:
                 sample_id = SampleType.TUMOR.value
             elif SampleType.NORMAL in config_sample.alignment_path:
                 sample_id = SampleType.NORMAL.value
 
-        config_sample.vcf2cytosure = self.fetch_sample_file(
+        config_sample.vcf2cytosure = self.get_sample_file(
             hk_tags=self.sample_tags.vcf2cytosure, sample_id=sample_id
         )
 
     def build_config_sample(self, case_sample: FamilySample) -> ScoutCancerIndividual:
         """Build a sample with balsamic specific information."""
         config_sample = ScoutCancerIndividual()
```

### Comparing `cg-27.1.9/cg/meta/upload/scout/balsamic_umi_config_builder.py` & `cg-27.2.0/cg/meta/upload/scout/balsamic_umi_config_builder.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/scout/hk_tags.py` & `cg-27.2.0/cg/meta/upload/scout/hk_tags.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/scout/mip_config_builder.py` & `cg-27.2.0/cg/meta/upload/scout/mip_config_builder.py`

 * *Files 4% similar despite different names*

```diff
@@ -96,67 +96,67 @@
         )
 
         return config_sample
 
     def include_case_files(self):
         """Include case level files for mip case"""
         LOG.info("Including MIP specific case level files")
-        self.load_config.vcf_snv = self.fetch_file_from_hk(self.case_tags.snv_vcf)
-        self.load_config.vcf_sv = self.fetch_file_from_hk(self.case_tags.sv_vcf)
-        self.load_config.vcf_snv_research = self.fetch_file_from_hk(self.case_tags.snv_research_vcf)
-        self.load_config.vcf_sv_research = self.fetch_file_from_hk(self.case_tags.sv_research_vcf)
-        self.load_config.vcf_str = self.fetch_file_from_hk(self.case_tags.vcf_str)
-        self.load_config.peddy_ped = self.fetch_file_from_hk(self.case_tags.peddy_ped)
-        self.load_config.peddy_sex = self.fetch_file_from_hk(self.case_tags.peddy_sex)
-        self.load_config.peddy_check = self.fetch_file_from_hk(self.case_tags.peddy_check)
-        self.load_config.smn_tsv = self.fetch_file_from_hk(self.case_tags.smn_tsv)
+        self.load_config.vcf_snv = self.get_file_from_hk(self.case_tags.snv_vcf)
+        self.load_config.vcf_sv = self.get_file_from_hk(self.case_tags.sv_vcf)
+        self.load_config.vcf_snv_research = self.get_file_from_hk(self.case_tags.snv_research_vcf)
+        self.load_config.vcf_sv_research = self.get_file_from_hk(self.case_tags.sv_research_vcf)
+        self.load_config.vcf_str = self.get_file_from_hk(self.case_tags.vcf_str)
+        self.load_config.peddy_ped = self.get_file_from_hk(self.case_tags.peddy_ped)
+        self.load_config.peddy_sex = self.get_file_from_hk(self.case_tags.peddy_sex)
+        self.load_config.peddy_check = self.get_file_from_hk(self.case_tags.peddy_check)
+        self.load_config.smn_tsv = self.get_file_from_hk(self.case_tags.smn_tsv)
         self.include_multiqc_report()
         self.include_delivery_report()
 
     def include_sample_files(self, config_sample: ScoutMipIndividual) -> None:
         """Include sample level files that are optional for mip samples"""
         LOG.info("Including MIP specific sample level files")
         sample_id: str = config_sample.sample_id
-        config_sample.vcf2cytosure = self.fetch_sample_file(
+        config_sample.vcf2cytosure = self.get_sample_file(
             hk_tags=self.sample_tags.vcf2cytosure, sample_id=sample_id
         )
-        config_sample.mt_bam = self.fetch_sample_file(
+        config_sample.mt_bam = self.get_sample_file(
             hk_tags=self.sample_tags.mt_bam, sample_id=sample_id
         )
         config_sample.chromograph_images.autozygous = self.extract_generic_filepath(
-            file_path=self.fetch_sample_file(
+            file_path=self.get_sample_file(
                 hk_tags=self.sample_tags.chromograph_autozyg, sample_id=sample_id
             )
         )
         config_sample.chromograph_images.coverage = self.extract_generic_filepath(
-            file_path=self.fetch_sample_file(
+            file_path=self.get_sample_file(
                 hk_tags=self.sample_tags.chromograph_coverage, sample_id=sample_id
             )
         )
         config_sample.chromograph_images.upd_regions = self.extract_generic_filepath(
-            file_path=self.fetch_sample_file(
+            file_path=self.get_sample_file(
                 hk_tags=self.sample_tags.chromograph_regions, sample_id=sample_id
             )
         )
         config_sample.chromograph_images.upd_sites = self.extract_generic_filepath(
-            file_path=self.fetch_sample_file(
+            file_path=self.get_sample_file(
                 hk_tags=self.sample_tags.chromograph_sites, sample_id=sample_id
             )
         )
-        config_sample.reviewer.alignment = self.fetch_sample_file(
+        config_sample.reviewer.alignment = self.get_sample_file(
             hk_tags=self.sample_tags.reviewer_alignment, sample_id=sample_id
         )
-        config_sample.reviewer.alignment_index = self.fetch_sample_file(
+        config_sample.reviewer.alignment_index = self.get_sample_file(
             hk_tags=self.sample_tags.reviewer_alignment_index, sample_id=sample_id
         )
-        config_sample.reviewer.vcf = self.fetch_sample_file(
+        config_sample.reviewer.vcf = self.get_sample_file(
             hk_tags=self.sample_tags.reviewer_vcf, sample_id=sample_id
         )
-        config_sample.reviewer.catalog = self.fetch_file_from_hk(hk_tags=self.case_tags.str_catalog)
-        config_sample.mitodel_file = self.fetch_sample_file(
+        config_sample.reviewer.catalog = self.get_file_from_hk(hk_tags=self.case_tags.str_catalog)
+        config_sample.mitodel_file = self.get_sample_file(
             hk_tags=self.sample_tags.mitodel_file, sample_id=sample_id
         )
 
     @staticmethod
     def extract_generic_filepath(file_path: Optional[str]) -> Optional[str]:
         """Remove a file's suffix and identifying integer or X/Y
         Example:
```

### Comparing `cg-27.1.9/cg/meta/upload/scout/rnafusion_config_builder.py` & `cg-27.2.0/cg/meta/upload/scout/rnafusion_config_builder.py`

 * *Files 2% similar despite different names*

```diff
@@ -45,15 +45,15 @@
 
     def _include_file(self, scout_key) -> None:
         """Include the file path associated to a scout configuration parameter if the corresponding housekeeper tags
         are found. Otherwise return None."""
         setattr(
             self.load_config,
             scout_key,
-            self.fetch_file_from_hk(getattr(self.case_tags, scout_key)),
+            self.get_file_from_hk(getattr(self.case_tags, scout_key)),
         )
 
     def build_config_sample(self, case_sample: FamilySample) -> ScoutCancerIndividual:
         """Build a sample with rnafusion specific information."""
         config_sample = ScoutCancerIndividual()
 
         self.add_common_sample_info(config_sample=config_sample, case_sample=case_sample)
```

### Comparing `cg-27.1.9/cg/meta/upload/scout/scout_config_builder.py` & `cg-27.2.0/cg/meta/upload/scout/scout_config_builder.py`

 * *Files 4% similar despite different names*

```diff
@@ -132,52 +132,56 @@
         cohorts: List[str] = self.analysis_obj.family.cohorts
         if cohorts:
             LOG.debug("Adding cohorts %s", ", ".join(cohorts))
             self.load_config.cohorts = cohorts
 
     def include_cnv_report(self) -> None:
         LOG.info("Include CNV report to case")
-        self.load_config.cnv_report = self.fetch_file_from_hk(self.case_tags.cnv_report)
+        self.load_config.cnv_report = self.get_file_from_hk(
+            hk_tags=self.case_tags.cnv_report, latest=True
+        )
 
     def include_multiqc_report(self) -> None:
         LOG.info("Include MultiQC report to case")
-        self.load_config.multiqc = self.fetch_file_from_hk(self.case_tags.multiqc_report)
+        self.load_config.multiqc = self.get_file_from_hk(
+            hk_tags=self.case_tags.multiqc_report, latest=True
+        )
 
     def include_delivery_report(self) -> None:
         LOG.info("Include delivery report to case")
-        self.load_config.delivery_report = self.fetch_file_from_hk(self.case_tags.delivery_report)
+        self.load_config.delivery_report = self.get_file_from_hk(
+            hk_tags=self.case_tags.delivery_report, latest=True
+        )
 
     def include_sample_alignment_file(self, config_sample: ScoutIndividual) -> None:
         """Include the alignment file for a sample
 
         First add the bam.
         Cram is preferred so overwrite if found
         """
         sample_id: str = config_sample.sample_id
-        config_sample.alignment_path = self.fetch_sample_file(
+        config_sample.alignment_path = self.get_sample_file(
             hk_tags=self.sample_tags.bam_file, sample_id=sample_id
         )
 
-        config_sample.alignment_path = self.fetch_sample_file(
+        config_sample.alignment_path = self.get_sample_file(
             hk_tags=self.sample_tags.alignment_file, sample_id=sample_id
         )
 
-    def fetch_sample_file(self, hk_tags: Set[str], sample_id: str) -> Optional[str]:
-        """Fetch a file that is specific for a individual from housekeeper"""
+    def get_sample_file(self, hk_tags: Set[str], sample_id: str) -> Optional[str]:
+        """Return a file that is specific for a individual from housekeeper"""
         tags: set = hk_tags.copy()
         tags.add(sample_id)
-        return self.fetch_file_from_hk(hk_tags=tags)
+        return self.get_file_from_hk(hk_tags=tags)
 
-    def fetch_file_from_hk(self, hk_tags: Set[str]) -> Optional[str]:
-        """Fetch a file from housekeeper and return the path as a string.
-        If file does not exist return None
-        """
-        LOG.info("Fetch file with tags %s", hk_tags)
+    def get_file_from_hk(self, hk_tags: Set[str], latest: Optional[bool] = False) -> Optional[str]:
+        """Get a file from housekeeper and return the path as a string."""
+        LOG.info(f"Get file with tags {hk_tags}")
         if not hk_tags:
             LOG.debug("No tags provided, skipping")
             return None
-        hk_file: Optional[File] = HousekeeperAPI.fetch_file_from_version(
-            version_obj=self.hk_version_obj, tags=hk_tags
+        hk_file: Optional[File] = (
+            HousekeeperAPI.get_latest_file_from_version(version=self.hk_version_obj, tags=hk_tags)
+            if latest
+            else HousekeeperAPI.get_file_from_version(version=self.hk_version_obj, tags=hk_tags)
         )
-        if hk_file is None:
-            return hk_file
-        return hk_file.full_path
+        return hk_file.full_path if hk_file else None
```

### Comparing `cg-27.1.9/cg/meta/upload/scout/uploadscoutapi.py` & `cg-27.2.0/cg/meta/upload/scout/uploadscoutapi.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-"""File includes api to uploading data into Scout"""
+"""File includes api to uploading data into Scout."""
 
 import logging
 from pathlib import Path
-from typing import Any, Dict, List, Optional, Set
+from typing import Dict, List, Optional, Set
 
 from housekeeper.store.models import File, Version
-from sqlalchemy.orm import Query
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.apps.lims import LimsAPI
 from cg.apps.madeline.api import MadelineAPI
 from cg.apps.scout.scoutapi import ScoutAPI
 from cg.constants import Pipeline
 from cg.constants.constants import FileFormat
@@ -26,15 +25,15 @@
 from cg.store import Store
 from cg.store.models import Analysis, Family, Sample, FamilySample
 
 LOG = logging.getLogger(__name__)
 
 
 class UploadScoutAPI:
-    """Class that handles everything that has to do with uploading to Scout"""
+    """Class that handles everything that has to do with uploading to Scout."""
 
     def __init__(
         self,
         hk_api: HousekeeperAPI,
         scout_api: ScoutAPI,
         lims_api: LimsAPI,
         analysis_api: AnalysisAPI,
@@ -63,51 +62,51 @@
 
         config_builder.build_load_config()
 
         return config_builder.load_config
 
     @staticmethod
     def get_load_config_tag() -> str:
-        """Get the hk tag for a scout load config"""
+        """Get the Housekeeper tag for a Scout load config."""
         return "scout-load-config"
 
     @staticmethod
     def save_config_file(upload_config: ScoutLoadConfig, file_path: Path) -> None:
-        """Save a scout load config file to <file_path>"""
+        """Save a Scout load config file to the supplied file path."""
 
-        LOG.info("Save Scout load config to %s", file_path)
+        LOG.info(f"Save Scout load config to {file_path.as_posix()}")
         WriteFile.write_file_from_content(
             content=upload_config.dict(exclude_none=True),
             file_format=FileFormat.YAML,
             file_path=file_path,
         )
 
     def add_scout_config_to_hk(
         self, config_file_path: Path, case_id: str, delete: bool = False
     ) -> File:
-        """Add scout load config to hk bundle"""
-        LOG.info("Adding load config %s to housekeeper", config_file_path)
+        """Add Scout load config to Housekeeper bundle."""
+        LOG.info(f"Adding load config {config_file_path} to Housekeeper")
         tag_name: str = self.get_load_config_tag()
-        version_obj: Version = self.housekeeper.last_version(bundle=case_id)
-        uploaded_config_file: Optional[File] = self.housekeeper.fetch_file_from_version(
-            version_obj=version_obj, tags={tag_name}
+        version: Version = self.housekeeper.last_version(bundle=case_id)
+        uploaded_config_file: Optional[File] = self.housekeeper.get_latest_file_from_version(
+            version=version, tags={tag_name}
         )
         if uploaded_config_file:
-            LOG.info("Found config file: %s", uploaded_config_file)
+            LOG.info(f"Found config file: {uploaded_config_file}")
             if not delete:
                 raise FileExistsError("Upload config already exists")
             self.housekeeper.delete_file(uploaded_config_file.id)
 
         file_obj: File = self.housekeeper.add_file(
-            path=str(config_file_path), version_obj=version_obj, tags=tag_name
+            path=str(config_file_path), version_obj=version, tags=tag_name
         )
-        self.housekeeper.include_file(file_obj=file_obj, version_obj=version_obj)
+        self.housekeeper.include_file(file_obj=file_obj, version_obj=version)
         self.housekeeper.add_commit(file_obj)
 
-        LOG.info("Added scout load config to housekeeper: %s", config_file_path)
+        LOG.info(f"Added Scout load config to Housekeeper: {config_file_path}")
         return file_obj
 
     def get_fusion_report(self, case_id: str, research: bool) -> Optional[File]:
         """Get a fusion report for case in housekeeper
 
         Args:
             case_id     (string):       Case identifier
@@ -189,15 +188,15 @@
         Returns:
             Nothing
         """
 
         scout_api: ScoutAPI = self.scout
         status_db: Store = self.status_db
         report_type: str = "Research" if research else "Clinical"
-        rna_case: Family = status_db.family(case_id)
+        rna_case: Family = status_db.get_case_by_internal_id(internal_id=case_id)
 
         rna_dna_sample_case_map: Dict[str, Dict[str, list]] = self.create_rna_dna_sample_case_map(
             rna_case=rna_case
         )
         unique_dna_cases: Set[str] = set()
         fusion_report: Optional[File] = self.get_fusion_report(case_id, research)
         if fusion_report is None:
@@ -238,15 +237,15 @@
             case_id     (string):       Case identifier
         Returns:
             Nothing
         """
 
         scout_api: ScoutAPI = self.scout
         status_db: Store = self.status_db
-        rna_case = status_db.family(case_id)
+        rna_case = status_db.get_case_by_internal_id(internal_id=case_id)
         rna_dna_sample_case_map: Dict[str, Dict[str, list]] = self.create_rna_dna_sample_case_map(
             rna_case=rna_case
         )
         for rna_sample_id in rna_dna_sample_case_map:
             rna_coverage_bigwig: Optional[File] = self.get_rna_coverage_bigwig(
                 case_id=case_id, sample_id=rna_sample_id
             )
@@ -289,15 +288,15 @@
             dry_run     (bool):         Skip uploading
             case_id     (string):       Case identifier
         Returns:
             Nothing
         """
         scout_api: ScoutAPI = self.scout
         status_db: Store = self.status_db
-        rna_case: Family = status_db.family(case_id)
+        rna_case: Family = status_db.get_case_by_internal_id(internal_id=case_id)
 
         rna_dna_sample_case_map: Dict[str, Dict[str, list]] = self.create_rna_dna_sample_case_map(
             rna_case=rna_case
         )
         for rna_sample_id in rna_dna_sample_case_map:
             splice_junctions_bed: Optional[File] = self.get_splice_junctions_bed(
                 case_id=case_id, sample_id=rna_sample_id
@@ -423,16 +422,18 @@
         self, rna_sample: Sample, rna_dna_sample_case_map: Dict[str, Dict[str, list]]
     ) -> Sample:
         if not rna_sample.subject_id:
             raise CgDataError(
                 f"Failed on RNA sample {rna_sample.internal_id} as subject_id field is empty"
             )
 
-        subject_id_samples: List[Sample] = self.status_db.get_samples_by_subject_id_and_is_tumour(
-            customer_id=rna_sample.customer.internal_id,
+        subject_id_samples: List[
+            Sample
+        ] = self.status_db.get_samples_by_customer_subject_id_and_is_tumour(
+            customer_internal_id=rna_sample.customer.internal_id,
             subject_id=rna_sample.subject_id,
             is_tumour=rna_sample.is_tumour,
         )
         subject_id_dna_samples: List[Sample] = self._get_application_prep_category(
             subject_id_samples=subject_id_samples
         )
```

### Comparing `cg-27.1.9/cg/meta/upload/upload_api.py` & `cg-27.2.0/cg/meta/upload/upload_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/upload/vogue.py` & `cg-27.2.0/cg/meta/upload/vogue.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/workflow/analysis.py` & `cg-27.2.0/cg/meta/workflow/analysis.py`

 * *Files 3% similar despite different names*

```diff
@@ -66,15 +66,15 @@
     def verify_case_config_file_exists(self, case_id: str) -> None:
         if not Path(self.get_case_config_path(case_id=case_id)).exists():
             raise CgError(f"No config file found for case {case_id}")
 
     def verify_case_id_in_statusdb(self, case_id: str) -> None:
         """Passes silently if case exists in StatusDB, raises error if case is missing"""
 
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         if not case_obj:
             LOG.error("Case %s could not be found in StatusDB!", case_id)
             raise CgError
         if not case_obj.links:
             LOG.error("Case %s has no samples in in StatusDB!", case_id)
             raise CgError
         LOG.info("Case %s exists in status db", case_id)
@@ -88,15 +88,15 @@
         """Check if case path exists."""
         if not self.get_case_path(case_id=case_id).exists():
             LOG.info(f"No working directory for {case_id} exists")
             raise FileNotFoundError(f"No working directory for {case_id} exists")
 
     def get_priority_for_case(self, case_id: str) -> int:
         """Get priority from the status db case priority"""
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         return case_obj.priority.value or Priority.research
 
     def get_slurm_qos_for_case(self, case_id: str) -> str:
         """Get Quality of service (SLURM QOS) for the case."""
         priority: int = self.get_priority_for_case(case_id=case_id)
         return PRIORITY_TO_SLURM_QOS[priority]
 
@@ -165,15 +165,15 @@
             f"Analysis successfully stored in Housekeeper: {case_id} : {bundle_version.created_at}"
         )
 
     def upload_bundle_statusdb(self, case_id: str, dry_run: bool = False) -> None:
         """Storing analysis bundle in StatusDB for CASE_ID"""
 
         LOG.info(f"Storing analysis in StatusDB for {case_id}")
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         analysis_start: dt.datetime = self.get_bundle_created_date(case_id=case_id)
         pipeline_version: str = self.get_pipeline_version(case_id=case_id)
         new_analysis: Family = self.status_db.add_analysis(
             pipeline=self.pipeline,
             version=pipeline_version,
             started_at=analysis_start,
             completed_at=dt.datetime.now(),
@@ -194,15 +194,17 @@
 
     def add_pending_trailblazer_analysis(self, case_id: str) -> None:
         self.check_analysis_ongoing(case_id=case_id)
         self.trailblazer_api.mark_analyses_deleted(case_id=case_id)
         self.trailblazer_api.add_pending_analysis(
             case_id=case_id,
             email=environ_email(),
-            analysis_type=self.get_application_type(self.status_db.family(case_id).links[0].sample),
+            analysis_type=self.get_application_type(
+                self.status_db.get_case_by_internal_id(internal_id=case_id).links[0].sample
+            ),
             out_dir=self.get_trailblazer_config_path(case_id=case_id).parent.as_posix(),
             config_path=self.get_trailblazer_config_path(case_id=case_id).as_posix(),
             slurm_quality_of_service=self.get_slurm_qos_for_case(case_id=case_id),
             data_analysis=str(self.pipeline),
             ticket=self.status_db.get_latest_ticket_from_case(case_id),
         )
 
@@ -235,15 +237,15 @@
         """
         Set one of the allowed actions on a case in StatusDB.
         """
         if dry_run:
             LOG.info(f"Dry-run: Action {action} would be set for case {case_id}")
             return
         if action in [None, *CASE_ACTIONS]:
-            case_obj: Family = self.status_db.family(case_id)
+            case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
             case_obj.action = action
             self.status_db.commit()
             LOG.info("Action %s set for case %s", action, case_id)
             return
         LOG.warning(
             f"Action '{action}' not permitted by StatusDB and will not be set for case {case_id}"
         )
@@ -254,15 +256,15 @@
 
     def get_cases_to_analyze(self) -> List[Family]:
         return self.status_db.cases_to_analyze(
             pipeline=self.pipeline, threshold=self.threshold_reads
         )
 
     def get_running_cases(self) -> List[Family]:
-        return self.status_db.get_running_cases_for_pipeline(pipeline=self.pipeline)
+        return self.status_db.get_running_cases_in_pipeline(pipeline=self.pipeline)
 
     def get_cases_to_store(self) -> List[Family]:
         """Retrieve a list of cases where analysis finished successfully,
         and is ready to be stored in Housekeeper"""
         return [
             case_object
             for case_object in self.get_running_cases()
@@ -323,15 +325,15 @@
         LOG.info("Concatenation in progress for sample %s.", sample_obj.internal_id)
         for read, value in linked_reads_paths.items():
             self.fastq_handler.concatenate(linked_reads_paths[read], concatenated_paths[read])
             self.fastq_handler.remove_files(value)
 
     def get_target_bed_from_lims(self, case_id: str) -> Optional[str]:
         """Get target bed filename from LIMS."""
-        case: Family = self.status_db.family(internal_id=case_id)
+        case: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         sample: Sample = case.links[0].sample
         if sample.from_sample:
             sample: Sample = self.status_db.get_sample_by_internal_id(
                 internal_id=sample.from_sample
             )
         target_bed_shortname: str = self.lims_api.capture_kit(lims_id=sample.internal_id)
         if not target_bed_shortname:
@@ -368,15 +370,15 @@
         )
         decompression_possible: bool = (
             self.prepare_fastq_api.can_at_least_one_sample_be_decompressed(case_id)
         )
         if not decompression_possible:
             self.decompression_running(case_id=case_id)
             return
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         link: FamilySample
         any_decompression_started = False
         for link in case_obj.links:
             sample_id: str = link.sample.internal_id
             if dry_run:
                 LOG.info(
                     f"This is a dry run, therefore decompression for {sample_id} won't be started"
@@ -437,15 +439,15 @@
     ) -> AnalysisModel:
         """Parses output analysis files"""
 
         raise NotImplementedError
 
     def clean_analyses(self, case_id: str) -> None:
         """Add a cleaned at date for all analyses related to a case."""
-        analyses: list = self.status_db.family(case_id).analyses
+        analyses: list = self.status_db.get_case_by_internal_id(internal_id=case_id).analyses
         LOG.info(f"Adding a cleaned at date for case {case_id}")
         for analysis_obj in analyses:
             analysis_obj.cleaned_at = analysis_obj.cleaned_at or dt.datetime.now()
             self.status_db.commit()
 
     def clean_run_dir(self, case_id: str, yes: bool, case_path: Union[List[Path], Path]) -> int:
         """Remove workflow run directory."""
```

### Comparing `cg-27.1.9/cg/meta/workflow/balsamic.py` & `cg-27.2.0/cg/meta/workflow/balsamic.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """Module for Balsamic Analysis API"""
 
 import logging
 from pathlib import Path
 from typing import Dict, List, Optional, Union
 
+from housekeeper.store.models import Version, File
 from pydantic import ValidationError
 
 from cg.constants import Pipeline
 from cg.constants.constants import FileFormat, SampleType, AnalysisType
 from cg.constants.housekeeper_tags import BalsamicAnalysisTag
 from cg.constants.indexes import ListIndexes
 from cg.constants.observations import ObservationsFileWildcards
@@ -122,18 +123,20 @@
 
     def get_bundle_deliverables_type(self, case_id: str) -> str:
         """Return the analysis type for a case
 
         Analysis types are any of ["tumor_wgs", "tumor_normal_wgs", "tumor_panel", "tumor_normal_panel"]
         """
         LOG.debug("Fetch analysis type for %s", case_id)
-        number_of_samples: int = len(self.status_db.family(case_id).links)
+        number_of_samples: int = len(
+            self.status_db.get_case_by_internal_id(internal_id=case_id).links
+        )
 
         application_type: str = self.get_application_type(
-            self.status_db.family(case_id).links[0].sample
+            self.status_db.get_case_by_internal_id(internal_id=case_id).links[0].sample
         )
         sample_type = "tumor"
         if number_of_samples == 2:
             sample_type = "tumor_normal"
         if application_type != "wgs":
             application_type = "panel"
         analysis_type = "_".join([sample_type, application_type])
@@ -141,15 +144,15 @@
         return analysis_type
 
     def get_sample_fastq_destination_dir(self, case: Family, sample: Sample = None) -> Path:
         """Return the path to the FASTQ destination directory."""
         return Path(self.get_case_path(case.internal_id), FileFormat.FASTQ)
 
     def link_fastq_files(self, case_id: str, dry_run: bool = False) -> None:
-        case_obj = self.status_db.family(case_id)
+        case_obj = self.status_db.get_case_by_internal_id(internal_id=case_id)
         for link in case_obj.links:
             self.link_fastq_files_for_sample(
                 case_obj=case_obj, sample_obj=link.sample, concatenate=True
             )
 
     def get_concatenated_fastq_path(self, link_object: FamilySample) -> Path:
         """Returns path to the concatenated FASTQ file of a sample"""
@@ -342,20 +345,20 @@
             "tumor_sample_name": tumor_sample_id,
             "tumor": tumor_sample_path,
             "normal_sample_name": normal_sample_id,
             "normal": normal_sample_path,
         }
 
     def get_latest_raw_file_data(self, case_id: str, tags: list) -> Union[dict, list]:
-        """Retrieves the data of the latest file associated to a specific case ID and a list of tags"""
+        """Retrieves the data of the latest file associated to a specific case ID and a list of tags."""
 
-        version = self.housekeeper_api.last_version(bundle=case_id)
-        raw_file = self.housekeeper_api.get_files(
+        version: Version = self.housekeeper_api.last_version(bundle=case_id)
+        raw_file: File = self.housekeeper_api.get_latest_file(
             bundle=case_id, version=version.id, tags=tags
-        ).first()
+        )
 
         if not raw_file:
             raise FileNotFoundError(
                 f"No file associated to {tags} was found in housekeeper for {case_id}"
             )
         return ReadFile.get_content_from_file(
             file_format=FileFormat.YAML, file_path=Path(raw_file.full_path)
@@ -509,15 +512,15 @@
             normal_string = f"{normal_sample_lims_id}:normal:{self.status_db.get_sample_by_internal_id(internal_id=normal_sample_lims_id).name}"
             return ",".join([tumor_string, normal_string])
         return tumor_string
 
     def build_case_id_map_string(self, case_id: str) -> Optional[str]:
         """Creates case info string for balsamic with format panel_shortname:case_name:application_tag."""
 
-        case: Family = self.status_db.family(internal_id=case_id)
+        case: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         sample: Sample = case.links[0].sample
         if sample.from_sample:
             sample: Sample = self.status_db.get_sample_by_internal_id(
                 internal_id=sample.from_sample
             )
         capture_kit: Optional[str] = self.lims_api.capture_kit(lims_id=sample.internal_id)
         if capture_kit:
@@ -567,24 +570,24 @@
             link_object.sample.internal_id: {
                 "gender": self.get_gender(link_object.sample),
                 "tissue_type": self.get_sample_type(link_object.sample).value,
                 "concatenated_path": self.get_concatenated_fastq_path(link_object).as_posix(),
                 "application_type": self.get_application_type(link_object.sample),
                 "target_bed": self.resolve_target_bed(panel_bed=panel_bed, link_object=link_object),
             }
-            for link_object in self.status_db.family(case_id).links
+            for link_object in self.status_db.get_case_by_internal_id(internal_id=case_id).links
         }
 
         self.print_sample_params(case_id=case_id, sample_data=sample_data)
         return sample_data
 
     def get_case_application_type(self, case_id: str) -> str:
         application_types = {
             self.get_application_type(link_object.sample)
-            for link_object in self.status_db.family(case_id).links
+            for link_object in self.status_db.get_case_by_internal_id(internal_id=case_id).links
         }
 
         if application_types:
             return application_types.pop().lower()
 
     def resolve_target_bed(
         self, panel_bed: Optional[str], link_object: FamilySample
@@ -598,40 +601,14 @@
     def get_pipeline_version(self, case_id: str) -> str:
         LOG.debug("Fetch pipeline version")
         config_data: dict = ReadFile.get_content_from_file(
             file_format=FileFormat.JSON, file_path=self.get_case_config_path(case_id=case_id)
         )
         return config_data["analysis"]["BALSAMIC_version"]
 
-    def family_has_correct_number_tumor_normal_samples(self, case_id: str) -> bool:
-        """Evaluates if a case has exactly one tumor and up to one normal sample in ClinicalDB.
-        This check is only applied to filter jobs which start automatically"""
-        query = (
-            self.status_db.query(Sample)
-            .join(Family.links, FamilySample.sample)
-            .filter(Family.internal_id == case_id)
-            .filter(Family.data_analysis == self.pipeline)
-        )
-        return all(
-            [
-                len(query.filter(Sample.is_tumour == False).all()) <= 1,
-                len(query.filter(Sample.is_tumour == True).all()) == 1,
-            ]
-        )
-
-    def get_valid_cases_to_analyze(self) -> list:
-        """Retrieve a list of balsamic cases without analysis,
-        where samples have enough reads to be analyzed"""
-
-        return [
-            case_object.internal_id
-            for case_object in self.get_cases_to_analyze()
-            if self.family_has_correct_number_tumor_normal_samples(case_object.internal_id)
-        ]
-
     def config_case(
         self,
         case_id: str,
         gender: str,
         genome_version: str,
         panel_bed: str,
         pon_cnn: str,
```

### Comparing `cg-27.1.9/cg/meta/workflow/balsamic_pon.py` & `cg-27.2.0/cg/meta/workflow/balsamic_pon.py`

 * *Files 1% similar despite different names*

```diff
@@ -34,15 +34,15 @@
         pon_cnn: str,
         observations: List[str],
         force_normal: bool,
         dry_run: bool = False,
     ) -> None:
         """Creates a config file for BALSAMIC PON analysis"""
 
-        case_obj = self.status_db.family(case_id)
+        case_obj = self.status_db.get_case_by_internal_id(internal_id=case_id)
         sample_data = self.get_sample_params(case_id=case_id, panel_bed=panel_bed)
         if len(sample_data) == 0:
             raise BalsamicStartError(f"{case_id} has no samples tagged for BALSAMIC PON analysis!")
         verified_panel_bed = self.get_verified_bed(panel_bed, sample_data)
 
         command = ["config", "pon"]
         options = BalsamicAnalysisAPI._BalsamicAnalysisAPI__build_command_str(
```

### Comparing `cg-27.1.9/cg/meta/workflow/balsamic_qc.py` & `cg-27.2.0/cg/meta/workflow/balsamic_qc.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/workflow/balsamic_umi.py` & `cg-27.2.0/cg/meta/workflow/balsamic_umi.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/meta/workflow/fastq.py` & `cg-27.2.0/cg/meta/workflow/fastq.py`

 * *Files 2% similar despite different names*

```diff
@@ -10,15 +10,14 @@
 import logging
 import os
 import re
 import shutil
 from pathlib import Path
 from typing import List, Optional
 
-from pydantic.main import BaseModel
 
 LOG = logging.getLogger(__name__)
 
 DEFAULT_DATE_STR = (
     "171015"  # Stand in value to use if sequencing date cannot be extracted from header
 )
 DEFAULT_INDEX = (
```

### Comparing `cg-27.1.9/cg/meta/workflow/fluffy.py` & `cg-27.2.0/cg/meta/workflow/fluffy.py`

 * *Files 2% similar despite different names*

```diff
@@ -46,15 +46,17 @@
         return Path(self.root_dir, case_id)
 
     def get_sample_sheet_path(self, case_id: str) -> Path:
         """
         Location in case folder where sample sheet is expected to be stored. Sample sheet is used as a config
         required to run Fluffy
         """
-        starlims_id: str = self.status_db.family(case_id).links[0].sample.order
+        starlims_id: str = (
+            self.status_db.get_case_by_internal_id(internal_id=case_id).links[0].sample.order
+        )
         return Path(self.root_dir, case_id, f"SampleSheet_{starlims_id}.csv")
 
     def get_workdir_path(self, case_id: str) -> Path:
         """
         Location in case folder where all sub-folders for each sample containing fastq files are to e saved
         """
         return Path(self.root_dir, case_id, "fastq")
@@ -89,15 +91,15 @@
     def get_analysis_finish_path(self, case_id: str) -> Path:
         return Path(self.get_output_path(case_id), "COMPLETE")
 
     def link_fastq_files(self, case_id: str, dry_run: bool = False) -> None:
         """
         Links fastq files from Housekeeper to case working directory
         """
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         latest_flow_cell = self.status_db.get_latest_flow_cell_on_case(family_id=case_id)
         workdir_path = self.get_workdir_path(case_id=case_id)
         if workdir_path.exists() and not dry_run:
             LOG.info("Fastq directory exists, removing and re-linking files!")
             shutil.rmtree(workdir_path, ignore_errors=True)
         workdir_path.mkdir(parents=True, exist_ok=True)
         for family_sample in case_obj.links:
```

### Comparing `cg-27.1.9/cg/meta/workflow/microsalt.py` & `cg-27.2.0/cg/meta/workflow/microsalt.py`

 * *Files 6% similar despite different names*

```diff
@@ -5,33 +5,32 @@
     Method: Outputted as 1273:23. Defaults to Not in LIMS
     Date: Returns latest == most recent date. Outputted as DT object YYYY MM DD. Defaults to
     datetime.min"""
 import logging
 import os
 import re
 import shutil
-from datetime import datetime, timedelta
+from datetime import datetime
 from pathlib import Path
-from subprocess import CalledProcessError
 from typing import Any, Dict, List, Optional, Tuple, Union
 import glob
 
 import click
 from cg.constants import Pipeline
 from cg.constants.constants import MicrosaltQC, MicrosaltAppTags
 from cg.constants.tb import AnalysisStatus
-from cg.exc import CgDataError, CgError
+from cg.exc import CgDataError
 from cg.meta.workflow.analysis import AnalysisAPI
 from cg.meta.workflow.fastq import MicrosaltFastqHandler
 from cg.models.cg_config import CGConfig
 from cg.models.orders.sample_base import ControlEnum
 from cg.store.models import Family, Sample
 from cg.utils import Process
 from cg.constants import EXIT_FAIL, EXIT_SUCCESS
-from cg.io.json import read_json, write_json_stream, write_json
+from cg.io.json import read_json, write_json
 
 from cg.constants import Priority
 
 LOG = logging.getLogger(__name__)
 
 
 class MicrosaltAnalysisAPI(AnalysisAPI):
@@ -62,28 +61,28 @@
                 conda_binary=f"{self.conda_binary}" if self.conda_binary else None,
                 environment=self.config.microsalt.conda_env,
             )
         return self._process
 
     def get_case_path(self, case_id: str) -> List[Path]:
         """Returns all paths associated with the case or single sample analysis."""
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         lims_project: str = self.get_project(case_obj.links[0].sample.internal_id)
         lims_project_dir_path: Path = Path(self.root_dir, "results", lims_project)
 
         case_directories: List[Path] = [
             Path(path) for path in glob.glob(f"{lims_project_dir_path}*", recursive=True)
         ]
 
         return sorted(case_directories, key=os.path.getctime, reverse=True)
 
     def get_latest_case_path(self, case_id: str) -> Union[Path, None]:
         """Return latest run dir for a microbial case, if no path found it returns None."""
         lims_project: str = self.get_project(
-            self.status_db.family(case_id).links[0].sample.internal_id
+            self.status_db.get_case_by_internal_id(internal_id=case_id).links[0].sample.internal_id
         )
 
         return next(
             (
                 path
                 for path in self.get_case_path(case_id=case_id)
                 if lims_project + "_" in str(path)
@@ -122,25 +121,25 @@
         return Path(self.root_dir, "fastq", case_id)
 
     def get_config_path(self, filename: str) -> Path:
         return Path(self.queries_path, filename).with_suffix(".json")
 
     def get_trailblazer_config_path(self, case_id: str) -> Path:
         """Get trailblazer config path."""
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         sample_obj: Sample = case_obj.links[0].sample
         project_id: str = self.get_project(sample_obj.internal_id)
         return Path(
             self.root_dir, "results", "reports", "trailblazer", f"{project_id}_slurm_ids.yaml"
         )
 
     def get_deliverables_file_path(self, case_id: str) -> Path:
         """Returns a path where the microSALT deliverables file for the order_id should be
         located"""
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         order_id: str = case_obj.name
         deliverables_file_path = Path(
             self.root_dir,
             "results",
             "reports",
             "deliverables",
             f"{order_id}_deliverables.yaml",
@@ -151,27 +150,27 @@
 
     def get_sample_fastq_destination_dir(self, case: Family, sample: Sample) -> Path:
         return Path(self.get_case_fastq_path(case_id=case.internal_id), sample.internal_id)
 
     def link_fastq_files(
         self, case_id: str, sample_id: Optional[str], dry_run: bool = False
     ) -> None:
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         samples: List[Sample] = self.get_samples(case_id=case_id, sample_id=sample_id)
         for sample_obj in samples:
             self.link_fastq_files_for_sample(case_obj=case_obj, sample_obj=sample_obj)
 
     def get_samples(self, case_id: str, sample_id: Optional[str] = None) -> List[Sample]:
         """Returns a list of samples to configure
         If sample_id is specified, will return a list with only this sample_id.
         Otherwise, returns all samples in given case"""
         if sample_id:
             return [self.status_db.query(Sample).filter(Sample.internal_id == sample_id).first()]
 
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         return [link.sample for link in case_obj.links]
 
     def get_lims_comment(self, sample_id: str) -> str:
         """Returns the comment associated with a sample stored in lims"""
         comment: str = self.lims_api.get_sample_comment(sample_id) or ""
         if re.match(r"\w{4}\d{2,3}", comment):
             return comment
@@ -304,19 +303,19 @@
             case_id, sample_id = self.get_case_id_from_case(unique_id)
 
         return case_id, sample_id
 
     def get_case_id_from_ticket(self, unique_id: str) -> Tuple[str, None]:
         """If ticked is provided as argument, finds the corresponding case_id and returns it.
         Since sample_id is not specified, nothing is returned as sample_id"""
-        case_obj: Family = self.status_db.find_family_by_name(unique_id)
-        if not case_obj:
+        case: Family = self.status_db.get_case_by_name(name=unique_id)
+        if not case:
             LOG.error("No case found for ticket number:  %s", unique_id)
             raise click.Abort
-        case_id = case_obj.internal_id
+        case_id = case.internal_id
         return case_id, None
 
     def get_case_id_from_sample(self, unique_id: str) -> Tuple[str, str]:
         """If sample is specified, finds the corresponding case_id to which this sample belongs.
         The case_id is to be used for identifying the appropriate path to link fastq files and store the analysis output
         """
         sample_obj: Sample = (
@@ -327,15 +326,15 @@
             raise click.Abort
         case_id = sample_obj.links[0].family.internal_id
         sample_id = sample_obj.internal_id
         return case_id, sample_id
 
     def get_case_id_from_case(self, unique_id: str) -> Tuple[str, None]:
         """If case_id is specified, validates the presence of case_id in database and returns it"""
-        case_obj: Family = self.status_db.family(unique_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=unique_id)
         if not case_obj:
             LOG.error("No case found with the id:  %s", unique_id)
             raise click.Abort
         case_id = case_obj.internal_id
         return case_id, None
 
     def microsalt_qc(self, case_id: str, run_dir_path: Path, lims_project: str) -> bool:
```

### Comparing `cg-27.1.9/cg/meta/workflow/mip.py` & `cg-27.2.0/cg/meta/workflow/mip.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 import logging
 
 from pathlib import Path
-from typing import Any, List, Optional, Type, Dict, Union
+from typing import Any, List, Optional, Dict, Union
 
 from pydantic import ValidationError
 
 from cg.apps.mip.confighandler import ConfigHandler
 from cg.constants import COLLABORATORS, COMBOS, GenePanelMasterList, Pipeline, FileExtensions
 from cg.constants.constants import FileFormat
 from cg.constants.housekeeper_tags import HkMipAnalysisTag
@@ -95,15 +95,15 @@
 
     def pedigree_config(self, case_id: str, panel_bed: str = None) -> dict:
         """Make the MIP pedigree config. Meta data for the family is taken from the family object
         and converted to MIP format via trailblazer.
         """
 
         # Validate and reformat to MIP pedigree config format
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         return ConfigHandler.make_pedigree_config(
             data={
                 "case": case_obj.internal_id,
                 "default_gene_panels": case_obj.panels,
                 "samples": [
                     self.config_sample(link_obj=link_obj, panel_bed=panel_bed)
                     for link_obj in case_obj.links
@@ -140,15 +140,15 @@
             case.internal_id,
             sample.application_version.application.analysis_type,
             sample.internal_id,
             FileFormat.FASTQ,
         )
 
     def link_fastq_files(self, case_id: str, dry_run: bool = False) -> None:
-        case_obj = self.status_db.family(case_id)
+        case_obj = self.status_db.get_case_by_internal_id(internal_id=case_id)
         for link in case_obj.links:
             self.link_fastq_files_for_sample(
                 case_obj=case_obj,
                 sample_obj=link.sample,
             )
 
     def write_panel(self, case_id: str, content: List[str]):
@@ -274,15 +274,15 @@
             for _link in case_obj.links
         )
 
     def get_skip_evaluation_flag(self, case_id: str, skip_evaluation: bool) -> bool:
         """If any sample in this case is downsampled or external, returns true"""
         if skip_evaluation:
             return True
-        case_obj = self.status_db.family(case_id)
+        case_obj = self.status_db.get_case_by_internal_id(internal_id=case_id)
         for link_obj in case_obj.links:
             downsampled = isinstance(link_obj.sample.downsampled_to, int)
             external = link_obj.sample.application_version.application.is_external
             if downsampled or external:
                 LOG.info(
                     "%s: downsampled/external - skip evaluation",
                     link_obj.sample.internal_id,
```

### Comparing `cg-27.1.9/cg/meta/workflow/mip_dna.py` & `cg-27.2.0/cg/meta/workflow/mip_dna.py`

 * *Files 9% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 
 from cg.constants import DEFAULT_CAPTURE_KIT, Pipeline
 from cg.constants.constants import AnalysisType
 from cg.constants.gene_panel import GENOME_BUILD_37
 from cg.constants.pedigree import Pedigree
 from cg.meta.workflow.mip import MipAnalysisAPI
 from cg.models.cg_config import CGConfig
-from cg.store.models import FamilySample
+from cg.store.models import Family, FamilySample
 from cg.utils import Process
 
 
 class MipDNAAnalysisAPI(MipAnalysisAPI):
     def __init__(self, config: CGConfig, pipeline: Pipeline = Pipeline.MIP_DNA):
         super().__init__(config, pipeline)
 
@@ -64,10 +64,10 @@
             sample_data[Pedigree.MOTHER.value]: str = link_obj.mother.internal_id
         if link_obj.father:
             sample_data[Pedigree.FATHER.value]: str = link_obj.father.internal_id
         return sample_data
 
     def panel(self, case_id: str, genome_build: str = GENOME_BUILD_37) -> List[str]:
         """Create the aggregated gene panel file"""
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         all_panels = self.convert_panels(case_obj.customer.internal_id, case_obj.panels)
         return self.scout_api.export_panels(build=genome_build, panels=all_panels)
```

### Comparing `cg-27.1.9/cg/meta/workflow/mip_rna.py` & `cg-27.2.0/cg/meta/workflow/mip_rna.py`

 * *Files 4% similar despite different names*

```diff
@@ -56,10 +56,10 @@
             sample_data[Pedigree.MOTHER]: str = link_obj.mother.internal_id
         if link_obj.father:
             sample_data[Pedigree.FATHER]: str = link_obj.father.internal_id
         return sample_data
 
     def panel(self, case_id: str, genome_build: str = GENOME_BUILD_38) -> List[str]:
         """Create the aggregated gene panel file"""
-        case_obj: Family = self.status_db.family(case_id)
+        case_obj: Family = self.status_db.get_case_by_internal_id(internal_id=case_id)
         all_panels = self.convert_panels(case_obj.customer.internal_id, case_obj.panels)
         return self.scout_api.export_panels(build=genome_build, panels=all_panels)
```

### Comparing `cg-27.1.9/cg/meta/workflow/mutant.py` & `cg-27.2.0/cg/meta/workflow/mutant.py`

 * *Files 2% similar despite different names*

```diff
@@ -72,15 +72,15 @@
     def get_case_config_path(self, case_id: str) -> Path:
         return Path(self.get_case_path(case_id=case_id), "case_config.json")
 
     def get_deliverables_file_path(self, case_id: str) -> Path:
         return Path(self.get_case_output_path(case_id=case_id), f"{case_id}_deliverables.yaml")
 
     def link_fastq_files(self, case_id: str, dry_run: bool = False) -> None:
-        case_obj = self.status_db.family(case_id)
+        case_obj = self.status_db.get_case_by_internal_id(internal_id=case_id)
         samples: List[Sample] = [link.sample for link in case_obj.links]
         for sample_obj in samples:
             application = sample_obj.application_version.application
             if self._is_nanopore(application):
                 self.link_nanopore_fastq_for_sample(
                     case_obj=case_obj, sample_obj=sample_obj, concatenate=True
                 )
@@ -122,15 +122,15 @@
             lab_code=self.lims_api.get_sample_attribute(
                 lims_id=sample_obj.internal_id, key="lab_code"
             ),
             primer=self.lims_api.get_sample_attribute(lims_id=sample_obj.internal_id, key="primer"),
         )
 
     def create_case_config(self, case_id: str, dry_run: bool) -> None:
-        case_obj = self.status_db.family(case_id)
+        case_obj = self.status_db.get_case_by_internal_id(internal_id=case_id)
         samples: List[Sample] = [link.sample for link in case_obj.links]
         case_config_list = [
             self.get_sample_parameters(sample_obj=sample_obj).dict() for sample_obj in samples
         ]
         config_path = self.get_case_config_path(case_id=case_id)
         if dry_run:
             LOG.info("Dry-run, would have created config at path %s, with content:", config_path)
```

### Comparing `cg-27.1.9/cg/meta/workflow/nextflow_common.py` & `cg-27.2.0/cg/meta/workflow/nextflow_common.py`

 * *Files 16% similar despite different names*

```diff
@@ -4,18 +4,26 @@
 import operator
 import os
 from datetime import datetime
 from pathlib import Path
 from subprocess import CalledProcessError
 from typing import Any, Dict, List, Optional
 
+from cg.apps.slurm.slurm_api import SlurmAPI
 from cg.constants.constants import FileFormat
-from cg.constants.nextflow import NFX_SAMPLE_HEADER, NFX_WORK_DIR, NXF_PID_FILE_ENV
+from cg.constants.nextflow import (
+    JAVA_MEMORY_HEADJOB,
+    NFX_SAMPLE_HEADER,
+    NFX_WORK_DIR,
+    NXF_JVM_ARGS_ENV,
+    SlurmHeadJobDefaults,
+)
 from cg.exc import CgError
 from cg.io.controller import ReadFile, WriteFile
+from cg.models.slurm.sbatch import Sbatch
 from cg.utils.utils import build_command_from_dict
 
 LOG = logging.getLogger(__name__)
 
 
 class NextflowAnalysisAPI:
     """Handles communication between nextflow processes
@@ -83,19 +91,15 @@
         except (Exception, CalledProcessError):
             LOG.warning(f"Could not retrieve {pipeline} workflow version!")
             return "0.0.0"
 
     @classmethod
     def get_variables_to_export(cls, case_id: str, root_dir: str) -> Dict[str, str]:
         """Generates a dictionary with variables that needs to be exported."""
-        return {
-            NXF_PID_FILE_ENV: cls.get_case_nextflow_pid_path(
-                case_id=case_id, root_dir=root_dir
-            ).as_posix()
-        }
+        return {NXF_JVM_ARGS_ENV: f"'{JAVA_MEMORY_HEADJOB}'"}
 
     @classmethod
     def verify_analysis_finished(cls, case_id: str, root_dir: str) -> None:
         if not Path(cls.get_software_version_path(case_id=case_id, root_dir=root_dir)).exists():
             raise ValueError(
                 f"Analysis not finished: pipeline_info/software_versions.yml file not found for case {case_id}"
             )
@@ -140,17 +144,15 @@
     @classmethod
     def get_nextflow_run_parameters(
         cls, case_id: str, pipeline_path: str, root_dir: str, command_args: dict
     ) -> List[str]:
         """Returns a nextflow run command given a dictionary with arguments."""
 
         nextflow_options: List[str] = build_command_from_dict(
-            options=dict(
-                (f"-{arg}", command_args.get(arg, True)) for arg in ("bg", "quiet", "log", "config")
-            ),
+            options=dict((f"-{arg}", command_args.get(arg, True)) for arg in ("log", "config")),
             exclude_true=True,
         )
         run_options: List[str] = build_command_from_dict(
             options=dict(
                 (f"-{arg}", command_args.get(arg, None))
                 for arg in (
                     "work-dir",
@@ -158,22 +160,15 @@
                     "profile",
                     "with-tower",
                     "params-file",
                 )
             ),
             exclude_true=True,
         )
-        parameters = (
-            nextflow_options
-            + ["run", pipeline_path]
-            + run_options
-            + NextflowAnalysisAPI.get_nextflow_stdout_stderr(case_id=case_id, root_dir=root_dir)
-        )
-
-        return parameters
+        return nextflow_options + ["run", pipeline_path] + run_options
 
     @classmethod
     def get_log_path(cls, case_id: str, pipeline: str, root_dir: str, log: str = None) -> Path:
         if log:
             return log
         launch_time: str = datetime.now().strftime("%Y-%m-%d_%H.%M.%S")
         return Path(
@@ -238,7 +233,51 @@
     @classmethod
     def write_deliverables_bundle(
         cls, deliverables_content: dict, file_path: Path, file_format=FileFormat.YAML
     ) -> None:
         WriteFile.write_file_from_content(
             content=deliverables_content, file_format=file_format, file_path=file_path
         )
+
+    @classmethod
+    def get_sbatch_path(cls, case_id: str, root_dir: str) -> Path:
+        """Returns a path where the nextflow sbatch for the head job should be located."""
+        return Path(
+            cls.get_case_path(case_id=case_id, root_dir=root_dir), "nextflow_head_job.sbatch"
+        )
+
+    @classmethod
+    def execute_head_job(
+        cls,
+        case_id: str,
+        root_dir: str,
+        slurm_account: str,
+        email: str,
+        qos: str,
+        commands: str,
+        hours: int = SlurmHeadJobDefaults.HOURS,
+        memory: int = SlurmHeadJobDefaults.MEMORY,
+        number_tasks: int = SlurmHeadJobDefaults.NUMBER_TASKS,
+        dry_run: bool = False,
+    ) -> int:
+        """Executes nextflow head job command."""
+
+        slurm_api: SlurmAPI = SlurmAPI()
+        slurm_api.set_dry_run(dry_run=dry_run)
+        sbatch_parameters: Sbatch = Sbatch(
+            account=slurm_account,
+            commands=commands,
+            email=email,
+            hours=hours,
+            job_name=f"{case_id}.%j",
+            log_dir=cls.get_case_path(case_id=case_id, root_dir=root_dir).as_posix(),
+            memory=memory,
+            number_tasks=number_tasks,
+            quality_of_service=qos,
+        )
+
+        sbatch_content: str = slurm_api.generate_sbatch_content(sbatch_parameters=sbatch_parameters)
+        sbatch_path: Path = cls.get_sbatch_path(case_id=case_id, root_dir=root_dir)
+        sbatch_number: int = slurm_api.submit_sbatch(
+            sbatch_content=sbatch_content, sbatch_path=sbatch_path
+        )
+        return sbatch_number
```

### Comparing `cg-27.1.9/cg/meta/workflow/prepare_fastq.py` & `cg-27.2.0/cg/meta/workflow/prepare_fastq.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,15 +21,15 @@
         self.store: Store = store
         self.hk_api: HousekeeperAPI = compress_api.hk_api
         self.compress_api: CompressAPI = compress_api
         self.crunchy_api: CrunchyAPI = compress_api.crunchy_api
 
     def get_compression_objects(self, case_id: str) -> List[CompressionData]:
         """Return a list of compression objects"""
-        case_obj: Family = self.store.family(case_id)
+        case_obj: Family = self.store.get_case_by_internal_id(internal_id=case_id)
         compression_objects = []
         for link in case_obj.links:
             sample_id = link.sample.internal_id
             version_obj: Version = self.compress_api.hk_api.get_latest_bundle_version(
                 bundle_name=sample_id
             )
             compression_objects.extend(files.get_spring_paths(version_obj))
@@ -58,15 +58,15 @@
         return any(
             self.crunchy_api.is_spring_decompression_possible(compression_object)
             for compression_object in compression_objects
         )
 
     def check_fastq_links(self, case_id: str) -> None:
         """Check if all FASTQ files are linked in Housekeeper."""
-        case_obj: Family = self.store.family(case_id)
+        case_obj: Family = self.store.get_case_by_internal_id(internal_id=case_id)
         for link in case_obj.links:
             sample_id = link.sample.internal_id
             version_obj: Version = self.compress_api.hk_api.get_latest_bundle_version(
                 bundle_name=sample_id
             )
             fastq_files: Dict[Path, File] = files.get_hk_files_dict(
                 tags=["fastq"], version_obj=version_obj
```

### Comparing `cg-27.1.9/cg/meta/workflow/rnafusion.py` & `cg-27.2.0/cg/meta/workflow/rnafusion.py`

 * *Files 2% similar despite different names*

```diff
@@ -41,14 +41,15 @@
         self.references: str = config.rnafusion.references
         self.profile: str = config.rnafusion.profile
         self.conda_env: str = config.rnafusion.conda_env
         self.conda_binary: str = config.rnafusion.conda_binary
         self.tower_binary_path: str = config.rnafusion.tower_binary_path
         self.tower_pipeline: str = config.rnafusion.tower_pipeline
         self.account: str = config.rnafusion.slurm.account
+        self.email: str = config.rnafusion.slurm.mail_user
 
     @property
     def root(self) -> str:
         return self.root_dir
 
     @property
     def fastq_handler(self):
@@ -70,17 +71,14 @@
         if profile:
             return profile
         return self.profile
 
     def get_case_config_path(self, case_id):
         return NextflowAnalysisAPI.get_case_config_path(case_id=case_id, root_dir=self.root_dir)
 
-    def get_variables_to_export(self, case_id) -> Dict[str, str]:
-        return NextflowAnalysisAPI.get_variables_to_export(case_id=case_id, root_dir=self.root_dir)
-
     def verify_analysis_finished(self, case_id):
         return NextflowAnalysisAPI.verify_analysis_finished(case_id=case_id, root_dir=self.root_dir)
 
     @staticmethod
     def build_samplesheet_content(
         case_id: str, fastq_r1: List[str], fastq_r2: List[str], strandedness: str
     ) -> Dict[str, List[str]]:
@@ -106,15 +104,15 @@
             NFX_READ2_HEADER: fastq_r2,
             RNAFUSION_STRANDEDNESS_HEADER: strandedness_full_list,
         }
         return samplesheet_content
 
     def write_samplesheet(self, case_id: str, strandedness: str, dry_run: bool = False) -> None:
         """Write sample sheet for rnafusion analysis in case folder."""
-        case_obj = self.status_db.family(case_id)
+        case_obj = self.status_db.get_case_by_internal_id(internal_id=case_id)
         if len(case_obj.links) != 1:
             raise NotImplementedError(
                 "Case objects are assumed to be related to a single sample (one link)"
             )
 
         for link in case_obj.links:
             sample_metadata: List[str] = self.gather_file_metadata_for_sample(link.sample)
@@ -211,28 +209,42 @@
             parameters: List[str] = NextflowAnalysisAPI.get_nextflow_run_parameters(
                 case_id=case_id,
                 pipeline_path=self.nfcore_pipeline_path,
                 root_dir=self.root_dir,
                 command_args=command_args,
             )
             self.process.export_variables(
-                export=self.get_variables_to_export(case_id),
+                export=NextflowAnalysisAPI.get_variables_to_export(
+                    case_id=case_id, root_dir=self.root_dir
+                ),
+            )
+
+            command = self.process.get_command(parameters=parameters)
+            LOG.info(f"{command}")
+            sbatch_number: int = NextflowAnalysisAPI.execute_head_job(
+                case_id=case_id,
+                root_dir=self.root_dir,
+                slurm_account=self.account,
+                email=self.email,
+                qos=self.get_slurm_qos_for_case(case_id=case_id),
+                commands=command,
+                dry_run=dry_run,
             )
+            LOG.info(f"Nextflow head job running as job {sbatch_number}")
+
         else:
             LOG.info("Pipeline will be executed using tower")
             parameters: List[str] = TowerAnalysisAPI.get_tower_launch_parameters(
                 tower_pipeline=self.tower_pipeline,
                 command_args=command_args,
             )
-        exit_code = self.process.run_command(parameters=parameters, dry_run=dry_run)
-        for line in self.process.stdout_lines():
-            LOG.info(line)
-        for line in self.process.stderr_lines():
-            LOG.info(line)
-        return exit_code
+            self.process.run_command(parameters=parameters, dry_run=dry_run)
+            if self.process.stderr:
+                LOG.error(self.process.stderr)
+            LOG.info(self.process.stdout)
 
     def verify_case_config_file_exists(self, case_id: str) -> None:
         NextflowAnalysisAPI.verify_case_config_file_exists(case_id=case_id, root_dir=self.root_dir)
 
     def get_deliverables_file_path(self, case_id: str) -> Path:
         return NextflowAnalysisAPI.get_deliverables_file_path(
             case_id=case_id, root_dir=self.root_dir
```

### Comparing `cg-27.1.9/cg/meta/workflow/tower_common.py` & `cg-27.2.0/cg/meta/workflow/tower_common.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/balsamic/config.py` & `cg-27.2.0/cg/models/balsamic/config.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/balsamic/metrics.py` & `cg-27.2.0/cg/models/balsamic/metrics.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/cg_config.py` & `cg-27.2.0/cg/models/cg_config.py`

 * *Files 1% similar despite different names*

```diff
@@ -216,14 +216,23 @@
 
 
 class ExternalConfig(BaseModel):
     hasta: str
     caesar: str
 
 
+class DDNDataFlowConfig(BaseModel):
+    database_name: str
+    user: str
+    password: str
+    url: str
+    local_storage: str
+    archive_repository: str
+
+
 class CGConfig(BaseModel):
     database: str
     environment: Literal["production", "stage"] = "stage"
     madeline_exe: str
     delivery_path: str
     max_flowcells: Optional[int]
     email_base_settings: EmailBaseSettings
@@ -239,14 +248,15 @@
     cg_stats_api_: StatsAPI = None
     chanjo: CommonAppConfig = None
     chanjo_api_: ChanjoAPI = None
     clean: Optional[CleanConfig] = None
     crunchy: CrunchyConfig = None
     crunchy_api_: CrunchyAPI = None
     data_delivery: DataDeliveryConfig = Field(None, alias="data-delivery")
+    ddn: Optional[DDNDataFlowConfig] = None
     demultiplex: DemultiplexConfig = None
     demultiplex_api_: DemultiplexingAPI = None
     encryption: Optional[CommonAppConfig] = None
     external: ExternalConfig = None
     genotype: CommonAppConfig = None
     genotype_api_: GenotypeAPI = None
     gens: CommonAppConfig = None
```

### Comparing `cg-27.1.9/cg/models/cgstats/stats_sample.py` & `cg-27.2.0/cg/models/cgstats/stats_sample.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-from typing import List, Optional, Set
+from typing import List, Set
 
 from pydantic import BaseModel, Field, validator
 
 
 class Unaligned(BaseModel):
     lane: int
     read_count: int = Field(..., alias="readcounts")
```

### Comparing `cg-27.1.9/cg/models/compression_data.py` & `cg-27.2.0/cg/models/compression_data.py`

 * *Files 1% similar despite different names*

```diff
@@ -85,20 +85,14 @@
                 return False
         except PermissionError:
             LOG.warning("Not permitted to access %s. Skipping", file_path)
             return False
         return True
 
     @staticmethod
-    def get_nlinks(file_path: Path) -> int:
-        """Get number of links to path"""
-        LOG.info("Check nr of links for %s", file_path)
-        return os.stat(file_path).st_nlink
-
-    @staticmethod
     def is_symlink(file_path: Path) -> bool:
         """Check if file path is symbolik link"""
         LOG.info("Check if %s is a symlink", file_path)
         return os.path.islink(file_path)
 
     @staticmethod
     def get_change_date(file_path: Path) -> datetime:
```

### Comparing `cg-27.1.9/cg/models/deliverables/metric_deliverables.py` & `cg-27.2.0/cg/models/deliverables/metric_deliverables.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/demultiplex/demux_results.py` & `cg-27.2.0/cg/models/demultiplex/demux_results.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/demultiplex/flow_cell.py` & `cg-27.2.0/cg/models/demultiplex/flow_cell.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/demultiplex/run_parameters.py` & `cg-27.2.0/cg/models/demultiplex/run_parameters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/demultiplex/sbatch.py` & `cg-27.2.0/cg/models/demultiplex/sbatch.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/file_data.py` & `cg-27.2.0/cg/models/file_data.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/invoice/invoice.py` & `cg-27.2.0/cg/models/invoice/invoice.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Module for defining invoice models."""
 from pydantic import BaseModel
 from typing import List, Optional, Any
-from cg.constants.priority import PriorityTerms, Priority
+from cg.constants.priority import PriorityTerms
 from cg.constants.sequencing import RecordType
 
 
 class InvoiceContact(BaseModel):
     """Class for collection contact information used in the invoice."""
 
     name: str
```

### Comparing `cg-27.1.9/cg/models/lims/sample.py` & `cg-27.2.0/cg/models/lims/sample.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-from datetime import datetime
 from typing import Optional
 
 from pydantic import BaseModel, validator
 from typing_extensions import Literal
 
 from cg.constants import Priority
```

### Comparing `cg-27.1.9/cg/models/mip/mip_config.py` & `cg-27.2.0/cg/models/mip/mip_config.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/mip/mip_metrics_deliverables.py` & `cg-27.2.0/cg/models/mip/mip_metrics_deliverables.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/mip/mip_sample_info.py` & `cg-27.2.0/cg/models/mip/mip_sample_info.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/nextflow/deliverables.py` & `cg-27.2.0/cg/models/nextflow/deliverables.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/nextflow/sample.py` & `cg-27.2.0/cg/models/nextflow/sample.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/observations/input_files.py` & `cg-27.2.0/cg/models/observations/input_files.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/orders/constants.py` & `cg-27.2.0/cg/models/orders/constants.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/orders/excel_sample.py` & `cg-27.2.0/cg/models/orders/excel_sample.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/orders/json_sample.py` & `cg-27.2.0/cg/models/orders/json_sample.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/orders/order.py` & `cg-27.2.0/cg/models/orders/order.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/orders/orderform_schema.py` & `cg-27.2.0/cg/models/orders/orderform_schema.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/orders/sample_base.py` & `cg-27.2.0/cg/models/orders/sample_base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from enum import Enum
 from typing import List, Optional
 
 from cg.constants import DataDelivery, Pipeline
-from pydantic import BaseModel, constr, NonNegativeInt, validator
+from pydantic import BaseModel, constr, validator
 
 from cg.store.models import Application, Family, Customer, Pool, Sample
 
 
 class ControlEnum(str, Enum):
     not_control = ""
     positive = "positive"
```

### Comparing `cg-27.1.9/cg/models/orders/samples.py` & `cg-27.2.0/cg/models/orders/samples.py`

 * *Files 1% similar despite different names*

```diff
@@ -63,15 +63,14 @@
             min_length=2,
             max_length=Sample.name.property.columns[0].type.length,
         )
     ]
 
     # customer
     age_at_sampling: Optional[float]
-    # "application": str,
     family_name: constr(
         regex=NAME_PATTERN,
         min_length=2,
         max_length=Family.name.property.columns[0].type.length,
     )
     case_internal_id: Optional[
         constr(max_length=Sample.internal_id.property.columns[0].type.length)
```

### Comparing `cg-27.1.9/cg/models/report/metadata.py` & `cg-27.2.0/cg/models/report/metadata.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/report/report.py` & `cg-27.2.0/cg/models/report/report.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/report/sample.py` & `cg-27.2.0/cg/models/report/sample.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/report/validators.py` & `cg-27.2.0/cg/models/report/validators.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/rnafusion/rnafusion_sample.py` & `cg-27.2.0/cg/models/rnafusion/rnafusion_sample.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/scout/scout_load_config.py` & `cg-27.2.0/cg/models/scout/scout_load_config.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/slurm/sbatch.py` & `cg-27.2.0/cg/models/slurm/sbatch.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/models/workflow/mutant.py` & `cg-27.2.0/cg/models/workflow/mutant.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/resources/20181012_Indices.csv` & `cg-27.2.0/cg/resources/20181012_Indices.csv`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/resources/rnafusion_bundle_filenames.csv` & `cg-27.2.0/cg/resources/rnafusion_bundle_filenames.csv`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/server/admin.py` & `cg-27.2.0/cg/server/admin.py`

 * *Files 2% similar despite different names*

```diff
@@ -248,39 +248,41 @@
 
     @action(
         "set_hold",
         "Set action to hold",
         "Are you sure you want to set the action for selected families to hold?",
     )
     def action_set_hold(self, ids: List[str]):
-        self.set_action_for_batch(action=CaseActions.HOLD, entry_ids=ids)
+        self.set_action_for_cases(action=CaseActions.HOLD, case_entry_ids=ids)
 
     @action(
         "set_empty",
         "Set action to Empty",
         "Are you sure you want to set the action for selected families to Empty?",
     )
     def action_set_empty(self, ids: List[str]):
-        self.set_action_for_batch(action=None, entry_ids=ids)
+        self.set_action_for_cases(action=None, case_entry_ids=ids)
 
-    def set_action_for_batch(self, action: Union[CaseActions, None], entry_ids: List[str]):
+    def set_action_for_cases(self, action: Union[CaseActions, None], case_entry_ids: List[str]):
         try:
-            query: Query = db.Family.query.filter(db.Family.id.in_(entry_ids))
-            family: Family
-            for family in query.all():
-                family.action = action
-
-            flash(
-                ngettext(
-                    f"Families were set to {action}.",
-                    f"{len(entry_ids)} families were set to {action}.",
-                    len(entry_ids),
-                )
-            )
+            for entry_id in case_entry_ids:
+                family = self.get_case_by_entry_id(entry_id=entry_id)
+                if family:
+                    family.action = action
+
             db.commit()
+
+            num_families = len(case_entry_ids)
+            action_message = (
+                f"Families were set to {action}."
+                if num_families == 1
+                else f"{num_families} families were set to {action}."
+            )
+            flash(action_message)
+
         except Exception as ex:
             if not self.handle_view_exception(ex):
                 raise
 
             flash(gettext(f"Failed to set family action. {str(ex)}"))
 
 
@@ -452,15 +454,15 @@
             ]
             all_associated_case_ids.update(sample_case_ids)
 
             db.delete_relationships_sample(sample=sample)
             self.write_cancel_comment(sample=sample)
 
         case_ids: List[str] = list(all_associated_case_ids)
-        db.delete_cases_without_samples(case_ids=case_ids)
+        db.delete_cases_without_samples(case_internal_ids=case_ids)
         cases_with_remaining_samples: List[str] = db.filter_cases_with_samples(case_ids=case_ids)
 
         self.display_cancel_confirmation(
             sample_entry_ids=entry_ids, remaining_cases=cases_with_remaining_samples
         )
 
     def write_cancel_comment(self, sample: Sample) -> None:
```

### Comparing `cg-27.1.9/cg/server/api.py` & `cg-27.2.0/cg/server/api.py`

 * *Files 11% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 
 import requests
 from sqlalchemy.exc import IntegrityError
 from urllib3.exceptions import MaxRetryError, NewConnectionError
 
 from cg.apps.orderform.excel_orderform_parser import ExcelOrderformParser
 from cg.apps.orderform.json_orderform_parser import JsonOrderformParser
-from cg.constants import ANALYSIS_SOURCES, METAGENOME_SOURCES
+from cg.constants import ANALYSIS_SOURCES, METAGENOME_SOURCES, Pipeline
 from cg.constants.constants import FileFormat
 from cg.exc import OrderError, OrderFormError, TicketCreationError
 from cg.server.ext import db, lims, osticket
 from cg.io.controller import WriteStream
 from cg.meta.orders import OrdersAPI
 from cg.store.models import Customer, Sample, Pool, Family, Application, Flowcell
 from cg.models.orders.order import OrderIn, OrderType
@@ -28,15 +28,15 @@
 from sqlalchemy.orm import Query
 from werkzeug.utils import secure_filename
 
 LOG = logging.getLogger(__name__)
 BLUEPRINT = Blueprint("api", __name__, url_prefix="/api/v1")
 
 
-def public(route_function):
+def is_public(route_function):
     @wraps(route_function)
     def public_endpoint(*args, **kwargs):
         return route_function(*args, **kwargs)
 
     public_endpoint.is_public = True
     return public_endpoint
 
@@ -139,229 +139,245 @@
         )
 
     if error_message:
         return abort(make_response(jsonify(message=error_message), http_error_response))
 
 
 @BLUEPRINT.route("/cases")
-def cases():
+def parse_cases():
     """Fetch cases."""
-    records = db.cases(days=31)
-    count = len(records)
-    return jsonify(cases=records, total=count)
+    cases: List[Family] = db.cases(days=31)
+    return jsonify(cases=cases, total=len(cases))
+
+
+def _get_current_customers() -> Optional[List[Customer]]:
+    """Return customers if the current user is not an admin."""
+    if not g.current_user.is_admin:
+        return g.current_user.customers
+    return None
+
+
+def _get_cases(
+    status: str, enquiry: Optional[str], action: Optional[str], customers: Optional[List[Customer]]
+) -> List[Family]:
+    """Get cases based on the provided filters."""
+    if status == "analysis":
+        return db.cases_to_analyze(pipeline=Pipeline.MIP_DNA)
+
+    return db.get_cases_by_customers_action_and_case_search(
+        case_search=enquiry,
+        customers=customers,
+        action=action,
+    )
 
 
 @BLUEPRINT.route("/families")
-def families():
-    """Return families."""
-    if request.args.get("status") == "analysis":
-        records = db.cases_to_mip_analyze()
-        count = len(records)
-    else:
-        customers: Optional[List[Customer]] = (
-            None if g.current_user.is_admin else g.current_user.customers
-        )
-        case_query = db.families(
-            enquiry=request.args.get("enquiry"),
-            customers=customers,
-            action=request.args.get("action"),
-        )
-        count = case_query.count()
-        records = case_query.limit(30)
+def get_families():
+    """Return cases."""
+    status: str = request.args.get("status")
+    enquiry: str = request.args.get("enquiry")
+    action: str = request.args.get("action")
+
+    customers: List[Customer] = _get_current_customers()
+    cases: List[Family] = _get_cases(
+        status=status, enquiry=enquiry, action=action, customers=customers
+    )
 
-    cases_data: List[Dict] = [case_obj.to_dict(links=True) for case_obj in records]
-    return jsonify(families=cases_data, total=count)
+    count = len(cases)
+    case_dicts = [case.to_dict(links=True) for case in cases]
+    return jsonify(families=case_dicts, total=count)
 
 
 @BLUEPRINT.route("/families_in_collaboration")
-def families_in_collaboration():
-    """Fetch families in collaboration."""
-    order_customer: Customer = db.get_customer_by_customer_id(
-        customer_id=request.args.get("customer")
-    )
-    data_analysis: str = request.args.get("data_analysis")
-    families_q: Query = db.families(
-        enquiry=request.args.get("enquiry"),
-        customers=order_customer.collaborators,
-        data_analysis=data_analysis,
-    )
-    count = families_q.count()
-    records = families_q.limit(30)
-    data: List[Dict] = [case_obj.to_dict(links=True) for case_obj in records]
-    return jsonify(families=data, total=count)
+def parse_families_in_collaboration():
+    """Return cases in collaboration."""
+
+    customer_internal_id = request.args.get("customer")
+    pipeline = request.args.get("data_analysis")
+    case_search_pattern = request.args.get("enquiry")
+
+    customer = db.get_customer_by_internal_id(customer_internal_id=customer_internal_id)
+
+    cases = db.get_cases_by_customer_pipeline_and_case_search(
+        case_search=case_search_pattern,
+        customer=customer,
+        pipeline=pipeline,
+    )
+
+    case_dicts = [case.to_dict(links=True) for case in cases]
+    return jsonify(families=case_dicts, total=len(cases))
 
 
 @BLUEPRINT.route("/families/<family_id>")
-def family(family_id):
-    """Fetch a family with links."""
-    case_obj: Family = db.family(family_id)
-    if case_obj is None:
+def parse_family(family_id):
+    """Return a family with links."""
+    case: Family = db.get_case_by_internal_id(internal_id=family_id)
+    if case is None:
         return abort(http.HTTPStatus.NOT_FOUND)
-    if not g.current_user.is_admin and (case_obj.customer not in g.current_user.customers):
+    if not g.current_user.is_admin and (case.customer not in g.current_user.customers):
         return abort(http.HTTPStatus.FORBIDDEN)
-
-    data = case_obj.to_dict(links=True, analyses=True)
-    return jsonify(**data)
+    return jsonify(**case.to_dict(links=True, analyses=True))
 
 
 @BLUEPRINT.route("/families_in_collaboration/<family_id>")
-def family_in_collaboration(family_id):
-    """Fetch a family with links."""
-    case_obj = db.family(family_id)
-    order_customer = db.get_customer_by_customer_id(customer_id=request.args.get("customer"))
-    if case_obj.customer not in order_customer.collaborators:
+def parse_family_in_collaboration(family_id):
+    """Return a family with links."""
+    case: Family = db.get_case_by_internal_id(internal_id=family_id)
+    customer: Customer = db.get_customer_by_internal_id(
+        customer_internal_id=request.args.get("customer")
+    )
+    if case.customer not in customer.collaborators:
         return abort(http.HTTPStatus.FORBIDDEN)
-    data: Dict = case_obj.to_dict(links=True, analyses=True)
-    return jsonify(**data)
+    return jsonify(**case.to_dict(links=True, analyses=True))
 
 
 @BLUEPRINT.route("/samples")
-def samples():
-    """Fetch samples."""
+def parse_samples():
+    """Return samples."""
     if request.args.get("status") and not g.current_user.is_admin:
         return abort(http.HTTPStatus.FORBIDDEN)
     if request.args.get("status") == "incoming":
-        samples_q: List[Sample] = db.get_all_samples_to_receive()
+        samples: List[Sample] = db.get_samples_to_receive()
     elif request.args.get("status") == "labprep":
-        samples_q: List[Sample] = db.get_all_samples_to_prepare()
+        samples: List[Sample] = db.get_samples_to_prepare()
     elif request.args.get("status") == "sequencing":
-        samples_q: List[Sample] = db.get_all_samples_to_sequence()
+        samples: List[Sample] = db.get_samples_to_sequence()
     else:
-        customer_objs: Optional[Customer] = (
+        customers: Optional[List[Customer]] = (
             None if g.current_user.is_admin else g.current_user.customers
         )
-        samples_q: List[Sample] = db.get_samples_by_enquiry(
-            enquiry=request.args.get("enquiry"), customers=customer_objs
+        samples: List[Sample] = db.get_samples_by_customer_id_and_pattern(
+            pattern=request.args.get("enquiry"), customers=customers
         )
     limit = int(request.args.get("limit", 50))
-    data: List[Dict] = [sample_obj.to_dict() for sample_obj in samples_q[:limit]]
-
-    return jsonify(samples=data, total=len(samples_q))
+    parsed_samples: List[Dict] = [sample.to_dict() for sample in samples[:limit]]
+    return jsonify(samples=parsed_samples, total=len(samples))
 
 
 @BLUEPRINT.route("/samples_in_collaboration")
-def samples_in_collaboration():
-    """Fetch samples in a customer group."""
-    order_customer = db.get_customer_by_customer_id(customer_id=request.args.get("customer"))
-    samples_q: List[Sample] = db.get_samples_by_enquiry(
-        enquiry=request.args.get("enquiry"), customers=order_customer.collaborators
+def parse_samples_in_collaboration():
+    """Return samples in a customer group."""
+    customer: Customer = db.get_customer_by_internal_id(
+        customer_internal_id=request.args.get("customer")
+    )
+    samples: List[Sample] = db.get_samples_by_customer_id_and_pattern(
+        pattern=request.args.get("enquiry"), customers=customer.collaborators
     )
     limit = int(request.args.get("limit", 50))
-    data: List[Dict] = [sample_obj.to_dict() for sample_obj in samples_q[:limit]]
-    return jsonify(samples=data, total=len(samples_q))
+    parsed_samples: List[Dict] = [sample.to_dict() for sample in samples[:limit]]
+    return jsonify(samples=parsed_samples, total=len(samples))
 
 
 @BLUEPRINT.route("/samples/<sample_id>")
-def sample(sample_id):
-    """Fetch a single sample."""
+def parse_sample(sample_id):
+    """Return a single sample."""
     sample: Sample = db.get_sample_by_internal_id(sample_id)
     if sample is None:
         return abort(http.HTTPStatus.NOT_FOUND)
     if not g.current_user.is_admin and (sample.customer not in g.current_user.customers):
         return abort(http.HTTPStatus.FORBIDDEN)
-    data: Dict = sample.to_dict(links=True, flowcells=True)
-    return jsonify(**data)
+    return jsonify(**sample.to_dict(links=True, flowcells=True))
 
 
 @BLUEPRINT.route("/samples_in_collaboration/<sample_id>")
-def sample_in_collaboration(sample_id):
-    """Fetch a single sample."""
+def parse_sample_in_collaboration(sample_id):
+    """Return a single sample."""
     sample: Sample = db.get_sample_by_internal_id(sample_id)
-    order_customer = db.get_customer_by_customer_id(customer_id=request.args.get("customer"))
-    if sample.customer not in order_customer.collaborators:
+    customer: Customer = db.get_customer_by_internal_id(
+        customer_internal_id=request.args.get("customer")
+    )
+    if sample.customer not in customer.collaborators:
         return abort(http.HTTPStatus.FORBIDDEN)
-    data: Dict = sample.to_dict(links=True, flowcells=True)
-    return jsonify(**data)
+    return jsonify(**sample.to_dict(links=True, flowcells=True))
 
 
 @BLUEPRINT.route("/pools")
-def pools():
-    """Fetch pools."""
+def parse_pools():
+    """Return pools."""
     customers: Optional[List[Customer]] = (
         g.current_user.customers if not g.current_user.is_admin else None
     )
-    pool_list: List[Pool] = db.get_pools_to_render(
+    pools: List[Pool] = db.get_pools_to_render(
         customers=customers, enquiry=request.args.get("enquiry")
     )
-
-    data = [pool_obj.to_dict() for pool_obj in pool_list[:30]]
-    return jsonify(pools=data, total=len(pool_list))
+    parsed_pools: List[Dict] = [pool_obj.to_dict() for pool_obj in pools[:30]]
+    return jsonify(pools=parsed_pools, total=len(pools))
 
 
 @BLUEPRINT.route("/pools/<pool_id>")
-def pool(pool_id):
-    """Fetch a single pool."""
-    record: Pool = db.get_pool_by_entry_id(entry_id=pool_id)
-    if record is None:
+def parse_pool(pool_id):
+    """Return a single pool."""
+    pool: Pool = db.get_pool_by_entry_id(entry_id=pool_id)
+    if pool is None:
         return abort(http.HTTPStatus.NOT_FOUND)
-    if not g.current_user.is_admin and (record.customer not in g.current_user.customers):
+    if not g.current_user.is_admin and (pool.customer not in g.current_user.customers):
         return abort(http.HTTPStatus.FORBIDDEN)
-    return jsonify(**record.to_dict())
+    return jsonify(**pool.to_dict())
 
 
 @BLUEPRINT.route("/flowcells")
-def flowcells() -> Any:
-    """Fetch flow cells."""
+def parse_flow_cells() -> Any:
+    """Return flow cells."""
     flow_cells: List[Flowcell] = db.get_flow_cell_by_enquiry_and_status(
         flow_cell_statuses=[request.args.get("status")],
         flow_cell_id_enquiry=request.args.get("enquiry"),
     )
-    parsed_flow_cells: List[dict] = [flow_cell.to_dict() for flow_cell in flow_cells[:50]]
+    parsed_flow_cells: List[Dict] = [flow_cell.to_dict() for flow_cell in flow_cells[:50]]
     return jsonify(flowcells=parsed_flow_cells, total=len(flow_cells))
 
 
 @BLUEPRINT.route("/flowcells/<flowcell_id>")
-def flowcell(flowcell_id):
-    """Fetch a single flowcell."""
-    record = db.get_flow_cell(flowcell_id)
-    if record is None:
+def parse_flow_cell(flowcell_id):
+    """Return a single flowcell."""
+    flow_cell: Flowcell = db.get_flow_cell(flowcell_id)
+    if flow_cell is None:
         return abort(http.HTTPStatus.NOT_FOUND)
-    return jsonify(**record.to_dict(samples=True))
+    return jsonify(**flow_cell.to_dict(samples=True))
 
 
 @BLUEPRINT.route("/analyses")
-def analyses():
-    """Fetch analyses."""
+def parse_analyses():
+    """Return analyses."""
     if request.args.get("status") == "delivery":
-        analyses_q = db.analyses_to_deliver()
+        analyses: Query = db.analyses_to_deliver()
     elif request.args.get("status") == "upload":
-        analyses_q = db.analyses_to_upload()
+        analyses: Query = db.analyses_to_upload()
     else:
-        analyses_q = db.Analysis.query
-    data = [analysis_obj.to_dict() for analysis_obj in analyses_q.limit(30)]
-    return jsonify(analyses=data, total=analyses_q.count())
+        analyses: Query = db.Analysis.query
+    parsed_analysis: List[Dict] = [analysis_obj.to_dict() for analysis_obj in analyses.limit(30)]
+    return jsonify(analyses=parsed_analysis, total=analyses.count())
 
 
 @BLUEPRINT.route("/options")
-def options():
-    """Fetch various options."""
+def parse_options():
+    """Return various options."""
     customers: List[Optional[Customer]] = (
         db.get_customers() if g.current_user.is_admin else g.current_user.customers
     )
 
-    apptag_groups: Dict[str, List[str]] = {"ext": []}
+    app_tag_groups: Dict[str, List[str]] = {"ext": []}
     applications: List[Application] = db.get_applications_is_not_archived()
     for application in applications:
         if not application.versions:
             LOG.debug(f"Skipping application {application} that doesn't have a price")
             continue
         if application.is_external:
-            apptag_groups["ext"].append(application.tag)
-        if application.prep_category not in apptag_groups:
-            apptag_groups[application.prep_category]: List[str] = []
-        apptag_groups[application.prep_category].append(application.tag)
+            app_tag_groups["ext"].append(application.tag)
+        if application.prep_category not in app_tag_groups:
+            app_tag_groups[application.prep_category]: List[str] = []
+        app_tag_groups[application.prep_category].append(application.tag)
 
     source_groups = {"metagenome": METAGENOME_SOURCES, "analysis": ANALYSIS_SOURCES}
 
     return jsonify(
         customers=[
             {"text": f"{customer.name} ({customer.internal_id})", "value": customer.internal_id}
             for customer in customers
         ],
-        applications=apptag_groups,
+        applications=app_tag_groups,
         panels=[panel.abbrev for panel in db.get_panels()],
         organisms=[
             {
                 "name": organism.name,
                 "reference_genome": organism.reference_genome,
                 "internal_id": organism.internal_id,
                 "verified": organism.verified,
@@ -370,48 +386,48 @@
         ],
         sources=source_groups,
         beds=[bed.name for bed in db.get_active_beds()],
     )
 
 
 @BLUEPRINT.route("/me")
-def me():
-    """Fetch information about current user."""
+def parse_current_user_information():
+    """Return information about current user."""
     if not g.current_user.is_admin and not g.current_user.customers:
         LOG.error(
             "%s is not admin and is not connected to any customers, aborting", g.current_user.email
         )
         return abort(http.HTTPStatus.FORBIDDEN)
 
     return jsonify(user=g.current_user.to_dict())
 
 
 @BLUEPRINT.route("/applications")
-@public
-def applications():
-    """Fetch application tags."""
-    query: List[Application] = db.get_applications_is_not_archived()
-    data = [record.to_dict() for record in query]
-    return jsonify(applications=data)
+@is_public
+def parse_applications():
+    """Return application tags."""
+    applications: List[Application] = db.get_applications_is_not_archived()
+    parsed_applications: List[Dict] = [application.to_dict() for application in applications]
+    return jsonify(applications=parsed_applications)
 
 
 @BLUEPRINT.route("/applications/<tag>")
-@public
-def application(tag):
-    """Fetch an application tag."""
-    record = db.get_application_by_tag(tag=tag)
-    if record is None:
+@is_public
+def parse_application(tag):
+    """Return an application tag."""
+    application: Application = db.get_application_by_tag(tag=tag)
+    if application is None:
         return abort(
             make_response(jsonify(message="application not found"), http.HTTPStatus.NOT_FOUND)
         )
-    return jsonify(**record.to_dict())
+    return jsonify(**application.to_dict())
 
 
 @BLUEPRINT.route("/orderform", methods=["POST"])
-def orderform():
+def parse_orderform():
     """Parse an orderform/JSON export."""
     input_file = request.files.get("file")
     filename = secure_filename(input_file.filename)
 
     error_message: str
     try:
         if filename.lower().endswith(".xlsx"):
```

### Comparing `cg-27.1.9/cg/server/app.py` & `cg-27.2.0/cg/server/app.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/server/config.py` & `cg-27.2.0/cg/server/config.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/server/ext.py` & `cg-27.2.0/cg/server/ext.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/server/invoices/templates/invoices/index.html` & `cg-27.2.0/cg/server/invoices/templates/invoices/index.html`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/server/invoices/templates/invoices/invoice.html` & `cg-27.2.0/cg/server/invoices/templates/invoices/invoice.html`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/server/invoices/templates/invoices/layout.html` & `cg-27.2.0/cg/server/invoices/templates/invoices/layout.html`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/server/invoices/templates/invoices/new.html` & `cg-27.2.0/cg/server/invoices/templates/invoices/new.html`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/server/invoices/views.py` & `cg-27.2.0/cg/server/invoices/views.py`

 * *Files 9% similar despite different names*

```diff
@@ -17,15 +17,15 @@
 )
 from flask_dance.contrib.google import google
 
 from cg.apps.invoice.render import render_xlsx
 from cg.meta.invoice import InvoiceAPI
 from cg.server.ext import db, lims
 from typing import List, Union
-from cg.store.models import Customer, Invoice, Pool, Sample, User
+from cg.store.models import Customer, Invoice, Pool, Sample
 
 
 BLUEPRINT = Blueprint("invoices", __name__, template_folder="templates")
 
 
 @BLUEPRINT.before_request
 def before_request():
@@ -50,15 +50,15 @@
     db.session.commit()
 
     return url_for(".new", record_type=record_type)
 
 
 def make_new_invoice():
     customer_id = request.form.get("customer")
-    customer: Customer = db.get_customer_by_customer_id(customer_id=customer_id)
+    customer: Customer = db.get_customer_by_internal_id(customer_internal_id=customer_id)
     record_ids = request.form.getlist("records")
     record_type = request.form.get("record_type")
     if len(record_ids) == 0:
         return redirect(url_for(".new", record_type=record_type))
     if record_type == "Pool":
         pools: List[Pool] = [db.get_pool_by_entry_id(pool_id) for pool_id in record_ids]
         new_invoice: Invoice = db.add_invoice(
@@ -133,20 +133,27 @@
 
 
 @BLUEPRINT.route("/new/<record_type>")
 def new(record_type):
     """Generate a new invoice."""
     count = request.args.get("total", 0)
     customer_id = request.args.get("customer", "cust002")
-    customer: Customer = db.get_customer_by_customer_id(customer_id=customer_id)
-
+    customer: Customer = db.get_customer_by_internal_id(customer_internal_id=customer_id)
     if record_type == "Sample":
-        records, customers_to_invoice = db.get_samples_to_invoice(customer=customer)
+        records: List[Union[Pool, Sample]] = db.get_samples_to_invoice_for_customer(
+            customer=customer
+        )
+        customers_to_invoice: List[Customer] = db.get_customers_to_invoice(
+            records=db.get_samples_to_invoice_query()
+        )
     elif record_type == "Pool":
-        records, customers_to_invoice = db.get_pools_to_invoice(customer=customer)
+        records: List[Union[Pool, Sample]] = db.get_pools_to_invoice_for_customer(customer=customer)
+        customers_to_invoice: List[Customer] = db.get_customers_to_invoice(
+            records=db.get_pools_to_invoice_query()
+        )
     return render_template(
         "invoices/new.html",
         customers_to_invoice=customers_to_invoice,
         count=count,
         records=records,
         record_type=record_type,
         total_price_threshold=current_app.config["TOTAL_PRICE_THRESHOLD"],
@@ -210,10 +217,8 @@
     temp_dir = tempfile.mkdtemp()
     file_path = os.path.join(temp_dir, file_name)
     with open(file_path, "wb") as file_object:
         if cost_center == "KTH":
             file_object.write(invoice_obj.excel_kth)
         elif cost_center == "KI":
             file_object.write(invoice_obj.excel_ki)
-        pass
-
     return send_from_directory(directory=temp_dir, filename=file_name, as_attachment=True)
```

### Comparing `cg-27.1.9/cg/store/api/add.py` & `cg-27.2.0/cg/store/api/add.py`

 * *Files 1% similar despite different names*

```diff
@@ -90,15 +90,15 @@
             description=description,
             is_accredited=is_accredited,
             percent_kth=percent_kth,
             percent_reads_guaranteed=percent_reads_guaranteed,
             **kwargs,
         )
 
-    def add_version(
+    def add_application_version(
         self,
         application: Application,
         version: int,
         valid_from: dt.datetime,
         prices: dict,
         **kwargs,
     ) -> ApplicationVersion:
@@ -175,15 +175,15 @@
         synopsis: Optional[str] = None,
     ) -> Family:
         """Build a new Family record."""
 
         # generate a unique case id
         while True:
             internal_id = petname.Generate(2, separator="")
-            if self.family(internal_id) is None:
+            if self.get_case_by_internal_id(internal_id) is None:
                 break
             else:
                 LOG.debug(f"{internal_id} already used - trying another id")
 
         return self.Family(
             cohorts=cohorts,
             data_analysis=str(data_analysis),
```

### Comparing `cg-27.1.9/cg/store/api/base.py` & `cg-27.2.0/cg/store/api/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 """All models aggregated in a base class"""
-from typing import Any, Type
+from typing import Type
 
 from alchy import Query, ModelBase
 from dataclasses import dataclass
 
 from cg.store.models import (
     Analysis,
     Application,
```

### Comparing `cg-27.1.9/cg/store/api/core.py` & `cg-27.2.0/cg/store/api/core.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/api/delete.py` & `cg-27.2.0/cg/store/api/delete.py`

 * *Files 14% similar despite different names*

```diff
@@ -20,14 +20,14 @@
     def delete_relationships_sample(self, sample: Sample) -> None:
         """Delete relationships between all cases and the provided sample."""
         if sample and sample.links:
             for case_sample in sample.links:
                 case_sample.delete()
             self.commit()
 
-    def delete_cases_without_samples(self, case_ids: List[str]) -> None:
+    def delete_cases_without_samples(self, case_internal_ids: List[str]) -> None:
         """Delete any cases specified in case_ids without samples."""
-        for case_id in case_ids:
-            case: Family = self.Family.query.filter(Family.internal_id == case_id).first()
+        for case_internal_id in case_internal_ids:
+            case: Family = self.get_case_by_internal_id(internal_id=case_internal_id)
             if case and not case.links:
                 case.delete()
         self.commit()
```

### Comparing `cg-27.1.9/cg/store/api/find_basic_data.py` & `cg-27.2.0/cg/store/api/find_basic_data.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,35 +1,38 @@
 """Handler to find basic data objects"""
 import datetime as dt
 from typing import List, Optional
 
-from sqlalchemy import desc
 from sqlalchemy.orm import Query
 
 from cg.store.models import (
     Application,
     ApplicationVersion,
     Bed,
     BedVersion,
     Customer,
     Collaboration,
     Organism,
     Panel,
     User,
 )
 from cg.store.api.base import BaseHandler
-from cg.store.filters.status_organism_filters import OrganismFilter, apply_organism_filter
+from cg.store.filters.status_application_filters import apply_application_filter, ApplicationFilter
+from cg.store.filters.status_application_version_filters import (
+    apply_application_versions_filter,
+    ApplicationVersionFilter,
+)
 from cg.store.filters.status_bed_filters import apply_bed_filter, BedFilter
 from cg.store.filters.status_bed_version_filters import BedVersionFilter, apply_bed_version_filter
-from cg.store.filters.status_customer_filters import apply_customer_filter, CustomerFilter
-from cg.store.filters.status_application_filters import apply_application_filter, ApplicationFilter
 from cg.store.filters.status_collaboration_filters import (
     CollaborationFilter,
     apply_collaboration_filter,
 )
+from cg.store.filters.status_customer_filters import apply_customer_filter, CustomerFilter
+from cg.store.filters.status_organism_filters import OrganismFilter, apply_organism_filter
 from cg.store.filters.status_panel_filters import PanelFilter, apply_panel_filter
 from cg.store.filters.status_user_filters import apply_user_filter, UserFilter
 
 
 class FindBasicDataHandler(BaseHandler):
     """Contains methods to find basic data model instances."""
 
@@ -102,18 +105,44 @@
         """Return all applications."""
         return (
             self._get_query(table=Application)
             .order_by(self.Application.prep_category, self.Application.tag)
             .all()
         )
 
-    def application_version(self, application: Application, version: int) -> ApplicationVersion:
-        """Fetch an application version."""
-        query = self.ApplicationVersion.query.filter_by(application=application, version=version)
-        return query.first()
+    def get_application_version_by_application_entry_id(
+        self, application_entry_id: int
+    ) -> ApplicationVersion:
+        """Return an application version by application entry id."""
+        application_versions = self._get_query(table=ApplicationVersion)
+        return apply_application_versions_filter(
+            application_versions=application_versions,
+            filter_functions=[ApplicationVersionFilter.FILTER_BY_ENTRY_ID],
+            application_entry_id=application_entry_id,
+        ).first()
+
+    def get_current_application_version_by_tag(self, tag: str) -> Optional[ApplicationVersion]:
+        """Return the current application version for an application tag."""
+        application = self.get_application_by_tag(tag=tag)
+        if not application:
+            return None
+        return apply_application_versions_filter(
+            filter_functions=[
+                ApplicationVersionFilter.FILTER_BY_ENTRY_ID,
+                ApplicationVersionFilter.FILTER_BY_VALID_FROM_BEFORE,
+                ApplicationVersionFilter.ORDER_BY_VALID_FROM_DESC,
+            ],
+            application_versions=self._get_query(table=ApplicationVersion),
+            application_entry_id=application.id,
+            valid_from=dt.datetime.now(),
+        ).first()
+
+    def get_application_versions(self) -> List[ApplicationVersion]:
+        """Return all application versions."""
+        return self._get_query(table=ApplicationVersion).all()
 
     def get_bed_version_by_short_name(self, bed_version_short_name: str) -> BedVersion:
         """Return bed version with short name."""
         return apply_bed_version_filter(
             bed_versions=self._get_query(table=BedVersion),
             bed_version_short_name=bed_version_short_name,
             filter_functions=[BedVersionFilter.FILTER_BY_SHORT_NAME],
@@ -138,49 +167,30 @@
         )
 
     def get_latest_bed_version(self, bed_name: str) -> Optional[BedVersion]:
         """Return the latest bed version for a bed by supplied name."""
         bed: Optional[Bed] = self.get_bed_by_name(bed_name=bed_name)
         return bed.versions[-1] if bed and bed.versions else None
 
-    def get_customer_by_customer_id(self, customer_id: str) -> Customer:
+    def get_customer_by_internal_id(self, customer_internal_id: str) -> Customer:
         """Return customer with customer id."""
         return apply_customer_filter(
             filter_functions=[CustomerFilter.FILTER_BY_INTERNAL_ID],
             customers=self._get_query(table=Customer),
-            customer_id=customer_id,
+            customer_internal_id=customer_internal_id,
         ).first()
 
     def get_collaboration_by_internal_id(self, internal_id: str) -> Collaboration:
         """Fetch a customer group by internal id from the store."""
         return apply_collaboration_filter(
             collaborations=self._get_query(table=Collaboration),
             filter_functions=[CollaborationFilter.FILTER_BY_INTERNAL_ID],
             internal_id=internal_id,
         ).first()
 
-    def current_application_version(self, tag: str) -> Optional[ApplicationVersion]:
-        """Fetch the current application version for an application tag."""
-        application_obj = self.Application.query.filter_by(tag=tag).first()
-        if not application_obj:
-            return None
-        application_id = application_obj.id
-        records = self.ApplicationVersion.query.filter_by(application_id=application_id)
-        records = records.filter(self.ApplicationVersion.valid_from < dt.datetime.now())
-        records = records.order_by(desc(self.ApplicationVersion.valid_from))
-
-        return records.first()
-
-    def latest_version(self, tag: str) -> Optional[ApplicationVersion]:
-        """Fetch the latest application version for an application tag."""
-        application_obj = self.Application.query.filter_by(tag=tag).first()
-        return (
-            application_obj.versions[-1] if application_obj and application_obj.versions else None
-        )
-
     def get_organism_by_internal_id(self, internal_id: str) -> Organism:
         """Find an organism by internal id."""
         return apply_organism_filter(
             organisms=self._get_query(table=Organism),
             filter_functions=[OrganismFilter.FILTER_BY_INTERNAL_ID],
             internal_id=internal_id,
         ).first()
```

### Comparing `cg-27.1.9/cg/store/api/find_business_data.py` & `cg-27.2.0/cg/store/api/find_business_data.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,20 +1,21 @@
 """Handler to find business data objects."""
 import datetime as dt
 import logging
-from typing import List, Optional, Iterator, Union
+from typing import Callable, List, Optional, Iterator, Union
 
 from sqlalchemy import and_, func, or_
 from sqlalchemy.orm import Query
 
-from cg.constants import FlowCellStatus
+from cg.constants import FlowCellStatus, Pipeline
 from cg.constants.constants import PrepCategory, SampleType
 from cg.constants.indexes import ListIndexes
 from cg.exc import CaseNotFoundError
 from cg.store.api.base import BaseHandler
+from cg.store.filters.status_case_filters import CaseFilter, apply_case_filter
 
 from cg.store.models import (
     Analysis,
     Application,
     Customer,
     Flowcell,
     Family,
@@ -22,79 +23,61 @@
     Invoice,
     Pool,
     Sample,
 )
 
 from cg.store.filters.status_invoice_filters import apply_invoice_filter, InvoiceFilter
 from cg.store.filters.status_pool_filters import apply_pool_filter, PoolFilter
+
 from cg.store.filters.status_flow_cell_filters import apply_flow_cell_filter, FlowCellFilter
 from cg.store.filters.status_case_sample_filters import apply_case_sample_filter, CaseSampleFilter
 from cg.store.filters.status_sample_filters import apply_sample_filter, SampleFilter
 
+from cg.store.filters.status_analysis_filters import apply_analysis_filter, AnalysisFilter
+from cg.store.filters.status_customer_filters import apply_customer_filter, CustomerFilter
+
 
 LOG = logging.getLogger(__name__)
 
 
 class FindBusinessDataHandler(BaseHandler):
     """Contains methods to find business data model instances"""
 
-    def analyses(self, *, family: Family = None, before: dt.datetime = None) -> Query:
-        """Fetch multiple analyses."""
-        records = self.Analysis.query
-        if family:
-            query_family = family
-            records = records.filter(Analysis.family == query_family)
-        if before:
-            subq = (
-                self.Analysis.query.join(Analysis.family)
-                .filter(Analysis.started_at < before)
-                .group_by(Family.id)
-                .with_entities(
-                    Analysis.family_id,
-                    func.max(Analysis.started_at).label("started_at"),
-                )
-                .subquery()
-            )
-            records = records.join(
-                subq,
-                and_(
-                    self.Analysis.family_id == subq.c.family_id,
-                    self.Analysis.started_at == subq.c.started_at,
-                ),
-            ).filter(Analysis.started_at < before)
-        return records
+    def get_analyses_by_case_entry_id(self, case_entry_id: int) -> List[Analysis]:
+        """Return analysis by case entry id."""
+        return apply_analysis_filter(
+            analyses=self._get_query(Analysis),
+            case_entry_id=case_entry_id,
+            filter_functions=[AnalysisFilter.FILTER_BY_CASE_ENTRY_ID],
+        ).all()
+
+    def get_case_by_entry_id(self, entry_id: str) -> Family:
+        """Return a case by entry id."""
+        cases_query: Query = self._get_query(table=Family)
+        return apply_case_filter(
+            cases=cases_query, filter_functions=[CaseFilter.FILTER_BY_ENTRY_ID], entry_id=entry_id
+        ).first()
 
-    def active_sample(self, internal_id: str) -> bool:
+    def has_active_cases_for_sample(self, internal_id: str) -> bool:
         """Check if there are any active cases for a sample"""
-        sample: Sample = self.get_sample_by_internal_id(internal_id=internal_id)
-        if any(
-            [
-                self.family(
-                    internal_id=self.Family.query.filter(Family.id == family_sample.family_id)
-                    .first()
-                    .internal_id
-                ).action
-                == "analyze"
-                or self.family(
-                    internal_id=self.Family.query.filter(Family.id == family_sample.family_id)
-                    .first()
-                    .internal_id
-                ).action
-                == "running"
-                for family_sample in sample.links
-            ]
-        ):
-            return True
+        sample = self.get_sample_by_internal_id(internal_id=internal_id)
+        active_actions = ["analyze", "running"]
+
+        for family_sample in sample.links:
+            case: Family = self.get_case_by_entry_id(entry_id=family_sample.family_id)
+            if case.action in active_actions:
+                return True
+
         return False
 
     def get_application_by_case(self, case_id: str) -> Application:
         """Return the application of a case."""
 
         return (
-            self.family(internal_id=case_id)
+            self.get_case_by_internal_id(internal_id=case_id)
             .links[ListIndexes.FIRST.value]
             .sample.application_version.application
         )
 
     def analyses_ready_for_vogue_upload(
         self,
         completed_after: Optional[dt.date],
@@ -107,14 +90,27 @@
         if completed_after:
             records = records.filter(Analysis.completed_at > completed_after)
         if completed_before:
             records = records.filter(Analysis.completed_at < completed_before)
 
         return records
 
+    def get_latest_nipt_analysis_to_upload(self):
+        """Return latest nipt analysis."""
+        latest_nipt_analyses = self.latest_analyses().filter(Analysis.pipeline == Pipeline.FLUFFY)
+        return latest_nipt_analyses.filter(Analysis.uploaded_at.is_(None))
+
+    def get_latest_microsalt_analysis_to_upload(self):
+        """Return latest mircosalt analysis."""
+        return (
+            self.latest_analyses()
+            .filter(Analysis.pipeline == Pipeline.MICROSALT)
+            .filter(Analysis.uploaded_at.is_(None))
+        )
+
     def latest_analyses(self) -> Query:
         """Fetch latest analysis for all cases."""
 
         records = self.Analysis.query
         sub_query = (
             self.Analysis.query.join(Analysis.family)
             .group_by(Family.id)
@@ -126,55 +122,139 @@
             and_(
                 self.Analysis.family_id == sub_query.c.family_id,
                 self.Analysis.started_at == sub_query.c.started_at,
             ),
         )
         return records
 
-    def analysis(self, family: Family, started_at: dt.datetime) -> Analysis:
+    def get_analysis_by_case_entry_id_and_started_at(
+        self, case_entry_id: int, started_at_date: dt.datetime
+    ) -> Analysis:
         """Fetch an analysis."""
-        return self.Analysis.query.filter_by(family=family, started_at=started_at).first()
+        filter_functions = [
+            AnalysisFilter.FILTER_BY_CASE_ENTRY_ID,
+            AnalysisFilter.FILTER_BY_STARTED_AT,
+        ]
+
+        return apply_analysis_filter(
+            analyses=self._get_query(Analysis),
+            case_entry_id=case_entry_id,
+            started_at_date=started_at_date,
+            filter_functions=filter_functions,
+        ).first()
 
     def deliveries(self) -> Query:
         """Fetch all deliveries."""
         return self.Delivery.query
 
-    def families(
+    def get_cases_by_customer_and_case_name_search(
+        self, customer: Customer, case_name_search: str
+    ) -> List[Family]:
+        """
+        Retrieve a list of cases filtered by a customer and matching names.
+
+        Args:
+            customer (Customer): The customer object to filter cases by.
+            case_name_search (str): The case name search string to filter cases by.
+
+        Returns:
+            List[Family]: A list of filtered cases sorted by creation time.
+        """
+        filter_functions: List[Callable] = [
+            CaseFilter.FILTER_BY_CUSTOMER_ENTRY_ID,
+            CaseFilter.FILTER_BY_NAME_SEARCH,
+            CaseFilter.ORDER_BY_CREATED_AT,
+        ]
+
+        return apply_case_filter(
+            cases=self._get_query(table=Family),
+            filter_functions=filter_functions,
+            customer_entry_id=customer.id,
+            name_search=case_name_search,
+        ).all()
+
+    def get_cases_by_customers_action_and_case_search(
         self,
-        *,
-        action: Optional[str] = None,
-        data_analysis: Optional[str] = None,
-        customers: List[Customer] = None,
-        enquiry: Optional[str] = None,
-    ) -> Query:
-        """Fetch families."""
+        customers: Optional[List[Customer]],
+        action: Optional[str],
+        case_search: Optional[str],
+        limit: Optional[int] = 30,
+    ) -> List[Family]:
+        """
+        Retrieve a list of cases filtered by customers, action, and matching names or internal ids.
 
-        records = self.Family.query
+        Args:
+            customers (Optional[List[Customer]]): A list of customer objects to filter cases by.
+            action (Optional[str]): The action string to filter cases by.
+            case_search (Optional[str]): The case search string to filter cases by.
+            limit (Optional[int], default=30): The maximum number of cases to return.
 
-        if customers:
-            customer_ids = [customer.id for customer in customers]
-            records = records.filter(Family.customer_id.in_(customer_ids))
+        Returns:
+            List[Family]: A list of filtered cases sorted by creation time and limited by the specified number.
+        """
+        filter_functions: List[Callable] = [
+            CaseFilter.FILTER_BY_CUSTOMER_ENTRY_IDS,
+            CaseFilter.FILTER_BY_ACTION,
+            CaseFilter.FILTER_BY_CASE_SEARCH,
+            CaseFilter.ORDER_BY_CREATED_AT,
+        ]
 
-        records = (
-            records.filter(
-                or_(
-                    Family.name.like(f"%{enquiry}%"),
-                    Family.internal_id.like(f"%{enquiry}%"),
-                )
-            )
-            if enquiry
-            else records
+        customer_entry_ids: List[int] = (
+            [customer.id for customer in customers] if customers else None
         )
-        records = records.filter_by(action=action) if action else records
-        records = records.filter_by(data_analysis=data_analysis) if data_analysis else records
-        return records.order_by(Family.created_at.desc())
-
-    def family(self, internal_id: str) -> Family:
-        """Fetch a family by internal id from the database."""
-        return self.Family.query.filter_by(internal_id=internal_id).first()
+
+        filtered_cases: Query = apply_case_filter(
+            cases=self._get_query(table=Family),
+            filter_functions=filter_functions,
+            customer_entry_ids=customer_entry_ids,
+            action=action,
+            case_search=case_search,
+        )
+        return filtered_cases.limit(limit=limit).all()
+
+    def get_cases_by_customer_pipeline_and_case_search(
+        self,
+        customer: Optional[Customer],
+        pipeline: Optional[str],
+        case_search: Optional[str],
+        limit: Optional[int] = 30,
+    ) -> List[Family]:
+        """
+        Retrieve a list of cases filtered by customer, pipeline, and matching names or internal ids.
+
+        Args:
+            customer (Optional[Customer]): A customer object to filter cases by.
+            pipeline (Optional[str]): The pipeline string to filter cases by.
+            case_search (Optional[str]): The case search string to filter cases by.
+            limit (Optional[int], default=30): The maximum number of cases to return.
+
+        Returns:
+            List[Family]: A list of filtered cases sorted by creation time and limited by the specified number.
+        """
+        filter_functions: List[Callable] = [
+            CaseFilter.FILTER_BY_CUSTOMER_ENTRY_ID,
+            CaseFilter.FILTER_BY_CASE_SEARCH,
+            CaseFilter.GET_WITH_PIPELINE,
+            CaseFilter.ORDER_BY_CREATED_AT,
+        ]
+
+        customer_entry_id: int = customer.id if customer else None
+
+        filtered_cases: Query = apply_case_filter(
+            cases=self._get_query(table=Family),
+            filter_functions=filter_functions,
+            customer_entry_id=customer_entry_id,
+            case_search=case_search,
+            pipeline=pipeline,
+        )
+        return filtered_cases.limit(limit=limit).all()
+
+    def get_cases(self) -> List[Family]:
+        """Return all cases."""
+        return self._get_query(table=Family).all()
 
     def family_samples(self, family_id: str) -> List[FamilySample]:
         """Return the case-sample links associated with a case."""
         return apply_case_sample_filter(
             filter_functions=[CaseSampleFilter.GET_SAMPLES_ASSOCIATED_WITH_CASE],
             case_id=family_id,
             case_samples=self._get_join_case_sample_query(),
@@ -196,80 +276,112 @@
             case_samples=self._get_join_case_sample_query(),
         )
 
     def filter_cases_with_samples(self, case_ids: List[str]) -> List[str]:
         """Return case id:s associated with samples."""
         cases_with_samples = set()
         for case_id in case_ids:
-            case: Family = self.family(internal_id=case_id)
+            case: Family = self.get_case_by_internal_id(internal_id=case_id)
             if case and case.links:
                 cases_with_samples.add(case_id)
         return list(cases_with_samples)
 
-    def get_cases_from_ticket(self, ticket: str) -> Query:
-        return self.Family.query.filter(Family.tickets.contains(ticket))
+    def get_cases_by_ticket_id(self, ticket_id: str) -> List[Family]:
+        """Return cases associated with a given ticket id."""
+        return apply_case_filter(
+            filter_functions=[CaseFilter.FILTER_BY_TICKET],
+            ticket_id=ticket_id,
+            cases=self._get_query(table=Family),
+        ).all()
 
     def get_customer_id_from_ticket(self, ticket: str) -> str:
         """Returns the customer related to given ticket"""
-        return (
-            self.Family.query.filter(Family.tickets.contains(ticket)).first().customer.internal_id
-        )
+        cases: List[Family] = self.get_cases_by_ticket_id(ticket_id=ticket)
+        if not cases:
+            raise ValueError(f"No case found for ticket {ticket}")
+        return cases[0].customer.internal_id
 
     def get_samples_from_ticket(self, ticket: str) -> List[Sample]:
-        return self._get_join_sample_family_query().filter(Family.tickets.contains(ticket)).all()
+        """Returns the samples related to given ticket."""
+        return apply_case_filter(
+            filter_functions=[CaseFilter.FILTER_BY_TICKET],
+            ticket_id=ticket,
+            cases=self._get_join_sample_family_query(),
+        ).all()
 
     def get_latest_ticket_from_case(self, case_id: str) -> str:
         """Returns the ticket from the most recent sample in a case"""
-        return self.family(case_id).latest_ticket
+        return self.get_case_by_internal_id(internal_id=case_id).latest_ticket
 
     def get_latest_flow_cell_on_case(self, family_id: str) -> Flowcell:
         """Fetch the latest sequenced flow cell related to a sample on a case."""
         flow_cells_on_case: List[Flowcell] = list(
-            self.get_flow_cells_by_case(case=self.family(family_id))
+            self.get_flow_cells_by_case(case=self.get_case_by_internal_id(internal_id=family_id))
         )
         flow_cells_on_case.sort(key=lambda flow_cell: flow_cell.sequenced_at)
         return flow_cells_on_case[-1]
 
     def _is_case_found(self, case: Family, case_id: str) -> None:
         """Raise error if case is false."""
         if not case:
             LOG.error(f"Could not find case {case_id}")
             raise CaseNotFoundError("")
 
     def get_samples_by_case_id(self, case_id: str) -> List[Sample]:
         """Get samples on a given case id."""
 
-        case: Family = self.family(internal_id=case_id)
+        case: Family = self.get_case_by_internal_id(internal_id=case_id)
         self._is_case_found(case=case, case_id=case_id)
         return case.samples if case else []
 
     def get_sample_ids_by_case_id(self, case_id: str = None) -> Iterator[str]:
         """Return sample ids from case id."""
-        case: Family = self.family(internal_id=case_id)
+        case: Family = self.get_case_by_internal_id(internal_id=case_id)
         self._is_case_found(case=case, case_id=case_id)
         for link in case.links:
             yield link.sample.internal_id
 
     def get_sequenced_samples(self, family_id: str) -> List[Sample]:
         """Get sequenced samples by family_id."""
 
         samples: List[Sample] = self.get_samples_by_case_id(family_id)
         return [sample for sample in samples if sample.sequencing_qc]
 
-    def find_family(self, customer: Customer, name: str) -> Family:
-        """Find a family by family name within a customer."""
-        return self.Family.query.filter_by(customer=customer, name=name).first()
-
-    def find_family_by_name(self, name: str) -> Family:
-        """Find a family by family name within a customer."""
-        return self.Family.query.filter_by(name=name).first()
-
-    def find_samples(self, customer: Customer, name: str) -> Query:
-        """Find samples within a customer."""
-        return self._get_query(table=Sample).filter_by(customer=customer, name=name)
+    def get_case_by_name_and_customer(self, customer: Customer, case_name: str) -> Family:
+        """Find a case by case name within a customer."""
+        return apply_case_filter(
+            cases=self._get_query(table=Family),
+            filter_functions=[CaseFilter.FILTER_BY_CUSTOMER_ENTRY_ID, CaseFilter.FILTER_BY_NAME],
+            customer_entry_id=customer.id,
+            name=case_name,
+        ).first()
+
+    def get_case_by_name(self, name: str) -> Family:
+        """Get a case by name."""
+        return apply_case_filter(
+            cases=self._get_query(table=Family),
+            filter_functions=[CaseFilter.FILTER_BY_NAME],
+            name=name,
+        ).first()
+
+    def get_sample_by_customer_and_name(
+        self, customer_entry_id: List[int], sample_name: str
+    ) -> Sample:
+        """Get samples within a customer."""
+        filter_functions = [
+            SampleFilter.FILTER_BY_CUSTOMER_ENTRY_IDS,
+            SampleFilter.FILTER_BY_SAMPLE_NAME,
+        ]
+
+        return apply_sample_filter(
+            samples=self._get_query(table=Sample),
+            filter_functions=filter_functions,
+            customer_entry_ids=customer_entry_id,
+            name=sample_name,
+        ).first()
 
     def get_flow_cell(self, flow_cell_id: str) -> Flowcell:
         """Return flow cell by flow cell id."""
         return apply_flow_cell_filter(
             flow_cells=self._get_query(table=Flowcell),
             flow_cell_id=flow_cell_id,
             filter_functions=[FlowCellFilter.GET_BY_ID],
@@ -326,15 +438,15 @@
             return flow_cell.samples
 
     def is_all_flow_cells_on_disk(self, case_id: str) -> bool:
         """Check if flow cells are on disk for sample before starting the analysis.
         Flow cells not on disk will be requested.
         """
         flow_cells: Optional[List[Flowcell]] = list(
-            self.get_flow_cells_by_case(case=self.family(case_id))
+            self.get_flow_cells_by_case(case=self.get_case_by_internal_id(internal_id=case_id))
         )
         if not flow_cells:
             LOG.info("No flow cells found")
             return False
         statuses: List[str] = []
         for flow_cell in flow_cells:
             LOG.info(f"{flow_cell.name}: checking if flow cell is on disk")
@@ -458,63 +570,103 @@
         if application.prep_category != PrepCategory.READY_MADE_LIBRARY.value:
             raise ValueError(
                 f"{case_id} is not a ready made library, found prep category: "
                 f"{application.prep_category}"
             )
         return application.expected_reads
 
-    def get_all_samples(self) -> List[Sample]:
+    def get_samples(self) -> List[Sample]:
         """Return all samples."""
         return self._get_query(table=Sample).order_by(Sample.created_at.desc()).all()
 
-    def get_samples_by_enquiry(
-        self, *, customers: Optional[List[Customer]] = None, enquiry: str = None
-    ) -> List[Sample]:
-        records = self._get_query(table=Sample)
+    def get_samples_by_name_pattern(self, name_pattern: str) -> List[Sample]:
+        """Return all samples with a name fitting the pattern."""
+        return apply_sample_filter(
+            samples=self._get_query(table=Sample),
+            name_pattern=name_pattern,
+            filter_functions=[SampleFilter.FILTER_BY_NAME_PATTERN],
+        ).all()
 
+    def get_samples_by_customer_id_and_pattern(
+        self, *, customers: Optional[List[Customer]] = None, pattern: str = None
+    ) -> List[Sample]:
+        """Get samples by customer and sample internal id  or sample name pattern."""
+        samples: Query = self._get_query(table=Sample)
+        customer_entry_ids: List[int] = []
+        filter_functions: List[SampleFilter] = []
         if customers:
-            customer_ids = [customer.id for customer in customers]
-            records = records.filter(Sample.customer_id.in_(customer_ids))
+            if not isinstance(customers, list):
+                customers = list(customers)
+            customer_entry_ids = [customer.id for customer in customers]
+            filter_functions.append(SampleFilter.FILTER_BY_CUSTOMER_ENTRY_IDS)
+        if pattern:
+            filter_functions.extend([SampleFilter.FILTER_BY_INTERNAL_ID_OR_NAME_SEARCH])
+        filter_functions.append(SampleFilter.ORDER_BY_CREATED_AT_DESC)
+        return apply_sample_filter(
+            samples=samples,
+            customer_entry_ids=customer_entry_ids,
+            search_pattern=pattern,
+            filter_functions=filter_functions,
+        ).all()
 
-        records = (
-            records.filter(
-                or_(
-                    Sample.name.like(f"%{enquiry}%"),
-                    Sample.internal_id.like(f"%{enquiry}%"),
-                )
-            )
-            if enquiry
-            else records
+    def _get_samples_by_customer_and_subject_id_query(
+        self, customer_internal_id: str, subject_id: str
+    ) -> Query:
+        """Return query of samples of customer with given subject id."""
+        records: Query = apply_customer_filter(
+            customers=self._get_join_sample_and_customer_query(),
+            customer_internal_id=customer_internal_id,
+            filter_functions=[CustomerFilter.FILTER_BY_INTERNAL_ID],
         )
-        return records.order_by(Sample.created_at.desc()).all()
-
-    def get_samples_by_subject_id(self, customer_id: str, subject_id: str) -> List[Sample]:
-        """Get samples of customer with given subject_id or subject_id and is_tumour."""
-        query: Query = self._get_join_sample_and_customer_query().filter(
-            Customer.internal_id == customer_id, Sample.subject_id == subject_id
+        return apply_sample_filter(
+            samples=records,
+            subject_id=subject_id,
+            filter_functions=[SampleFilter.FILTER_BY_SUBJECT_ID],
         )
-        return query.all()
 
-    def get_samples_by_subject_id_and_is_tumour(
-        self, customer_id: str, subject_id: str, is_tumour: bool
+    def get_samples_by_customer_and_subject_id(
+        self, customer_internal_id: str, subject_id: str
     ) -> List[Sample]:
-        """Get samples of customer with given subject_id and is_tumour."""
-        samples: Query = self._get_join_sample_and_customer_query().filter(
-            Customer.internal_id == customer_id, Sample.subject_id == subject_id
-        )
+        """Get samples of customer with given subject id."""
+        return self._get_samples_by_customer_and_subject_id_query(
+            customer_internal_id=customer_internal_id, subject_id=subject_id
+        ).all()
 
+    def get_samples_by_customer_subject_id_and_is_tumour(
+        self, customer_internal_id: str, subject_id: str, is_tumour: bool
+    ) -> List[Sample]:
+        """Get samples of customer with given subject id and is tumour."""
+        samples: Query = self._get_samples_by_customer_and_subject_id_query(
+            customer_internal_id=customer_internal_id, subject_id=subject_id
+        )
         if is_tumour:
             return apply_sample_filter(
                 samples=samples, filter_functions=[SampleFilter.FILTER_IS_TUMOUR]
             ).all()
         else:
             return apply_sample_filter(
                 samples=samples, filter_functions=[SampleFilter.FILTER_IS_NOT_TUMOUR]
             ).all()
 
+    def get_samples_by_customer_id_list_and_subject_id_and_is_tumour(
+        self, customer_ids: List[int], subject_id: str
+    ) -> List[Sample]:
+        """Return a list of samples matching a list of customers with given subject id and is a tumour sample."""
+        samples = self._get_query(table=Sample)
+        return apply_sample_filter(
+            samples=samples,
+            customer_entry_ids=customer_ids,
+            subject_id=subject_id,
+            filter_functions=[
+                SampleFilter.FILTER_BY_CUSTOMER_ENTRY_IDS,
+                SampleFilter.FILTER_BY_SUBJECT_ID,
+                SampleFilter.FILTER_IS_TUMOUR,
+            ],
+        ).all()
+
     def get_samples_by_any_id(self, **identifiers: dict) -> Query:
         records = self._get_query(table=Sample)
 
         for identifier_name, identifier_value in identifiers.items():
             identifier = getattr(Sample, identifier_name)
             records = records.filter(identifier.contains(identifier_value))
 
@@ -539,14 +691,30 @@
             samples=samples,
             tissue_type=sample_type,
         )
         return samples.all() if samples else None
 
     def is_case_down_sampled(self, case_id: str) -> bool:
         """Returns True if all samples in a case are down sampled from another sample."""
-        case: Family = self.family(internal_id=case_id)
+        case: Family = self.get_case_by_internal_id(internal_id=case_id)
         return all(sample.from_sample is not None for sample in case.samples)
 
     def is_case_external(self, case_id: str) -> bool:
         """Returns True if all samples in a case have been sequenced externally."""
-        case: Family = self.family(internal_id=case_id)
+        case: Family = self.get_case_by_internal_id(internal_id=case_id)
         return all(sample.application_version.application.is_external for sample in case.samples)
+
+    def get_case_by_internal_id(self, internal_id: str) -> Family:
+        """Get case by internal id."""
+        return apply_case_filter(
+            filter_functions=[CaseFilter.FILTER_BY_INTERNAL_ID],
+            cases=self._get_query(table=Family),
+            internal_id=internal_id,
+        ).first()
+
+    def get_running_cases_in_pipeline(self, pipeline: Pipeline) -> List[Family]:
+        """Get all running cases in a pipeline."""
+        return apply_case_filter(
+            filter_functions=[CaseFilter.GET_WITH_PIPELINE, CaseFilter.IS_RUNNING],
+            cases=self._get_query(table=Family),
+            pipeline=pipeline,
+        ).all()
```

### Comparing `cg-27.1.9/cg/store/api/import_func.py` & `cg-27.2.0/cg/store/api/import_func.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,15 +5,14 @@
 from datetime import datetime
 from typing import Iterable, List, Optional
 
 import openpyxl
 from openpyxl.workbook import Workbook
 from openpyxl.worksheet.worksheet import Worksheet
 
-from cg.exc import CgError
 from cg.store import Store
 from cg.store.models import Application, ApplicationVersion
 
 from .models import ApplicationSchema, ApplicationVersionSchema, ParsedApplicationVersion
 
 LOG = logging.getLogger(__name__)
 
@@ -48,15 +47,17 @@
                 continue
 
             LOG.error("Rolling back transaction.")
             store.rollback()
             sys.exit()
 
         app_tag: str = application_obj.tag
-        latest_version: ApplicationVersion = store.latest_version(application_version.app_tag)
+        latest_version: ApplicationVersion = store.get_current_application_version_by_tag(
+            tag=application_version.app_tag
+        )
 
         if latest_version and versions_are_same(
             version_obj=latest_version, application_version=application_version
         ):
             LOG.info("skipping redundant application version for app tag %s", app_tag)
             continue
 
@@ -114,15 +115,15 @@
         store.commit()
     else:
         LOG.error("Dry-run, rolling back transaction.")
         store.rollback()
 
 
 def prices_are_same(first_price: float, second_price: float) -> bool:
-    """Checks if the given prices are to be considered equal"""
+    """Checks if the given prices are to be considered equal."""
 
     if first_price == second_price:
         return True
     if first_price and second_price:
         return int(round(float(first_price))) == int(round(float(second_price)))
 
     return False
@@ -153,15 +154,15 @@
 def add_application_version(
     application_obj: Application,
     latest_version: Optional[ApplicationVersion],
     version: ApplicationVersionSchema,
     sign: str,
     store: Store,
 ) -> ApplicationVersion:
-    new_version = store.add_version(
+    new_version = store.add_application_version(
         application=application_obj,
         version=latest_version.version + 1 if latest_version else 1,
         valid_from=version.valid_from,
         prices={
             "standard": version.standard,
             "priority": version.priority,
             "express": version.express,
@@ -206,15 +207,15 @@
     signature: str,
     sheet_name: str,
     tag_column: int,
     tag_row: int,
     activate: bool,
     inactivate: bool,
 ):
-    """Syncs all applications from the specified excel file"""
+    """Syncs all applications from the specified excel file."""
 
     orderform_application_tags = []
 
     for tag in get_cells_from_excel(
         excel_path=excel_path, sheet_name=sheet_name, tag_column=tag_column, tag_row=tag_row
     ):
         LOG.info("Found: %s in orderform", tag)
```

### Comparing `cg-27.1.9/cg/store/api/models.py` & `cg-27.2.0/cg/store/api/models.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/api/status.py` & `cg-27.2.0/cg/store/api/status.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 from datetime import datetime, timedelta
 from types import SimpleNamespace
-from typing import List, Optional, Tuple, Callable
+from typing import List, Optional
+
 
 from sqlalchemy.orm import Query
 from typing_extensions import Literal
 
 from cg.constants import CASE_ACTIONS, Pipeline, FlowCellStatus
 from cg.constants.constants import CaseActions
+from cg.constants.invoice import CustomerNames
 from cg.store.models import (
     Analysis,
     Application,
     ApplicationVersion,
     Customer,
     Family,
     FamilySample,
@@ -27,15 +29,15 @@
 from cg.store.filters.status_pool_filters import apply_pool_filter, PoolFilter
 from cg.store.filters.status_application_filters import apply_application_filter, ApplicationFilter
 
 
 class StatusHandler(BaseHandler):
     """Handles status states for entities in the database."""
 
-    def get_all_samples_to_receive(self, external: bool = False) -> List[Sample]:
+    def get_samples_to_receive(self, external: bool = False) -> List[Sample]:
         """Return samples to receive."""
         records: Query = self._get_join_sample_application_version_query()
         sample_filter_functions: List[SampleFilter] = [
             SampleFilter.FILTER_IS_NOT_RECEIVED,
             SampleFilter.FILTER_IS_NOT_DOWN_SAMPLED,
         ]
         records: Query = apply_sample_filter(
@@ -48,15 +50,15 @@
         else:
             records: Query = apply_application_filter(
                 applications=records,
                 filter_functions=[ApplicationFilter.FILTER_IS_NOT_EXTERNAL],
             )
         return records.order_by(Sample.ordered_at).all()
 
-    def get_all_samples_to_prepare(self) -> List[Sample]:
+    def get_samples_to_prepare(self) -> List[Sample]:
         """Return samples to prepare."""
         records: Query = self._get_join_sample_application_version_query()
         sample_filter_functions: List[SampleFilter] = [
             SampleFilter.FILTER_IS_RECEIVED,
             SampleFilter.FILTER_IS_NOT_PREPARED,
             SampleFilter.FILTER_IS_NOT_DOWN_SAMPLED,
             SampleFilter.FILTER_IS_NOT_SEQUENCED,
@@ -66,15 +68,15 @@
         )
         records: Query = apply_application_filter(
             applications=records, filter_functions=[ApplicationFilter.FILTER_IS_NOT_EXTERNAL]
         )
 
         return records.order_by(Sample.received_at).all()
 
-    def get_all_samples_to_sequence(self) -> List[Sample]:
+    def get_samples_to_sequence(self) -> List[Sample]:
         """Return samples in sequencing."""
         records: Query = self._get_join_sample_application_version_query()
         sample_filter_functions: List[SampleFilter] = [
             SampleFilter.FILTER_IS_PREPARED,
             SampleFilter.FILTER_IS_NOT_SEQUENCED,
             SampleFilter.FILTER_IS_NOT_DOWN_SAMPLED,
         ]
@@ -126,32 +128,14 @@
             )
         ]
 
         if threshold:
             families = [case_obj for case_obj in families if case_obj.all_samples_pass_qc]
         return families[:limit]
 
-    def cases_to_store(self, pipeline: Pipeline, limit: int = None) -> list:
-        """Returns a list of cases that may be available to store in Housekeeper."""
-        families_query = (
-            self.Family.query.outerjoin(Analysis)
-            .join(Family.links, FamilySample.sample)
-            .filter(Family.data_analysis == str(pipeline))
-            .filter(Family.action == "running")
-        )
-        return list(families_query)[:limit]
-
-    def get_running_cases_for_pipeline(self, pipeline: Pipeline) -> List[Family]:
-        return (
-            self.query(Family)
-            .filter(Family.action == "running")
-            .filter(Family.data_analysis == pipeline)
-            .all()
-        )
-
     def cases(
         self,
         internal_id: str = None,
         name: str = None,
         days: int = 0,
         case_action: Optional[str] = None,
         priority: str = None,
@@ -219,18 +203,18 @@
 
             case_output = self._get_case_output(case_data)
 
             cases.append(case_output)
 
         return sorted(cases, key=lambda k: k["tat"], reverse=True)
 
-    def set_case_action(self, action: Literal[CASE_ACTIONS], case_id: str) -> None:
+    def set_case_action(self, action: Literal[CASE_ACTIONS], case_internal_id: str) -> None:
         """Sets the action of provided cases to None or the given action."""
-        case_obj: Family = self.Family.query.filter(Family.internal_id == case_id).first()
-        case_obj.action = action
+        case: Family = self.get_case_by_internal_id(internal_id=case_internal_id)
+        case.action = action
         self.commit()
 
     def add_sample_comment(self, sample: Sample, comment: str) -> None:
         """Update comment on sample with the provided comment."""
         if sample.comment:
             sample.comment = sample.comment + " " + comment
         else:
@@ -598,22 +582,14 @@
         return (
             (len(case_obj.analyses) > 0)
             or (samples_received_at and samples_received_at < case_obj.ordered_at)
             or (samples_prepared_at and samples_prepared_at < case_obj.ordered_at)
             or (samples_sequenced_at and samples_sequenced_at < case_obj.ordered_at)
         )
 
-    @staticmethod
-    def _all_samples_have_sequence_data(links: List[FamilySample]) -> bool:
-        """Return True if all samples are external or sequenced in-house."""
-        return all(
-            (link.sample.sequenced_at or link.sample.application_version.application.is_external)
-            for link in links
-        )
-
     def analyses_to_upload(self, pipeline: Pipeline = None) -> List[Analysis]:
         """Return analyses that have not been uploaded."""
         analysis_filter_functions: List[AnalysisFilter] = [
             AnalysisFilter.FILTER_WITH_PIPELINE,
             AnalysisFilter.FILTER_COMPLETED,
             AnalysisFilter.FILTER_NOT_UPLOADED,
             AnalysisFilter.FILTER_VALID_IN_PRODUCTION,
@@ -639,30 +615,77 @@
         if pipeline:
             records = records.filter(
                 Analysis.pipeline == str(pipeline),
             )
 
         return records
 
-    def get_analyses_before_date(
+    def get_analyses_for_case_and_pipeline_started_at_before(
         self,
-        case_id: Optional[str] = None,
-        before: Optional[datetime] = datetime.now(),
-        pipeline: Optional[Pipeline] = None,
-    ) -> Query:
-        """Fetch all analyses older than certain date."""
-        records: Query = self._get_join_analysis_case_query()
-        if case_id:
-            records = records.filter(Family.internal_id == case_id)
-        if pipeline:
-            records = records.filter(
-                Analysis.pipeline == str(pipeline),
-            )
-        records = records.filter(Analysis.started_at <= before)
-        return records
+        pipeline: Pipeline,
+        started_at_before: datetime,
+        case_internal_id: str,
+    ) -> List[Analysis]:
+        """Return all analyses older than certain date."""
+        case = self.get_case_by_internal_id(internal_id=case_internal_id)
+        case_entry_id: int = case.id if case else None
+        filter_functions: List[AnalysisFilter] = [
+            AnalysisFilter.FILTER_BY_CASE_ENTRY_ID,
+            AnalysisFilter.FILTER_WITH_PIPELINE,
+            AnalysisFilter.FILTER_STARTED_AT_BEFORE,
+        ]
+        return apply_analysis_filter(
+            analyses=self._get_query(table=Analysis),
+            filter_functions=filter_functions,
+            case_entry_id=case_entry_id,
+            started_at_date=started_at_before,
+            pipeline=pipeline,
+        ).all()
+
+    def get_analyses_for_case_started_at_before(
+        self,
+        case_internal_id: str,
+        started_at_before: datetime,
+    ) -> List[Analysis]:
+        """Return all analyses for a case older than certain date."""
+        case = self.get_case_by_internal_id(internal_id=case_internal_id)
+        case_entry_id: int = case.id if case else None
+        filter_functions: List[AnalysisFilter] = [
+            AnalysisFilter.FILTER_BY_CASE_ENTRY_ID,
+            AnalysisFilter.FILTER_STARTED_AT_BEFORE,
+        ]
+        return apply_analysis_filter(
+            analyses=self._get_query(table=Analysis),
+            filter_functions=filter_functions,
+            case_entry_id=case_entry_id,
+            started_at_date=started_at_before,
+        ).all()
+
+    def get_analyses_for_pipeline_started_at_before(
+        self, pipeline: Pipeline, started_at_before: datetime
+    ) -> List[Analysis]:
+        """Return all analyses for a pipeline started before a certain date."""
+        filter_functions: List[AnalysisFilter] = [
+            AnalysisFilter.FILTER_WITH_PIPELINE,
+            AnalysisFilter.FILTER_STARTED_AT_BEFORE,
+        ]
+        return apply_analysis_filter(
+            filter_functions=filter_functions,
+            analyses=self._get_query(table=Analysis),
+            pipeline=pipeline,
+            started_at_date=started_at_before,
+        ).all()
+
+    def get_analyses_started_at_before(self, started_at_before: datetime) -> List[Analysis]:
+        """Return all analyses for a pipeline started before a certain date."""
+        return apply_analysis_filter(
+            filter_functions=[AnalysisFilter.FILTER_STARTED_AT_BEFORE],
+            analyses=self._get_query(table=Analysis),
+            started_at_date=started_at_before,
+        ).all()
 
     def observations_to_upload(self, pipeline: Pipeline = None) -> Query:
         """Return observations that have not been uploaded."""
         case_filter_functions: List[CaseFilter] = [
             CaseFilter.GET_WITH_LOQUSDB_SUPPORTED_PIPELINE,
             CaseFilter.GET_WITH_LOQUSDB_SUPPORTED_SEQUENCING_METHOD,
         ]
@@ -782,63 +805,62 @@
     def get_samples_not_down_sampled(self) -> List[Sample]:
         """Return all samples that have not been down sampled."""
         return apply_sample_filter(
             filter_functions=[SampleFilter.FILTER_IS_NOT_DOWN_SAMPLED],
             samples=self._get_query(table=Sample),
         ).all()
 
-    def get_samples_to_invoice(self, customer: Customer = None) -> Tuple[Query, list]:
+    def get_samples_to_invoice_query(self) -> Query:
         """Return all samples that should be invoiced."""
         sample_filter_functions: List[SampleFilter] = [
             SampleFilter.FILTER_IS_DELIVERED,
             SampleFilter.FILTER_HAS_NO_INVOICE_ID,
             SampleFilter.FILTER_DO_INVOICE,
             SampleFilter.FILTER_IS_NOT_DOWN_SAMPLED,
         ]
-
-        records: Query = apply_sample_filter(
+        return apply_sample_filter(
             filter_functions=sample_filter_functions,
             samples=self._get_query(table=Sample),
         )
 
-        customers_to_invoice = [
-            case_obj.customer
-            for case_obj in records.all()
-            if case_obj.customer.internal_id != "cust000"
-        ]
-
-        customers_to_invoice = list(set(customers_to_invoice))
-        records = records.filter(Sample.customer == customer) if customer else records
-        return records, customers_to_invoice
-
-    def get_pools_to_invoice(self, customer: Customer = None) -> Tuple[Query, list]:
-        """
-        Return all pools that should be invoiced.
-        """
-        records = self._get_query(table=Pool)
+    def get_pools_to_invoice_query(self) -> Query:
+        """Return all pools that should be invoiced."""
         pool_filter_functions: List[PoolFilter] = [
             PoolFilter.FILTER_IS_DELIVERED,
             PoolFilter.FILTER_WITHOUT_INVOICE_ID,
             PoolFilter.FILTER_DO_INVOICE,
         ]
-
-        records: Query = apply_pool_filter(
+        return apply_pool_filter(
             filter_functions=pool_filter_functions,
-            pools=records,
+            pools=self._get_query(table=Pool),
         )
 
-        customers_to_invoice = [
-            case_obj.customer
-            for case_obj in records.all()
-            if case_obj.customer.internal_id != "cust000"
-        ]
+    def get_samples_to_invoice_for_customer(self, customer: Customer = None) -> List[Sample]:
+        """Return all samples that should be invoiced for a customer."""
+        return apply_sample_filter(
+            samples=self.get_samples_to_invoice_query(),
+            filter_functions=[SampleFilter.FILTER_BY_CUSTOMER],
+            customer=customer,
+        ).all()
+
+    def get_pools_to_invoice_for_customer(self, customer: Customer = None) -> List[Pool]:
+        """Return all pools for a customer that should be invoiced."""
+        return apply_pool_filter(
+            filter_functions=[PoolFilter.FILTER_BY_CUSTOMER],
+            pools=self.get_pools_to_invoice_query(),
+            customer=customer,
+        ).all()
 
-        customers_to_invoice = list(set(customers_to_invoice))
-        records = records.filter(Pool.customer_id == customer.id) if customer else records
-        return records, customers_to_invoice
+    def get_customers_to_invoice(self, records: Query) -> List[Customer]:
+        customers_to_invoice: List[Customer] = [
+            record.customer
+            for record in records.all()
+            if record.customer.internal_id != CustomerNames.CG_INTERNAL_CUSTOMER
+        ]
+        return list(set(customers_to_invoice))
 
     def get_pools_to_receive(self) -> List[Pool]:
         """Return all pools that have been not yet been received."""
         return apply_pool_filter(
             filter_functions=[PoolFilter.FILTER_IS_NOT_RECEIVED], pools=self._get_query(table=Pool)
         ).all()
```

### Comparing `cg-27.1.9/cg/store/filters/status_application_filters.py` & `cg-27.2.0/cg/store/filters/status_application_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/filters/status_bed_filters.py` & `cg-27.2.0/cg/store/filters/status_bed_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/filters/status_bed_version_filters.py` & `cg-27.2.0/cg/store/filters/status_bed_version_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/filters/status_case_sample_filters.py` & `cg-27.2.0/cg/store/filters/status_case_sample_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/filters/status_collaboration_filters.py` & `cg-27.2.0/cg/store/filters/status_collaboration_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/filters/status_customer_filters.py` & `cg-27.2.0/cg/store/filters/status_customer_filters.py`

 * *Files 10% similar despite different names*

```diff
@@ -2,30 +2,32 @@
 from typing import List, Optional, Callable
 
 from sqlalchemy.orm import Query
 
 from cg.store.models import Customer
 
 
-def filter_customer_by_customer_internal_id(customers: Query, customer_id: str, **kwargs) -> Query:
+def filter_customer_by_customer_internal_id(
+    customers: Query, customer_internal_id: str, **kwargs
+) -> Query:
     """Return customer by customer internal id."""
-    return customers.filter(Customer.internal_id == customer_id)
+    return customers.filter(Customer.internal_id == customer_internal_id)
 
 
 class CustomerFilter(Enum):
     """Define customer filter functions."""
 
     FILTER_BY_INTERNAL_ID: Callable = filter_customer_by_customer_internal_id
 
 
 def apply_customer_filter(
     customers: Query,
     filter_functions: List[Callable],
-    customer_id: Optional[str] = None,
+    customer_internal_id: Optional[str] = None,
 ) -> Query:
     """Apply filtering functions and return filtered results."""
     for filter_function in filter_functions:
         customers: Query = filter_function(
             customers=customers,
-            customer_id=customer_id,
+            customer_internal_id=customer_internal_id,
         )
     return customers
```

### Comparing `cg-27.1.9/cg/store/filters/status_flow_cell_filters.py` & `cg-27.2.0/cg/store/filters/status_flow_cell_filters.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 from enum import Enum
-from typing import Optional, List, Union, Callable
+from typing import Optional, List, Callable
 
 from sqlalchemy.orm import Query
 
 from cg.store.models import Flowcell, FamilySample, Family
 
 
 def get_flow_cells_by_case(case: Family, flow_cells: Query, **kwargs) -> Query:
```

### Comparing `cg-27.1.9/cg/store/filters/status_invoice_filters.py` & `cg-27.2.0/cg/store/filters/status_invoice_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/filters/status_organism_filters.py` & `cg-27.2.0/cg/store/filters/status_organism_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/filters/status_panel_filters.py` & `cg-27.2.0/cg/store/filters/status_panel_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/filters/status_pool_filters.py` & `cg-27.2.0/cg/store/filters/status_pool_filters.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 from enum import Enum
 from typing import List, Optional, Callable
 from alchy import Query
-from cg.store.models import Pool
+from cg.store.models import Pool, Customer
 
 
 def filter_pools_by_customer_id(pools: Query, customer_ids: List[int], **kwargs) -> Query:
     """Return pools by customer id."""
     return pools.filter(Pool.customer_id.in_(customer_ids))
 
 
@@ -65,35 +65,42 @@
 
 
 def filter_pools_do_not_invoice(pools: Query, **kwargs) -> Query:
     """Return pools marked to skip invoicing."""
     return pools.filter(Pool.no_invoice.is_(True))
 
 
+def filter_pools_by_customer(pools: Query, customer: Customer, **kwargs) -> Query:
+    """Return pools by customer id."""
+    return pools.filter(Pool.customer == customer)
+
+
 def apply_pool_filter(
     filter_functions: List[Callable],
     pools: Query,
     invoice_id: Optional[int] = None,
     entry_id: Optional[int] = None,
     name: Optional[str] = None,
     customer_ids: Optional[List[int]] = None,
     name_enquiry: Optional[str] = None,
     order_enquiry: Optional[str] = None,
+    customer: Optional[Customer] = None,
 ) -> Query:
     """Apply filtering functions to the pool queries and return filtered results"""
 
     for filter_function in filter_functions:
         pools: Query = filter_function(
             pools=pools,
             invoice_id=invoice_id,
             entry_id=entry_id,
             name=name,
             customer_ids=customer_ids,
             name_enquiry=name_enquiry,
             order_enquiry=order_enquiry,
+            customer=customer,
         )
     return pools
 
 
 class PoolFilter(Enum):
     """Define Pool filter functions."""
 
@@ -106,7 +113,8 @@
     FILTER_BY_INVOICE_ID: Callable = filter_pools_by_invoice_id
     FILTER_WITHOUT_INVOICE_ID: Callable = filter_pools_without_invoice_id
     FILTER_DO_INVOICE: Callable = filter_pools_do_invoice
     FILTER_DO_NOT_INVOICE: Callable = filter_pools_do_not_invoice
     FILTER_BY_CUSTOMER_ID: Callable = filter_pools_by_customer_id
     FILTER_BY_NAME_ENQUIRY: Callable = filter_pools_by_name_enquiry
     FILTER_BY_ORDER_ENQUIRY: Callable = filter_pools_by_order_enquiry
+    FILTER_BY_CUSTOMER: Callable = filter_pools_by_customer
```

### Comparing `cg-27.1.9/cg/store/filters/status_sample_filters.py` & `cg-27.2.0/cg/store/filters/status_sample_filters.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 from typing import Optional, List, Callable
 from enum import Enum
 from sqlalchemy.orm import Query
+from sqlalchemy import and_, or_
 
 from cg.constants.constants import SampleType
-from cg.store.models import Sample
+from cg.store.models import Sample, Customer
 
 
 def filter_samples_by_internal_id(internal_id: str, samples: Query, **kwargs) -> Query:
     """Return sample by internal id."""
     return samples.filter_by(internal_id=internal_id)
 
 
@@ -83,17 +84,19 @@
 
 
 def filter_samples_do_not_invoice(samples: Query, **kwargs) -> Query:
     """Return samples marked to skip invoicing."""
     return samples.filter(Sample.no_invoice.is_(True))
 
 
-def filter_samples_by_customer_id(samples: Query, customer_id: str, **kwargs) -> Query:
+def filter_samples_by_entry_customer_ids(
+    samples: Query, customer_entry_ids: List[int], **kwargs
+) -> Query:
     """Return samples by customer id."""
-    return samples.filter(Sample.customer_id.in_(customer_id))
+    return samples.filter(Sample.customer_id.in_(customer_entry_ids))
 
 
 def filter_samples_by_customer_name(samples: Query, customer_name: str, **kwargs) -> Query:
     """Return samples by customer name."""
     return samples.filter(Sample.customer_name == customer_name)
 
 
@@ -128,39 +131,81 @@
 
 
 def filter_samples_is_not_tumour(samples: Query, **kwargs) -> Query:
     """Return samples that are not tumour."""
     return samples.filter(Sample.is_tumour.is_(False))
 
 
+def filter_samples_by_name_pattern(samples: Query, name_pattern: str, **kwargs) -> Query:
+    """Return samples matching the name pattern."""
+    return samples.filter(Sample.name.like(f"%{name_pattern}%"))
+
+
+def filter_samples_by_internal_id_pattern(
+    samples: Query, internal_id_pattern: str, **kwargs
+) -> Query:
+    """Return samples matching the internal id pattern."""
+    return samples.filter(Sample.internal_id.like(f"%{internal_id_pattern}%"))
+
+
+def filter_samples_by_internal_id_or_name_search(
+    samples: Query, search_pattern: str, **kwargs
+) -> Query:
+    """Return samples matching the internal id or name search."""
+    return samples.filter(
+        or_(
+            Sample.name.like(f"%{search_pattern}%"),
+            Sample.internal_id.like(f"%{search_pattern}%"),
+        )
+    )
+
+
+def filter_samples_by_customer(samples: Query, customer: Customer, **kwargs) -> Query:
+    """Return samples by customer."""
+    return samples.filter(Sample.customer == customer)
+
+
+def order_samples_by_created_at_desc(samples: Query, **kwargs) -> Query:
+    """Return samples ordered by created_at descending."""
+    return samples.order_by(Sample.created_at.desc())
+
+
 def apply_sample_filter(
     filter_functions: List[Callable],
     samples: Query,
     entry_id: Optional[int] = None,
     internal_id: Optional[str] = None,
     tissue_type: Optional[SampleType] = None,
     data_analysis: Optional[str] = None,
     invoice_id: Optional[int] = None,
-    customer_id: Optional[str] = None,
+    customer_entry_ids: Optional[List[int]] = None,
     subject_id: Optional[str] = None,
     name: Optional[str] = None,
+    customer: Optional[Customer] = None,
+    name_pattern: Optional[str] = None,
+    internal_id_pattern: Optional[str] = None,
+    search_pattern: Optional[str] = None,
 ) -> Query:
     """Apply filtering functions to the sample queries and return filtered results."""
 
-    for function in filter_functions:
-        samples: Query = function(
+    for filter_function in filter_functions:
+        samples: Query = filter_function(
             samples=samples,
             entry_id=entry_id,
             internal_id=internal_id,
             tissue_type=tissue_type,
             data_analysis=data_analysis,
             invoice_id=invoice_id,
-            customer_id=customer_id,
+            customer_entry_ids=customer_entry_ids,
             subject_id=subject_id,
             name=name,
+            customer=customer,
+            name_pattern=name_pattern,
+            internal_id_pattern=internal_id_pattern,
+            search_pattern=search_pattern,
         )
     return samples
 
 
 class SampleFilter(Enum):
     """Define Sample filter functions."""
 
@@ -176,16 +221,21 @@
     FILTER_IS_NOT_DOWN_SAMPLED: Callable = filter_samples_is_not_down_sampled
     FILTER_IS_DOWN_SAMPLED: Callable = filter_samples_is_down_sampled
     FILTER_IS_SEQUENCED: Callable = filter_samples_is_sequenced
     FILTER_IS_NOT_SEQUENCED: Callable = filter_samples_is_not_sequenced
     FILTER_DO_INVOICE: Callable = filter_samples_do_invoice
     FILTER_DO_NOT_INVOICE: Callable = filter_samples_do_not_invoice
     FILTER_BY_CUSTOMER_NAME: Callable = filter_samples_by_customer_name
-    FILTER_BY_CUSTOMER_ID: Callable = filter_samples_by_customer_id
+    FILTER_BY_CUSTOMER_ENTRY_IDS: Callable = filter_samples_by_entry_customer_ids
     FILTER_IS_RECEIVED: Callable = filter_samples_is_received
     FILTER_IS_NOT_RECEIVED: Callable = filter_samples_is_not_received
     FILTER_IS_PREPARED: Callable = filter_samples_is_prepared
     FILTER_IS_NOT_PREPARED: Callable = filter_samples_is_not_prepared
     FILTER_BY_SAMPLE_NAME: Callable = filter_samples_by_name
     FILTER_BY_SUBJECT_ID: Callable = filter_samples_by_subject_id
     FILTER_IS_TUMOUR: Callable = filter_samples_is_tumour
     FILTER_IS_NOT_TUMOUR: Callable = filter_samples_is_not_tumour
+    FILTER_BY_NAME_PATTERN: Callable = filter_samples_by_name_pattern
+    FILTER_BY_INTERNAL_ID_PATTERN: Callable = filter_samples_by_internal_id_pattern
+    FILTER_BY_CUSTOMER: Callable = filter_samples_by_customer
+    FILTER_BY_INTERNAL_ID_OR_NAME_SEARCH: Callable = filter_samples_by_internal_id_or_name_search
+    ORDER_BY_CREATED_AT_DESC: Callable = order_samples_by_created_at_desc
```

### Comparing `cg-27.1.9/cg/store/filters/status_user_filters.py` & `cg-27.2.0/cg/store/filters/status_user_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/store/models.py` & `cg-27.2.0/cg/store/models.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/utils/checksum/checksum.py` & `cg-27.2.0/cg/utils/checksum/checksum.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/utils/click/EnumChoice.py` & `cg-27.2.0/cg/utils/click/EnumChoice.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/utils/commands.py` & `cg-27.2.0/cg/utils/commands.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 """
 Code to handle communications to the shell from CG.
 """
 
 import copy
 import logging
 import subprocess
-from pathlib import Path
 from subprocess import CalledProcessError
 from typing import Dict, List
 
 from cg.constants.process import RETURN_SUCCESS
 
 LOG = logging.getLogger(__name__)
 
@@ -105,14 +104,23 @@
         if res.returncode != RETURN_SUCCESS:
             LOG.critical("Call %s exit with a non zero exit code", command)
             LOG.critical(self.stderr)
             raise CalledProcessError(res.returncode, command)
 
         return res.returncode
 
+    def get_command(self, parameters: list = None) -> str:
+        """Returns a command string given a list of parameters."""
+
+        command: List[str] = copy.deepcopy(self.base_call)
+        if parameters:
+            command.extend(parameters)
+
+        return " ".join(command)
+
     @property
     def stdout(self):
         """Fetch stdout"""
         return self._stdout
 
     @stdout.setter
     def stdout(self, text):
```

### Comparing `cg-27.1.9/cg/utils/date.py` & `cg-27.2.0/cg/utils/date.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/utils/dict.py` & `cg-27.2.0/cg/utils/dict.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/utils/email.py` & `cg-27.2.0/cg/utils/email.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/utils/flask/enum.py` & `cg-27.2.0/cg/utils/flask/enum.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg/utils/utils.py` & `cg-27.2.0/cg/utils/utils.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/cg.egg-info/PKG-INFO` & `cg-27.2.0/cg.egg-info/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: cg
-Version: 27.1.9
+Version: 27.2.0
 Summary: Clinical Genomics command center
 Home-page: https://github.com/Clinical-Genomics/cg
 Author: Clinical Genomics
 Author-email: support@clinicalgenomics.se
 License: UNKNOWN
 Description: 
         # cg
```

### Comparing `cg-27.1.9/cg.egg-info/SOURCES.txt` & `cg-27.2.0/cg.egg-info/SOURCES.txt`

 * *Files 2% similar despite different names*

```diff
@@ -228,14 +228,16 @@
 cg/io/json.py
 cg/io/yaml.py
 cg/meta/__init__.py
 cg/meta/deliver.py
 cg/meta/deliver_ticket.py
 cg/meta/invoice.py
 cg/meta/meta.py
+cg/meta/archive/__init__.py
+cg/meta/archive/ddn_dataflow.py
 cg/meta/backup/__init__.py
 cg/meta/backup/backup.py
 cg/meta/backup/pdc.py
 cg/meta/clean/__init__.py
 cg/meta/clean/api.py
 cg/meta/clean/demultiplexed_flow_cells.py
 cg/meta/clean/flow_cell_run_directories.py
@@ -419,14 +421,15 @@
 cg/store/api/find_business_data.py
 cg/store/api/import_func.py
 cg/store/api/models.py
 cg/store/api/status.py
 cg/store/filters/__init__.py
 cg/store/filters/status_analysis_filters.py
 cg/store/filters/status_application_filters.py
+cg/store/filters/status_application_version_filters.py
 cg/store/filters/status_bed_filters.py
 cg/store/filters/status_bed_version_filters.py
 cg/store/filters/status_case_filters.py
 cg/store/filters/status_case_sample_filters.py
 cg/store/filters/status_collaboration_filters.py
 cg/store/filters/status_customer_filters.py
 cg/store/filters/status_flow_cell_filters.py
@@ -436,14 +439,15 @@
 cg/store/filters/status_pool_filters.py
 cg/store/filters/status_sample_filters.py
 cg/store/filters/status_user_filters.py
 cg/utils/__init__.py
 cg/utils/commands.py
 cg/utils/date.py
 cg/utils/dict.py
+cg/utils/dispatcher.py
 cg/utils/email.py
 cg/utils/enums.py
 cg/utils/files.py
 cg/utils/time.py
 cg/utils/utils.py
 cg/utils/checksum/__init__.py
 cg/utils/checksum/checksum.py
@@ -790,14 +794,16 @@
 tests/io/conftest.py
 tests/io/test_io_controller.py
 tests/io/test_io_json.py
 tests/io/test_io_yaml.py
 tests/meta/__init__.py
 tests/meta/conftest.py
 tests/meta/test_invoice.py
+tests/meta/archive/conftest.py
+tests/meta/archive/test_archiving.py
 tests/meta/backup/conftest.py
 tests/meta/backup/test_meta_backup.py
 tests/meta/backup/test_meta_pdc.py
 tests/meta/clean/conftest.py
 tests/meta/clean/test_clean_demultiplexed_runs.py
 tests/meta/clean/test_clean_flow_cell_run_directories.py
 tests/meta/compress/conftest.py
@@ -845,15 +851,14 @@
 tests/meta/upload/conftest.py
 tests/meta/upload/test_meta_upload_coverage.py
 tests/meta/upload/test_upload_api.py
 tests/meta/upload/test_upload_genotypes_api.py
 tests/meta/upload/balsamic/test_balsamic.py
 tests/meta/upload/gisaid/__init__.py
 tests/meta/upload/gisaid/conftest.py
-tests/meta/upload/gisaid/test_gisaid_api.py
 tests/meta/upload/gisaid/fixtures/four_samples.csv
 tests/meta/upload/gisaid/fixtures/invalid_housekeeper.fasta
 tests/meta/upload/gisaid/fixtures/valid_gisaid.fasta
 tests/meta/upload/gisaid/fixtures/valid_housekeeper.fasta
 tests/meta/upload/mutacc/__init__.py
 tests/meta/upload/mutacc/conftest.py
 tests/meta/upload/mutacc/test_meta_upload_mutacc.py
@@ -914,45 +919,55 @@
 tests/models/rnafusion/test_rnafusion_sample.py
 tests/server/conftest.py
 tests/server/test_server_app.py
 tests/server/test_server_auto.py
 tests/store/__init__.py
 tests/store/conftest.py
 tests/store/test_delivery.py
-tests/store/test_organism_filters.py
-tests/store/test_panel_filters.py
-tests/store/test_status_customer_filters.py
 tests/store/test_store_models.py
-tests/store/test_user_filters.py
 tests/store/api/__init__.py
 tests/store/api/conftest.py
 tests/store/api/test_base.py
-tests/store/api/test_find_basic_data.py
-tests/store/api/test_find_business_data.py
-tests/store/api/test_store_api_status.py
-tests/store/api/test_store_api_status_analysis.py
-tests/store/api/test_store_api_status_cases.py
 tests/store/api/test_store_import_func.py
+tests/store/api/add/test_store_add_application_version.py
 tests/store/api/add/test_store_add_base.py
 tests/store/api/add/test_store_add_customer.py
 tests/store/api/add/test_store_add_flow_celll.py
 tests/store/api/delete/test_store_api_delete.py
+tests/store/api/find/test_find_basic_data.py
+tests/store/api/find/test_find_basic_data_application_version.py
+tests/store/api/find/test_find_business_data.py
+tests/store/api/find/test_find_business_data_analysis.py
+tests/store/api/find/test_find_business_data_case.py
+tests/store/api/find/test_find_business_data_sample.py
 tests/store/api/status/test_analyses_to_clean.py
 tests/store/api/status/test_analyses_to_delivery_report.py
+tests/store/api/status/test_store_api_status.py
+tests/store/api/status/test_store_api_status_analysis.py
+tests/store/api/status/test_store_api_status_cases.py
+tests/store/api/status/test_store_api_status_customer.py
+tests/store/api/status/test_store_api_status_pool.py
+tests/store/api/status/test_store_api_status_sample.py
 tests/store/filters/test_status_analyses_filters.py
 tests/store/filters/test_status_application_filters.py
+tests/store/filters/test_status_application_version_filters.py
 tests/store/filters/test_status_bed_filters.py
 tests/store/filters/test_status_bed_version_filters.py
 tests/store/filters/test_status_cases_filters.py
 tests/store/filters/test_status_collaboration_filters.py
+tests/store/filters/test_status_customer_filters.py
 tests/store/filters/test_status_flow_cell_filters.py
 tests/store/filters/test_status_invoice_filters.py
+tests/store/filters/test_status_organism_filters.py
+tests/store/filters/test_status_panel_filters.py
 tests/store/filters/test_status_pool_filters.py
 tests/store/filters/test_status_samples_filters.py
+tests/store/filters/test_status_user_filters.py
 tests/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/copycomplete.txt
 tests/tests/fixtures/data/fastq.fastq.gz
 tests/utils/__init__.py
 tests/utils/conftest.py
 tests/utils/test_commands.py
 tests/utils/test_date.py
 tests/utils/test_dict.py
+tests/utils/test_dispatcher.py
 tests/utils/test_utils.py
```

### Comparing `cg-27.1.9/requirements.txt` & `cg-27.2.0/requirements.txt`

 * *Files 1% similar despite different names*

```diff
@@ -42,8 +42,8 @@
 setuptools>=39.2.0      # due to WeasyPrint 45, tinycss2 1.0.1 and cairocffi file-.cairocffi-VERSION
 tabulate
 typing_extensions
 wtforms<3.0.0          # wtforms.compat missing in 3.0.0
 
 # apps
 genologics
-housekeeper==3.*
+housekeeper==4.*
```

### Comparing `cg-27.1.9/setup.py` & `cg-27.2.0/setup.py`

 * *Files 2% similar despite different names*

```diff
@@ -38,15 +38,15 @@
     with io.open(os.path.join(HERE, "README.md"), encoding="utf-8") as f:
         LONG_DESCRIPTION = "\n" + f.read()
 except FileNotFoundError:
     LONG_DESCRIPTION = DESCRIPTION
 
 setup(
     name=NAME,
-    version="27.1.9",
+    version="27.2.0",
     description=DESCRIPTION,
     long_description=LONG_DESCRIPTION,
     long_description_content_type="text/markdown",
     author=AUTHOR,
     author_email=EMAIL,
     url=URL,
     include_package_data=True,
```

### Comparing `cg-27.1.9/tests/apps/cgstats/conftest.py` & `cg-27.2.0/tests/apps/cgstats/conftest.py`

 * *Files 2% similar despite different names*

```diff
@@ -94,24 +94,24 @@
 
 @pytest.fixture(name="nipt_stats_api")
 def fixture_nipt_stats_api(
     stats_api: StatsAPI,
     flow_cell_full_name: str,
     novaseq_dragen_sample_sheet_path: Path,
     sample_id: str,
-    ticket: str,
+    ticket_id: str,
 ):
     nipt_stats_api: StatsAPI = stats_api
     mock_demux_sample = MockDemuxSample(pass_filter_clusters=600000000, pass_filter_Q30=0.90)
     mock_demux_results = MockDemuxResults(
         flow_cell_full_name=flow_cell_full_name, sample_sheet_path=novaseq_dragen_sample_sheet_path
     )
 
     project_obj: stats_models.Project = create.create_project(
-        manager=nipt_stats_api, project_name=ticket
+        manager=nipt_stats_api, project_name=ticket_id
     )
     support_parameters_obj: stats_models.Supportparams = create.create_support_parameters(
         manager=nipt_stats_api, demux_results=mock_demux_results
     )
     flowcell_obj: stats_models.FlowCell = create.create_flowcell(
         manager=nipt_stats_api, demux_results=mock_demux_results
     )
```

### Comparing `cg-27.1.9/tests/apps/cgstats/crud/test_create_novaseq.py` & `cg-27.2.0/tests/apps/cgstats/crud/test_create_novaseq.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/cgstats/crud/test_delete.py` & `cg-27.2.0/tests/apps/cgstats/crud/test_delete.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/cgstats/parsers/test_conversion_stats.py` & `cg-27.2.0/tests/apps/cgstats/parsers/test_conversion_stats.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/cgstats/parsers/test_demux_stats.py` & `cg-27.2.0/tests/apps/cgstats/parsers/test_demux_stats.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/cgstats/parsers/test_run_info.py` & `cg-27.2.0/tests/apps/cgstats/parsers/test_run_info.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/cgstats/test_cgstats_create.py` & `cg-27.2.0/tests/apps/cgstats/test_cgstats_create.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/cgstats/test_stats.py` & `cg-27.2.0/tests/apps/cgstats/test_stats.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/conftest.py` & `cg-27.2.0/tests/apps/conftest.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 """Fixtures for testing apps"""
 
-from pathlib import Path
 
 import pytest
 import requests
 
 from cg.utils.commands import Process
```

### Comparing `cg-27.1.9/tests/apps/coverage/test_coverage.py` & `cg-27.2.0/tests/apps/coverage/test_coverage.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/crunchy/conftest.py` & `cg-27.2.0/tests/apps/crunchy/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/crunchy/test_compress_fastq.py` & `cg-27.2.0/tests/apps/crunchy/test_compress_fastq.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/crunchy/test_config.py` & `cg-27.2.0/tests/apps/crunchy/test_config.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/crunchy/test_crunchy.py` & `cg-27.2.0/tests/apps/crunchy/test_crunchy.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/crunchy/test_spring_decompression.py` & `cg-27.2.0/tests/apps/crunchy/test_spring_decompression.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/demultiplex/conftest.py` & `cg-27.2.0/tests/apps/demultiplex/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/demultiplex/test_convert_to_sample_sheet.py` & `cg-27.2.0/tests/apps/demultiplex/test_convert_to_sample_sheet.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/demultiplex/test_demultiplex_api.py` & `cg-27.2.0/tests/apps/demultiplex/test_demultiplex_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/demultiplex/test_parse_run_parameters.py` & `cg-27.2.0/tests/apps/demultiplex/test_parse_run_parameters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/demultiplex/test_sample_sheet.py` & `cg-27.2.0/tests/apps/demultiplex/test_sample_sheet.py`

 * *Files 19% similar despite different names*

```diff
@@ -38,18 +38,7 @@
         lane=1,
         name=index_obj.name,
         bcl_converter="bcl2fastq",
     )
 
     # THEN assert the sample id was correct
     assert dummy_sample_obj.sample_id == dummy_sample.dummy_sample_name(index_obj.name)
-
-
-def test_get_project_name():
-    # GIVEN a raw string
-    raw = "project name"
-
-    # WheN parsing the project name
-    project_name = SampleSheetCreator.get_project_name(raw)
-
-    # THEN assert the correct project name was returned
-    assert project_name == "project"
```

### Comparing `cg-27.1.9/tests/apps/gens/test_gens_api.py` & `cg-27.2.0/tests/apps/gens/test_gens_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/gt/conftest.py` & `cg-27.2.0/tests/apps/gt/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/gt/test_gt_api.py` & `cg-27.2.0/tests/apps/gt/test_gt_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/hk/conftest.py` & `cg-27.2.0/tests/apps/hk/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/hk/test__getattr__.py` & `cg-27.2.0/tests/apps/hk/test__getattr__.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,13 +8,13 @@
 def test_calling_method_on_private_store_give_warning(housekeeper_api: MockHousekeeperAPI, caplog):
     """Test that we get a log warning for unwrapped methods."""
 
     # GIVEN an hk api and a method that is not wrapped
     caplog.set_level(logging.WARNING)
 
     # WHEN we call add_file
-    housekeeper_api.files_before()
+    housekeeper_api.get_files_before()
 
     # THEN the log should contain a warning that we have called something non-wrapped
     with caplog.at_level(logging.WARNING):
         assert "files_before" in caplog.text
         assert "HousekeeperAPI" in caplog.text
```

### Comparing `cg-27.1.9/tests/apps/hk/test_add_file.py` & `cg-27.2.0/tests/apps/hk/test_add_file.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/hk/test_bundles.py` & `cg-27.2.0/tests/apps/hk/test_bundles.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/hk/test_core.py` & `cg-27.2.0/tests/apps/hk/test_core.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/hk/test_file.py` & `cg-27.2.0/tests/apps/hk/test_file.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,20 +1,21 @@
 """Test how the api handles files."""
 from datetime import datetime
 from pathlib import Path
-from typing import List
+from typing import List, Dict, Any
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.constants import SequencingFileTag
 from tests.meta.compress.conftest import MockCompressionData
 from tests.mocks.hk_mock import MockHousekeeperAPI
 
-from housekeeper.store.models import Version, File, Bundle
+from housekeeper.store.models import Version, File
 
 from tests.small_helpers import SmallHelpers
+from tests.store_helpers import StoreHelpers
 
 
 def test_new_file(bed_file: Path, housekeeper_api: MockHousekeeperAPI, small_helpers: SmallHelpers):
     """Test to create a new file with the Housekeeper API"""
     # GIVEN a housekeeper api without files and the path to an existing file
     assert small_helpers.length_of_iterable(housekeeper_api.files()) == 0
     assert bed_file.exists() is True
@@ -113,14 +114,77 @@
     # WHEN fetching the file with get_file
     hk_file = populated_housekeeper_api.get_file(hk_file.id)
 
     # THEN assert a file was returned
     assert hk_file is not None
 
 
+def test_get_files_from_version(
+    helpers: StoreHelpers,
+    real_housekeeper_api: HousekeeperAPI,
+    hk_bundle_data: Dict[str, Any],
+    hk_tag: str,
+    observations_clinical_snv_file_path: Path,
+    observations_clinical_sv_file_path: Path,
+):
+    """Test get the files from the Housekeeper database given the version object."""
+
+    # GIVEN a Housekeeper API with some files
+    version: Version = helpers.ensure_hk_version(real_housekeeper_api, hk_bundle_data)
+    first_file: File = real_housekeeper_api.add_file(
+        path=observations_clinical_snv_file_path, version_obj=version, tags=hk_tag
+    )
+    second_file: File = real_housekeeper_api.add_file(
+        path=observations_clinical_sv_file_path, version_obj=version, tags=hk_tag
+    )
+
+    # GIVEN that the files exist in the version object
+    assert first_file in version.files
+    assert second_file in version.files
+
+    # WHEN extracting the files from version
+    files: List[File] = real_housekeeper_api.get_files_from_version(version=version, tags={hk_tag})
+
+    # THEN the added files should be retrieved
+    assert first_file in files
+    assert second_file in files
+
+
+def test_get_latest_file_from_version(
+    helpers: StoreHelpers,
+    real_housekeeper_api: HousekeeperAPI,
+    hk_bundle_data: Dict[str, Any],
+    hk_tag: str,
+    observations_clinical_snv_file_path: Path,
+    observations_clinical_sv_file_path: Path,
+):
+    """Test to get the latest file from the Housekeeper database given the version object."""
+
+    # GIVEN a Housekeeper API with some files
+    version: Version = helpers.ensure_hk_version(real_housekeeper_api, hk_bundle_data)
+    first_file: File = real_housekeeper_api.add_file(
+        path=observations_clinical_snv_file_path, version_obj=version, tags=hk_tag
+    )
+    second_file: File = real_housekeeper_api.add_file(
+        path=observations_clinical_sv_file_path, version_obj=version, tags=hk_tag
+    )
+
+    # GIVEN that the files exist in the version object
+    assert first_file in version.files
+    assert second_file in version.files
+
+    # WHEN extracting the latest file from version
+    latest_file: File = real_housekeeper_api.get_latest_file_from_version(
+        version=version, tags={hk_tag}
+    )
+
+    # THEN the file with the higher ID should be returned
+    assert latest_file == second_file
+
+
 def test_get_file_from_latest_version(case_id: str, populated_housekeeper_api: MockHousekeeperAPI):
     """Test to get a file from the database from the latest version."""
     # GIVEN a housekeeper api with a file
     hk_file: File = populated_housekeeper_api.files().first()
 
     # GIVEN a tag of a file that exists in HK
     assert hk_file.tags
@@ -439,40 +503,38 @@
     case_id: str,
     compression_object: MockCompressionData,
     populated_housekeeper_api: MockHousekeeperAPI,
     madeline_output: Path,
     sample_id: str,
     tags: List[str],
 ):
-    """Test checking if all FASTQ or SPRING files are present in bundles when all bundles have files present and some both FASTQ and SPRING."""
-    # GIVEN a populated housekeeper api with some files
+    """
+    Test checking if all FASTQ or SPRING files are present in bundles when all bundles have files present and some
+    both FASTQ and SPRING.
+    """
+    # GIVEN a populated Housekeeper API with some files
 
-    # GIVEN a FASTQ file tag with a file included the bundle
+    # GIVEN a FASTQ file tag with a file included in the bundle
     populated_housekeeper_api.add_and_include_file_to_latest_version(
         file=madeline_output, bundle_name=case_id, tags=[SequencingFileTag.FASTQ]
     )
 
     # GIVEN an empty bundle
     populated_housekeeper_api.create_new_bundle_and_version(name=sample_id)
 
     # GIVEN an existing SPRING metadata file
     compression_object.spring_metadata_path.touch()
 
-    # GIVEN a SPRING file tag with a file included the bundle
+    # GIVEN a SPRING file tag with a file included in the bundle
     populated_housekeeper_api.add_and_include_file_to_latest_version(
         file=compression_object.spring_metadata_path,
         bundle_name=sample_id,
         tags=[SequencingFileTag.SPRING_METADATA],
     )
 
-    # GIVEN a FASTQ file tag with a file included the bundle
-    populated_housekeeper_api.add_and_include_file_to_latest_version(
-        file=madeline_output, bundle_name=case_id, tags=[SequencingFileTag.FASTQ]
-    )
-
     # WHEN fetching all files
     was_true = populated_housekeeper_api.is_fastq_or_spring_in_all_bundles(
         bundle_names=[case_id, sample_id]
     )
 
     # THEN assert all file were present in all bundles
     assert was_true
```

### Comparing `cg-27.1.9/tests/apps/hk/test_version.py` & `cg-27.2.0/tests/apps/hk/test_version.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/lims/conftest.py` & `cg-27.2.0/tests/apps/lims/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/loqus/conftest.py` & `cg-27.2.0/tests/apps/loqus/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/loqus/test_loqusdb_api.py` & `cg-27.2.0/tests/apps/loqus/test_loqusdb_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/madeline/conftest.py` & `cg-27.2.0/tests/apps/madeline/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/madeline/test_madeline.py` & `cg-27.2.0/tests/apps/madeline/test_madeline.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/mip/conftest.py` & `cg-27.2.0/tests/apps/mip/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/mip/test_config_mip.py` & `cg-27.2.0/tests/apps/mip/test_config_mip.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/mutacc_auto/conftest.py` & `cg-27.2.0/tests/apps/mutacc_auto/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/mutacc_auto/test_mutacc_auto.py` & `cg-27.2.0/tests/apps/mutacc_auto/test_mutacc_auto.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/orderform/conftest.py` & `cg-27.2.0/tests/apps/orderform/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/orderform/test_excel_orderform_parser.py` & `cg-27.2.0/tests/apps/orderform/test_excel_orderform_parser.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/orderform/test_excel_sample_schema.py` & `cg-27.2.0/tests/apps/orderform/test_excel_sample_schema.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-import datetime
-
 import pytest
 from pydantic import ValidationError
 
 from cg.constants import DataDelivery
 from cg.models.orders.excel_sample import ExcelSample
```

### Comparing `cg-27.1.9/tests/apps/orderform/test_json_orderform_parser.py` & `cg-27.2.0/tests/apps/orderform/test_json_orderform_parser.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/orderform/test_orderform_parser.py` & `cg-27.2.0/tests/apps/orderform/test_orderform_parser.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/scout/conftest.py` & `cg-27.2.0/tests/apps/scout/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/scout/test_get_causative_variants.py` & `cg-27.2.0/tests/apps/scout/test_get_causative_variants.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/scout/test_get_scout_cases.py` & `cg-27.2.0/tests/apps/scout/test_get_scout_cases.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/scout/test_scout_load_config.py` & `cg-27.2.0/tests/apps/scout/test_scout_load_config.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 """Tests for the models in scout load config"""
-from pathlib import Path
 from typing import Any
 
 import pytest
 from pydantic import ValidationError
 
 from cg.models.scout import scout_load_config
 from cg.models.scout.scout_load_config import MipLoadConfig, ScoutMipIndividual
```

### Comparing `cg-27.1.9/tests/apps/scout/test_scout_models.py` & `cg-27.2.0/tests/apps/scout/test_scout_models.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/slurm/conftest.py` & `cg-27.2.0/tests/apps/slurm/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/slurm/test_slurm_api.py` & `cg-27.2.0/tests/apps/slurm/test_slurm_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/test_apps_environ.py` & `cg-27.2.0/tests/apps/test_apps_environ.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/test_osticket.py` & `cg-27.2.0/tests/apps/test_osticket.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/vogue/conftest.py` & `cg-27.2.0/tests/apps/vogue/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/apps/vogue/test_vogue_api.py` & `cg-27.2.0/tests/apps/vogue/test_vogue_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/add/test_cli_add.py` & `cg-27.2.0/tests/cli/add/test_cli_add.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/add/test_cli_add_customer.py` & `cg-27.2.0/tests/cli/add/test_cli_add_customer.py`

 * *Files 6% similar despite different names*

```diff
@@ -67,16 +67,16 @@
             collaboration_id,
             NEW_TEST_CUST_INTERNAL_ID,
             NEW_TEST_CUST_NAME,
         ],
         obj=base_context,
     )
 
-    new_customer: Customer = status_db.get_customer_by_customer_id(
-        customer_id=NEW_TEST_CUST_INTERNAL_ID
+    new_customer: Customer = status_db.get_customer_by_internal_id(
+        customer_internal_id=NEW_TEST_CUST_INTERNAL_ID
     )
 
     # THEN exit successfully
     assert result.exit_code == EXIT_SUCCESS
 
     # THEN it should be stored in the database
     assert status_db._get_query(table=Customer).count() == nr_customers + 1
```

### Comparing `cg-27.1.9/tests/cli/add/test_cli_add_family.py` & `cg-27.2.0/tests/cli/add/test_cli_add_family.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 from tests.store_helpers import StoreHelpers
 
 CLI_OPTION_ANALYSIS = Pipeline.BALSAMIC_UMI
 CLI_OPTION_DELIVERY = DataDelivery.FASTQ_QC
 
 
 def test_add_case_required(
-    cli_runner: CliRunner, base_context: CGConfig, helpers: StoreHelpers, ticket: str
+    cli_runner: CliRunner, base_context: CGConfig, helpers: StoreHelpers, ticket_id: str
 ):
     """Test to add a case using only the required arguments"""
     # GIVEN a database with a customer and an panel
     disk_store: Store = base_context.status_db
 
     customer: Customer = helpers.ensure_customer(store=disk_store)
     customer_id = customer.internal_id
@@ -33,30 +33,30 @@
             "--panel",
             panel_id,
             "--analysis",
             CLI_OPTION_ANALYSIS,
             "--data-delivery",
             CLI_OPTION_DELIVERY,
             "--ticket",
-            ticket,
+            ticket_id,
             customer_id,
             name,
         ],
         obj=base_context,
     )
 
     # THEN it should be added
     assert result.exit_code == 0
     assert disk_store.Family.query.count() == 1
     assert disk_store.Family.query.first().name == name
     assert disk_store.Family.query.first().panels == [panel_id]
 
 
 def test_add_case_bad_pipeline(
-    cli_runner: CliRunner, base_context: CGConfig, helpers: StoreHelpers, ticket: str
+    cli_runner: CliRunner, base_context: CGConfig, helpers: StoreHelpers, ticket_id: str
 ):
     """Test to add a case using only the required arguments"""
     # GIVEN a database with a customer and an panel
 
     # WHEN adding a case
     disk_store: Store = base_context.status_db
 
@@ -74,15 +74,15 @@
             "--panel",
             panel_id,
             "--analysis",
             non_existing_analysis,
             "--data-delivery",
             CLI_OPTION_DELIVERY,
             "--ticket",
-            ticket,
+            ticket_id,
             customer_id,
             name,
         ],
     )
 
     # THEN it should not be added
     assert result.exit_code != 0
@@ -122,15 +122,15 @@
     )
 
     # THEN it should not be added
     assert result.exit_code != 0
     assert disk_store.Family.query.count() == 0
 
 
-def test_add_case_bad_customer(cli_runner: CliRunner, base_context: CGConfig, ticket: str):
+def test_add_case_bad_customer(cli_runner: CliRunner, base_context: CGConfig, ticket_id: str):
     """Test to add a case using a non-existing customer"""
     # GIVEN an empty database
     disk_store: Store = base_context.status_db
     # WHEN adding a case
     panel_id = "dummy_panel"
     customer_id = "dummy_customer"
     name = "dummy_name"
@@ -141,28 +141,28 @@
             "--panel",
             panel_id,
             "--analysis",
             CLI_OPTION_ANALYSIS,
             "--data-delivery",
             CLI_OPTION_DELIVERY,
             "--ticket",
-            ticket,
+            ticket_id,
             customer_id,
             name,
         ],
         obj=base_context,
     )
 
     # THEN it should complain about missing customer instead of adding a case
     assert result.exit_code == 1
     assert disk_store.Family.query.count() == 0
 
 
 def test_add_case_bad_panel(
-    cli_runner: CliRunner, base_context: CGConfig, helpers: StoreHelpers, ticket: str
+    cli_runner: CliRunner, base_context: CGConfig, helpers: StoreHelpers, ticket_id: str
 ):
     """Test to add a case using a non-existing panel"""
     # GIVEN a database with a customer
     disk_store: Store = base_context.status_db
     # WHEN adding a case
     customer: Customer = helpers.ensure_customer(store=disk_store)
     customer_id = customer.internal_id
@@ -175,28 +175,28 @@
             "--panel",
             panel_id,
             "--analysis",
             CLI_OPTION_ANALYSIS,
             "--data-delivery",
             CLI_OPTION_DELIVERY,
             "--ticket",
-            ticket,
+            ticket_id,
             customer_id,
             name,
         ],
         obj=base_context,
     )
 
     # THEN it should complain about missing panel instead of adding a case
     assert result.exit_code == 1
     assert disk_store.Family.query.count() == 0
 
 
 def test_add_case_priority(
-    cli_runner: CliRunner, base_context: CGConfig, helpers: StoreHelpers, ticket: str
+    cli_runner: CliRunner, base_context: CGConfig, helpers: StoreHelpers, ticket_id: str
 ):
     """Test that the added case get the priority we send in"""
     # GIVEN a database with a customer and an panel
     disk_store: Store = base_context.status_db
     # WHEN adding a case
     customer: Customer = helpers.ensure_customer(store=disk_store)
     customer_id = customer.internal_id
@@ -214,15 +214,15 @@
             "--priority",
             priority,
             "--analysis",
             CLI_OPTION_ANALYSIS,
             "--data-delivery",
             CLI_OPTION_DELIVERY,
             "--ticket",
-            ticket,
+            ticket_id,
             customer_id,
             name,
         ],
         obj=base_context,
     )
 
     # THEN it should be added
```

### Comparing `cg-27.1.9/tests/cli/add/test_cli_add_relationship.py` & `cg-27.2.0/tests/cli/add/test_cli_add_relationship.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/add/test_cli_add_sample.py` & `cg-27.2.0/tests/cli/add/test_cli_add_sample.py`

 * *Files 0% similar despite different names*

```diff
@@ -67,15 +67,14 @@
     assert disk_store.Sample.query.count() == 0
 
 
 def test_add_sample_required(cli_runner: CliRunner, base_context: CGConfig, helpers: StoreHelpers):
     """Test adding a sample."""
     # GIVEN a database with a customer and an application
     disk_store: Store = base_context.status_db
-    sex = "male"
     application_tag = "dummy_tag"
     helpers.ensure_application(store=disk_store, tag=application_tag)
     helpers.ensure_application_version(store=disk_store, application_tag=application_tag)
     customer: Customer = helpers.ensure_customer(store=disk_store)
     name = "sample_name"
 
     # WHEN adding a sample
```

### Comparing `cg-27.1.9/tests/cli/backup/conftest.py` & `cg-27.2.0/tests/cli/backup/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/backup/test_backup_command.py` & `cg-27.2.0/tests/cli/backup/test_backup_command.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/clean/conftest.py` & `cg-27.2.0/tests/cli/clean/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/clean/test_balsamic_clean.py` & `cg-27.2.0/tests/cli/clean/test_balsamic_clean.py`

 * *Files 5% similar despite different names*

```diff
@@ -43,15 +43,17 @@
     caplog,
     mocker,
 ):
     """Test command with dry run options."""
     # GIVEN a case on disk that could be deleted
     analysis_api = clean_context.meta_apis["analysis_api"]
 
-    analysis_to_clean = analysis_api.status_db.family(balsamic_case_clean).analyses[0]
+    analysis_to_clean = analysis_api.status_db.get_case_by_internal_id(
+        balsamic_case_clean
+    ).analyses[0]
     case_path = analysis_api.get_case_path(balsamic_case_clean)
     Path(case_path).mkdir(exist_ok=True, parents=True)
 
     mocker.patch.object(TrailblazerAPI, "is_latest_analysis_ongoing")
     TrailblazerAPI.is_latest_analysis_ongoing.return_value = False
 
     # WHEN running with yes and remove stuff from before today
@@ -81,15 +83,15 @@
         base_store,
         pipeline=Pipeline.BALSAMIC,
         started_at=timestamp_yesterday,
         uploaded_at=timestamp_yesterday,
         cleaned_at=None,
     )
 
-    analysis_to_clean = base_store.family(balsamic_case_clean).analyses[0]
+    analysis_to_clean = base_store.get_case_by_internal_id(balsamic_case_clean).analyses[0]
     case_path = clean_context.meta_apis["analysis_api"].get_case_path(balsamic_case_clean)
     Path(case_path).mkdir(exist_ok=True, parents=True)
 
     mocker.patch.object(TrailblazerAPI, "is_latest_analysis_ongoing")
     TrailblazerAPI.is_latest_analysis_ongoing.return_value = False
 
     # WHEN dry running with dry run specified
@@ -114,28 +116,28 @@
     TrailblazerAPI.is_latest_analysis_ongoing.return_value = False
 
     # WHEN dry running with dry run specified
     result = cli_runner.invoke(clean_run_dir, [balsamic_case_clean, "-y"], obj=clean_context)
 
     # THEN command should say it would have deleted
     assert result.exit_code == EXIT_SUCCESS
-    assert base_store.family("balsamic_case_clean").analyses[0].cleaned_at
+    assert base_store.get_case_by_internal_id("balsamic_case_clean").analyses[0].cleaned_at
     assert not Path(case_path).exists()
 
 
 def test_cleaned_at_invalid(
     balsamic_case_not_clean: str, cli_runner: CliRunner, clean_context: CGConfig, caplog
 ):
     """Test command with dry run options"""
     # GIVEN a case on disk that could be deleted
     base_store = clean_context.status_db
     case_path = clean_context.meta_apis["analysis_api"].get_case_path(balsamic_case_not_clean)
     Path(case_path).mkdir(exist_ok=True, parents=True)
-    assert not base_store.family(balsamic_case_not_clean).analyses[0].cleaned_at
+    assert not base_store.get_case_by_internal_id(balsamic_case_not_clean).analyses[0].cleaned_at
     # WHEN dry running with dry run specified
 
     result = cli_runner.invoke(past_run_dirs, ["2020-12-01", "-d", "-y"], obj=clean_context)
 
     # THEN case directory should not have been cleaned
     assert result.exit_code == EXIT_SUCCESS
-    assert not base_store.family(balsamic_case_not_clean).analyses[0].cleaned_at
+    assert not base_store.get_case_by_internal_id(balsamic_case_not_clean).analyses[0].cleaned_at
     assert Path(case_path).exists()
```

### Comparing `cg-27.1.9/tests/cli/clean/test_clean_hk_bundle_files.py` & `cg-27.2.0/tests/cli/clean/test_clean_hk_bundle_files.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/clean/test_hk_bundle_files.py` & `cg-27.2.0/tests/cli/clean/test_hk_bundle_files.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,21 @@
 import logging
 from datetime import datetime
-from pathlib import Path
 
 from cg.cli.clean import hk_bundle_files
 from cg.models.cg_config import CGConfig
 from click.testing import CliRunner
 from tests.store_helpers import StoreHelpers
 
 
 def test_clean_hk_bundle_files_no_files(cli_runner: CliRunner, cg_context: CGConfig, caplog):
     # GIVEN a housekeeper api and a bundle without files
     bundle_name = "non_existing"
     assert not cg_context.housekeeper_api.bundle(bundle_name)
-
+    case = cg_context.status_db.get_case_by_internal_id(bundle_name)
     # WHEN running the clean hk alignment files command
     caplog.set_level(logging.INFO)
     result = cli_runner.invoke(
         hk_bundle_files, ["-c", bundle_name, "--tags", "tag"], obj=cg_context
     )
 
     # THEN assert it exits with success
```

### Comparing `cg-27.1.9/tests/cli/clean/test_hk_case_bundle_files.py` & `cg-27.2.0/tests/cli/clean/test_hk_case_bundle_files.py`

 * *Files 4% similar despite different names*

```diff
@@ -38,15 +38,15 @@
 
 
 def test_clean_hk_case_files_too_old(cli_runner: CliRunner, clean_context: CGConfig, caplog):
     # GIVEN no analysis in database
     days_ago = 365 * 100
     date_one_year_ago = get_date_days_ago(days_ago)
     context = clean_context
-    assert not context.status_db.get_analyses_before_date(before=date_one_year_ago).all()
+    assert not context.status_db.get_analyses_started_at_before(started_at_before=date_one_year_ago)
 
     # WHEN running the clean command
     caplog.set_level(logging.DEBUG)
     result = cli_runner.invoke(
         hk_case_bundle_files,
         ["--days-old", days_ago, "--dry-run"],
         obj=context,
```

### Comparing `cg-27.1.9/tests/cli/clean/test_microbial_clean.py` & `cg-27.2.0/tests/cli/clean/test_microbial_clean.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 import datetime as dt
 import logging
 from pathlib import Path
 
-import pytest
 
 from cg.apps.tb import TrailblazerAPI
 from cg.cli.workflow.commands import clean_run_dir
 from cg.constants import Pipeline
 from click.testing import CliRunner
 
 from cg.models.cg_config import CGConfig
@@ -33,15 +32,15 @@
         base_store,
         pipeline=Pipeline.MICROSALT,
         started_at=timestamp_yesterday,
         uploaded_at=timestamp_yesterday,
         cleaned_at=None,
     )
 
-    analysis_to_clean = base_store.family(microsalt_case_clean_dry).analyses[0]
+    analysis_to_clean = base_store.get_case_by_internal_id(microsalt_case_clean_dry).analyses[0]
     case_path_list = clean_context_microsalt.meta_apis["analysis_api"].get_case_path(
         microsalt_case_clean_dry
     )
 
     for path in case_path_list:
         Path(path).mkdir(exist_ok=True, parents=True)
 
@@ -81,15 +80,15 @@
         base_store,
         pipeline=Pipeline.MICROSALT,
         started_at=timestamp_yesterday,
         uploaded_at=timestamp_yesterday,
         cleaned_at=None,
     )
 
-    analysis_to_clean = base_store.family(microsalt_case_clean).analyses[0]
+    analysis_to_clean = base_store.get_case_by_internal_id(microsalt_case_clean).analyses[0]
     case_path_list = clean_context_microsalt.meta_apis["analysis_api"].get_case_path(
         microsalt_case_clean
     )
 
     for path in case_path_list:
         Path(path).mkdir(exist_ok=True, parents=True)
```

### Comparing `cg-27.1.9/tests/cli/clean/test_rsync_past_run_dirs.py` & `cg-27.2.0/tests/cli/clean/test_rsync_past_run_dirs.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/compress/conftest.py` & `cg-27.2.0/tests/cli/compress/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/compress/test_cli_compress_fastq.py` & `cg-27.2.0/tests/cli/compress/test_cli_compress_fastq.py`

 * *Files 4% similar despite different names*

```diff
@@ -155,15 +155,15 @@
 
 def test_compress_fastq_cli_multiple_family(
     caplog, cli_runner: CliRunner, mocker, populated_multiple_compress_context: CGConfig
 ):
     """Test to run the compress command with multiple families."""
     caplog.set_level(logging.DEBUG)
     # GIVEN a database with multiple families
-    nr_cases = populated_multiple_compress_context.status_db.families().count()
+    nr_cases = populated_multiple_compress_context.status_db._get_query(table=Family).count()
     assert nr_cases > 1
 
     # GIVEN no adjusting according to readsa
     mocker.patch(MOCK_SET_MEM_ACCORDING_TO_READS_PATH, return_value=None)
 
     # WHEN running the compress command
     res = cli_runner.invoke(
@@ -179,15 +179,15 @@
 def test_compress_fastq_cli_multiple_set_limit(
     caplog, cli_runner: CliRunner, mocker, populated_multiple_compress_context: CGConfig
 ):
     """Test to run the compress command with multiple families and use a limit."""
     compress_context = populated_multiple_compress_context
     caplog.set_level(logging.DEBUG)
     # GIVEN a context with more families than the limit
-    nr_cases = compress_context.status_db.families().count()
+    nr_cases = compress_context.status_db._get_query(table=Family).count()
     limit = 5
     assert nr_cases > limit
 
     # GIVEN no adjusting according to readsa
     mocker.patch(MOCK_SET_MEM_ACCORDING_TO_READS_PATH, return_value=None)
 
     # WHEN running the compress command
```

### Comparing `cg-27.1.9/tests/cli/compress/test_cli_decompress_spring.py` & `cg-27.2.0/tests/cli/compress/test_cli_decompress_spring.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,16 +1,13 @@
 """Tests for the compress fastq cli"""
 
 import logging
 
 from cg.cli.compress.fastq import (
     decompress_case,
-    decompress_flowcell,
-    decompress_sample,
-    decompress_ticket,
 )
 from cg.models.cg_config import CGConfig
 from click.testing import CliRunner
 
 
 def test_decompress_spring_cli_no_family(
     compress_context: CGConfig, case_id: str, cli_runner: CliRunner, caplog
```

### Comparing `cg-27.1.9/tests/cli/compress/test_compress_helpers.py` & `cg-27.2.0/tests/cli/compress/test_compress_helpers.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,18 @@
 """Tests for helper functions in Cg Compress CLI."""
 
 import logging
-import os
 from pathlib import Path
 
 from housekeeper.store.models import Version
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.cli.compress import helpers
 from cg.cli.compress.helpers import set_memory_according_to_reads
 from cg.constants.compression import MAX_READS_PER_GB, CRUNCHY_MIN_GB_PER_PROCESS
-from cg.constants.slurm import Slurm
 
 
 def test_set_memory_according_to_reads_when_no_reads(caplog, sample_id: str):
     """Test setting memory according to reads when no sample reads."""
     caplog.set_level(logging.DEBUG)
 
     # GIVEN a sample id and no reads supplied
```

### Comparing `cg-27.1.9/tests/cli/compress/test_store_fastq.py` & `cg-27.2.0/tests/cli/compress/test_store_fastq.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/conftest.py` & `cg-27.2.0/tests/cli/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/delete/test_case.py` & `cg-27.2.0/tests/cli/delete/test_case.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/delete/test_cases.py` & `cg-27.2.0/tests/cli/delete/test_cases.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,19 +7,19 @@
 from cg.store import Store
 
 SUCCESS = 0
 
 
 @pytest.mark.parametrize("identifier_key", ["original_ticket", "order"])
 def test_set_cases_by_sample_identifiers(
-    cli_runner, base_context, base_store: Store, identifier_key, helpers, caplog, ticket
+    cli_runner, base_context, base_store: Store, identifier_key, helpers, caplog, ticket_id
 ):
     # GIVEN a database with a case with a sample
     sample_obj = helpers.add_sample(base_store)
-    sample_obj.original_ticket = ticket
+    sample_obj.original_ticket = ticket_id
     sample_obj.order = "An order"
     case = helpers.add_case(base_store)
     helpers.add_relationship(base_store, sample=sample_obj, case=case)
     identifier_value = getattr(sample_obj, identifier_key)
 
     caplog.set_level(logging.INFO)
```

### Comparing `cg-27.1.9/tests/cli/deliver/conftest.py` & `cg-27.2.0/tests/cli/deliver/conftest.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,16 +11,16 @@
 from housekeeper.store.models import Version
 from tests.store_helpers import StoreHelpers
 
 # Paths
 
 
 @pytest.fixture(name="delivery_inbox")
-def fixture_delivery_inbox(project_dir: Path, customer_id: Path, ticket: str) -> Path:
-    return Path(project_dir, customer_id, INBOX_NAME, ticket)
+def fixture_delivery_inbox(project_dir: Path, customer_id: Path, ticket_id: str) -> Path:
+    return Path(project_dir, customer_id, INBOX_NAME, ticket_id)
 
 
 @pytest.fixture(name="deliver_vcf_path")
 def fixture_deliver_vcf_path(
     delivery_inbox: Path, family_name: str, case_id: str, vcf_file: Path
 ) -> Path:
     return Path(delivery_inbox, family_name, vcf_file.name.replace(case_id, family_name))
@@ -104,14 +104,14 @@
 @pytest.fixture(name="context_with_missing_bundle")
 def fixture_context_with_missing_bundle(
     cg_context: CGConfig,
     analysis_store: Store,
     mip_dna_housekeeper: HousekeeperAPI,
     project_dir: Path,
     helpers: StoreHelpers,
-    ticket: str,
+    ticket_id: str,
 ) -> CGConfig:
     cg_context.housekeeper_api_ = mip_dna_housekeeper
-    helpers.add_case(store=analysis_store, ticket=ticket)
+    helpers.add_case(store=analysis_store, ticket=ticket_id)
     cg_context.status_db_ = analysis_store
     cg_context.delivery_path: str = project_dir.as_posix()
     return cg_context
```

### Comparing `cg-27.1.9/tests/cli/deliver/test_deliver_base.py` & `cg-27.2.0/tests/cli/deliver/test_deliver_base.py`

 * *Files 2% similar despite different names*

```diff
@@ -46,40 +46,40 @@
     # THEN assert the command exists without problems
     assert result.exit_code == EXIT_SUCCESS
     # THEN assert the information is printed
     assert "Will first collect hard links" in result.output
 
 
 def test_run_deliver_delivered_ticket(
-    cli_runner: CliRunner, cg_context: CGConfig, mocker, caplog, ticket
+    cli_runner: CliRunner, cg_context: CGConfig, mocker, caplog, ticket_id
 ):
     """Test for when files are already delivered to customer inbox the HPC"""
     caplog.set_level(logging.INFO)
 
     # GIVEN a cli runner
 
     # GIVEN uploading data to the delivery server is not needed
     mocker.patch.object(DeliverTicketAPI, "check_if_upload_is_needed")
     DeliverTicketAPI.check_if_upload_is_needed.return_value = False
 
     # WHEN running cg deliver ticket
     result = cli_runner.invoke(
         deliver_cmd,
-        ["ticket", "--dry-run", "--ticket", ticket, "--delivery-type", "fastq"],
+        ["ticket", "--dry-run", "--ticket", ticket_id, "--delivery-type", "fastq"],
         obj=cg_context,
     )
 
     # THEN assert the command exists without problems
     assert result.exit_code == EXIT_SUCCESS
 
     # THEN assert that files are already delivered to the customer inbox on the HPC
     assert "Files already delivered to customer inbox on the HPC" in caplog.text
 
 
-def test_run_deliver_ticket(cli_runner: CliRunner, cg_context: CGConfig, mocker, caplog, ticket):
+def test_run_deliver_ticket(cli_runner: CliRunner, cg_context: CGConfig, mocker, caplog, ticket_id):
     """Test for delivering tu customer inbox"""
     caplog.set_level(logging.INFO)
 
     # GIVEN a cli runner
 
     # GIVEN uploading data to the delivery server is needed
     mocker.patch.object(DeliverTicketAPI, "check_if_upload_is_needed")
@@ -88,13 +88,13 @@
     # GIVEN data needs to be concatenated
     mocker.patch.object(DeliverTicketAPI, "check_if_concatenation_is_needed")
     DeliverTicketAPI.check_if_concatenation_is_needed.return_value = True
 
     # WHEN running cg deliver ticket
     cli_runner.invoke(
         deliver_cmd,
-        ["ticket", "--dry-run", "--ticket", ticket, "--delivery-type", "fastq"],
+        ["ticket", "--dry-run", "--ticket", ticket_id, "--delivery-type", "fastq"],
         obj=cg_context,
     )
 
     # THEN assert that files are delivered
     assert "Delivering files to customer inbox on the HPC" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/deliver/test_rsync_base.py` & `cg-27.2.0/tests/cli/deliver/test_rsync_base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/deliver/test_run_deliver_cmd.py` & `cg-27.2.0/tests/cli/deliver/test_run_deliver_cmd.py`

 * *Files 2% similar despite different names*

```diff
@@ -39,15 +39,15 @@
     cli_runner: CliRunner, base_context: CGConfig, case_id: str, caplog
 ):
     """Test to run the deliver command when the provided case does not exist"""
     caplog.set_level(logging.WARNING)
     # GIVEN a cli runner and a base context
     # GIVEN a case_id that does not exist in the database
     store: Store = base_context.status_db
-    assert store.family(case_id) is None
+    assert store.get_case_by_internal_id(internal_id=case_id) is None
 
     # WHEN running the deliver command with the non existing case
     result = cli_runner.invoke(
         deliver_analysis, ["--case-id", case_id, "--delivery-type", "mip-dna"], obj=base_context
     )
 
     # THEN assert the command exits without problems
@@ -104,26 +104,26 @@
     assert delivery_inbox.exists() is True
 
 
 def test_delivery_ticket_id(
     cli_runner: CliRunner,
     populated_mip_context: CGConfig,
     delivery_inbox: Path,
-    ticket: str,
+    ticket_id: str,
 ):
     """Test that to run the deliver command with ticket nr"""
     # GIVEN a context with a case that have files in housekeeper to deliver
     # GIVEN a cli runner
     # GIVEN that the delivery file does not exist
     assert delivery_inbox.exists() is False
 
     # WHEN running the deliver analysis command
     cli_runner.invoke(
         deliver_analysis,
-        ["--ticket", ticket, "--delivery-type", "mip-dna"],
+        ["--ticket", ticket_id, "--delivery-type", "mip-dna"],
         obj=populated_mip_context,
     )
 
     # THEN assert that the path to the delivery folder was created
     assert delivery_inbox.exists() is True
 
 
@@ -177,62 +177,69 @@
     # THEN assert that the case file was delivered to the inbox
     assert deliver_vcf_path.exists() is True
 
 
 def test_delivering_analysis_with_missing_bundle_errors(
     cli_runner: CliRunner,
     context_with_missing_bundle: CGConfig,
-    ticket: str,
+    ticket_id: str,
 ):
     """Test that the deliver command fails when a bundle is missing."""
     # GIVEN a context with a case that does not have files in housekeeper to deliver.
     # GIVEN a cli runner
     # WHEN running the deliver analysis command
     result = cli_runner.invoke(
         deliver_analysis,
-        ["--ticket", ticket, "--delivery-type", "mip-dna"],
+        ["--ticket", ticket_id, "--delivery-type", "mip-dna"],
         obj=context_with_missing_bundle,
     )
 
     # THEN assert that the command failed
     assert result.exit_code is not EXIT_SUCCESS
 
 
 def test_delivering_analysis_with_missing_bundle_ignoring_errors(
     cli_runner: CliRunner,
     context_with_missing_bundle: CGConfig,
     delivery_inbox: Path,
-    ticket: str,
+    ticket_id: str,
 ):
     """Test that it is possible to deliver analysis with a missing bundle using the --ignore-missing-bundles flag."""
     # GIVEN a context without files in housekeeper to deliver.
     # GIVEN a cli runner
     # GIVEN that the delivery file does not exist
     assert delivery_inbox.exists() is False
 
     # WHEN running the deliver analysis command
     cli_runner.invoke(
         deliver_analysis,
-        ["--ticket", ticket, "--ignore-missing-bundles", "--delivery-type", "mip-dna"],
+        ["--ticket", ticket_id, "--ignore-missing-bundles", "--delivery-type", "mip-dna"],
         obj=context_with_missing_bundle,
     )
 
     # THEN assert that the path to the delivery folder was created
     assert delivery_inbox.exists() is True
 
 
 def test_deliver_ticket_with_missing_bundle(
-    cli_runner: CliRunner, context_with_missing_bundle: CGConfig, caplog, ticket
+    cli_runner: CliRunner, context_with_missing_bundle: CGConfig, caplog, ticket_id
 ):
     caplog.set_level(logging.INFO)
 
     # GIVEN a cli runner
     # WHEN running cg deliver ticket
     result = cli_runner.invoke(
         deliver_ticket,
-        ["--ticket", ticket, "--dry-run", "--ignore-missing-bundles", "--delivery-type", "mip-dna"],
+        [
+            "--ticket",
+            ticket_id,
+            "--dry-run",
+            "--ignore-missing-bundles",
+            "--delivery-type",
+            "mip-dna",
+        ],
         obj=context_with_missing_bundle,
     )
 
     # THEN assert that the command succeeded and files are delivered
     assert result.exit_code is EXIT_SUCCESS
     assert "Delivering files to customer inbox on the HPC" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/demultiplex/conftest.py` & `cg-27.2.0/tests/cli/demultiplex/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/demultiplex/test_add_flowcell.py` & `cg-27.2.0/tests/cli/demultiplex/test_add_flowcell.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/demultiplex/test_create_sample_sheet.py` & `cg-27.2.0/tests/cli/demultiplex/test_create_sample_sheet.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from pathlib import Path
 from typing import List
 
 from click import testing
 
 from cg.apps.demultiplex.demultiplex_api import DemultiplexingAPI
 from cg.apps.lims.samplesheet import (
-    LimsFlowcellSample,
     LimsFlowcellSampleBcl2Fastq,
     LimsFlowcellSampleDragen,
 )
 from cg.cli.demultiplex.sample_sheet import create_sheet
 from cg.models.cg_config import CGConfig
 from cg.models.demultiplex.flow_cell import FlowCell
```

### Comparing `cg-27.1.9/tests/cli/demultiplex/test_demultiplex_flowcell.py` & `cg-27.2.0/tests/cli/demultiplex/test_demultiplex_flowcell.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/demultiplex/test_finish_demux.py` & `cg-27.2.0/tests/cli/demultiplex/test_finish_demux.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/demultiplex/test_stats_command.py` & `cg-27.2.0/tests/cli/demultiplex/test_stats_command.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/demultiplex/test_validate_sample_sheet.py` & `cg-27.2.0/tests/cli/demultiplex/test_validate_sample_sheet.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/generate/report/conftest.py` & `cg-27.2.0/tests/cli/generate/report/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/generate/report/test_cli_delivery_report.py` & `cg-27.2.0/tests/cli/generate/report/test_cli_delivery_report.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/generate/report/test_utils.py` & `cg-27.2.0/tests/cli/generate/report/test_utils.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/generate/test_cli_base.py` & `cg-27.2.0/tests/cli/generate/test_cli_base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/get/test_cli_get.py` & `cg-27.2.0/tests/cli/get/test_cli_get.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/get/test_cli_get_analysis.py` & `cg-27.2.0/tests/cli/get/test_cli_get_analysis.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/get/test_cli_get_case.py` & `cg-27.2.0/tests/cli/get/test_cli_get_case.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/get/test_cli_get_flow_cell.py` & `cg-27.2.0/tests/cli/get/test_cli_get_flow_cell.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/get/test_cli_get_sample.py` & `cg-27.2.0/tests/cli/get/test_cli_get_sample.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 from cg.cli.get import get
 from cg.constants import EXIT_SUCCESS
 from cg.models.cg_config import CGConfig
 from cg.store import Store
 from click.testing import CliRunner
 
-from cg.store.models import Flowcell, Sample, Family, FamilySample
+from cg.store.models import Flowcell, Sample, Family
 from tests.store_helpers import StoreHelpers
 
 
 def test_get_sample_bad_sample(cli_runner: CliRunner, base_context: CGConfig):
     """Test to get a sample using a non-existing sample-id"""
     # GIVEN an empty database
```

### Comparing `cg-27.1.9/tests/cli/set/conftest.py` & `cg-27.2.0/tests/cli/set/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/set/test_families.py` & `cg-27.2.0/tests/cli/set/test_families.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,20 +8,20 @@
 from cg.store.models import Family, Sample
 
 SUCCESS = 0
 
 
 @pytest.mark.parametrize("identifier_key", ["original_ticket", "order"])
 def test_set_families_by_sample_identifiers(
-    cli_runner, base_context: CGConfig, identifier_key, helpers, caplog, ticket
+    cli_runner, base_context: CGConfig, identifier_key, helpers, caplog, ticket_id
 ):
     # GIVEN a database with a case with a sample
     base_store: Store = base_context.status_db
     sample_obj: Sample = helpers.add_sample(base_store)
-    sample_obj.original_ticket = ticket
+    sample_obj.original_ticket = ticket_id
     sample_obj.order = "An order"
     case: Family = helpers.add_case(base_store)
     helpers.add_relationship(base_store, sample=sample_obj, case=case)
     identifier_value = getattr(sample_obj, identifier_key)
 
     caplog.set_level(logging.INFO)
```

### Comparing `cg-27.1.9/tests/cli/set/test_family.py` & `cg-27.2.0/tests/cli/set/test_family.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/set/test_flowcell.py` & `cg-27.2.0/tests/cli/set/test_flowcell.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/set/test_list_keys.py` & `cg-27.2.0/tests/cli/set/test_list_keys.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 """Test methods for cg cli set list_keys"""
 import logging
 
-import pytest
 from cg.cli.set.base import list_keys
-from cg.constants import EXIT_SUCCESS, Priority
+from cg.constants import EXIT_SUCCESS
 from cg.constants.subject import Gender
 from cg.models.cg_config import CGConfig
 from cg.store import Store
 from click.testing import CliRunner
 
 
 def test_list_keys_without_sample(
```

### Comparing `cg-27.1.9/tests/cli/set/test_sample.py` & `cg-27.2.0/tests/cli/set/test_sample.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 """Test methods for cg cli set sample"""
-import logging
 
 import pytest
 from cg.cli.set.base import sample
 from cg.constants import EXIT_SUCCESS, Priority
 from cg.constants.subject import Gender
 from cg.models.cg_config import CGConfig
 from cg.store import Store
```

### Comparing `cg-27.1.9/tests/cli/set/test_samples.py` & `cg-27.2.0/tests/cli/set/test_samples.py`

 * *Files 0% similar despite different names*

```diff
@@ -73,15 +73,15 @@
     cli_runner, base_context, base_store: Store, helpers, caplog
 ):
     # GIVEN a database with a sample that belongs to a case
     sample_obj = helpers.add_sample(base_store)
 
     # WHEN calling set samples with an identifier not existing on sample
     non_existing_case = "not_a_case"
-    assert not base_store.family(non_existing_case)
+    assert not base_store.get_case_by_internal_id(internal_id=non_existing_case)
     with caplog.at_level(logging.INFO):
         result = cli_runner.invoke(
             samples, [non_existing_case, "-y", "--skip-lims"], obj=base_context
         )
 
     # THEN it should fail and not name the sample to be changed
     assert result.exit_code != SUCCESS
```

### Comparing `cg-27.1.9/tests/cli/store/test_fastq.py` & `cg-27.2.0/tests/cli/store/test_fastq.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 import logging
 
 from click.testing import CliRunner
 
-from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.cli.store.fastq import (
     store_case,
     store_demultiplexed_flow_cell,
     store_flow_cell,
     store_sample,
     store_ticket,
 )
@@ -152,26 +151,26 @@
 
 def test_store_ticket(
     caplog,
     cli_runner: CliRunner,
     mocker,
     populated_compress_context: CGConfig,
     sample_id: str,
-    ticket: str,
+    ticket_id: str,
 ):
     """Test to run store ticket command."""
     caplog.set_level(logging.DEBUG)
     # GIVEN a context with a sample
 
     # GIVEN that decompression is not finished
     mocker.patch.object(CompressAPI, "add_decompressed_fastq")
     CompressAPI.add_decompressed_fastq.return_value = True
 
     # WHEN running the store ticket command
-    res = cli_runner.invoke(store_ticket, [ticket], obj=populated_compress_context)
+    res = cli_runner.invoke(store_ticket, [ticket_id], obj=populated_compress_context)
 
     # THEN assert that the command exits successfully
     assert res.exit_code == EXIT_SUCCESS
 
     # THEN assert that we log that we stored FASTQ files
     assert f"Stored fastq files for {sample_id}" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/test_base.py` & `cg-27.2.0/tests/cli/test_base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/test_clean.py` & `cg-27.2.0/tests/cli/test_clean.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/test_cli_status_cases.py` & `cg-27.2.0/tests/cli/test_cli_status_cases.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/upload/conftest.py` & `cg-27.2.0/tests/cli/upload/conftest.py`

 * *Files 1% similar despite different names*

```diff
@@ -89,15 +89,15 @@
 
 
 @pytest.fixture(name="analysis_obj")
 def fixture_analysis_obj(
     analysis_store_trio: Store, case_id: str, timestamp: datetime, helpers
 ) -> Analysis:
     """Return a analysis object with a trio"""
-    return analysis_store_trio.family(case_id).analyses[0]
+    return analysis_store_trio.get_case_by_internal_id(internal_id=case_id).analyses[0]
 
 
 @pytest.fixture(name="upload_genotypes_hk_api")
 def fixture_upload_genotypes_hk_api(
     real_housekeeper_api: HousekeeperAPI,
     upload_genotypes_hk_bundle: dict,
     analysis_obj: Analysis,
@@ -278,15 +278,15 @@
     return api
 
 
 class MockScoutApi(ScoutAPI):
     def __init__(self):
         """docstring for __init__"""
 
-    def upload(self, scout_load_config: Path, threshold: int = 5, force: bool = False):
+    def upload(self, scout_load_config: Path, force: bool = False):
         """docstring for upload"""
         LOG.info("Case loaded successfully to Scout")
 
 
 class MockAnalysisApi(MipAnalysisAPI):
     def __init__(self):
         """docstring for __init__"""
```

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_scout.py` & `cg-27.2.0/tests/cli/upload/test_cli_scout.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,10 @@
 """Test CG CLI upload module."""
-import logging
 from datetime import datetime, timedelta
 
-from cgmodels.cg.constants import Pipeline
 from click.testing import CliRunner
 
 from cg.cli.upload.base import upload
 from cg.models.cg_config import CGConfig
 from cg.store import Store
 from cg.store.models import Family
 from tests.store_helpers import StoreHelpers
```

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload_auto.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload_auto.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload_delivery_report.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload_delivery_report.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload_fastq.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload_fastq.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload_genotype.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload_genotype.py`

 * *Files 16% similar despite different names*

```diff
@@ -18,15 +18,15 @@
     caplog,
 ):
     """Test to upload genotypes via the CLI"""
     caplog.set_level(logging.DEBUG)
     # GIVEN a context with a case that is ready for upload sequence genotypes
     upload_context.status_db_ = analysis_store_trio
     upload_context.housekeeper_api_ = upload_genotypes_hk_api
-    case_obj = upload_context.status_db.family(case_id)
+    case_obj = upload_context.status_db.get_case_by_internal_id(internal_id=case_id)
     assert case_obj
 
     # WHEN uploading the genotypes
     result = cli_runner.invoke(upload_genotypes_cmd, [case_id], obj=upload_context)
 
     # THEN check that the command exits with success
     assert result.exit_code == 0
```

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload_gens.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload_gens.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload_nipt.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload_nipt.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload_nipt_ftp.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload_nipt_ftp.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload_nipt_statina.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload_nipt_statina.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload_observations.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload_observations.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/upload/test_cli_upload_vogue.py` & `cg-27.2.0/tests/cli/upload/test_cli_upload_vogue.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/balsamic/conftest.py` & `cg-27.2.0/tests/cli/workflow/balsamic/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/balsamic/test_cli_balsamic_config_case.py` & `cg-27.2.0/tests/cli/workflow/balsamic/test_cli_balsamic_config_case.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,19 +1,17 @@
 """Tests cli methods to create the case config for balsamic"""
 
 import logging
 from pathlib import Path
 
-import pytest
 from _pytest.logging import LogCaptureFixture
 
 from cg.cli.workflow.balsamic.base import config_case
 from click.testing import CliRunner
 
-from cg.exc import BalsamicStartError
 from cg.models.cg_config import CGConfig
 
 EXIT_SUCCESS = 0
 
 
 def test_without_options(cli_runner: CliRunner, balsamic_context: CGConfig):
     """Test command without case_id."""
@@ -28,15 +26,15 @@
 def test_with_missing_case(
     cli_runner: CliRunner, balsamic_context: CGConfig, caplog: LogCaptureFixture
 ):
     """Test command with invalid case to start with."""
     caplog.set_level(logging.ERROR)
     # GIVEN case_id not in database
     case_id = "soberelephant"
-    assert not balsamic_context.status_db.family(case_id)
+    assert not balsamic_context.status_db.get_case_by_internal_id(internal_id=case_id)
     # WHEN running
     result = cli_runner.invoke(config_case, [case_id], obj=balsamic_context)
     # THEN command should NOT successfully call the command it creates
     assert result.exit_code != EXIT_SUCCESS
     # THEN ERROR log should be printed containing invalid case_id
     assert "could not be found in StatusDB!" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/workflow/balsamic/test_compound_commands.py` & `cg-27.2.0/tests/cli/workflow/balsamic/test_compound_commands.py`

 * *Files 6% similar despite different names*

```diff
@@ -65,28 +65,28 @@
     balsamic_context.housekeeper_api_ = real_housekeeper_api
     balsamic_context.meta_apis["analysis_api"].housekeeper_api = real_housekeeper_api
 
     # Make sure the bundle was not present in the store
     assert not balsamic_context.housekeeper_api.bundle(case_id)
 
     # Make sure  analysis not already stored in ClinicalDB
-    assert not balsamic_context.status_db.family(case_id).analyses
+    assert not balsamic_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
 
     # GIVEN that HermesAPI returns a deliverables output
     mocker.patch.object(HermesApi, "convert_deliverables")
     HermesApi.convert_deliverables.return_value = CGDeliverables(**hermes_deliverables)
 
     # WHEN running command
     result = cli_runner.invoke(store, [case_id, "--dry-run"], obj=balsamic_context)
 
     # THEN bundle should be successfully added to HK and STATUS
     assert result.exit_code == EXIT_SUCCESS
     assert "Analysis successfully stored in Housekeeper" in caplog.text
     assert "Analysis successfully stored in StatusDB" in caplog.text
-    assert balsamic_context.status_db.family(case_id).analyses
+    assert balsamic_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
     assert balsamic_context.housekeeper_api.bundle(case_id)
 
 
 def test_start_available(cli_runner: CliRunner, balsamic_context: CGConfig, caplog, mocker):
     """Test to ensure all parts of compound start-available command are executed given ideal conditions
     Test that start-available picks up eligible cases and does not pick up ineligible ones"""
     caplog.set_level(logging.INFO)
@@ -121,15 +121,15 @@
     # THEN it should successfully identify the one case eligible for auto-start
     assert case_id_success in caplog.text
 
     # THEN the ineligible case should NOT be ran
     assert case_id_fail not in caplog.text
 
     # THEN action of the case should NOT be set to running
-    assert balsamic_context.status_db.family(case_id_fail).action is None
+    assert balsamic_context.status_db.get_case_by_internal_id(case_id_fail).action is None
 
 
 def test_store_available(
     tmpdir_factory,
     cli_runner: CliRunner,
     balsamic_context: CGConfig,
     real_housekeeper_api,
@@ -161,35 +161,35 @@
 
     # GIVEN that HermesAPI returns a deliverables output
     mocker.patch.object(HermesApi, "convert_deliverables")
     HermesApi.convert_deliverables.return_value = CGDeliverables(**hermes_deliverables)
 
     # Ensure case was successfully picked up by start-available and status set to running
     result = cli_runner.invoke(start_available, ["--dry-run"], obj=balsamic_context)
-    balsamic_context.status_db.family(case_id_success).action = "running"
+    balsamic_context.status_db.get_case_by_internal_id(case_id_success).action = "running"
     balsamic_context.status_db.commit()
 
     # THEN command exits with 1 because one of the cases threw errors
     assert result.exit_code == 1
     assert case_id_success in caplog.text
-    assert balsamic_context.status_db.family(case_id_success).action == "running"
+    assert balsamic_context.status_db.get_case_by_internal_id(case_id_success).action == "running"
 
     balsamic_context.housekeeper_api_ = real_housekeeper_api
     balsamic_context.meta_apis["analysis_api"].housekeeper_api = real_housekeeper_api
 
     # WHEN running command
     result = cli_runner.invoke(store_available, obj=balsamic_context)
 
     # THEN command exits successfully
     assert result.exit_code == 0
 
     # THEN case id with analysis_finish gets picked up
     assert case_id_success in caplog.text
 
     # THEN case has analyses
-    assert balsamic_context.status_db.family(case_id_success).analyses
+    assert balsamic_context.status_db.get_case_by_internal_id(case_id_success).analyses
 
     # THEN bundle can be found in Housekeeper
     assert balsamic_context.housekeeper_api.bundle(case_id_success)
 
     # THEN bundle added successfully and action set to None
-    assert balsamic_context.status_db.family(case_id_success).action is None
+    assert balsamic_context.status_db.get_case_by_internal_id(case_id_success).action is None
```

### Comparing `cg-27.1.9/tests/cli/workflow/balsamic/test_link.py` & `cg-27.2.0/tests/cli/workflow/balsamic/test_link.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 import logging
-from pathlib import Path
 
 from cg.cli.workflow.balsamic.base import link
 from cg.models.cg_config import CGConfig
 from click.testing import CliRunner
 
 EXIT_SUCCESS = 0
 
@@ -19,15 +18,15 @@
 
 
 def test_with_missing_case(cli_runner: CliRunner, balsamic_context: CGConfig, caplog):
     """Test command with invalid case to start with"""
     caplog.set_level(logging.ERROR)
     # GIVEN case_id not in database
     case_id = "soberelephant"
-    assert not balsamic_context.status_db.family(case_id)
+    assert not balsamic_context.status_db.get_case_by_internal_id(internal_id=case_id)
     # WHEN running
     result = cli_runner.invoke(link, [case_id], obj=balsamic_context)
     # THEN command should NOT successfully call the command it creates
     assert result.exit_code != EXIT_SUCCESS
     # THEN ERROR log should be printed containing invalid case_id
     assert "could not be found in StatusDB!" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/workflow/balsamic/test_report_deliver.py` & `cg-27.2.0/tests/cli/workflow/balsamic/test_report_deliver.py`

 * *Files 8% similar despite different names*

```diff
@@ -24,15 +24,15 @@
 
 
 def test_with_missing_case(cli_runner: CliRunner, balsamic_context: CGConfig, caplog):
     """Test command with invalid case to start with"""
     caplog.set_level(logging.WARNING)
     # GIVEN case_id not in database
     case_id = "soberelephant"
-    assert not balsamic_context.status_db.family(case_id)
+    assert not balsamic_context.status_db.get_case_by_internal_id(internal_id=case_id)
     # WHEN running
     result = cli_runner.invoke(report_deliver, [case_id], obj=balsamic_context)
     # THEN command should NOT successfully call the command it creates
     assert result.exit_code != EXIT_SUCCESS
     # THEN ERROR log should be printed containing invalid case_id
     assert case_id in caplog.text
     assert "could not be found" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/workflow/balsamic/test_run.py` & `cg-27.2.0/tests/cli/workflow/balsamic/test_run.py`

 * *Files 0% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 
 
 def test_with_missing_case(cli_runner: CliRunner, balsamic_context: CGConfig, caplog):
     """Test command with invalid case to start with"""
     caplog.set_level(logging.ERROR)
     # GIVEN case_id not in database
     case_id = "soberelephant"
-    assert not balsamic_context.status_db.family(case_id)
+    assert not balsamic_context.status_db.get_case_by_internal_id(internal_id=case_id)
     # WHEN running
     result = cli_runner.invoke(run, [case_id], obj=balsamic_context)
     # THEN command should NOT successfully call the command it creates
     assert result.exit_code != EXIT_SUCCESS
     # THEN ERROR log should be printed containing invalid case_id
     assert case_id in caplog.text
     assert "could not be found" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/workflow/balsamic/test_store_housekeeper.py` & `cg-27.2.0/tests/cli/workflow/balsamic/test_store_housekeeper.py`

 * *Files 6% similar despite different names*

```diff
@@ -32,15 +32,15 @@
 
 def test_with_missing_case(cli_runner: CliRunner, balsamic_context: CGConfig, caplog):
     """Test command with invalid case to start with"""
     caplog.set_level(logging.ERROR)
 
     # GIVEN case_id not in database
     case_id = "soberelephant"
-    assert not balsamic_context.status_db.family(case_id)
+    assert not balsamic_context.status_db.get_case_by_internal_id(internal_id=case_id)
 
     # WHEN running
     result = cli_runner.invoke(store_housekeeper, [case_id], obj=balsamic_context)
 
     # THEN command should NOT successfully call the command it creates
     assert result.exit_code != EXIT_SUCCESS
 
@@ -136,28 +136,28 @@
     caplog.set_level(logging.INFO)
     # GIVEN case-id
     case_id = "balsamic_case_wgs_single"
 
     # Make sure nothing is currently stored in Housekeeper
 
     # Make sure  analysis not alredy stored in ClinicalDB
-    assert not balsamic_context.status_db.family(case_id).analyses
+    assert not balsamic_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
 
     # GIVEN that HermesAPI returns a deliverables output
     mocker.patch.object(HermesApi, "convert_deliverables")
     HermesApi.convert_deliverables.return_value = CGDeliverables(**hermes_deliverables)
 
     # WHEN running command
     result = cli_runner.invoke(store_housekeeper, [case_id], obj=balsamic_context)
 
     # THEN bundle should be successfully added to HK and STATUS
     assert result.exit_code == EXIT_SUCCESS
     assert "Analysis successfully stored in Housekeeper" in caplog.text
     assert "Analysis successfully stored in StatusDB" in caplog.text
-    assert balsamic_context.status_db.family(case_id).analyses
+    assert balsamic_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
     assert balsamic_context.meta_apis["analysis_api"].housekeeper_api.bundle(case_id)
 
 
 def test_valid_case_already_added(
     cli_runner,
     mocker,
     hermes_deliverables,
@@ -173,15 +173,15 @@
     case_id = "balsamic_case_wgs_single"
 
     # Make sure nothing is currently stored in Housekeeper
     balsamic_context.housekeeper_api_ = real_housekeeper_api
     balsamic_context.meta_apis["analysis_api"].housekeeper_api = real_housekeeper_api
 
     # Make sure  analysis not already stored in ClinicalDB
-    assert not balsamic_context.status_db.family(case_id).analyses
+    assert not balsamic_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
 
     # GIVEN that HermesAPI returns a deliverables output
     mocker.patch.object(HermesApi, "convert_deliverables")
     HermesApi.convert_deliverables.return_value = CGDeliverables(**hermes_deliverables)
 
     # Ensure bundles exist by creating them first
     cli_runner.invoke(store_housekeeper, [case_id], obj=balsamic_context)
```

### Comparing `cg-27.1.9/tests/cli/workflow/conftest.py` & `cg-27.2.0/tests/cli/workflow/conftest.py`

 * *Files 6% similar despite different names*

```diff
@@ -76,57 +76,57 @@
     # Add fastq case to db
     fastq_case["samples"][0]["sequenced_at"] = datetime.now()
     helpers.ensure_case_from_dict(store=_store, case_info=fastq_case)
     return cg_context
 
 
 @pytest.fixture(name="fastq_case")
-def fixture_fastq_case(case_id, family_name, sample_id, cust_sample_id, ticket: str) -> dict:
+def fixture_fastq_case(case_id, family_name, sample_id, cust_sample_id, ticket_id: str) -> dict:
     """Returns a dict describing a fastq case"""
     return {
         "name": family_name,
         "panels": None,
         "internal_id": case_id,
         "data_analysis": Pipeline.FASTQ,
         "data_delivery": DataDelivery.FASTQ,
         "completed_at": None,
         "action": None,
-        "tickets": ticket,
+        "tickets": ticket_id,
         "samples": [
             {
                 "internal_id": sample_id,
                 "sex": "male",
                 "name": cust_sample_id,
-                "original_ticket": ticket,
+                "original_ticket": ticket_id,
                 "reads": 1000000,
                 "capture_kit": "anything",
             },
         ],
     }
 
 
 @pytest.fixture(scope="function")
 def dna_case(analysis_store, helpers) -> Family:
     """Case with DNA application"""
     cust = helpers.ensure_customer(analysis_store)
-    return analysis_store.find_family(cust, "dna_case")
+    return analysis_store.get_case_by_name_and_customer(customer=cust, case_name="dna_case")
 
 
 @pytest.fixture(scope="function")
 def rna_case(analysis_store, helpers) -> Family:
     """Case with RNA application"""
     cust = helpers.ensure_customer(analysis_store)
-    return analysis_store.find_family(cust, "rna_case")
+    return analysis_store.get_case_by_name_and_customer(customer=cust, case_name="rna_case")
 
 
 @pytest.fixture(scope="function")
 def dna_rna_mix_case(analysis_store, helpers) -> Family:
     """Case with MIP analysis type DNA and RNA application"""
     cust = helpers.ensure_customer(analysis_store)
-    return analysis_store.find_family(cust, "dna_rna_mix_case")
+    return analysis_store.get_case_by_name_and_customer(customer=cust, case_name="dna_rna_mix_case")
 
 
 @pytest.fixture(name="create_multiqc_html_file")
 def fixture_create_multiqc_html_file(tmpdir_factory) -> Path:
     output_dir = tmpdir_factory.mktemp("output")
     file_path = Path(output_dir, "multiqc_report.html")
     file_path.touch(exist_ok=True)
```

### Comparing `cg-27.1.9/tests/cli/workflow/fastq/test_fastq_base.py` & `cg-27.2.0/tests/cli/workflow/fastq/test_fastq_base.py`

 * *Files 13% similar despite different names*

```diff
@@ -5,31 +5,31 @@
 from cg.store.models import Family, Sample
 
 
 def test_store_fastq_analysis(caplog, case_id: str, cli_runner, fastq_context):
     """Test for CLI command creating an analysis object for a fastq case"""
     # GIVEN a fastq context
     caplog.set_level(logging.INFO)
-    case_obj: Family = fastq_context.status_db.family(internal_id=case_id)
+    case_obj: Family = fastq_context.status_db.get_case_by_internal_id(internal_id=case_id)
     case_obj.analyses = []
 
     # WHEN the store_fastq_analysis command is invoked
     cli_runner.invoke(store_fastq_analysis, [case_id], obj=fastq_context)
 
     # THEN the run command should be reached
-    assert len(fastq_context.status_db.analyses(family=case_obj).all()) > 0
+    assert len(fastq_context.status_db.get_analyses_by_case_entry_id(case_entry_id=case_obj.id)) > 0
 
 
 def test_store_available_fastq_analysis(
     caplog, case_id: str, cli_runner, fastq_context, sample_id: str
 ):
     """Test for CLI command creating an analysis object for all fastq cases to be delivered"""
     caplog.set_level(logging.INFO)
     # GIVEN a case with no analysis, a sample that has been sequenced and a fastq context
-    case_obj: Family = fastq_context.status_db.family(internal_id=case_id)
+    case_obj: Family = fastq_context.status_db.get_case_by_internal_id(internal_id=case_id)
     case_obj.analyses = []
     sample_obj: Sample = fastq_context.status_db.get_sample_by_internal_id(internal_id=sample_id)
     sample_obj.sequenced_at = datetime.now()
 
     # WHEN the store_available_fastq_analysis command is invoked
     cli_runner.invoke(store_available_fastq_analysis, ["--dry-run"], obj=fastq_context)
```

### Comparing `cg-27.1.9/tests/cli/workflow/fluffy/conftest.py` & `cg-27.2.0/tests/cli/workflow/fluffy/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/fluffy/test_cli_create_samplesheet.py` & `cg-27.2.0/tests/cli/workflow/fluffy/test_cli_create_samplesheet.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/fluffy/test_cli_link.py` & `cg-27.2.0/tests/cli/workflow/fluffy/test_cli_link.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/fluffy/test_cli_run.py` & `cg-27.2.0/tests/cli/workflow/fluffy/test_cli_run.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/fluffy/test_cli_start.py` & `cg-27.2.0/tests/cli/workflow/fluffy/test_cli_start.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-from pathlib import Path
-
 from cg.cli.workflow.fluffy.base import start_available
 from cg.constants import EXIT_SUCCESS
 from cg.meta.workflow.fluffy import FluffyAnalysisAPI
 from cg.models.cg_config import CGConfig
 from click.testing import CliRunner
 import datetime as dt
```

### Comparing `cg-27.1.9/tests/cli/workflow/fluffy/test_cli_store.py` & `cg-27.2.0/tests/cli/workflow/fluffy/test_cli_store.py`

 * *Files 4% similar despite different names*

```diff
@@ -66,15 +66,17 @@
     assert result.exit_code == EXIT_SUCCESS
 
     # THEN log informs that analysis was stored in Housekeeper and StatusDB
     assert "stored in Housekeeper" in caplog.text
     assert "stored in StatusDB" in caplog.text
 
     # THEN action of case in StatusDB is set to None
-    assert not fluffy_analysis_api.status_db.family(fluffy_case_id_existing).action
+    assert not fluffy_analysis_api.status_db.get_case_by_internal_id(
+        internal_id=fluffy_case_id_existing
+    ).action
 
 
 def test_cli_store_bundle_already_added(
     cli_runner: CliRunner,
     fluffy_case_id_existing,
     deliverables_yaml_fixture_path,
     fluffy_hermes_deliverables_response_data,
@@ -151,15 +153,17 @@
     assert "stored in Housekeeper" in caplog.text
     assert "stored in StatusDB" in caplog.text
 
     # THEN log informs about eligible case
     assert fluffy_case_id_existing in caplog.text
 
     # THEN case action is set to None after storing
-    assert not fluffy_analysis_api.status_db.family(fluffy_case_id_existing).action
+    assert not fluffy_analysis_api.status_db.get_case_by_internal_id(
+        internal_id=fluffy_case_id_existing
+    ).action
 
 
 def test_cli_store_available_case_not_running(
     cli_runner: CliRunner,
     fluffy_case_id_existing,
     deliverables_yaml_fixture_path,
     fluffy_hermes_deliverables_response_data,
@@ -170,15 +174,17 @@
 ):
     caplog.set_level("INFO")
     fluffy_analysis_api: FluffyAnalysisAPI = fluffy_context.meta_apis["analysis_api"]
 
     # GIVEN a case_id that does exist in database
 
     # GIVEN that case action is None
-    fluffy_analysis_api.status_db.family(fluffy_case_id_existing).action = None
+    fluffy_analysis_api.status_db.get_case_by_internal_id(
+        internal_id=fluffy_case_id_existing
+    ).action = None
     fluffy_analysis_api.status_db.commit()
 
     # GIVEN deliverables were generated and could be found
     mocker.patch.object(FluffyAnalysisAPI, "get_deliverables_file_path")
     FluffyAnalysisAPI.get_deliverables_file_path.return_value = deliverables_yaml_fixture_path
 
     # GIVEN the same timestamp is attained when storing analysis in different databases
```

### Comparing `cg-27.1.9/tests/cli/workflow/microsalt/conftest.py` & `cg-27.2.0/tests/cli/workflow/microsalt/conftest.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 """ Fixtures for microsalt CLI test """
 
-from pathlib import Path
 
 import pytest
 from cg.apps.hermes.hermes_api import HermesApi
 from cg.meta.workflow.microsalt import MicrosaltAnalysisAPI
 from cg.models.cg_config import CGConfig
 from cg.store import Store
 from tests.store_helpers import StoreHelpers
```

### Comparing `cg-27.1.9/tests/cli/workflow/microsalt/snapshots/snap_test_microsalt_case_config.py` & `cg-27.2.0/tests/cli/workflow/microsalt/snapshots/snap_test_microsalt_case_config.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/microsalt/test_microsalt_case_config.py` & `cg-27.2.0/tests/cli/workflow/microsalt/test_microsalt_case_config.py`

 * *Files 1% similar despite different names*

```diff
@@ -92,23 +92,23 @@
     # WHEN dry running a sample name
     result = cli_runner.invoke(config_case, [microbial_sample_id, "-s", "-d"], obj=base_context)
 
     # THEN command should give us a json dump
     assert result.exit_code == EXIT_SUCCESS
 
 
-def test_dry_order(cli_runner: CliRunner, base_context: CGConfig, ticket, snapshot: Snapshot):
+def test_dry_order(cli_runner: CliRunner, base_context: CGConfig, ticket_id, snapshot: Snapshot):
     """Test working dry command for a order"""
 
     # GIVEN
 
     # WHEN dry running a sample name
     result = cli_runner.invoke(
         config_case,
-        [ticket, "-t", "-d"],
+        [ticket_id, "-t", "-d"],
         obj=base_context,
     )
 
     # THEN command should give us a json dump
     assert result.exit_code == EXIT_SUCCESS
```

### Comparing `cg-27.1.9/tests/cli/workflow/microsalt/test_microsalt_run.py` & `cg-27.2.0/tests/cli/workflow/microsalt/test_microsalt_run.py`

 * *Files 12% similar despite different names*

```diff
@@ -16,19 +16,19 @@
     # WHEN dry running without anything specified
     result = cli_runner.invoke(run, obj=base_context)
 
     # THEN command should mention missing arguments
     assert result.exit_code != EXIT_SUCCESS
 
 
-def test_dry_arguments(cli_runner: CliRunner, base_context: CGConfig, ticket, caplog):
+def test_dry_arguments(cli_runner: CliRunner, base_context: CGConfig, ticket_id, caplog):
     """Test command dry"""
 
     # GIVEN
     caplog.set_level(logging.INFO)
 
     # WHEN dry running without anything specified
-    result = cli_runner.invoke(run, [ticket, "-t", "-d"], obj=base_context)
+    result = cli_runner.invoke(run, [ticket_id, "-t", "-d"], obj=base_context)
 
     # THEN command should mention missing arguments
     assert result.exit_code == EXIT_SUCCESS
     assert f"Running command" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/workflow/mip/conftest.py` & `cg-27.2.0/tests/cli/workflow/mip/conftest.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 from pathlib import Path
-from typing import Any, Callable
 
 import pytest
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.apps.housekeeper.models import InputBundle
 from cg.apps.tb import TrailblazerAPI
 from cg.constants import Pipeline
@@ -106,15 +105,15 @@
     case_id: str,
     housekeeper_api: HousekeeperAPI,
     tb_api,
 ) -> CGConfig:
     cg_context.housekeeper_api_ = housekeeper_api
     cg_context.trailblazer_api_ = tb_api
     analysis_family_single_case["data_analysis"] = str(Pipeline.MIP_RNA)
-    if not cg_context.status_db.family(case_id):
+    if not cg_context.status_db.get_case_by_internal_id(internal_id=case_id):
         helpers.ensure_case_from_dict(
             cg_context.status_db, case_info=analysis_family_single_case, app_tag=apptag_rna
         )
     cg_context.meta_apis["analysis_api"] = MipRNAAnalysisAPI(cg_context)
     return cg_context
 
 
@@ -133,15 +132,15 @@
 
     # Add apptag to db
     helpers.ensure_application_version(store=_store, application_tag="WGSA", prep_category="wgs")
 
     # Add sample, cases and relationships to db
 
     for case_id in mip_case_ids:
-        if not _store.family(case_id):
+        if not _store.get_case_by_internal_id(internal_id=case_id):
             case_obj = helpers.add_case(
                 store=_store,
                 data_analysis=Pipeline.MIP_DNA,
                 internal_id=case_id,
                 name=mip_case_ids[case_id]["name"],
             )
             sample = helpers.add_sample(
```

### Comparing `cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_base.py` & `cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_base.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_dna_config_case.py` & `cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_dna_config_case.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_dna_run.py` & `cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_dna_run.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,11 @@
 """ Test the CLI for run mip-dna """
 import logging
-import pytest
 
 from cg.cli.workflow.mip_dna.base import run
-from cg.exc import CgError
 from cg.meta.workflow.mip_dna import MipDNAAnalysisAPI
 
 
 def test_cg_dry_run(
     cli_runner, mocker, caplog, case_id, email_adress, mip_dna_context, mip_dna_fixture_config_path
 ):
     """Test print the MIP run to console"""
```

### Comparing `cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_dna_start.py` & `cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_dna_start.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """This script tests the cli methods to create prerequisites and start a mip-dna analysis"""
 import logging
 
-from cg.cli.workflow.mip_dna.base import start, start_available
+from cg.cli.workflow.mip_dna.base import start_available
 from cg.constants import EXIT_SUCCESS, Pipeline
 from cg.meta.workflow.prepare_fastq import PrepareFastqAPI
 
 
 def test_dry(cli_runner, mip_dna_context):
     """Test mip dna start with --dry option"""
```

### Comparing `cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_rna_config_case.py` & `cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_rna_config_case.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_rna_link.py` & `cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_rna_link.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_rna_run.py` & `cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_rna_run.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/mip/test_cli_mip_store.py` & `cg-27.2.0/tests/cli/workflow/mip/test_cli_mip_store.py`

 * *Files 3% similar despite different names*

```diff
@@ -69,15 +69,15 @@
     assert result.exit_code == EXIT_SUCCESS
 
     # THEN log informs that analysis was stored in Housekeeper and StatusDB
     assert "stored in Housekeeper" in caplog.text
     assert "stored in StatusDB" in caplog.text
 
     # THEN action of case in StatusDB is set to None
-    assert not mip_analysis_api.status_db.family(mip_case_id).action
+    assert not mip_analysis_api.status_db.get_case_by_internal_id(internal_id=mip_case_id).action
 
 
 def test_cli_store_bundle_already_added(
     cli_runner: CliRunner,
     mip_case_id: str,
     mip_deliverables_file,
     mip_hermes_dna_deliverables_response_data,
@@ -153,15 +153,15 @@
     # GIVEN sample_info were generated and could be found
     mocker.patch.object(MipDNAAnalysisAPI, "get_sample_info_path")
     MipDNAAnalysisAPI.get_sample_info_path.return_value = case_qc_sample_info_path
 
     # GIVEN that the case analysis is finished in trailblazer
     mocker.patch.object(MipDNAAnalysisAPI, "get_cases_to_store")
     MipDNAAnalysisAPI.get_cases_to_store.return_value = [
-        mip_analysis_api.status_db.family(internal_id=mip_case_id)
+        mip_analysis_api.status_db.get_case_by_internal_id(internal_id=mip_case_id)
     ]
 
     # WHEN running command
     result = cli_runner.invoke(store_available, [], obj=mip_dna_context)
 
     # THEN command terminates successfully
     assert result.exit_code == EXIT_SUCCESS
@@ -170,15 +170,15 @@
     assert "stored in Housekeeper" in caplog.text
     assert "stored in StatusDB" in caplog.text
 
     # THEN log informs about eligible case
     assert mip_case_id in caplog.text
 
     # THEN case action is set to None after storing
-    assert not mip_analysis_api.status_db.family(mip_case_id).action
+    assert not mip_analysis_api.status_db.get_case_by_internal_id(internal_id=mip_case_id).action
 
 
 def test_cli_store_available_case_not_running(
     cli_runner: CliRunner,
     mip_case_id,
     mip_deliverables_file,
     mip_hermes_dna_deliverables_response_data,
@@ -189,15 +189,15 @@
 ):
     caplog.set_level("INFO")
     mip_analysis_api: MipDNAAnalysisAPI = mip_dna_context.meta_apis["analysis_api"]
 
     # GIVEN a case_id that does exist in database
 
     # GIVEN that case action is None
-    mip_analysis_api.status_db.family(mip_case_id).action = None
+    mip_analysis_api.status_db.get_case_by_internal_id(internal_id=mip_case_id).action = None
     mip_analysis_api.status_db.commit()
 
     # GIVEN deliverables were generated and could be found
     mocker.patch.object(MipDNAAnalysisAPI, "get_deliverables_file_path")
     MipDNAAnalysisAPI.get_deliverables_file_path.return_value = mip_deliverables_file
 
     # GIVEN the same timestamp is attained when storing analysis in different databases
```

### Comparing `cg-27.1.9/tests/cli/workflow/rnafusion/conftest.py` & `cg-27.2.0/tests/cli/workflow/rnafusion/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/rnafusion/test_cli_rnafusion_compound_commands.py` & `cg-27.2.0/tests/cli/workflow/rnafusion/test_cli_rnafusion_compound_commands.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,23 +1,21 @@
 import logging
 
 from _pytest.logging import LogCaptureFixture
 from click.testing import CliRunner
-from pytest_mock import MockFixture
 
 from cg.apps.hermes.hermes_api import HermesApi
 from cg.apps.hermes.models import CGDeliverables
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.cli.workflow.rnafusion.base import (
     rnafusion,
     start,
     start_available,
     store,
     store_available,
-    store_housekeeper,
 )
 from cg.constants import EXIT_SUCCESS
 from cg.meta.workflow.rnafusion import RnafusionAnalysisAPI
 from cg.models.cg_config import CGConfig
 
 
 def test_rnafusion_no_args(cli_runner: CliRunner, rnafusion_context: CGConfig):
@@ -86,27 +84,27 @@
     rnafusion_context.housekeeper_api_: HousekeeperAPI = real_housekeeper_api
     rnafusion_context.meta_apis["analysis_api"].housekeeper_api = real_housekeeper_api
 
     # Make sure the bundle was not present in hk
     assert not rnafusion_context.housekeeper_api.bundle(case_id)
 
     # Make sure analysis not already stored in status_db
-    assert not rnafusion_context.status_db.family(case_id).analyses
+    assert not rnafusion_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
 
     # GIVEN that HermesAPI returns a deliverables output
     mocker.patch.object(HermesApi, "convert_deliverables")
     HermesApi.convert_deliverables.return_value = CGDeliverables(**hermes_deliverables)
 
     # WHEN running command
     result = cli_runner.invoke(store, [case_id], obj=rnafusion_context)
     # THEN bundle should be successfully added to HK and STATUSDB
     assert result.exit_code == EXIT_SUCCESS
     assert "Analysis successfully stored in Housekeeper" in caplog.text
     assert "Analysis successfully stored in StatusDB" in caplog.text
-    assert rnafusion_context.status_db.family(case_id).analyses
+    assert rnafusion_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
     assert rnafusion_context.housekeeper_api.bundle(case_id)
 
 
 def test_store_fail(
     cli_runner: CliRunner,
     rnafusion_context: CGConfig,
     real_housekeeper_api: HousekeeperAPI,
@@ -190,35 +188,35 @@
     mocker.patch.object(HermesApi, "convert_deliverables")
     HermesApi.convert_deliverables.return_value = CGDeliverables(**hermes_deliverables)
 
     # GIVEN a mocked config
 
     # Ensure case was successfully picked up by start-available and status set to running
     result = cli_runner.invoke(start_available, ["--dry-run"], obj=rnafusion_context)
-    rnafusion_context.status_db.family(case_id_success).action = "running"
+    rnafusion_context.status_db.get_case_by_internal_id(case_id_success).action = "running"
     rnafusion_context.status_db.commit()
 
     # THEN command exits with 0
     assert result.exit_code == EXIT_SUCCESS
     assert case_id_success in caplog.text
-    assert rnafusion_context.status_db.family(case_id_success).action == "running"
+    assert rnafusion_context.status_db.get_case_by_internal_id(case_id_success).action == "running"
 
     rnafusion_context.housekeeper_api_ = real_housekeeper_api
     rnafusion_context.meta_apis["analysis_api"].housekeeper_api = real_housekeeper_api
 
     # WHEN running command
     result = cli_runner.invoke(store_available, obj=rnafusion_context)
 
     # THEN command exits successfully
     assert result.exit_code == EXIT_SUCCESS
 
     # THEN case id with analysis_finish gets picked up
     assert case_id_success in caplog.text
 
     # THEN case has analyses
-    assert rnafusion_context.status_db.family(case_id_success).analyses
+    assert rnafusion_context.status_db.get_case_by_internal_id(case_id_success).analyses
 
     # THEN bundle can be found in Housekeeper
     assert rnafusion_context.housekeeper_api.bundle(case_id_success)
 
     # THEN bundle added successfully and action set to None
-    assert rnafusion_context.status_db.family(case_id_success).action is None
+    assert rnafusion_context.status_db.get_case_by_internal_id(case_id_success).action is None
```

### Comparing `cg-27.1.9/tests/cli/workflow/rnafusion/test_cli_rnafusion_config_case.py` & `cg-27.2.0/tests/cli/workflow/rnafusion/test_cli_rnafusion_config_case.py`

 * *Files 1% similar despite different names*

```diff
@@ -28,15 +28,15 @@
     rnafusion_context: CGConfig,
     caplog: LogCaptureFixture,
     not_existing_case_id: str,
 ):
     """Test command with invalid case to start with."""
     caplog.set_level(logging.ERROR)
     # GIVEN case_id not in database
-    assert not rnafusion_context.status_db.family(not_existing_case_id)
+    assert not rnafusion_context.status_db.get_case_by_internal_id(internal_id=not_existing_case_id)
     # WHEN running
     result = cli_runner.invoke(config_case, [not_existing_case_id], obj=rnafusion_context)
     # THEN command should NOT successfully call the command it creates
     assert result.exit_code != EXIT_SUCCESS
     # THEN ERROR log should be printed containing invalid case_id
     assert "could not be found in StatusDB!" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/workflow/rnafusion/test_cli_rnafusion_report_deliver.py` & `cg-27.2.0/tests/cli/workflow/rnafusion/test_cli_rnafusion_report_deliver.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 """Tests for the report-deliver cli command"""
 
 import logging
-from pathlib import Path
 
 from _pytest.logging import LogCaptureFixture
 from click.testing import CliRunner
 
 from cg.cli.workflow.rnafusion.base import report_deliver
 from cg.constants import EXIT_SUCCESS
 from cg.models.cg_config import CGConfig
@@ -31,15 +30,15 @@
     caplog: LogCaptureFixture,
     not_existing_case_id: str,
 ):
     """Test command with invalid case to start with."""
     caplog.set_level(logging.WARNING)
 
     # GIVEN case_id not in database
-    assert not rnafusion_context.status_db.family(not_existing_case_id)
+    assert not rnafusion_context.status_db.get_case_by_internal_id(internal_id=not_existing_case_id)
 
     # WHEN running
     result = cli_runner.invoke(report_deliver, [not_existing_case_id], obj=rnafusion_context)
 
     # THEN command should NOT successfully call the command it creates
     assert result.exit_code != EXIT_SUCCESS
```

### Comparing `cg-27.1.9/tests/cli/workflow/rnafusion/test_cli_rnafusion_run.py` & `cg-27.2.0/tests/cli/workflow/rnafusion/test_cli_rnafusion_run.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 """This script tests the run cli command"""
 import logging
-from pathlib import Path
 
 from _pytest.logging import LogCaptureFixture
 from click.testing import CliRunner
 
 from cg.cli.workflow.rnafusion.base import run
 from cg.constants import EXIT_SUCCESS
 from cg.models.cg_config import CGConfig
@@ -26,15 +25,15 @@
     rnafusion_context: CGConfig,
     caplog: LogCaptureFixture,
     not_existing_case_id: str,
 ):
     """Test command with invalid case to start with."""
     caplog.set_level(logging.ERROR)
     # GIVEN case_id not in database
-    assert not rnafusion_context.status_db.family(not_existing_case_id)
+    assert not rnafusion_context.status_db.get_case_by_internal_id(internal_id=not_existing_case_id)
     # WHEN running
     result = cli_runner.invoke(run, [not_existing_case_id], obj=rnafusion_context)
     # THEN command should NOT successfully call the command it creates
     assert result.exit_code != EXIT_SUCCESS
     # THEN ERROR log should be printed containing invalid case_id
     assert not_existing_case_id in caplog.text
     assert "could not be found" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/workflow/rnafusion/test_cli_rnafusion_store_housekeeper.py` & `cg-27.2.0/tests/cli/workflow/rnafusion/test_cli_rnafusion_store_housekeeper.py`

 * *Files 3% similar despite different names*

```diff
@@ -39,15 +39,15 @@
     caplog: LogCaptureFixture,
     not_existing_case_id: str,
 ):
     """Test command with invalid case to start with."""
     caplog.set_level(logging.ERROR)
 
     # GIVEN case_id not in database
-    assert not rnafusion_context.status_db.family(not_existing_case_id)
+    assert not rnafusion_context.status_db.get_case_by_internal_id(internal_id=not_existing_case_id)
 
     # WHEN running
     result = cli_runner.invoke(store_housekeeper, [not_existing_case_id], obj=rnafusion_context)
 
     # THEN command should NOT successfully call the command it creates
     assert result.exit_code != EXIT_SUCCESS
 
@@ -130,28 +130,28 @@
     caplog.set_level(logging.INFO)
     # GIVEN case-id
     case_id: str = rnafusion_case_id
 
     # Make sure nothing is currently stored in Housekeeper
 
     # Make sure  analysis not already stored in StatusDB
-    assert not rnafusion_context.status_db.family(case_id).analyses
+    assert not rnafusion_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
 
     # GIVEN that HermesAPI returns a deliverables output
     mocker.patch.object(HermesApi, "convert_deliverables")
     HermesApi.convert_deliverables.return_value = CGDeliverables(**hermes_deliverables)
 
     # WHEN running command
     result = cli_runner.invoke(store_housekeeper, [case_id], obj=rnafusion_context)
 
     # THEN bundle should be successfully added to HK and StatusDB
     assert result.exit_code == EXIT_SUCCESS
     assert "Analysis successfully stored in Housekeeper" in caplog.text
     assert "Analysis successfully stored in StatusDB" in caplog.text
-    assert rnafusion_context.status_db.family(case_id).analyses
+    assert rnafusion_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
     assert rnafusion_context.meta_apis["analysis_api"].housekeeper_api.bundle(case_id)
 
 
 def test_valid_case_already_added(
     cli_runner,
     mocker,
     hermes_deliverables,
@@ -167,15 +167,15 @@
     case_id: str = rnafusion_case_id
 
     # Make sure nothing is currently stored in Housekeeper
     rnafusion_context.housekeeper_api_: HousekeeperAPI = real_housekeeper_api
     rnafusion_context.meta_apis["analysis_api"].housekeeper_api = real_housekeeper_api
 
     # Make sure  analysis not already stored in ClinicalDB
-    assert not rnafusion_context.status_db.family(case_id).analyses
+    assert not rnafusion_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
     # GIVEN that HermesAPI returns a deliverables output
     mocker.patch.object(HermesApi, "convert_deliverables")
     HermesApi.convert_deliverables.return_value = CGDeliverables(**hermes_deliverables)
 
     # Ensure bundles exist by creating them first
     result_first = cli_runner.invoke(store_housekeeper, [case_id], obj=rnafusion_context)
 
@@ -217,15 +217,15 @@
     mocker.patch.object(HermesApi, "convert_deliverables")
     HermesApi.convert_deliverables.return_value = CGDeliverables(**hermes_deliverables)
 
     # Make sure the bundle was not present in hk
     assert not rnafusion_context.housekeeper_api.bundle(case_id)
 
     # Make sure analysis not already stored in status_db
-    assert not rnafusion_context.status_db.family(case_id).analyses
+    assert not rnafusion_context.status_db.get_case_by_internal_id(internal_id=case_id).analyses
 
     # WHEN running command
     result = cli_runner.invoke(store_housekeeper, [case_id, "--dry-run"], obj=rnafusion_context)
 
     # THEN bundle should not be added to HK nor STATUSDB
     assert result.exit_code == EXIT_SUCCESS
     assert "Dry-run: Housekeeper changes will not be commited" in caplog.text
```

### Comparing `cg-27.1.9/tests/cli/workflow/test_cli_workflow.py` & `cg-27.2.0/tests/cli/workflow/test_cli_workflow.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/cli/workflow/test_cli_workflow_clean.py` & `cg-27.2.0/tests/cli/workflow/test_cli_workflow_clean.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/conftest.py` & `cg-27.2.0/tests/conftest.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,37 +1,37 @@
 """Conftest file for pytest fixtures that needs to be shared for multiple tests."""
 import copy
-import datetime as dt
 import logging
 import os
 import shutil
+from datetime import datetime, timedelta, MAXYEAR
 from pathlib import Path
-from typing import Any, Dict, Generator, List, Tuple
+from typing import Any, Dict, Generator, List, Tuple, Union
 
 import pytest
 from housekeeper.store.models import File, Version
 
 from cg.apps.gens import GensAPI
 from cg.apps.gt import GenotypeAPI
 from cg.apps.hermes.hermes_api import HermesApi
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.constants import FileExtensions, Pipeline
-from cg.constants.constants import FileFormat
+from cg.constants.constants import FileFormat, CaseActions
 from cg.constants.demultiplexing import BclConverter, DemultiplexingDirsAndFiles
 from cg.constants.priority import SlurmQos
 from cg.constants.subject import Gender
 from cg.io.controller import ReadFile
 from cg.meta.rsync import RsyncAPI
 from cg.meta.transfer.external_data import ExternalDataAPI
 from cg.models import CompressionData
 from cg.models.cg_config import CGConfig
 from cg.models.demultiplex.demux_results import DemuxResults
 from cg.models.demultiplex.flow_cell import FlowCell
 from cg.store import Store
-from cg.store.models import Bed, BedVersion, Customer, Organism, User
+from cg.store.models import Bed, BedVersion, Customer, Family, Organism, User
 from tests.mocks.crunchy import MockCrunchyAPI
 from tests.mocks.hk_mock import MockHousekeeperAPI
 from tests.mocks.limsmock import MockLimsAPI
 from tests.mocks.madeline import MockMadelineAPI
 from tests.mocks.osticket import MockOsTicket
 from tests.mocks.process_mock import ProcessMock
 from tests.mocks.scout import MockScoutAPI
@@ -42,47 +42,53 @@
 LOG = logging.getLogger(__name__)
 
 
 # Timestamp fixture
 
 
 @pytest.fixture(name="old_timestamp")
-def fixture_old_timestamp() -> dt.datetime:
+def fixture_old_timestamp() -> datetime:
     """Return a time stamp in date time format."""
-    return dt.datetime(1900, 1, 1)
+    return datetime(1900, 1, 1)
 
 
 @pytest.fixture(name="timestamp")
-def fixture_timestamp() -> dt.datetime:
+def fixture_timestamp() -> datetime:
     """Return a time stamp in date time format."""
-    return dt.datetime(2020, 5, 1)
+    return datetime(2020, 5, 1)
 
 
 @pytest.fixture(name="later_timestamp")
-def fixture_later_timestamp() -> dt.datetime:
+def fixture_later_timestamp() -> datetime:
     """Return a time stamp in date time format."""
-    return dt.datetime(2020, 6, 1)
+    return datetime(2020, 6, 1)
+
+
+@pytest.fixture(name="future_date")
+def fixture_future_date() -> datetime:
+    """Return a distant date in the future for which no events happen later."""
+    return datetime(MAXYEAR, 1, 1, 1, 1, 1)
 
 
 @pytest.fixture(name="timestamp_now")
-def fixture_timestamp_now() -> dt.datetime:
+def fixture_timestamp_now() -> datetime:
     """Return a time stamp of today's date in date time format."""
-    return dt.datetime.now()
+    return datetime.now()
 
 
 @pytest.fixture(name="timestamp_yesterday")
-def fixture_timestamp_yesterday(timestamp_now: dt.datetime) -> dt.datetime:
+def fixture_timestamp_yesterday(timestamp_now: datetime) -> datetime:
     """Return a time stamp of yesterday's date in date time format."""
-    return timestamp_now - dt.timedelta(days=1)
+    return timestamp_now - timedelta(days=1)
 
 
 @pytest.fixture(name="timestamp_in_2_weeks")
-def fixture_timestamp_in_2_weeks(timestamp_now: dt.datetime) -> dt.datetime:
+def fixture_timestamp_in_2_weeks(timestamp_now: datetime) -> datetime:
     """Return a time stamp 14 days ahead in time."""
-    return timestamp_now + dt.timedelta(days=14)
+    return timestamp_now + timedelta(days=14)
 
 
 # Case fixtures
 
 
 @pytest.fixture(name="slurm_account")
 def fixture_slurm_account() -> str:
@@ -185,75 +191,75 @@
     slurm_process = ProcessMock(binary="sbatch")
     slurm_process.set_stdout(text=str(sbatch_job_number))
     return slurm_process
 
 
 @pytest.fixture(name="analysis_family_single_case")
 def fixture_analysis_family_single(
-    case_id: str, family_name: str, sample_id: str, ticket: str
+    case_id: str, family_name: str, sample_id: str, ticket_id: str
 ) -> dict:
     """Build an example case."""
     return {
         "name": family_name,
         "internal_id": case_id,
         "data_analysis": str(Pipeline.MIP_DNA),
         "application_type": "wgs",
         "panels": ["IEM", "EP"],
-        "tickets": ticket,
+        "tickets": ticket_id,
         "samples": [
             {
                 "name": "proband",
                 "sex": Gender.MALE,
                 "internal_id": sample_id,
                 "status": "affected",
-                "original_ticket": ticket,
+                "original_ticket": ticket_id,
                 "reads": 5000000000,
                 "capture_kit": "GMSmyeloid",
             }
         ],
     }
 
 
 @pytest.fixture(name="analysis_family")
-def fixture_analysis_family(case_id: str, family_name: str, sample_id: str, ticket: str) -> dict:
+def fixture_analysis_family(case_id: str, family_name: str, sample_id: str, ticket_id: str) -> dict:
     """Return a dictionary with information from a analysis case."""
     return {
         "name": family_name,
         "internal_id": case_id,
         "data_analysis": str(Pipeline.MIP_DNA),
         "application_type": "wgs",
-        "tickets": ticket,
+        "tickets": ticket_id,
         "panels": ["IEM", "EP"],
         "samples": [
             {
                 "name": "child",
                 "sex": Gender.MALE,
                 "internal_id": sample_id,
                 "father": "ADM2",
                 "mother": "ADM3",
                 "status": "affected",
-                "original_ticket": ticket,
+                "original_ticket": ticket_id,
                 "reads": 5000000,
                 "capture_kit": "GMSmyeloid",
             },
             {
                 "name": "father",
                 "sex": Gender.MALE,
                 "internal_id": "ADM2",
                 "status": "unaffected",
-                "original_ticket": ticket,
+                "original_ticket": ticket_id,
                 "reads": 6000000,
                 "capture_kit": "GMSmyeloid",
             },
             {
                 "name": "mother",
                 "sex": Gender.FEMALE,
                 "internal_id": "ADM3",
                 "status": "unaffected",
-                "original_ticket": ticket,
+                "original_ticket": ticket_id,
                 "reads": 7000000,
                 "capture_kit": "GMSmyeloid",
             },
         ],
     }
 
 
@@ -396,25 +402,25 @@
 def madeline_api(madeline_output) -> MockMadelineAPI:
     """madeline_api fixture."""
     _api = MockMadelineAPI()
     _api.set_outpath(madeline_output)
     return _api
 
 
-@pytest.fixture(name="ticket", scope="session")
+@pytest.fixture(name="ticket_id", scope="session")
 def fixture_ticket_number() -> str:
     """Return a ticket number for testing."""
     return "123456"
 
 
 @pytest.fixture(name="osticket")
-def fixture_os_ticket(ticket: str) -> MockOsTicket:
+def fixture_os_ticket(ticket_id: str) -> MockOsTicket:
     """Return a api that mock the os ticket api."""
     api = MockOsTicket()
-    api.set_ticket_nr(ticket)
+    api.set_ticket_nr(ticket_id)
     return api
 
 
 # Files fixtures
 
 
 # Common file fixtures
@@ -811,38 +817,44 @@
 def fixture_root_path(project_dir: Path) -> Path:
     """Return the path to a hk bundles dir."""
     _root_path = project_dir / "bundles"
     _root_path.mkdir(parents=True, exist_ok=True)
     return _root_path
 
 
+@pytest.fixture(name="hk_bundle_sample_path")
+def fixture_hk_bundle_sample_path(sample_id: str, timestamp: datetime) -> Path:
+    """Return the relative path to a HK bundle mock sample."""
+    return Path(sample_id, timestamp.strftime("%Y-%m-%d"))
+
+
 @pytest.fixture(name="hk_bundle_data")
-def fixture_hk_bundle_data(case_id: str, bed_file: Path, timestamp: dt.datetime) -> Dict[str, Any]:
+def fixture_hk_bundle_data(case_id: str, bed_file: Path, timestamp: datetime) -> Dict[str, Any]:
     """Return some bundle data for Housekeeper."""
     return {
         "name": case_id,
         "created": timestamp,
         "expires": timestamp,
         "files": [{"path": bed_file.as_posix(), "archive": False, "tags": ["bed", "sample"]}],
     }
 
 
 @pytest.fixture(name="sample_hk_bundle_no_files")
-def fixture_sample_hk_bundle_no_files(sample_id: str, timestamp: dt.datetime) -> dict:
+def fixture_sample_hk_bundle_no_files(sample_id: str, timestamp: datetime) -> dict:
     """Create a complete bundle mock for testing compression."""
     return {
         "name": sample_id,
         "created": timestamp,
         "expires": timestamp,
         "files": [],
     }
 
 
 @pytest.fixture(name="case_hk_bundle_no_files")
-def fixture_case_hk_bundle_no_files(case_id: str, timestamp: dt.datetime) -> dict:
+def fixture_case_hk_bundle_no_files(case_id: str, timestamp: datetime) -> dict:
     """Create a complete bundle mock for testing compression."""
     return {
         "name": case_id,
         "created": timestamp,
         "expires": timestamp,
         "files": [],
     }
@@ -861,15 +873,15 @@
     first_fastq = compression_object.fastq_first
     second_fastq = compression_object.fastq_second
     for fastq_file in [first_fastq, second_fastq]:
         fastq_file.touch()
         # We need to set the time to an old date
         # Create a older date
         # Convert the date to a float
-        before_timestamp = dt.datetime.timestamp(dt.datetime(2020, 1, 1))
+        before_timestamp = datetime.timestamp(datetime(2020, 1, 1))
         # Update the utime so file looks old
         os.utime(fastq_file, (before_timestamp, before_timestamp))
         fastq_file_info = {"path": str(fastq_file), "archive": False, "tags": ["fastq"]}
 
         hk_bundle_data["files"].append(fastq_file_info)
     return hk_bundle_data
 
@@ -1108,24 +1120,31 @@
 
 @pytest.fixture(name="invoice_reference")
 def fixture_invoice_reference() -> str:
     """Return an invoice reference."""
     return "ABCDEF"
 
 
+@pytest.fixture(name="prices")
+def fixture_prices() -> Dict[str, int]:
+    """Return dictionary with prices for each priority status."""
+    return {"standard": 10, "priority": 20, "express": 30, "research": 5}
+
+
 @pytest.fixture(name="base_store")
 def fixture_base_store(
     apptag_rna: str,
     bed_name: str,
     bed_version_short_name: str,
     collaboration_id: str,
     customer_id: str,
     invoice_address: str,
     invoice_reference: str,
     store: Store,
+    prices: Dict[str, int],
 ) -> Store:
     """Setup and example store."""
     collaboration = store.add_collaboration(internal_id=collaboration_id, name=collaboration_id)
 
     store.add_commit(collaboration)
     customers: List[Customer] = []
     customer_map: Dict[str, str] = {
@@ -1247,17 +1266,18 @@
             percent_reads_guaranteed=75,
             target_reads=10,
         ),
     ]
 
     store.add_commit(applications)
 
-    prices = {"standard": 10, "priority": 20, "express": 30, "research": 5}
     versions = [
-        store.add_version(application, 1, valid_from=dt.datetime.now(), prices=prices)
+        store.add_application_version(
+            application=application, version=1, valid_from=datetime.now(), prices=prices
+        )
         for application in applications
     ]
     store.add_commit(versions)
 
     beds: List[Bed] = [store.add_bed(name=bed_name)]
     store.add_commit(beds)
     bed_versions: List[BedVersion] = [
@@ -1277,41 +1297,53 @@
     yield store
 
 
 @pytest.fixture()
 def sample_store(base_store: Store) -> Store:
     """Populate store with samples."""
     new_samples = [
-        base_store.add_sample("ordered", sex=Gender.MALE),
-        base_store.add_sample("received", sex=Gender.UNKNOWN, received=dt.datetime.now()),
+        base_store.add_sample(name="ordered", sex=Gender.MALE, internal_id="test_internal_id"),
+        base_store.add_sample(name="received", sex=Gender.UNKNOWN, received=datetime.now()),
         base_store.add_sample(
-            "received-prepared",
+            name="received-prepared",
             sex=Gender.UNKNOWN,
-            received=dt.datetime.now(),
-            prepared_at=dt.datetime.now(),
+            received=datetime.now(),
+            prepared_at=datetime.now(),
         ),
         base_store.add_sample("external", sex=Gender.FEMALE, external=True),
         base_store.add_sample(
-            "external-received", sex=Gender.FEMALE, received=dt.datetime.now(), external=True
+            name="external-received", sex=Gender.FEMALE, received=datetime.now(), external=True
         ),
         base_store.add_sample(
-            "sequenced",
+            name="sequenced",
             sex=Gender.MALE,
-            received=dt.datetime.now(),
-            prepared_at=dt.datetime.now(),
-            sequenced_at=dt.datetime.now(),
+            received=datetime.now(),
+            prepared_at=datetime.now(),
+            sequenced_at=datetime.now(),
             reads=(310 * 1000000),
         ),
         base_store.add_sample(
-            "sequenced-partly",
+            name="sequenced-partly",
             sex=Gender.MALE,
-            received=dt.datetime.now(),
-            prepared_at=dt.datetime.now(),
+            received=datetime.now(),
+            prepared_at=datetime.now(),
             reads=(250 * 1000000),
         ),
+        base_store.add_sample(
+            name="to-deliver",
+            sex=Gender.MALE,
+            sequenced_at=datetime.now(),
+        ),
+        base_store.add_sample(
+            name="delivered",
+            sex=Gender.MALE,
+            sequenced_at=datetime.now(),
+            delivered_at=datetime.now(),
+            no_invoice=False,
+        ),
     ]
     customer: Customer = (base_store.get_customers())[0]
     external_app = base_store.get_application_by_tag("WGXCUSC000").versions[0]
     wgs_app = base_store.get_application_by_tag("WGSPCFC030").versions[0]
     for sample in new_samples:
         sample.customer = customer
         sample.application_version = external_app if "external" in sample.name else wgs_app
@@ -1679,57 +1711,60 @@
     cg_config = CGConfig(**context_config)
     cg_config.status_db_ = base_store
     cg_config.housekeeper_api_ = housekeeper_api
     return cg_config
 
 
 @pytest.fixture(name="case_id_with_single_sample")
-def case_id_with_single_sample():
+def fixture_case_id_with_single_sample():
     """Return a case id that should only be associated with one sample."""
     return "exhaustedcrocodile"
 
 
 @pytest.fixture(name="case_id_with_multiple_samples")
-def case_id_with_multiple_samples():
+def fixture_case_id_with_multiple_samples():
     """Return a case id that should be associated with multiple samples."""
     return "righteouspanda"
 
 
 @pytest.fixture(name="case_id_without_samples")
-def case_id_without_samples():
+def fixture_case_id_without_samples():
     """Return a case id that should not be associated with any samples."""
     return "confusedtrout"
 
 
 @pytest.fixture(name="sample_id_in_single_case")
-def sample_id_in_single_case():
+def fixture_sample_id_in_single_case():
     """Return a sample id that should be associated with a single case."""
     return "ASM1"
 
 
 @pytest.fixture(name="sample_id_in_multiple_cases")
-def sample_id_in_multiple_cases():
+def fixture_sample_id_in_multiple_cases():
     """Return a sample id that should be associated with multiple cases."""
     return "ASM2"
 
 
 @pytest.fixture(name="store_with_multiple_cases_and_samples")
-def store_with_multiple_cases_and_samples(
+def fixture_store_with_multiple_cases_and_samples(
     case_id_without_samples: str,
     case_id_with_single_sample: str,
     case_id_with_multiple_samples: str,
     sample_id_in_single_case: str,
     sample_id_in_multiple_cases: str,
     case_id: str,
+    ticket_id: str,
     helpers: StoreHelpers,
     store: Store,
 ):
     """Return a store containing multiple cases and samples."""
 
-    helpers.add_case(store=store, internal_id=case_id_without_samples)
+    helpers.add_case(
+        store=store, internal_id=case_id_without_samples, ticket=ticket_id, action="running"
+    )
     helpers.add_case_with_samples(
         base_store=store, case_id=case_id_with_multiple_samples, nr_samples=5
     )
 
     case_samples: List[Tuple[str, str]] = [
         (case_id_with_multiple_samples, sample_id_in_multiple_cases),
         (case_id, sample_id_in_multiple_cases),
@@ -1740,23 +1775,23 @@
         case_id, sample_id = case_sample
         helpers.add_case_with_sample(base_store=store, case_id=case_id, sample_id=sample_id)
 
     yield store
 
 
 @pytest.fixture(name="store_with_panels")
-def store_with_panels(store: Store, helpers: StoreHelpers):
+def fixture_store_with_panels(store: Store, helpers: StoreHelpers):
     helpers.ensure_panel(store=store, panel_abbreviation="panel1", customer_id="cust000")
     helpers.ensure_panel(store=store, panel_abbreviation="panel2", customer_id="cust000")
     helpers.ensure_panel(store=store, panel_abbreviation="panel3", customer_id="cust000")
     yield store
 
 
 @pytest.fixture(name="store_with_organisms")
-def store_with_organisms(store: Store, helpers: StoreHelpers) -> Store:
+def fixture_store_with_organisms(store: Store, helpers: StoreHelpers) -> Store:
     """Return a store with multiple organisms."""
 
     organism_details = [
         ("organism_1", "Organism 1"),
         ("organism_2", "Organism 2"),
         ("organism_3", "Organism 3"),
     ]
@@ -1767,21 +1802,21 @@
         organisms.append(organism)
 
     store.add_commit(organisms)
     yield store
 
 
 @pytest.fixture(name="non_existent_email")
-def non_existent_email():
+def fixture_non_existent_email():
     """Return email not associated with any entity."""
     return "non_existent_email@example.com"
 
 
 @pytest.fixture(name="non_existent_id")
-def non_existent_id():
+def fixture_non_existent_id():
     """Return id not associated with any entity."""
     return "non_existent_entity_id"
 
 
 @pytest.fixture(name="store_with_users")
 def fixture_store_with_users(store: Store, helpers: StoreHelpers) -> Store:
     """Return a store with multiple users."""
@@ -1796,7 +1831,49 @@
 
     for email, name, is_admin in user_details:
         store.add_user(customer=customer, email=email, name=name, is_admin=is_admin)
 
     store.commit()
 
     yield store
+
+
+@pytest.fixture(name="store_with_cases_and_customers")
+def fixture_store_with_cases_and_customers(store: Store, helpers: StoreHelpers) -> Store:
+    """Return a store with cases and customers."""
+
+    customer_details: List[Tuple[str, str, bool]] = [
+        ("cust000", "Customer 1", True),
+        ("cust001", "Customer 2", False),
+        ("cust002", "Customer 3", True),
+    ]
+    customers = []
+
+    for customer_id, customer_name, scout_access in customer_details:
+        customer: Customer = helpers.ensure_customer(
+            store=store,
+            customer_id=customer_id,
+            customer_name=customer_name,
+            scout_access=scout_access,
+        )
+        customers.append(customer)
+
+    case_details: List[Tuple[str, str, Pipeline, CaseActions, Customer]] = [
+        ("case 1", "flyingwhale", Pipeline.BALSAMIC, CaseActions.RUNNING, customers[0]),
+        ("case 2", "swimmingtiger", Pipeline.FLUFFY, CaseActions.ANALYZE, customers[0]),
+        ("case 3", "sadbaboon", Pipeline.SARS_COV_2, CaseActions.HOLD, customers[1]),
+        ("case 4", "funkysloth", Pipeline.MIP_DNA, CaseActions.ANALYZE, customers[1]),
+        ("case 5", "deadparrot", Pipeline.MICROSALT, CaseActions.RUNNING, customers[2]),
+        ("case 6", "anxiousbeetle", Pipeline.DEMULTIPLEX, CaseActions.RUNNING, customers[2]),
+    ]
+
+    for case_name, case_id, pipeline, action, customer in case_details:
+        helpers.ensure_case(
+            store=store,
+            case_name=case_name,
+            case_id=case_id,
+            data_analysis=pipeline.value,
+            action=action.value,
+            customer=customer,
+        )
+    store.commit()
+    yield store
```

### Comparing `cg-27.1.9/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/runParameters.xml` & `cg-27.2.0/tests/fixtures/DEMUX/160219_D00410_0217_AHJKMYBCXX/runParameters.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/analysis/microsalt/ACC11111_qc_fail/ACC11111_qc_fail.json` & `cg-27.2.0/tests/fixtures/analysis/microsalt/ACC11111_qc_fail/ACC11111_qc_fail.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/analysis/microsalt/ACC22222_qc_pass/ACC22222_qc_pass.json` & `cg-27.2.0/tests/fixtures/analysis/microsalt/ACC22222_qc_pass/ACC22222_qc_pass.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/analysis/sample_coverage.bed` & `cg-27.2.0/tests/fixtures/analysis/sample_coverage.bed`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/balsamic/case/config.json` & `cg-27.2.0/tests/fixtures/apps/balsamic/case/config.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/balsamic/case/metadata.yml` & `cg-27.2.0/tests/fixtures/apps/balsamic/case/metadata.yml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/balsamic/case/metrics_deliverables.yaml` & `cg-27.2.0/tests/fixtures/apps/balsamic/case/metrics_deliverables.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/crunchy/spring_metadata.json` & `cg-27.2.0/tests/fixtures/apps/crunchy/spring_metadata.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/201203_A00689_0200_AHVKJCDRXX/SampleSheet.csv` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/201203_A00689_0200_AHVKJCDRXX/SampleSheet.csv`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/SampleSheetS2_Bcl2Fastq.csv` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/SampleSheetS2_Bcl2Fastq.csv`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/SampleSheetS2_Dragen.csv` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/SampleSheetS2_Dragen.csv`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/ConversionStats.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/ConversionStats.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/DemultiplexingStats.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/DemultiplexingStats.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/Reports/RunInfo.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/211101_A00187_0615_AHLG5GDRXY/Unaligned/Reports/RunInfo.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/fastq_run_R1_001.fastq.gz` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/fastq_run_R1_001.fastq.gz`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/fastq_run_R2_001.fastq.gz` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs/fastq/fastq_run_R2_001.fastq.gz`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/ConversionStats.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/ConversionStats.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/DemultiplexingStats.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/demultiplexed-runs-unfinished/201203_A00689_0200_AHVKJCDRXX/Unaligned/Stats/DemultiplexingStats.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/HLG5GDRXY_demultiplex.stdout` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/HLG5GDRXY_demultiplex.stdout`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/RunParameters.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/211101_A00187_0615_AHLG5GDRXY/RunParameters.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/bcl2fastq/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/HVKJCDRXX_demultiplex.stderr`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/flowcell-runs/dragen/201203_A00689_0200_AHVKJCDRXX/RunParameters.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/hiseq_run/runParameters.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/hiseq_run/runParameters.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/raw_lims_samples/raw_samplesheet_novaseq.json` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/raw_lims_samples/raw_samplesheet_novaseq.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/runParameters_missing_flowcell_run_field.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/runParameters_missing_flowcell_run_field.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/demultiplexing/unknown_run_parameters.xml` & `cg-27.2.0/tests/fixtures/apps/demultiplexing/unknown_run_parameters.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/fluffy/SampleSheet.csv` & `cg-27.2.0/tests/fixtures/apps/fluffy/SampleSheet.csv`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/fluffy/deliverables.yaml` & `cg-27.2.0/tests/fixtures/apps/fluffy/deliverables.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/madeline/madeline.xml` & `cg-27.2.0/tests/fixtures/apps/madeline/madeline.xml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/case_metrics_deliverables.yaml` & `cg-27.2.0/tests/fixtures/apps/mip/case_metrics_deliverables.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/dna/store/case_config.yaml` & `cg-27.2.0/tests/fixtures/apps/mip/dna/store/case_config.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/dna/store/case_id_deliverables.yaml` & `cg-27.2.0/tests/fixtures/apps/mip/dna/store/case_id_deliverables.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/dna/store/case_qc_sample_info.yaml` & `cg-27.2.0/tests/fixtures/apps/mip/dna/store/case_qc_sample_info.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/dna/store/yellowhog_clinical_selected.vcf` & `cg-27.2.0/tests/fixtures/apps/mip/dna/store/yellowhog_clinical_selected.vcf`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/rna/case_config.yaml` & `cg-27.2.0/tests/fixtures/apps/mip/rna/case_config.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/rna/case_qc_sampleinfo.yaml` & `cg-27.2.0/tests/fixtures/apps/mip/rna/case_qc_sampleinfo.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/rna/store/bundle_data.yaml` & `cg-27.2.0/tests/fixtures/apps/mip/rna/store/bundle_data.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/rna/store/case_config.yaml` & `cg-27.2.0/tests/fixtures/apps/mip/rna/store/case_config.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/rna/store/case_id_deliverables.yaml` & `cg-27.2.0/tests/fixtures/apps/mip/rna/store/case_id_deliverables.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/mip/rna/store/case_qc_sample_info.yaml` & `cg-27.2.0/tests/fixtures/apps/mip/rna/store/case_qc_sample_info.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/scout/643594.config.yaml` & `cg-27.2.0/tests/fixtures/apps/scout/643594.config.yaml`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/scout/case_export.json` & `cg-27.2.0/tests/fixtures/apps/scout/case_export.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/scout/export_causatives.json` & `cg-27.2.0/tests/fixtures/apps/scout/export_causatives.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/scout/none_case_export.json` & `cg-27.2.0/tests/fixtures/apps/scout/none_case_export.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/scout/other_sex_case.json` & `cg-27.2.0/tests/fixtures/apps/scout/other_sex_case.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/scout/panel_export.bed` & `cg-27.2.0/tests/fixtures/apps/scout/panel_export.bed`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/apps/scout/panel_export.csv` & `cg-27.2.0/tests/fixtures/apps/scout/panel_export.csv`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/cgweb_orders/balsamic.json` & `cg-27.2.0/tests/fixtures/cgweb_orders/balsamic.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/cgweb_orders/fastq.json` & `cg-27.2.0/tests/fixtures/cgweb_orders/fastq.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/cgweb_orders/metagenome.json` & `cg-27.2.0/tests/fixtures/cgweb_orders/metagenome.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/cgweb_orders/microsalt.json` & `cg-27.2.0/tests/fixtures/cgweb_orders/microsalt.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/cgweb_orders/mip.json` & `cg-27.2.0/tests/fixtures/cgweb_orders/mip.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/cgweb_orders/mip_rna.json` & `cg-27.2.0/tests/fixtures/cgweb_orders/mip_rna.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/cgweb_orders/rml.json` & `cg-27.2.0/tests/fixtures/cgweb_orders/rml.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/cgweb_orders/sarscov2.json` & `cg-27.2.0/tests/fixtures/cgweb_orders/sarscov2.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/data/SampleSheet.csv` & `cg-27.2.0/tests/fixtures/data/SampleSheet.csv`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/data/cgfixture.db` & `cg-27.2.0/tests/fixtures/data/cgfixture.db`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/data/hkstore.db` & `cg-27.2.0/tests/fixtures/data/hkstore.db`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/io/example_json.json` & `cg-27.2.0/tests/fixtures/io/example_json.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/1508.27.balsamic.xlsx` & `cg-27.2.0/tests/fixtures/orderforms/1508.27.balsamic.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/1508.27.balsamic_qc.xlsx` & `cg-27.2.0/tests/fixtures/orderforms/1508.27.balsamic_qc.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/1508.27.balsamic_umi.xlsx` & `cg-27.2.0/tests/fixtures/orderforms/1508.27.balsamic_umi.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/1508.27.fastq.xlsx` & `cg-27.2.0/tests/fixtures/orderforms/1508.27.fastq.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/1508.27.mip.xlsx` & `cg-27.2.0/tests/fixtures/orderforms/1508.27.mip.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/1508.27.mip_rna.xlsx` & `cg-27.2.0/tests/fixtures/orderforms/1508.27.mip_rna.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/1603.11.microbial.xlsx` & `cg-27.2.0/tests/fixtures/orderforms/1603.11.microbial.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/1604.15.rml.xlsx` & `cg-27.2.0/tests/fixtures/orderforms/1604.15.rml.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/1605.10.metagenome.xlsx` & `cg-27.2.0/tests/fixtures/orderforms/1605.10.metagenome.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/2184.7.sarscov2.xlsx` & `cg-27.2.0/tests/fixtures/orderforms/2184.7.sarscov2.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/NIPT-json.json` & `cg-27.2.0/tests/fixtures/orderforms/NIPT-json.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/balsamic_uploaded_json_orderform.json` & `cg-27.2.0/tests/fixtures/orderforms/balsamic_uploaded_json_orderform.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/orderforms/mip_uploaded_json_orderform.json` & `cg-27.2.0/tests/fixtures/orderforms/mip_uploaded_json_orderform.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/report/case_data.json` & `cg-27.2.0/tests/fixtures/report/case_data.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/report/lims_exported_samples.json` & `cg-27.2.0/tests/fixtures/report/lims_exported_samples.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/report/lims_family.json` & `cg-27.2.0/tests/fixtures/report/lims_family.json`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/store/api/application_versions.xlsx` & `cg-27.2.0/tests/fixtures/store/api/application_versions.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/fixtures/store/api/applications.xlsx` & `cg-27.2.0/tests/fixtures/store/api/applications.xlsx`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/io/conftest.py` & `cg-27.2.0/tests/io/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/io/test_io_controller.py` & `cg-27.2.0/tests/io/test_io_controller.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/io/test_io_json.py` & `cg-27.2.0/tests/io/test_io_json.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/io/test_io_yaml.py` & `cg-27.2.0/tests/io/test_io_yaml.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/backup/conftest.py` & `cg-27.2.0/tests/meta/backup/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/backup/test_meta_backup.py` & `cg-27.2.0/tests/meta/backup/test_meta_backup.py`

 * *Files 0% similar despite different names*

```diff
@@ -208,15 +208,14 @@
         encryption_api=mock.Mock(),
         encrypt_dir=cg_context.backup.encrypt_dir.dict(),
         status=mock_store,
         tar_api=mock_tar,
         pdc_api=mock.Mock(),
         root_dir=cg_context.backup.root.dict(),
     )
-    # breakpoint()
 
     # WHEN no flow cell is specified, but a flow cell in status-db has the status "requested"
     mock_flow_cell.status = FlowCellStatus.REQUESTED
     mock_flow_cell.sequencer_type = Sequencers.NOVASEQ
     backup_api.get_first_flow_cell.return_value = mock_flow_cell
     backup_api.check_processing.return_value = True
     backup_api.get_archived_encryption_key_path.return_value = archived_key
```

### Comparing `cg-27.1.9/tests/meta/backup/test_meta_pdc.py` & `cg-27.2.0/tests/meta/backup/test_meta_pdc.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/clean/conftest.py` & `cg-27.2.0/tests/meta/clean/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/clean/test_clean_demultiplexed_runs.py` & `cg-27.2.0/tests/meta/clean/test_clean_demultiplexed_runs.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/clean/test_clean_flow_cell_run_directories.py` & `cg-27.2.0/tests/meta/clean/test_clean_flow_cell_run_directories.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 """Tests for cleaning flow cell run directories using
 cg.meta.clean.flow_cell_run_directories.RunDirFlowCell."""
 from unittest import mock
 
 from cg.constants.demultiplexing import DemultiplexingDirsAndFiles
 from cg.constants.housekeeper_tags import SequencingFileTag
 from cg.meta.clean.flow_cell_run_directories import RunDirFlowCell
+from tests.mocks.hk_mock import MockBundle
 
 
 @mock.patch("cg.apps.housekeeper.hk.HousekeeperAPI")
 @mock.patch("cg.store.Store")
 def test_age(
     mock_statusdb,
     mock_hk,
@@ -86,7 +87,28 @@
 
     # THEN the sample sheet should be be added to Housekeeper
     flow_cell.hk.add_and_include_file_to_latest_version.assert_called_once_with(
         bundle_name=flow_cell.id,
         file=flow_cell.sample_sheet_path,
         tags=[SequencingFileTag.ARCHIVED_SAMPLE_SHEET, flow_cell.id],
     )
+
+
+@mock.patch("cg.apps.housekeeper.hk.HousekeeperAPI")
+@mock.patch("cg.store.Store")
+def test_archive_sample_sheet_included(mock_statusdb, mock_hk, flow_cell_path, novaseq_dir, caplog):
+    """Test archive of a sample sheet when it has been already included in HK."""
+
+    # GIVEN a flow cell
+    flow_cell: RunDirFlowCell = RunDirFlowCell(flow_cell_path, mock_statusdb, mock_hk)
+
+    # GIVEN a sample sheet connected to the flow cell
+    flow_cell.sample_sheet_path = novaseq_dir / DemultiplexingDirsAndFiles.SAMPLE_SHEET_FILE_NAME
+
+    # GIVEN the sample sheet does exist in Housekeeper
+    mock_hk.get_file_from_latest_version.return_value = True
+
+    # WHEN archiving the sample sheet
+    flow_cell.archive_sample_sheet()
+
+    # THEN the sample sheet should not be included again
+    assert "Sample sheet already included!" in caplog.text
```

### Comparing `cg-27.1.9/tests/meta/compress/conftest.py` & `cg-27.2.0/tests/meta/compress/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/compress/test_clean_fastq.py` & `cg-27.2.0/tests/meta/compress/test_clean_fastq.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,30 +1,35 @@
 """Tests for cleaning FASTQ files."""
 import logging
 from pathlib import Path
-from typing import Generator, Dict
+from typing import Generator, Dict, List
 
 import pytest
+from _pytest.logging import LogCaptureFixture
 
-from housekeeper.store.models import Version
+from housekeeper.store.models import Version, File
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.constants import SequencingFileTag
 from cg.meta.compress import files
+from cg.models import CompressionData
 from tests.cli.compress.conftest import MockCompressAPI
 from tests.meta.compress.conftest import MockCompressionData
 from tests.store_helpers import StoreHelpers
 
 
 @pytest.mark.compress_meta
 def test_remove_fastqs(
-    compress_api: MockCompressAPI, compression_object: MockCompressionData, caplog
+    compress_api: MockCompressAPI,
+    compression_object: MockCompressionData,
+    caplog: LogCaptureFixture,
 ):
     """Test remove_fastq method."""
     caplog.set_level(logging.DEBUG)
+
     # GIVEN existing FASTQ and flag file
     fastq_first: Path = compression_object.fastq_first
     fastq_second: Path = compression_object.fastq_second
     fastq_first.touch()
     fastq_second.touch()
     compression_object.spring_metadata_path.touch()
 
@@ -33,63 +38,77 @@
 
     # THEN assert that the FASTQ-files are deleted
     assert not fastq_first.exists()
     assert not fastq_second.exists()
 
     # THEN assert that the flag file is still there since this holds important information
     assert compression_object.spring_metadata_path.exists()
-    expected_output = f"Will remove {fastq_first} and {fastq_second}"
+    expected_output: str = f"Will remove {fastq_first} and {fastq_second}"
     assert expected_output in caplog.text
     assert "FASTQ files removed" in caplog.text
 
 
 @pytest.mark.compress_meta
 def test_update_hk_fastq(
+    root_path: Path,
     real_housekeeper_api: Generator[HousekeeperAPI, None, None],
     compress_hk_fastq_bundle: dict,
+    compression_files: MockCompressionData,
     compress_api: MockCompressAPI,
     helpers: StoreHelpers,
 ):
     """Test to update the FASTQ and SPRING paths in Housekeeper after completed compression."""
+
     # GIVEN real Housekeeper API populated with a Housekeeper bundle
     sample_id: str = compress_hk_fastq_bundle["name"]
     hk_api: Generator[HousekeeperAPI, None, None] = real_housekeeper_api
     helpers.ensure_hk_bundle(hk_api, compress_hk_fastq_bundle)
     compress_api.hk_api = hk_api
 
-    # GIVEN that there are some FASTQ files in housekeeper
-    hk_fastq_files = list(hk_api.files(tags=[SequencingFileTag.FASTQ]))
+    # GIVEN that there are FASTQ files in Housekeeper
+    hk_fastq_files: list = list(hk_api.files(tags=[SequencingFileTag.FASTQ]))
     assert hk_fastq_files
-    # GIVEN that there are no SPRING files in housekeeper
-    hk_spring_files = list(hk_api.files(tags=[SequencingFileTag.SPRING]))
-    assert not hk_spring_files
-    hk_fastq_flag_files = list(hk_api.files(tags=[SequencingFileTag.SPRING_METADATA]))
-    assert not hk_fastq_flag_files
-    # GIVEN a housekeeper version
+
+    # GIVEN that the SPRING files exist in disk but has been not added to Housekeeper
+    assert compression_files.spring_file.exists()
+    assert compression_files.spring_metadata_file.exists()
+    hk_spring_files: list = list(hk_api.files(tags=[SequencingFileTag.SPRING]))
+    hk_spring_metadata_files: list = list(hk_api.files(tags=[SequencingFileTag.SPRING_METADATA]))
+    for spring_file in [hk_spring_files, hk_spring_metadata_files]:
+        assert not spring_file
+
+    # GIVEN a Housekeeper version and a compression object
     hk_version: Version = compress_api.hk_api.get_latest_bundle_version(bundle_name=sample_id)
     fastq: Dict[str, dict] = files.get_fastq_files(sample_id=sample_id, version_obj=hk_version)
-    run = list(fastq.keys())[0]
-    compression = fastq[run]["compression_data"]
+    run: str = list(fastq.keys())[0]
+    compression: CompressionData = fastq[run]["compression_data"]
 
-    # WHEN updating hk
+    # WHEN updating Housekeeper with compressed FASTQ files
     compress_api.update_fastq_hk(
         sample_id=sample_id,
         compression_obj=compression,
         hk_fastq_first=fastq[run]["hk_first"],
         hk_fastq_second=fastq[run]["hk_second"],
     )
 
+    # THEN assert that the SPRING files have been added to Housekeeper
+    hk_spring_files: List[File] = list(real_housekeeper_api.files(tags=[SequencingFileTag.SPRING]))
+    hk_spring_metadata_files: List[File] = list(
+        real_housekeeper_api.files(tags=[SequencingFileTag.SPRING_METADATA])
+    )
+    for spring_file in [hk_spring_files, hk_spring_metadata_files]:
+        assert spring_file
+
+    # THEN assert that the SPRING files have been added to bundles directory
+    for spring_file in [hk_spring_files[0].path, hk_spring_metadata_files[0].path]:
+        assert Path(root_path, spring_file).exists()
+
     # THEN assert that the FASTQ files are removed from Housekeeper
-    hk_fastq_files = list(hk_api.files(tags=[SequencingFileTag.FASTQ]))
+    hk_fastq_files: List[File] = list(hk_api.files(tags=[SequencingFileTag.FASTQ]))
     assert not hk_fastq_files
-    # THEN assert that the SPRING file and the metadata file is added to Housekeeper
-    hk_spring_files = list(real_housekeeper_api.files(tags=[SequencingFileTag.SPRING]))
-    assert hk_spring_files
-    hk_fastq_flag_files = list(real_housekeeper_api.files(tags=[SequencingFileTag.SPRING_METADATA]))
-    assert hk_fastq_flag_files
 
 
 @pytest.mark.compress_meta
 @pytest.mark.clean_fastq
 def test_cli_clean_fastqs_removed(
     populated_compress_fastq_api: MockCompressAPI,
     compression_files: MockCompressionData,
@@ -169,10 +188,11 @@
     assert crunchy_flag_file.exists()
 
     # WHEN running the clean command
     populated_compress_fastq_api.clean_fastq(sample)
 
     # THEN assert SPRING file exists
     assert spring_file.exists()
+
     # THEN assert that the FASTQ files are NOT removed
     assert fastq_first.exists()
     assert fastq_second.exists()
```

### Comparing `cg-27.1.9/tests/meta/compress/test_compress_files.py` & `cg-27.2.0/tests/meta/compress/test_compress_files.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/compress/test_compress_meta_fastq.py` & `cg-27.2.0/tests/meta/compress/test_compress_meta_fastq.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/compress/test_decompress_spring_meta.py` & `cg-27.2.0/tests/meta/compress/test_decompress_spring_meta.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/compress/test_meta_compress_update_hk.py` & `cg-27.2.0/tests/meta/compress/test_meta_compress_update_hk.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,14 +1,21 @@
-"""Tests for meta compress functionality that updates housekeeper"""
-
-import logging
+"""Tests for meta compress functionality that updates housekeeper."""
 from pathlib import Path
+from typing import Generator
+
+from housekeeper.store.models import Version
 
+from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.constants import HK_FASTQ_TAGS
 from cg.meta.compress import CompressAPI, files
+from cg.store import Store
+from cg.store.models import Sample
+from tests.cli.conftest import MockCompressAPI
+from tests.meta.compress.conftest import MockCompressionData
+from tests.store_helpers import StoreHelpers
 
 
 def test_get_flow_cell_id_when_hiseqx(
     compress_api: CompressAPI, flow_cell_id: str, flow_cell_full_name: str
 ):
     """Test extracting the flow cell id from a fastq file path."""
 
@@ -40,86 +47,89 @@
     returned_flow_cell_name: str = compress_api.get_flow_cell_id(fastq_path=fastq_path)
 
     # THEN the flow cell id retrieved should be identical to the flow cell id used
     assert returned_flow_cell_name == flow_cell_id
 
 
 def test_add_fastq_housekeeper_when_no_fastq_in_hk(
-    caplog,
-    compress_api,
-    real_housekeeper_api,
-    decompress_hk_spring_bundle,
-    compression_files,
-    store,
-    helpers,
+    compress_api: MockCompressAPI,
+    real_housekeeper_api: Generator[HousekeeperAPI, None, None],
+    decompress_hk_spring_bundle: dict,
+    compression_files: MockCompressionData,
+    store: Store,
+    helpers: StoreHelpers,
 ):
     """Test adding fastq files to Housekeeper when no fastq files in Housekeeper."""
-    caplog.set_level(logging.INFO)
 
-    # GIVEN real housekeeper api populated with a housekeeper bundle with spring info
-    hk_bundle = decompress_hk_spring_bundle
-    sample_id = hk_bundle["name"]
+    # GIVEN real Housekeeper API populated with a bundle with SPRING metadata
+    hk_bundle: dict = decompress_hk_spring_bundle
+    sample_id: str = hk_bundle["name"]
     helpers.ensure_hk_bundle(real_housekeeper_api, hk_bundle)
-    sample_obj = helpers.add_sample(store, internal_id=sample_id)
+    sample: Sample = helpers.add_sample(store, internal_id=sample_id)
     compress_api.hk_api = real_housekeeper_api
-    # GIVEN that there are no fastq files in HK
-    version_obj = compress_api.hk_api.get_latest_bundle_version(bundle_name=sample_id)
-    file_tags = set()
-    for file_obj in version_obj.files:
+
+    # GIVEN that there are no FASTQ files in HK
+    version: Version = compress_api.hk_api.get_latest_bundle_version(bundle_name=sample_id)
+    file_tags: set = set()
+    for file_obj in version.files:
         for tag in file_obj.tags:
             file_tags.add(tag.name)
     assert not set(HK_FASTQ_TAGS).intersection(file_tags)
 
     # WHEN adding the files to housekeeper
     compress_api.add_fastq_hk(
-        sample_obj=sample_obj,
+        sample_obj=sample,
         fastq_first=compression_files.fastq_first_file,
         fastq_second=compression_files.fastq_second_file,
     )
 
-    # THEN assert that the fastq files where added to HK
-    version_obj = compress_api.hk_api.get_latest_bundle_version(bundle_name=sample_id)
+    # THEN assert that the FASTQ files where added to HK
     file_tags = set()
-    for file_obj in version_obj.files:
+    for file_obj in version.files:
         for tag in file_obj.tags:
             file_tags.add(tag.name)
 
     assert set(HK_FASTQ_TAGS).intersection(file_tags)
 
 
 def test_add_decompressed_fastq(
-    compress_api,
-    real_housekeeper_api,
-    decompress_hk_spring_bundle,
-    compression_files,
-    store,
-    helpers,
+    compress_api: MockCompressAPI,
+    real_housekeeper_api: Generator[HousekeeperAPI, None, None],
+    decompress_hk_spring_bundle: dict,
+    compression_files: MockCompressionData,
+    store: Store,
+    helpers: StoreHelpers,
+    hk_bundle_sample_path: Path,
 ):
     """Test functionality to add decompressed FASTQ files."""
-    # GIVEN real Housekeeper api populated with a Housekeeper bundle with SPRING meta data
-    hk_bundle = decompress_hk_spring_bundle
-    sample_id = hk_bundle["name"]
-    sample = helpers.add_sample(store, internal_id=sample_id)
+
+    # GIVEN real HK API populated with a HK bundle with SPRING info
+    hk_bundle: dict = decompress_hk_spring_bundle
+    sample_id: str = hk_bundle["name"]
+    sample: Sample = helpers.add_sample(store, internal_id=sample_id)
     helpers.ensure_hk_bundle(real_housekeeper_api, hk_bundle)
     compress_api.hk_api = real_housekeeper_api
 
-    # GIVEN that there exists a SPRING archive, spring metadata and unpacked fastqs
-    version = compress_api.hk_api.get_latest_bundle_version(bundle_name=sample_id)
-    fastq_first = compression_files.fastq_first_file
-    fastq_second = compression_files.fastq_second_file
-    spring_file = compression_files.spring_file
-    spring_metadata_file = compression_files.updated_spring_metadata_file
+    # GIVEN that there exists a SPRING archive, spring metadata and unpacked FASTQs
+    version: Version = compress_api.hk_api.get_latest_bundle_version(bundle_name=sample_id)
+    fastq_first: Path = compression_files.fastq_first_file
+    fastq_second: Path = compression_files.fastq_second_file
+    spring_file: Path = compression_files.spring_file
+    spring_metadata_file: Path = compression_files.updated_spring_metadata_file
     assert files.is_file_in_version(version_obj=version, path=spring_file)
     assert files.is_file_in_version(version_obj=version, path=spring_metadata_file)
-
     assert not files.is_file_in_version(version_obj=version, path=fastq_first)
+    assert not files.is_file_in_version(version_obj=version, path=fastq_second)
 
     # WHEN adding decompressed files
-    compress_api.add_decompressed_fastq(sample=sample)
+    was_decompressed: bool = compress_api.add_decompressed_fastq(sample=sample)
 
-    # THEN assert that the files where added
-    version = compress_api.hk_api.get_latest_bundle_version(bundle_name=sample_id)
-    assert files.is_file_in_version(version_obj=version, path=spring_file)
-    assert files.is_file_in_version(version_obj=version, path=spring_metadata_file)
+    # THEN check that the files were actually decompressed
+    assert was_decompressed
 
-    assert files.is_file_in_version(version_obj=version, path=fastq_first)
-    assert files.is_file_in_version(version_obj=version, path=fastq_second)
+    # THEN assert that the FASTQ files have been added with a relative path
+    assert files.is_file_in_version(
+        version_obj=version, path=Path(hk_bundle_sample_path, fastq_first.name)
+    )
+    assert files.is_file_in_version(
+        version_obj=version, path=Path(hk_bundle_sample_path, fastq_second.name)
+    )
```

### Comparing `cg-27.1.9/tests/meta/conftest.py` & `cg-27.2.0/tests/meta/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/deliver/conftest.py` & `cg-27.2.0/tests/meta/deliver/conftest.py`

 * *Files 2% similar despite different names*

```diff
@@ -85,9 +85,11 @@
 ) -> Path:
     """Fixture that returns a customer inbox path with all samples delivered."""
     all_samples_in_inbox.joinpath(analysis_family["samples"][0]["name"], dummy_file_name).unlink()
     return Path(all_samples_in_inbox)
 
 
 @pytest.fixture(name="deliver_api_destination_path")
-def fixture_deliver_api_destination_path(customer_id: str, case_obj: Family, ticket: str) -> Path:
-    return Path(customer_id, INBOX_NAME, ticket, case_obj.name)
+def fixture_deliver_api_destination_path(
+    customer_id: str, case_obj: Family, ticket_id: str
+) -> Path:
+    return Path(customer_id, INBOX_NAME, ticket_id, case_obj.name)
```

### Comparing `cg-27.1.9/tests/meta/deliver/test_deliver_ticket.py` & `cg-27.2.0/tests/meta/deliver/test_deliver_ticket.py`

 * *Files 11% similar despite different names*

```diff
@@ -7,92 +7,92 @@
 from cg.models.cg_config import CGConfig
 from cgmodels.cg.constants import Pipeline
 from cg.store import Store
 from tests.store_helpers import StoreHelpers
 
 
 def test_get_inbox_path(
-    cg_context: CGConfig, customer_id: str, helpers: StoreHelpers, mocker, ticket: str
+    cg_context: CGConfig, customer_id: str, helpers: StoreHelpers, mocker, ticket_id: str
 ):
     """Test to get the path to customer inbox on the HPC."""
     # GIVEN a deliver_ticket API
     deliver_ticket_api = DeliverTicketAPI(config=cg_context)
 
     # GIVEN a case for analysis
     case = helpers.add_case(
         store=cg_context.status_db,
         internal_id="angrybird",
-        name=ticket,
+        name=ticket_id,
         data_analysis=Pipeline.SARS_COV_2,
     )
 
     mocker.patch.object(DeliverTicketAPI, "get_all_cases_from_ticket")
     DeliverTicketAPI.get_all_cases_from_ticket.return_value = [case]
 
     # WHEN running get_inbox_path
-    inbox = deliver_ticket_api.get_inbox_path(ticket=ticket)
+    inbox = deliver_ticket_api.get_inbox_path(ticket=ticket_id)
 
     # THEN a path is returned for cust000 with the folder ticket in the inbox
-    assert inbox.parts[-3:] == (customer_id, INBOX_NAME, ticket)
+    assert inbox.parts[-3:] == (customer_id, INBOX_NAME, ticket_id)
 
 
-def test_check_if_upload_is_needed(cg_context: CGConfig, mocker, ticket: str):
+def test_check_if_upload_is_needed(cg_context: CGConfig, mocker, ticket_id: str):
     """Test if upload is needed when it is needed"""
     # GIVEN a deliver_ticket API
     deliver_ticket_api = DeliverTicketAPI(config=cg_context)
 
     # GIVEN the customer inbox
     mocker.patch.object(DeliverTicketAPI, "get_inbox_path")
     DeliverTicketAPI.get_inbox_path.return_value = Path(
         "th155h0uLdC3R7aNlyNo7eX157f0RsuReaNdIfiTd03St3n0Mg"
     )
 
     # WHEN running check_if_upload_is_needed
-    is_upload_needed = deliver_ticket_api.check_if_upload_is_needed(ticket=ticket)
+    is_upload_needed = deliver_ticket_api.check_if_upload_is_needed(ticket=ticket_id)
 
     # THEN it turns out that upload is needed
     assert is_upload_needed is True
 
 
-def test_check_if_upload_is_needed_part_deux(cg_context: CGConfig, mocker, ticket: str):
+def test_check_if_upload_is_needed_part_deux(cg_context: CGConfig, mocker, ticket_id: str):
     """Test if upload is needed when it is not needed"""
     # GIVEN a deliver_ticket API
     deliver_ticket_api = DeliverTicketAPI(config=cg_context)
 
     # GIVEN the customer inbox
     mocker.patch.object(DeliverTicketAPI, "get_inbox_path")
     DeliverTicketAPI.get_inbox_path.return_value = Path("/")
 
     # WHEN running check_if_upload_is_needed
-    is_upload_needed = deliver_ticket_api.check_if_upload_is_needed(ticket=ticket)
+    is_upload_needed = deliver_ticket_api.check_if_upload_is_needed(ticket=ticket_id)
 
     # THEN it turns out that upload is not needed
     assert is_upload_needed is False
 
 
-def test_generate_date_tag(cg_context: CGConfig, mocker, helpers, ticket: str, timestamp_now):
+def test_generate_date_tag(cg_context: CGConfig, mocker, helpers, ticket_id: str, timestamp_now):
     """Test to generate the date tag."""
     # GIVEN a deliver_ticket API
     deliver_ticket_api = DeliverTicketAPI(config=cg_context)
 
     # GIVEN a case for analysis
     case = helpers.add_case(
         store=cg_context.status_db,
         internal_id="angrybird",
-        name=ticket,
+        name=ticket_id,
         data_analysis=Pipeline.SARS_COV_2,
     )
 
     case.ordered_at = timestamp_now
 
     mocker.patch.object(DeliverTicketAPI, "get_all_cases_from_ticket")
     DeliverTicketAPI.get_all_cases_from_ticket.return_value = [case]
 
     # WHEN running generate_date_tag
-    date = deliver_ticket_api.generate_date_tag(ticket=ticket)
+    date = deliver_ticket_api.generate_date_tag(ticket=ticket_id)
 
     # THEN check that a date was returned
     assert str(timestamp_now) == str(date)
 
 
 def test_sort_files(cg_context: CGConfig):
     """Test to sort files"""
@@ -109,133 +109,133 @@
     sorted_list_of_paths = deliver_ticket_api.sort_files(unsorted_list_of_paths)
 
     # THEN 1.fastq is first in the list
     assert str(sorted_list_of_paths[0]) == "1.fastq"
 
 
 def test_check_if_concatenation_is_needed(
-    cg_context: CGConfig, mocker, helpers, analysis_store: Store, case_id, ticket: str
+    cg_context: CGConfig, mocker, helpers, analysis_store: Store, case_id, ticket_id: str
 ):
     """Test to check if concatenation is needed when it is not needed"""
     # GIVEN a deliver_ticket API
     deliver_ticket_api = DeliverTicketAPI(config=cg_context)
 
     # GIVEN a case object
-    case_obj = analysis_store.family(case_id)
+    case_obj = analysis_store.get_case_by_internal_id(internal_id=case_id)
 
     mocker.patch.object(DeliverTicketAPI, "get_all_cases_from_ticket")
     DeliverTicketAPI.get_all_cases_from_ticket.return_value = [case_obj]
 
     # GIVEN an application tag that is not a micro application
     mocker.patch.object(DeliverTicketAPI, "get_app_tag")
     DeliverTicketAPI.get_app_tag.return_value = "RMLP15S175"
 
     # WHEN running check_if_concatenation_is_needed
-    is_concatenation_needed = deliver_ticket_api.check_if_concatenation_is_needed(ticket=ticket)
+    is_concatenation_needed = deliver_ticket_api.check_if_concatenation_is_needed(ticket=ticket_id)
 
     # THEN concatenation is not needed
     assert is_concatenation_needed is False
 
 
 def test_check_if_concatenation_is_needed_part_deux(
-    cg_context: CGConfig, mocker, helpers, analysis_store: Store, case_id, ticket: str
+    cg_context: CGConfig, mocker, helpers, analysis_store: Store, case_id, ticket_id: str
 ):
     """Test to check if concatenation is needed when it is needed"""
     # GIVEN a deliver_ticket API
     deliver_ticket_api = DeliverTicketAPI(config=cg_context)
 
     # GIVEN a case object
-    case_obj = analysis_store.family(case_id)
+    case_obj = analysis_store.get_case_by_internal_id(internal_id=case_id)
 
     mocker.patch.object(DeliverTicketAPI, "get_all_cases_from_ticket")
     DeliverTicketAPI.get_all_cases_from_ticket.return_value = [case_obj]
 
     # GIVEN an application tag that is a micro application
     mocker.patch.object(DeliverTicketAPI, "get_app_tag")
     DeliverTicketAPI.get_app_tag.return_value = "MWRNXTR003"
 
     # WHEN running check_if_concatenation_is_needed
-    is_concatenation_needed = deliver_ticket_api.check_if_concatenation_is_needed(ticket=ticket)
+    is_concatenation_needed = deliver_ticket_api.check_if_concatenation_is_needed(ticket=ticket_id)
 
     # THEN concatenation is needed
     assert is_concatenation_needed is True
 
 
-def test_get_all_samples_from_ticket(
-    cg_context: CGConfig, mocker, helpers, analysis_store: Store, case_id, ticket: str
+def test_get_samples_from_ticket(
+    cg_context: CGConfig, mocker, helpers, analysis_store: Store, case_id, ticket_id: str
 ):
     """Test to get all samples from a ticket"""
     # GIVEN a deliver_ticket API
     deliver_ticket_api = DeliverTicketAPI(config=cg_context)
 
     # GIVEN a case object
-    case_obj = analysis_store.family(case_id)
+    case_obj = analysis_store.get_case_by_internal_id(internal_id=case_id)
 
     mocker.patch.object(DeliverTicketAPI, "get_all_cases_from_ticket")
     DeliverTicketAPI.get_all_cases_from_ticket.return_value = [case_obj]
 
     # WHEN checking which samples there are in the ticket
-    all_samples = deliver_ticket_api.get_all_samples_from_ticket(ticket=ticket)
+    all_samples: list = deliver_ticket_api.get_samples_from_ticket(ticket=ticket_id)
 
     # THEN concatenation is needed
     assert "child" in all_samples
     assert "father" in all_samples
     assert "mother" in all_samples
 
 
 def test_all_samples_in_cust_inbox(
-    cg_context: CGConfig, mocker, caplog, ticket: str, all_samples_in_inbox
+    cg_context: CGConfig, mocker, caplog, ticket_id: str, all_samples_in_inbox
 ):
     """Test that no samples will be reported as missing when all samples in inbox"""
     caplog.set_level(logging.INFO)
 
     # GIVEN a deliver_ticket API
     deliver_ticket_api = DeliverTicketAPI(config=cg_context)
 
     # GIVEN a path to the customer inbox
     mocker.patch.object(DeliverTicketAPI, "get_inbox_path")
     DeliverTicketAPI.get_inbox_path.return_value = all_samples_in_inbox
 
     # GIVEN a ticket with certain samples
-    mocker.patch.object(DeliverTicketAPI, "get_all_samples_from_ticket")
-    DeliverTicketAPI.get_all_samples_from_ticket.return_value = ["ACC1", "ACC2"]
+    mocker.patch.object(DeliverTicketAPI, "get_samples_from_ticket")
+    DeliverTicketAPI.get_samples_from_ticket.return_value = ["ACC1", "ACC2"]
 
     # WHEN checking if a sample is missing
-    deliver_ticket_api.report_missing_samples(ticket=ticket, dry_run=False)
+    deliver_ticket_api.report_missing_samples(ticket=ticket_id, dry_run=False)
 
     # THEN assert that all files were delivered
     assert "Data has been delivered for all samples" in caplog.text
 
 
 def test_samples_missing_in_inbox(
     analysis_family: dict,
     cg_context: CGConfig,
     mocker,
     caplog,
-    ticket: str,
+    ticket_id: str,
     samples_missing_in_inbox,
 ):
     """Test when samples is missing in customer inbox."""
     caplog.set_level(logging.INFO)
 
     # GIVEN a deliver_ticket API
     deliver_ticket_api = DeliverTicketAPI(config=cg_context)
 
     # GIVEN a path to the customer inbox
     mocker.patch.object(DeliverTicketAPI, "get_inbox_path")
     DeliverTicketAPI.get_inbox_path.return_value = samples_missing_in_inbox
 
     # GIVEN a ticket with certain samples
-    mocker.patch.object(DeliverTicketAPI, "get_all_samples_from_ticket")
-    DeliverTicketAPI.get_all_samples_from_ticket.return_value = [
+    mocker.patch.object(DeliverTicketAPI, "get_samples_from_ticket")
+    DeliverTicketAPI.get_samples_from_ticket.return_value = [
         sample["name"] for sample in analysis_family["samples"]
     ]
 
     # WHEN checking if a sample is missing
-    deliver_ticket_api.report_missing_samples(ticket=ticket, dry_run=False)
+    deliver_ticket_api.report_missing_samples(ticket=ticket_id, dry_run=False)
 
     # THEN assert that a sample that is not missing is not missing
     assert analysis_family["samples"][1]["name"] not in caplog.text
 
     # THEN assert that the empty case folder is not considered as a sample that is missing data
     assert analysis_family["name"] not in caplog.text
```

### Comparing `cg-27.1.9/tests/meta/deliver/test_delivery_api.py` & `cg-27.2.0/tests/meta/deliver/test_delivery_api.py`

 * *Files 2% similar despite different names*

```diff
@@ -70,15 +70,15 @@
     case_hk_bundle_no_files: dict,
     bed_file: Path,
     vcf_file: Path,
     project_dir: Path,
     helpers=StoreHelpers,
 ):
     # GIVEN a store with a case
-    case_obj = analysis_store.family(case_id)
+    case_obj = analysis_store.get_case_by_internal_id(internal_id=case_id)
     assert case_obj.internal_id == case_id
     # GIVEN a delivery api
     deliver_api = DeliverAPI(
         store=analysis_store,
         hk_api=real_housekeeper_api,
         case_tags=[{"case-tag"}],
         sample_tags=[{"sample-tag"}],
@@ -198,15 +198,15 @@
     fastq_delivery_bundle: dict,
     helpers: StoreHelpers,
     mip_delivery_bundle: dict,
     sample_id: str,
 ):
     """Tests the deliver_files method for a sample with enough reads."""
     # GIVEN a case to be delivered and a sample with enough reads
-    case: Family = deliver_api.store.family(internal_id=case_id)
+    case: Family = deliver_api.store.get_case_by_internal_id(internal_id=case_id)
     sample: Sample = deliver_api.store.get_sample_by_internal_id(sample_id)
     helpers.ensure_hk_bundle(deliver_api.hk_api, fastq_delivery_bundle, include=True)
     helpers.ensure_hk_bundle(deliver_api.hk_api, mip_delivery_bundle, include=True)
 
     # WHEN delivering files for the case
     deliver_api.deliver_files(case_obj=case)
 
@@ -222,15 +222,15 @@
     fastq_delivery_bundle: dict,
     helpers: StoreHelpers,
     mip_delivery_bundle: dict,
     sample_id: str,
 ):
     """Tests the deliver_files method for a sample with too few reads."""
     # GIVEN a case to be delivered and a sample with too few reads
-    case: Family = deliver_api.store.family(internal_id=case_id)
+    case: Family = deliver_api.store.get_case_by_internal_id(internal_id=case_id)
     sample: Sample = deliver_api.store.get_sample_by_internal_id(sample_id)
     sample.reads = 1
     helpers.ensure_hk_bundle(deliver_api.hk_api, fastq_delivery_bundle, include=True)
     helpers.ensure_hk_bundle(deliver_api.hk_api, mip_delivery_bundle, include=True)
 
     # WHEN delivering files for the case
     deliver_api.deliver_files(case_obj=case)
@@ -249,15 +249,15 @@
     fastq_delivery_bundle: dict,
     helpers: StoreHelpers,
     mip_delivery_bundle: dict,
     sample_id: str,
 ):
     """Tests the deliver_files method for a sample with too few reads but with override."""
     # GIVEN a case to be delivered and a sample with too few reads
-    case: Family = deliver_api.store.family(internal_id=case_id)
+    case: Family = deliver_api.store.get_case_by_internal_id(internal_id=case_id)
     sample: Sample = deliver_api.store.get_sample_by_internal_id(sample_id)
     sample.reads = 1
     helpers.ensure_hk_bundle(deliver_api.hk_api, fastq_delivery_bundle, include=True)
     helpers.ensure_hk_bundle(deliver_api.hk_api, mip_delivery_bundle, include=True)
 
     # Given that the API was created with force_all=True
     deliver_api.deliver_failed_samples = True
```

### Comparing `cg-27.1.9/tests/meta/demultiplex/conftest.py` & `cg-27.2.0/tests/meta/demultiplex/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/demultiplex/test_delete_demultiplex_api.py` & `cg-27.2.0/tests/meta/demultiplex/test_delete_demultiplex_api.py`

 * *Files 1% similar despite different names*

```diff
@@ -112,15 +112,15 @@
     # GIVEN a flow cell with no active samples related to it
     store_: Store = populated_wipe_demultiplex_api.status_db
     samples_on_flow_cell: List[Sample] = (
         store_.query(Flowcell).filter(Flowcell.name == flow_cell_id).first().samples
     )
     assert samples_on_flow_cell
     for sample in samples_on_flow_cell:
-        active: bool = store_.active_sample(internal_id=sample.internal_id)
+        active: bool = store_.has_active_cases_for_sample(internal_id=sample.internal_id)
         assert not active
 
     # WHEN checking for active samples on flowcell
     populated_wipe_demultiplex_api._set_samples_on_flow_cell()
     active_samples_on_flow_cell: Optional[
         List[str]
     ] = populated_wipe_demultiplex_api.active_samples_on_flow_cell()
@@ -140,15 +140,15 @@
 
     samples_on_flow_cell: List[Sample] = (
         store_.query(Flowcell).filter(Flowcell.name == flow_cell_id).first().samples
     )
 
     assert samples_on_flow_cell
     for sample in samples_on_flow_cell:
-        active: bool = store_.active_sample(internal_id=sample.internal_id)
+        active: bool = store_.has_active_cases_for_sample(internal_id=sample.internal_id)
         assert active
 
     # WHEN checking for active samples on flowcell
     active_wipe_demultiplex_api._set_samples_on_flow_cell()
     active_samples_on_flow_cell: Optional[
         List[str]
     ] = active_wipe_demultiplex_api.active_samples_on_flow_cell()
```

### Comparing `cg-27.1.9/tests/meta/demultiplex/test_demux_post_processing.py` & `cg-27.2.0/tests/meta/demultiplex/test_demux_post_processing.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/demultiplex/test_rename_files.py` & `cg-27.2.0/tests/meta/demultiplex/test_rename_files.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/encryption/conftest.py` & `cg-27.2.0/tests/meta/encryption/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/encryption/test_encryption.py` & `cg-27.2.0/tests/meta/encryption/test_encryption.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 """Tests for the meta EncryptionAPI and SpringEncryptionAPI"""
 import logging
 import pathlib
-from pathlib import Path
 
 import mock
 import pytest
 
 import cg.utils.checksum.checksum
 from cg.exc import ChecksumFailedError
 from cg.meta.encryption.encryption import EncryptionAPI, SpringEncryptionAPI
```

### Comparing `cg-27.1.9/tests/meta/observations/conftest.py` & `cg-27.2.0/tests/meta/observations/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/observations/test_meta_upload_observations.py` & `cg-27.2.0/tests/meta/observations/test_meta_upload_observations.py`

 * *Files 8% similar despite different names*

```diff
@@ -33,15 +33,15 @@
     caplog: LogCaptureFixture,
     mocker,
 ):
     """Test upload observations method."""
     caplog.set_level(logging.DEBUG)
 
     # GIVEN a mocked observations API and a list of mocked observations files
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
     case.customer.internal_id = LoqusdbMipCustomers.KLINISK_IMMUNOLOGI.value
     mocker.patch.object(
         mip_dna_observations_api,
         "get_observations_input_files",
         return_value=observations_input_files,
     )
     mocker.patch.object(mip_dna_observations_api, "is_duplicate", return_value=False)
@@ -79,15 +79,15 @@
     observations_input_files: MipDNAObservationsInputFiles,
     analysis_store: Store,
     mocker,
 ):
     """Test duplicate extraction for a case that is not in Loqusdb."""
 
     # GIVEN a Loqusdb instance with no case duplicates
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
     mocker.patch.object(mip_dna_observations_api.loqusdb_api, "get_case", return_value=None)
     mocker.patch.object(mip_dna_observations_api.loqusdb_api, "get_duplicate", return_value=False)
 
     # WHEN checking that a case has not been uploaded to Loqusdb
     is_duplicate: bool = mip_dna_observations_api.is_duplicate(
         case=case,
         loqusdb_api=mip_dna_observations_api.loqusdb_api,
@@ -104,15 +104,15 @@
     observations_input_files: MipDNAObservationsInputFiles,
     mip_dna_observations_api: MipDNAObservationsAPI,
     analysis_store: Store,
 ):
     """Test duplicate extraction for a case that already exists in Loqusdb."""
 
     # GIVEN a Loqusdb instance with a duplicated case
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
 
     # WHEN checking that a case has already been uploaded to Loqusdb
     is_duplicate: bool = mip_dna_observations_api.is_duplicate(
         case=case,
         loqusdb_api=mip_dna_observations_api.loqusdb_api,
         profile_vcf_path=observations_input_files.profile_vcf_path,
         profile_threshold=MipDNALoadParameters.PROFILE_THRESHOLD.value,
@@ -129,15 +129,15 @@
     observations_input_files: MipDNAObservationsInputFiles,
     analysis_store: Store,
     mocker,
 ):
     """Test duplicate extraction for a case that already exists in Loqusdb."""
 
     # GIVEN a Loqusdb instance with a duplicated case and whose samples already have a Loqusdb ID
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
     case.links[0].sample.loqusdb_id = loqusdb_id
     mocker.patch.object(mip_dna_observations_api.loqusdb_api, "get_case", return_value=None)
     mocker.patch.object(mip_dna_observations_api.loqusdb_api, "get_duplicate", return_value=False)
 
     # WHEN checking that the sample observations have already been uploaded
     is_duplicate: bool = mip_dna_observations_api.is_duplicate(
         case=case,
@@ -211,15 +211,15 @@
     caplog: LogCaptureFixture,
     mocker,
 ):
     """Test loading of case observations for rare disease."""
     caplog.set_level(logging.DEBUG)
 
     # GIVEN a mock MIP DNA observations API and a list of observations input files
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
     mocker.patch.object(mip_dna_observations_api, "is_duplicate", return_value=False)
 
     # WHEN loading the case to Loqusdb
     mip_dna_observations_api.load_observations(case, observations_input_files)
 
     # THEN the observations should be loaded without any errors
     assert f"Uploaded {nr_of_loaded_variants} variants to Loqusdb" in caplog.text
@@ -233,15 +233,15 @@
     caplog: LogCaptureFixture,
     mocker,
 ):
     """Test upload case duplicate to Loqusdb."""
     caplog.set_level(logging.DEBUG)
 
     # GIVEN a mocked observations API and a case object that has already been uploaded to Loqusdb
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
     mocker.patch.object(mip_dna_observations_api, "is_duplicate", return_value=True)
 
     # WHEN uploading the case observations to Loqusdb
     with pytest.raises(LoqusdbDuplicateRecordError):
         # THEN a duplicate record error should be raised
         mip_dna_observations_api.load_observations(case, observations_input_files)
 
@@ -256,15 +256,15 @@
     caplog: LogCaptureFixture,
     mocker,
 ):
     """Test loading of a tumor case to Loqusdb."""
     caplog.set_level(logging.DEBUG)
 
     # GIVEN a MIP DNA observations API and a case object with a tumour sample
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
     mocker.patch.object(mip_dna_observations_api, "is_duplicate", return_value=False)
     case.links[0].sample.is_tumour = True
 
     # WHEN getting the Loqusdb API
     with pytest.raises(LoqusdbUploadCaseError):
         # THEN an upload error should be raised and the execution aborted
         mip_dna_observations_api.load_observations(case, observations_input_files)
@@ -278,15 +278,15 @@
     analysis_store: Store,
     caplog: LogCaptureFixture,
 ):
     """Test delete case from Loqusdb."""
     caplog.set_level(logging.DEBUG)
 
     # GIVEN a Loqusdb instance filled with a case
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
 
     # WHEN deleting a case
     mip_dna_observations_api.delete_case(case)
 
     # THEN the case should be deleted from Loqusdb
     assert f"Removed observations for case {case.internal_id} from Loqusdb" in caplog.text
 
@@ -326,15 +326,15 @@
     caplog: LogCaptureFixture,
     mocker,
 ):
     """Test loading of cancer case observations."""
     caplog.set_level(logging.DEBUG)
 
     # GIVEN a mock BALSAMIC observations API and a list of observations input files
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
     mocker.patch.object(balsamic_observations_api, "is_duplicate", return_value=False)
 
     # WHEN loading the case to Loqusdb
     balsamic_observations_api.load_observations(case, balsamic_observations_input_files)
 
     # THEN the observations should be loaded successfully
     assert f"Uploaded {nr_of_loaded_variants} variants to Loqusdb" in caplog.text
@@ -348,15 +348,15 @@
     caplog: LogCaptureFixture,
     mocker,
 ):
     """Test upload cancer duplicate case observations to Loqusdb."""
     caplog.set_level(logging.DEBUG)
 
     # GIVEN a balsamic observations API and a case object that has already been uploaded to Loqusdb
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
     mocker.patch.object(mip_dna_observations_api, "is_duplicate", return_value=True)
 
     # WHEN uploading the case observations to Loqusdb
     with pytest.raises(LoqusdbDuplicateRecordError):
         # THEN a duplicate record error should be raised
         mip_dna_observations_api.load_observations(case, observations_input_files)
 
@@ -371,15 +371,15 @@
     analysis_store: Store,
     caplog: LogCaptureFixture,
 ):
     """Test loading of case observations for cancer."""
     caplog.set_level(logging.DEBUG)
 
     # GIVEN a mock BALSAMIC observations API and a list of observations input files
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
 
     # WHEN loading the case to a somatic Loqusdb instance
     balsamic_observations_api.load_cancer_observations(
         case, balsamic_observations_input_files, balsamic_observations_api.loqusdb_somatic_api
     )
 
     # THEN the observations should be loaded successfully
@@ -393,15 +393,15 @@
     analysis_store: Store,
     caplog: LogCaptureFixture,
 ):
     """Test delete balsamic case observations from Loqusdb."""
     caplog.set_level(logging.DEBUG)
 
     # GIVEN a Loqusdb instance and a case that has been uploaded to both somatic and tumor instances
-    case: Family = analysis_store.family(case_id)
+    case: Family = analysis_store.get_case_by_internal_id(internal_id=case_id)
 
     # WHEN deleting the case
     balsamic_observations_api.delete_case(case)
 
     # THEN the case should be deleted from Loqusdb
     assert f"Removed observations for case {case.internal_id} from Loqusdb" in caplog.text
```

### Comparing `cg-27.1.9/tests/meta/orders/conftest.py` & `cg-27.2.0/tests/meta/orders/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/orders/test_PoolSubmitter_validate_order.py` & `cg-27.2.0/tests/meta/orders/test_PoolSubmitter_validate_order.py`

 * *Files 1% similar despite different names*

```diff
@@ -27,15 +27,15 @@
     order: OrderIn = OrderIn.parse_obj(rml_order_to_submit, OrderType.RML)
 
     sample: RmlSample
     customer: Customer = helpers.ensure_customer(store=base_store, customer_id=order.customer)
     for sample in order.samples:
         case = helpers.ensure_case(
             store=base_store,
-            name=PoolSubmitter.create_case_name(ticket=order.ticket, pool_name=sample.pool),
+            case_name=PoolSubmitter.create_case_name(ticket=order.ticket, pool_name=sample.pool),
             customer=customer,
             data_analysis=Pipeline.FLUFFY,
             data_delivery=DataDelivery.STATINA,
         )
         base_store.add_commit(case)
 
     # WHEN validating the order
```

### Comparing `cg-27.1.9/tests/meta/orders/test_SarsCov2Submitter_order_to_status.py` & `cg-27.2.0/tests/meta/orders/test_SarsCov2Submitter_order_to_status.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/orders/test_SarsCov2Submitter_store_order.py` & `cg-27.2.0/tests/meta/orders/test_SarsCov2Submitter_store_order.py`

 * *Files 11% similar despite different names*

```diff
@@ -36,12 +36,14 @@
         order="",
         ordered=dt.datetime.now(),
         ticket_id=123456,
         items=status_data.get("samples"),
     )
 
     # THEN control should exist on the sample in the store
-    customer: Customer = base_store.get_customer_by_customer_id(customer_id=order.customer)
+    customer: Customer = base_store.get_customer_by_internal_id(customer_internal_id=order.customer)
     sample: SarsCov2Sample
     for sample in order.samples:
-        stored_sample: Sample = base_store.find_samples(customer=customer, name=sample.name).first()
+        stored_sample: Sample = base_store.get_sample_by_customer_and_name(
+            customer_entry_id=[customer.id], sample_name=sample.name
+        )
         assert stored_sample.control == control_value
```

### Comparing `cg-27.1.9/tests/meta/orders/test_SarsCov2Submitter_validate_order.py` & `cg-27.2.0/tests/meta/orders/test_SarsCov2Submitter_validate_order.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/orders/test_meta_orders_api.py` & `cg-27.2.0/tests/meta/orders/test_meta_orders_api.py`

 * *Files 3% similar despite different names*

```diff
@@ -56,39 +56,39 @@
 def test_submit(
     mail_patch,
     all_orders_to_submit: dict,
     base_store: Store,
     monkeypatch,
     order_type: OrderType,
     orders_api: OrdersAPI,
-    ticket: str,
+    ticket_id: str,
     user_mail: str,
     user_name: str,
 ):
     order_data = OrderIn.parse_obj(obj=all_orders_to_submit[order_type], project=order_type)
     monkeypatch_process_lims(monkeypatch, order_data)
 
     # GIVEN an order and an empty store
-    assert not base_store.get_all_samples()
+    assert not base_store.get_samples()
 
     # WHEN submitting the order
 
     result = orders_api.submit(
         project=order_type, order_in=order_data, user_name=user_name, user_mail=user_mail
     )
 
     # THEN the result should contain the ticket number for the order
     for record in result["records"]:
         if isinstance(record, Pool):
-            assert record.ticket == ticket
+            assert record.ticket == ticket_id
         elif isinstance(record, Sample):
-            assert record.original_ticket == ticket
+            assert record.original_ticket == ticket_id
         elif isinstance(record, Family):
             for link_obj in record.links:
-                assert link_obj.sample.original_ticket == ticket
+                assert link_obj.sample.original_ticket == ticket_id
 
 
 def monkeypatch_process_lims(monkeypatch, order_data):
     lims_project_data = {"id": "ADM1234", "date": dt.datetime.now()}
     lims_map = {sample.name: f"ELH123A{index}" for index, sample in enumerate(order_data.samples)}
     for submitter in SUBMITTERS:
         monkeypatch.setattr(
@@ -134,15 +134,15 @@
 )
 def test_submit_illegal_sample_customer(
     all_orders_to_submit: dict,
     monkeypatch,
     order_type: OrderType,
     orders_api: OrdersAPI,
     sample_store: Store,
-    ticket: str,
+    ticket_id: str,
     user_mail: str,
     user_name: str,
 ):
     order_data = OrderIn.parse_obj(obj=all_orders_to_submit[order_type], project=order_type)
     monkeypatch_process_lims(monkeypatch, order_data)
 
     # GIVEN we have an order with a customer that is not in the same customer group as customer
@@ -151,15 +151,15 @@
         "customer999",
         "customer 999",
         scout_access=True,
         invoice_address="dummy street",
         invoice_reference="dummy nr",
     )
     sample_store.add_commit(new_customer)
-    existing_sample = sample_store.get_all_samples()[0]
+    existing_sample: Sample = sample_store.get_samples()[0]
     existing_sample.customer = new_customer
     sample_store.add_commit(existing_sample)
 
     for sample in order_data.samples:
         sample.internal_id = existing_sample.internal_id
 
     # WHEN calling submit
@@ -208,15 +208,15 @@
         invoice_address="dummy street 2",
         invoice_reference="dummy nr",
     )
     sample_customer.collaborations.append(collaboration)
     order_customer.collaborations.append(collaboration)
     sample_store.add_commit(sample_customer)
     sample_store.add_commit(order_customer)
-    existing_sample = sample_store.get_all_samples()[0]
+    existing_sample: Sample = sample_store.get_samples()[0]
     existing_sample.customer = sample_customer
     sample_store.commit()
     order_data.customer = order_customer.internal_id
 
     for sample in order_data.samples:
         sample.internal_id = existing_sample.internal_id
         break
@@ -233,35 +233,35 @@
     [OrderType.MIP_DNA, OrderType.MIP_RNA, OrderType.BALSAMIC],
 )
 def test_submit_duplicate_sample_case_name(
     all_orders_to_submit: dict,
     monkeypatch,
     order_type: OrderType,
     orders_api: OrdersAPI,
-    ticket: str,
+    ticket_id: str,
     user_mail: str,
     user_name: str,
 ):
     # GIVEN we have an order with a case that is already in the database
     order_data = OrderIn.parse_obj(obj=all_orders_to_submit[order_type], project=order_type)
     store = orders_api.status
-    customer: Customer = store.get_customer_by_customer_id(customer_id=order_data.customer)
+    customer: Customer = store.get_customer_by_internal_id(customer_internal_id=order_data.customer)
 
     for sample in order_data.samples:
         case_id = sample.family_name
-        if not store.find_family(customer=customer, name=case_id):
+        if not store.get_case_by_name_and_customer(customer=customer, case_name=case_id):
             case: Family = store.add_case(
                 data_analysis=Pipeline.MIP_DNA,
                 data_delivery=DataDelivery.SCOUT,
                 name=case_id,
-                ticket=ticket,
+                ticket=ticket_id,
             )
             case.customer = customer
             store.add_commit(case)
-        assert store.find_family(customer=customer, name=case_id)
+        assert store.get_case_by_name_and_customer(customer=customer, case_name=case_id)
 
     monkeypatch_process_lims(monkeypatch, order_data)
 
     # WHEN calling submit
     # THEN an OrderError should be raised on duplicate case name
     with pytest.raises(OrderError):
         orders_api.submit(
@@ -279,15 +279,15 @@
 )
 def test_submit_fluffy_duplicate_sample_case_name(
     mail_patch,
     all_orders_to_submit: dict,
     monkeypatch,
     order_type: OrderType,
     orders_api: OrdersAPI,
-    ticket: str,
+    ticket_id: str,
     user_mail: str,
     user_name: str,
 ):
     # GIVEN we have an order with a case that is already in the database
     order_data = OrderIn.parse_obj(obj=all_orders_to_submit[order_type], project=order_type)
     monkeypatch_process_lims(monkeypatch, order_data)
 
@@ -307,29 +307,31 @@
 
 
 @patch("cg.meta.orders.ticket_handler.FormDataRequest.submit", return_value=None)
 def test_submit_unique_sample_case_name(
     mail_patch,
     orders_api: OrdersAPI,
     mip_order_to_submit: dict,
-    ticket: str,
+    ticket_id: str,
     user_name: str,
     user_mail: str,
     monkeypatch,
 ):
     # GIVEN we have an order with a case that is not existing in the database
     order_data = OrderIn.parse_obj(obj=mip_order_to_submit, project=OrderType.MIP_DNA)
 
     store = orders_api.status
 
     sample: MipDnaSample
     for sample in order_data.samples:
         case_id = sample.family_name
-        customer: Customer = store.get_customer_by_customer_id(customer_id=order_data.customer)
-        assert not store.find_family(customer=customer, name=case_id)
+        customer: Customer = store.get_customer_by_internal_id(
+            customer_internal_id=order_data.customer
+        )
+        assert not store.get_case_by_name_and_customer(customer=customer, case_name=case_id)
 
     monkeypatch_process_lims(monkeypatch, order_data)
 
     # WHEN calling submit
     orders_api.submit(
         project=OrderType.MIP_DNA,
         order_in=order_data,
@@ -342,15 +344,15 @@
 
 def test_validate_sex_inconsistent_sex(
     orders_api: OrdersAPI, mip_order_to_submit: dict, helpers: StoreHelpers
 ):
     # GIVEN we have an order with a sample that is already in the database but with different sex
     order_data = OrderIn.parse_obj(mip_order_to_submit, project=OrderType.MIP_DNA)
     store = orders_api.status
-    customer: Customer = store.get_customer_by_customer_id(customer_id=order_data.customer)
+    customer: Customer = store.get_customer_by_internal_id(customer_internal_id=order_data.customer)
 
     # add sample with different sex than in order
     sample: MipDnaSample
     for sample in order_data.samples:
         sample_obj: Sample = helpers.add_sample(
             store=store,
             subject_id=sample.subject_id,
@@ -371,15 +373,15 @@
 
 def test_validate_sex_consistent_sex(
     orders_api: OrdersAPI, mip_order_to_submit: dict, helpers: StoreHelpers
 ):
     # GIVEN we have an order with a sample that is already in the database and with same gender
     order_data = OrderIn.parse_obj(mip_order_to_submit, project=OrderType.MIP_DNA)
     store = orders_api.status
-    customer: Customer = store.get_customer_by_customer_id(customer_id=order_data.customer)
+    customer: Customer = store.get_customer_by_internal_id(customer_internal_id=order_data.customer)
 
     # add sample with different sex than in order
     sample: MipDnaSample
     for sample in order_data.samples:
         sample_obj: Sample = helpers.add_sample(
             store=store,
             subject_id=sample.subject_id,
@@ -401,15 +403,15 @@
 def test_validate_sex_unknown_existing_sex(
     orders_api: OrdersAPI, mip_order_to_submit: dict, helpers: StoreHelpers
 ):
     # GIVEN we have an order with a sample that is already in the database and with different gender but the existing is
     # of type "unknown"
     order_data = OrderIn.parse_obj(mip_order_to_submit, project=OrderType.MIP_DNA)
     store = orders_api.status
-    customer: Customer = store.get_customer_by_customer_id(customer_id=order_data.customer)
+    customer: Customer = store.get_customer_by_internal_id(customer_internal_id=order_data.customer)
 
     # add sample with different sex than in order
     sample: MipDnaSample
     for sample in order_data.samples:
         sample_obj: Sample = helpers.add_sample(
             store=store,
             subject_id=sample.subject_id,
@@ -431,15 +433,15 @@
 def test_validate_sex_unknown_new_sex(
     orders_api: OrdersAPI, mip_order_to_submit: dict, helpers: StoreHelpers
 ):
     # GIVEN we have an order with a sample that is already in the database and with different gender but the new is of
     # type "unknown"
     order_data = OrderIn.parse_obj(mip_order_to_submit, project=OrderType.MIP_DNA)
     store = orders_api.status
-    customer: Customer = store.get_customer_by_customer_id(customer_id=order_data.customer)
+    customer: Customer = store.get_customer_by_internal_id(customer_internal_id=order_data.customer)
 
     # add sample with different sex than in order
     for sample in order_data.samples:
         sample_obj: Sample = helpers.add_sample(
             store=store,
             subject_id=sample.subject_id,
             name=sample.name,
@@ -477,22 +479,22 @@
 )
 def test_submit_unique_sample_name(
     mail_patch,
     all_orders_to_submit: dict,
     monkeypatch,
     order_type: OrderType,
     orders_api: OrdersAPI,
-    ticket: str,
+    ticket_id: str,
     user_mail: str,
     user_name: str,
 ):
     # GIVEN we have an order with a sample that is not existing in the database
     order_data = OrderIn.parse_obj(obj=all_orders_to_submit[order_type], project=order_type)
     store = orders_api.status
-    assert not store.get_all_samples()
+    assert not store.get_samples()
 
     monkeypatch_process_lims(monkeypatch, order_data)
 
     # WHEN calling submit
     orders_api.submit(
         project=order_type, order_in=order_data, user_name=user_name, user_mail=user_mail
     )
@@ -527,18 +529,20 @@
             order_in=order_data,
             user_name=user_name,
             user_mail=user_mail,
         )
 
 
 def store_samples_with_names_from_order(store: Store, helpers: StoreHelpers, order_data: OrderIn):
-    customer: Customer = store.get_customer_by_customer_id(customer_id=order_data.customer)
+    customer: Customer = store.get_customer_by_internal_id(customer_internal_id=order_data.customer)
     for sample in order_data.samples:
         sample_name = sample.name
-        if not store.find_samples(customer=customer, name=sample_name).first():
+        if not store.get_sample_by_customer_and_name(
+            customer_entry_id=[customer.id], sample_name=sample_name
+        ):
             sample_obj = helpers.add_sample(
                 store=store, name=sample_name, customer_id=customer.internal_id
             )
             store.add_commit(sample_obj)
 
 
 @patch("cg.meta.orders.ticket_handler.FormDataRequest.submit", return_value=None)
```

### Comparing `cg-27.1.9/tests/meta/orders/test_meta_orders_lims.py` & `cg-27.2.0/tests/meta/orders/test_meta_orders_lims.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/orders/test_meta_orders_status.py` & `cg-27.2.0/tests/meta/orders/test_meta_orders_status.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 import datetime as dt
 from copy import deepcopy
+from typing import List
 
 import pytest
 
 from cg.constants import DataDelivery, Pipeline
 from cg.constants.constants import CaseActions, PrepCategory
 from cg.exc import OrderError
 from cg.meta.orders.api import FastqSubmitter
@@ -16,15 +17,15 @@
 from cg.meta.orders.mip_rna_submitter import MipRnaSubmitter
 from cg.meta.orders.rml_submitter import RmlSubmitter
 from cg.meta.orders.sars_cov_2_submitter import SarsCov2Submitter
 from cg.meta.orders.submitter import Submitter
 from cg.models.orders.order import OrderIn, OrderType
 from cg.meta.orders import OrdersAPI
 from cg.store import Store
-from cg.store.models import Pool
+from cg.store.models import Family, Pool
 from cg.constants import Priority
 
 
 def test_pools_to_status(rml_order_to_submit):
     # GIVEN a rml order with three samples in one pool
     order = OrderIn.parse_obj(rml_order_to_submit, OrderType.RML)
 
@@ -191,40 +192,40 @@
 
     # WHEN parsing for status
     MipDnaSubmitter.order_to_status(order=order)
 
     # THEN No exception should have been raised on synopsis
 
 
-def test_store_rml(orders_api, base_store, rml_status_data, ticket: str):
+def test_store_rml(orders_api, base_store, rml_status_data, ticket_id: str):
     # GIVEN a basic store with no samples and a rml order
     assert base_store._get_query(table=Pool).count() == 0
-    assert base_store.families().count() == 0
-    assert len(base_store.get_all_samples()) == 0
+    assert base_store._get_query(table=Family).count() == 0
+    assert not base_store.get_samples()
 
     submitter: RmlSubmitter = RmlSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     new_pools = submitter.store_items_in_status(
         customer_id=rml_status_data["customer"],
         order=rml_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=rml_status_data["pools"],
     )
 
     # THEN it should update the database with new pools
     assert len(new_pools) == 2
 
-    assert base_store._get_query(table=Pool).count() == base_store.families().count()
-    assert len(base_store.get_all_samples()) == 4
+    assert base_store._get_query(table=Pool).count() == base_store._get_query(table=Family).count()
+    assert len(base_store.get_samples()) == 4
 
     # ASSERT that there is one negative sample
     negative_samples = 0
-    for sample in base_store.get_all_samples():
+    for sample in base_store.get_samples():
         if sample.control == "negative":
             negative_samples += 1
     assert negative_samples == 1
 
     new_pool = base_store._get_query(table=Pool).order_by(Pool.created_at.desc()).first()
     assert new_pool == new_pools[1]
 
@@ -232,78 +233,78 @@
     assert new_pool.application_version.application.tag == "RMLP05R800"
     assert not hasattr(new_pool, "data_analysis")
 
     # ... and add a delivery
     assert len(new_pool.deliveries) == 1
     assert new_pool.deliveries[0].destination == "caesar"
 
-    new_case = base_store.families().first()
+    new_case = base_store.get_cases()[0]
     assert new_case.data_analysis == str(Pipeline.FASTQ)
     assert new_case.data_delivery == str(DataDelivery.FASTQ)
 
     # and that the pool is set for invoicing but not the samples of the pool
     assert not new_pool.no_invoice
     for link in new_case.links:
         assert link.sample.no_invoice
 
 
-def test_store_samples(orders_api, base_store, fastq_status_data, ticket: str):
+def test_store_samples(orders_api, base_store, fastq_status_data, ticket_id: str):
     # GIVEN a basic store with no samples and a fastq order
-    assert len(base_store.get_all_samples()) == 0
-    assert base_store.families().count() == 0
+    assert not base_store.get_samples()
+    assert base_store._get_query(table=Family).count() == 0
 
     submitter: FastqSubmitter = FastqSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     new_samples = submitter.store_items_in_status(
         customer_id=fastq_status_data["customer"],
         order=fastq_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=fastq_status_data["samples"],
     )
 
     # THEN it should store the samples and create a case for each sample
     assert len(new_samples) == 2
-    assert len(base_store.get_all_samples()) == 2
-    assert base_store.families().count() == 2
+    assert len(base_store.get_samples()) == 2
+    assert base_store._get_query(table=Family).count() == 2
     first_sample = new_samples[0]
     assert len(first_sample.links) == 2
     family_link = first_sample.links[0]
-    assert family_link.family in base_store.families()
+    assert family_link.family in base_store.get_cases()
     for sample in new_samples:
         assert len(sample.deliveries) == 1
     assert family_link.family.data_analysis
     assert family_link.family.data_delivery in [DataDelivery.FASTQ, DataDelivery.NO_DELIVERY]
 
 
-def test_store_samples_sex_stored(orders_api, base_store, fastq_status_data, ticket: str):
+def test_store_samples_sex_stored(orders_api, base_store, fastq_status_data, ticket_id: str):
     # GIVEN a basic store with no samples and a fastq order
-    assert len(base_store.get_all_samples()) == 0
-    assert base_store.families().count() == 0
+    assert not base_store.get_samples()
+    assert base_store._get_query(table=Family).count() == 0
 
     submitter = FastqSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     new_samples = submitter.store_items_in_status(
         customer_id=fastq_status_data["customer"],
         order=fastq_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=fastq_status_data["samples"],
     )
 
     # THEN the sample sex should be stored
     assert new_samples[0].sex == "male"
 
 
 def test_store_fastq_samples_non_tumour_wgs_to_mip(orders_api, base_store, fastq_status_data):
     # GIVEN a basic store with no samples and a non-tumour fastq order as wgs
-    assert len(base_store.get_all_samples()) == 0
-    assert base_store.families().count() == 0
+    assert not base_store.get_samples()
+    assert base_store._get_query(table=Family).count() == 0
     base_store.get_application_by_tag(
         fastq_status_data["samples"][0]["application"]
     ).prep_category = PrepCategory.WHOLE_GENOME_SEQUENCING
     fastq_status_data["samples"][0]["tumour"] = False
 
     submitter = FastqSubmitter(lims=orders_api.lims, status=orders_api.status)
 
@@ -317,188 +318,188 @@
     )
 
     # THEN the analysis for the case should be MAF
     assert new_samples[0].links[0].family.data_analysis == Pipeline.MIP_DNA
 
 
 def test_store_fastq_samples_tumour_wgs_to_fastq(
-    orders_api, base_store, fastq_status_data, ticket: str
+    orders_api, base_store, fastq_status_data, ticket_id: str
 ):
     # GIVEN a basic store with no samples and a tumour fastq order as wgs
-    assert len(base_store.get_all_samples()) == 0
-    assert base_store.families().count() == 0
+    assert not base_store.get_samples()
+    assert base_store._get_query(table=Family).count() == 0
     base_store.get_application_by_tag(
         fastq_status_data["samples"][0]["application"]
     ).prep_category = PrepCategory.WHOLE_GENOME_SEQUENCING
     fastq_status_data["samples"][0]["tumour"] = True
 
     submitter = FastqSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     new_samples = submitter.store_items_in_status(
         customer_id=fastq_status_data["customer"],
         order=fastq_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=fastq_status_data["samples"],
     )
 
     # THEN the analysis for the case should be FASTQ
     assert new_samples[0].links[0].family.data_analysis == Pipeline.FASTQ
 
 
 def test_store_fastq_samples_non_wgs_as_fastq(
-    orders_api, base_store, fastq_status_data, ticket: str
+    orders_api, base_store, fastq_status_data, ticket_id: str
 ):
     # GIVEN a basic store with no samples and a fastq order as non wgs
-    assert len(base_store.get_all_samples()) == 0
-    assert base_store.families().count() == 0
+    assert not base_store.get_samples()
+    assert base_store._get_query(table=Family).count() == 0
     non_wgs_prep_category = PrepCategory.WHOLE_EXOME_SEQUENCING
     assert base_store.get_applications_by_prep_category(prep_category=non_wgs_prep_category)
     for sample in fastq_status_data["samples"]:
         sample["application"] = base_store.get_applications_by_prep_category(
             prep_category=non_wgs_prep_category
         )[0].tag
 
     submitter = FastqSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     new_samples = submitter.store_items_in_status(
         customer_id=fastq_status_data["customer"],
         order=fastq_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=fastq_status_data["samples"],
     )
 
     # THEN the analysis for the case should be fastq (none)
     assert new_samples[0].links[0].family.data_analysis == Pipeline.FASTQ
 
 
-def test_store_samples_bad_apptag(orders_api, base_store, fastq_status_data, ticket: str):
+def test_store_samples_bad_apptag(orders_api, base_store, fastq_status_data, ticket_id: str):
     # GIVEN a basic store with no samples and a fastq order
-    assert len(base_store.get_all_samples()) == 0
-    assert base_store.families().count() == 0
+    assert not base_store.get_samples()
+    assert base_store._get_query(table=Family).count() == 0
 
     for sample in fastq_status_data["samples"]:
         sample["application"] = "nonexistingtag"
 
     submitter = FastqSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # THEN it should raise OrderError
     with pytest.raises(OrderError):
         # WHEN storing the order
         submitter.store_items_in_status(
             customer_id=fastq_status_data["customer"],
             order=fastq_status_data["order"],
             ordered=dt.datetime.now(),
-            ticket_id=ticket,
+            ticket_id=ticket_id,
             items=fastq_status_data["samples"],
         )
 
 
-def test_store_microbial_samples(orders_api, base_store, microbial_status_data, ticket: str):
+def test_store_microbial_samples(orders_api, base_store, microbial_status_data, ticket_id: str):
     # GIVEN a basic store with no samples and a microbial order and one Organism
-    assert len(base_store.get_all_samples()) == 0
-    assert base_store.families().count() == 0
+    assert not base_store.get_samples()
+    assert base_store._get_query(table=Family).count() == 0
     assert base_store.get_all_organisms().count() == 1
 
     submitter = MicrobialSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     new_samples = submitter.store_items_in_status(
         customer_id=microbial_status_data["customer"],
         order=microbial_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=microbial_status_data["samples"],
         comment="",
         data_analysis=Pipeline.MICROSALT,
         data_delivery=DataDelivery.FASTQ_QC,
     )
 
     # THEN it should store the samples under a case (case) and the used previously unknown
     # organisms
     assert new_samples
-    assert base_store.families().count() == 1
+    assert base_store._get_query(table=Family).count() == 1
     assert len(new_samples) == 5
-    assert len(base_store.get_all_samples()) == 5
+    assert len(base_store.get_samples()) == 5
     assert base_store.get_all_organisms().count() == 3
 
 
 def test_store_microbial_case_data_analysis_stored(
-    orders_api, base_store, microbial_status_data, ticket: str
+    orders_api, base_store, microbial_status_data, ticket_id: str
 ):
     # GIVEN a basic store with no samples and a microbial order and one Organism
-    assert len(base_store.get_all_samples()) == 0
-    assert base_store.families().count() == 0
+    assert not base_store.get_samples()
+    assert base_store._get_query(table=Family).count() == 0
 
     submitter = MicrobialSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     submitter.store_items_in_status(
         customer_id=microbial_status_data["customer"],
         order=microbial_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=microbial_status_data["samples"],
         comment="",
         data_analysis=Pipeline.MICROSALT,
         data_delivery=DataDelivery.FASTQ_QC,
     )
 
     # THEN store the samples under a case with the microbial data_analysis type on case level
-    assert len(base_store.get_all_samples()) > 0
-    assert base_store.families().count() == 1
+    assert len(base_store.get_samples()) > 0
+    assert base_store._get_query(table=Family).count() == 1
 
-    microbial_case = base_store.families().first()
+    microbial_case = base_store.get_cases()[0]
     assert microbial_case.data_analysis == str(Pipeline.MICROSALT)
     assert microbial_case.data_delivery == str(DataDelivery.FASTQ_QC)
 
 
 def test_store_microbial_sample_priority(
-    orders_api, base_store, microbial_status_data, ticket: str
+    orders_api, base_store, microbial_status_data, ticket_id: str
 ):
     # GIVEN a basic store with no samples
-    assert len(base_store.get_all_samples()) == 0
+    assert not base_store.get_samples()
 
     submitter = MicrobialSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     submitter.store_items_in_status(
         customer_id=microbial_status_data["customer"],
         order=microbial_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=microbial_status_data["samples"],
         comment="",
         data_analysis=Pipeline.MICROSALT,
         data_delivery=DataDelivery.FASTQ_QC,
     )
 
     # THEN it should store the sample priority
-    assert len(base_store.get_all_samples()) > 0
-    microbial_sample = base_store.get_all_samples()[0]
+    assert len(base_store.get_samples()) > 0
+    microbial_sample = base_store.get_samples()[0]
 
     assert microbial_sample.priority_human == "research"
 
 
-def test_store_mip(orders_api, base_store, mip_status_data, ticket: str):
+def test_store_mip(orders_api, base_store, mip_status_data, ticket_id: str):
     # GIVEN a basic store with no samples or nothing in it + scout order
-    assert not base_store.get_all_samples()
-    assert base_store.families().first() is None
+    assert not base_store.get_samples()
+    assert not base_store.get_cases()
 
     submitter: MipDnaSubmitter = MipDnaSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     new_families = submitter.store_items_in_status(
         customer_id=mip_status_data["customer"],
         order=mip_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=mip_status_data["families"],
     )
 
     # THEN it should create and link samples and the case
     assert len(new_families) == 2
     new_case = new_families[0]
     assert new_case.name == "family1"
@@ -525,34 +526,34 @@
 
     assert set(new_link.sample.phenotype_groups) == {"Phenotype-group"}
     assert set(new_link.sample.phenotype_terms) == {"HP:0012747", "HP:0025049"}
     assert new_link.sample.subject_id == "subject1"
 
     assert new_link.sample.age_at_sampling == 17.18192
 
-    assert base_store.deliveries().count() == len(base_store.get_all_samples())
+    assert base_store.deliveries().count() == len(base_store.get_samples())
     for link in new_case.links:
         assert len(link.sample.deliveries) == 1
 
 
-def test_store_mip_rna(orders_api, base_store, mip_rna_status_data, ticket: str):
+def test_store_mip_rna(orders_api, base_store, mip_rna_status_data, ticket_id: str):
     # GIVEN a basic store with no samples or nothing in it + rna order
     rna_application_tag = "RNAPOAR025"
-    assert not base_store.get_all_samples()
-    assert base_store.families().first() is None
+    assert not base_store.get_samples()
+    assert not base_store.get_cases()
     assert base_store.get_application_by_tag(tag=rna_application_tag)
 
     submitter: MipRnaSubmitter = MipRnaSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     new_cases = submitter.store_items_in_status(
         customer_id=mip_rna_status_data["customer"],
         order=mip_rna_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=mip_rna_status_data["families"],
     )
 
     # THEN it should create and link samples and the casing
     assert len(new_cases) == 1
     new_casing = new_cases[0]
 
@@ -560,73 +561,75 @@
     new_link = new_casing.links[0]
     assert new_casing.data_analysis == str(Pipeline.MIP_RNA)
     assert new_casing.data_delivery == str(DataDelivery.SCOUT)
     assert new_link.sample.name == "sample1-rna-t1"
     assert new_link.sample.application_version.application.tag == rna_application_tag
 
 
-def test_store_metagenome_samples(orders_api, base_store, metagenome_status_data, ticket: str):
+def test_store_metagenome_samples(orders_api, base_store, metagenome_status_data, ticket_id: str):
     # GIVEN a basic store with no samples and a metagenome order
-    assert len(base_store.get_all_samples()) == 0
+    assert not base_store.get_samples()
 
     submitter = MetagenomeSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     new_samples = submitter.store_items_in_status(
         customer_id=metagenome_status_data["customer"],
         order=metagenome_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=metagenome_status_data["families"],
     )
 
     # THEN it should store the samples
     assert len(new_samples) == 2
-    assert len(base_store.get_all_samples()) == 2
+    assert len(base_store.get_samples()) == 2
 
 
 def test_store_metagenome_samples_bad_apptag(
-    orders_api, base_store, metagenome_status_data, ticket: str
+    orders_api, base_store, metagenome_status_data, ticket_id: str
 ):
     # GIVEN a basic store with no samples and a metagenome order
-    assert len(base_store.get_all_samples()) == 0
+    assert not base_store.get_samples()
 
     for sample in metagenome_status_data["families"][0]["samples"]:
         sample["application"] = "nonexistingtag"
 
     submitter = MetagenomeSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # THEN it should raise OrderError
     with pytest.raises(OrderError):
         # WHEN storing the order
         submitter.store_items_in_status(
             customer_id=metagenome_status_data["customer"],
             order=metagenome_status_data["order"],
             ordered=dt.datetime.now(),
-            ticket_id=ticket,
+            ticket_id=ticket_id,
             items=metagenome_status_data["families"],
         )
 
 
 @pytest.mark.parametrize(
     "submitter", [BalsamicSubmitter, BalsamicQCSubmitter, BalsamicUmiSubmitter]
 )
-def test_store_cancer_samples(orders_api, base_store, balsamic_status_data, submitter, ticket: str):
+def test_store_cancer_samples(
+    orders_api, base_store, balsamic_status_data, submitter, ticket_id: str
+):
     # GIVEN a basic store with no samples and a cancer order
-    assert not base_store.get_all_samples()
-    assert base_store.families().first() is None
+    assert not base_store.get_samples()
+    assert not base_store.get_cases()
 
     submitter: Submitter = submitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     new_families = submitter.store_items_in_status(
         customer_id=balsamic_status_data["customer"],
         order=balsamic_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=balsamic_status_data["families"],
     )
 
     # THEN it should create and link samples and the case
     assert len(new_families) == 1
     new_case = new_families[0]
     assert new_case.name == "family1"
@@ -643,29 +646,29 @@
     new_link = new_case.links[0]
     assert new_link.sample.name == "s1"
     assert new_link.sample.sex == "male"
     assert new_link.sample.application_version.application.tag == "WGSPCFC030"
     assert new_link.sample.comment == "other Elution buffer"
     assert new_link.sample.is_tumour
 
-    assert base_store.deliveries().count() == len(base_store.get_all_samples())
+    assert base_store.deliveries().count() == len(base_store.get_samples())
     for link in new_case.links:
         assert len(link.sample.deliveries) == 1
 
 
 def test_store_existing_single_sample_from_trio(
-    orders_api, base_store, mip_status_data, ticket: str
+    orders_api, base_store, mip_status_data, ticket_id: str
 ):
     # GIVEN a stored trio case
     submitter: MipDnaSubmitter = MipDnaSubmitter(lims=orders_api.lims, status=orders_api.status)
     new_families = submitter.store_items_in_status(
         customer_id=mip_status_data["customer"],
         order=mip_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=mip_status_data["families"],
     )
 
     new_case = new_families[0]
     assert new_case.name == "family1"
     assert set(new_case.panels) == {"IEM"}
     assert new_case.priority_human == Priority.standard.name
@@ -695,58 +698,58 @@
     mip_status_data["families"] = list(filter(None, mip_status_data["families"]))
 
     submitter: MipDnaSubmitter = MipDnaSubmitter(lims=orders_api.lims, status=orders_api.status)
     new_families = submitter.store_items_in_status(
         customer_id=mip_status_data["customer"],
         order=mip_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=mip_status_data["families"],
     )
 
     # THEN there should be no complaints about missing parents
     assert len(new_families) == 1
     assert len(new_families[0].links) == 1
     assert not new_families[0].links[0].mother
     assert not new_families[0].links[0].father
 
 
 def test_store_existing_case(
-    orders_api: OrdersAPI, base_store: Store, mip_status_data: dict, ticket: str
+    orders_api: OrdersAPI, base_store: Store, mip_status_data: dict, ticket_id: str
 ):
     # GIVEN a basic store with no samples or nothing in it + scout order
-    assert not base_store.get_all_samples()
-    assert base_store.families().first() is None
+    assert not base_store.get_samples()
+    assert not base_store.get_cases()
 
     submitter: MipDnaSubmitter = MipDnaSubmitter(lims=orders_api.lims, status=orders_api.status)
 
     # WHEN storing the order
     submitter.store_items_in_status(
         customer_id=mip_status_data["customer"],
         order=mip_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=mip_status_data["families"],
     )
 
     base_store.close()
-    new_cases = base_store.families().all()
+    new_cases: List[Family] = base_store.get_cases()
 
     # Save internal id
     stored_cases_internal_ids = dict([(case["name"], case["internal_id"]) for case in new_cases])
     for case in mip_status_data["families"]:
         case["internal_id"] = stored_cases_internal_ids[case["name"]]
 
     submitter.store_items_in_status(
         customer_id=mip_status_data["customer"],
         order=mip_status_data["order"],
         ordered=dt.datetime.now(),
-        ticket_id=ticket,
+        ticket_id=ticket_id,
         items=mip_status_data["families"],
     )
 
     base_store.close()
-    rerun_cases = base_store.families().all()
+    rerun_cases: List[Family] = base_store.get_cases()
 
     # THEN the sample ticket should be appended to previos ticket and action set to analyze
-    assert rerun_cases[0].tickets == f"{ticket},{ticket}"
+    assert rerun_cases[0].tickets == f"{ticket_id},{ticket_id}"
     assert rerun_cases[0].action == CaseActions.ANALYZE
```

### Comparing `cg-27.1.9/tests/meta/orders/test_ticket_handler.py` & `cg-27.2.0/tests/meta/orders/test_ticket_handler.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from cg.meta.orders.ticket_handler import TicketHandler
 
 
-def test_parse_ticket_number(ticket: str):
+def test_parse_ticket_number(ticket_id: str):
     # GIVEN a string with a ticket number
-    order_name = f"#{ticket}"
+    order_name = f"#{ticket_id}"
 
     # WHEN parsing the string
     result = TicketHandler.parse_ticket_number(order_name)
 
     # THEN assert that the correct string was parsed
-    assert result == ticket
+    assert result == ticket_id
 
 
 def test_add_user_name_message(ticket_handler: TicketHandler):
     # GIVEN a message string
     message = ""
     application: str = "apptag"
```

### Comparing `cg-27.1.9/tests/meta/report/conftest.py` & `cg-27.2.0/tests/meta/report/conftest.py`

 * *Files 3% similar despite different names*

```diff
@@ -42,22 +42,22 @@
     return BalsamicReportAPI(cg_context, cg_context.meta_apis["analysis_api"])
 
 
 @pytest.fixture(scope="function", name="case_mip_dna")
 def case_mip_dna(case_id, report_api_mip_dna) -> Family:
     """MIP DNA case instance."""
 
-    return report_api_mip_dna.status_db.family(case_id)
+    return report_api_mip_dna.status_db.get_case_by_internal_id(internal_id=case_id)
 
 
 @pytest.fixture(scope="function", name="case_balsamic")
 def case_balsamic(case_id, report_api_balsamic) -> Family:
     """BALSAMIC case instance."""
 
-    return report_api_balsamic.status_db.family(case_id)
+    return report_api_balsamic.status_db.get_case_by_internal_id(internal_id=case_id)
 
 
 @pytest.fixture(scope="function", name="case_samples_data")
 def case_samples_data(case_id, report_api_mip_dna):
     """MIP DNA family sample object."""
 
     return report_api_mip_dna.status_db.family_samples(case_id)
@@ -85,15 +85,15 @@
     return lims_family["samples"]
 
 
 @pytest.fixture(scope="function", autouse=True, name="report_store")
 def report_store(analysis_store, helpers, timestamp_yesterday):
     """A mock store instance for report testing."""
 
-    case = analysis_store.families()[0]
+    case = analysis_store.get_cases()[0]
     helpers.add_analysis(
         analysis_store, case, pipeline=Pipeline.MIP_DNA, started_at=timestamp_yesterday
     )
     helpers.add_analysis(analysis_store, case, pipeline=Pipeline.MIP_DNA, started_at=datetime.now())
 
     # Mock sample dates to calculate processing times
     for family_sample in analysis_store.family_samples(case.internal_id):
```

### Comparing `cg-27.1.9/tests/meta/report/test_balsamic_api.py` & `cg-27.2.0/tests/meta/report/test_balsamic_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/report/test_field_validators.py` & `cg-27.2.0/tests/meta/report/test_field_validators.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/report/test_mip_dna_api.py` & `cg-27.2.0/tests/meta/report/test_mip_dna_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/report/test_report_api.py` & `cg-27.2.0/tests/meta/report/test_report_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/rsync/conftest.py` & `cg-27.2.0/tests/meta/rsync/conftest.py`

 * *Files 8% similar despite different names*

```diff
@@ -4,32 +4,32 @@
 
 from cg.store.models import Family
 from cg.models.cg_config import CGConfig
 from cgmodels.cg.constants import Pipeline
 
 
 @pytest.fixture(name="mutant_case")
-def fixture_mutant_case(cg_context: CGConfig, case_id: str, ticket: str, helpers) -> Family:
+def fixture_mutant_case(cg_context: CGConfig, case_id: str, ticket_id: str, helpers) -> Family:
     """Return mutant case"""
     case = helpers.add_case(
         store=cg_context.status_db,
         internal_id=case_id,
-        name=ticket,
+        name=ticket_id,
         data_analysis=Pipeline.SARS_COV_2,
     )
     return case
 
 
 @pytest.fixture(name="microsalt_case")
-def fixture_microsalt_case(cg_context: CGConfig, case_id: str, ticket: str, helpers) -> Family:
+def fixture_microsalt_case(cg_context: CGConfig, case_id: str, ticket_id: str, helpers) -> Family:
     """Return mutant case"""
     case = helpers.add_case(
         store=cg_context.status_db,
         internal_id=case_id,
-        name=ticket,
+        name=ticket_id,
         data_analysis=Pipeline.MICROSALT,
     )
     return case
 
 
 @pytest.fixture(name="destination_path")
 def fixture_destination_path() -> Path:
```

### Comparing `cg-27.1.9/tests/meta/rsync/test_rsync.py` & `cg-27.2.0/tests/meta/rsync/test_rsync.py`

 * *Files 3% similar despite different names*

```diff
@@ -12,90 +12,90 @@
 from cg.store import Store
 from cg.store.models import Family
 from tests.meta.deliver.conftest import fixture_all_samples_in_inbox, fixture_dummy_file_name
 from tests.store.conftest import fixture_case_obj
 
 
 def test_get_source_and_destination_paths(
-    mutant_case: Family, rsync_api: RsyncAPI, ticket: str, mocker
+    mutant_case: Family, rsync_api: RsyncAPI, ticket_id: str, mocker
 ):
     """Test generating the source path before rsync"""
 
     # GIVEN a valid Sars-cov-2 case
     case = mutant_case
 
     # GIVEN file exists
     mocker.patch.object(RsyncAPI, "get_all_cases_from_ticket")
     RsyncAPI.get_all_cases_from_ticket.return_value = [case]
 
     # WHEN the source path is created
-    source_and_destination_paths = rsync_api.get_source_and_destination_paths(ticket=ticket)
+    source_and_destination_paths = rsync_api.get_source_and_destination_paths(ticket=ticket_id)
 
-    # THEN the source path ends with a customer id, followed by "inbox" and a ticket id
+    # THEN the source path ends with a customer id, followed by "inbox" and a ticket_id id
     assert (
         source_and_destination_paths["delivery_source_path"]
         .as_posix()
-        .endswith(f"/cust000/inbox/{ticket}")
+        .endswith(f"/cust000/inbox/{ticket_id}")
     )
-    # THEN the destination path is in the format server.name.se:/path/cust_id/path/ticket/
+    # THEN the destination path is in the format server.name.se:/path/cust_id/path/ticket_id/
     assert (
         source_and_destination_paths["rsync_destination_path"].as_posix()
         == "server.name.se:/some/cust000/inbox"
     )
 
 
-def test_get_source_path_no_case(rsync_api: RsyncAPI, ticket: str, mocker, helpers, caplog):
+def test_get_source_path_no_case(rsync_api: RsyncAPI, ticket_id: str, mocker, helpers, caplog):
     """Test generating the source path before rsync when there is no case"""
     caplog.set_level(logging.WARNING)
 
     # GIVEN file exists
     mocker.patch.object(RsyncAPI, "get_all_cases_from_ticket")
     RsyncAPI.get_all_cases_from_ticket.return_value = None
 
     with pytest.raises(CgError):
         # WHEN the source path is collected
-        rsync_api.get_source_and_destination_paths(ticket=ticket)
+        rsync_api.get_source_and_destination_paths(ticket=ticket_id)
 
-        # THEN the source path ends with a customer id, followed by "inbox" and a ticket id
+        # THEN the source path ends with a customer id, followed by "inbox" and a ticket_id id
         assert "Could not find any cases for ticket_id" in caplog.text
 
 
-def test_set_log_dir(rsync_api: RsyncAPI, ticket: str, caplog):
+def test_set_log_dir(rsync_api: RsyncAPI, ticket_id: str, caplog):
     """Test function to set log dir for path"""
 
     caplog.set_level(logging.INFO)
 
     # GIVEN an RsyncAPI, with its base path as its log dir
     base_path: Path = rsync_api.log_dir
 
     # WHEN setting the log directory
-    rsync_api.set_log_dir(folder_prefix=ticket)
+    rsync_api.set_log_dir(folder_prefix=ticket_id)
 
     # THEN the log dir should set to a new path, different from the base path
     assert base_path.as_posix() != rsync_api.log_dir.as_posix()
     assert "Setting log dir to:" in caplog.text
 
 
-def test_make_log_dir(rsync_api: RsyncAPI, ticket: str, caplog):
+def test_make_log_dir(rsync_api: RsyncAPI, ticket_id: str, caplog):
     """Test generating the directory for logging"""
     caplog.set_level(logging.INFO)
 
     # WHEN the log directory is created
-    rsync_api.set_log_dir(folder_prefix=ticket)
+    rsync_api.set_log_dir(folder_prefix=ticket_id)
     rsync_api.create_log_dir(dry_run=True)
 
     # THEN the path is not created since it is a dry run
     assert "Would have created path" in caplog.text
 
     # THEN the created path is
-    assert str(rsync_api.log_dir).startswith(f"/another/path/{ticket}")
+    assert str(rsync_api.log_dir).startswith(f"/another/path/{ticket_id}")
 
 
 def test_run_rsync_on_slurm(
-    microsalt_case: Family, rsync_api: RsyncAPI, ticket: str, caplog, mocker, helpers
+    microsalt_case: Family, rsync_api: RsyncAPI, ticket_id: str, caplog, mocker, helpers
 ):
     """Test for running rsync using SLURM."""
     caplog.set_level(logging.INFO)
 
     # GIVEN a valid microsalt case
     case: Family = microsalt_case
 
@@ -106,15 +106,15 @@
         "rsync_destination_path": Path("/path/to/destination"),
     }
 
     mocker.patch.object(RsyncAPI, "get_all_cases_from_ticket")
     RsyncAPI.get_all_cases_from_ticket.return_value = [case]
 
     # WHEN the destination path is created
-    sbatch_number: int = rsync_api.run_rsync_on_slurm(ticket=ticket, dry_run=True)
+    sbatch_number: int = rsync_api.run_rsync_on_slurm(ticket=ticket_id, dry_run=True)
 
     # THEN check that SARS-COV-2 analysis is not delivered
     assert "Delivering report for SARS-COV-2 analysis" not in caplog.text
 
     # THEN check that an integer was returned as sbatch number
     assert isinstance(sbatch_number, int)
 
@@ -136,28 +136,28 @@
         analysis_family["samples"][1]["name"],
         analysis_family["samples"][2]["name"],
         analysis_family["name"],
     ]
 
 
 def test_concatenate_rsync_commands(
-    analysis_family: dict, analysis_store_trio, project_dir, customer_id, ticket: str
+    analysis_family: dict, analysis_store_trio, project_dir, customer_id, ticket_id: str
 ):
     """Tests the function to concatenate rsync commands for transferring multiple files."""
     # GIVEN a list with a case and a sample name
     folder_list: List[str] = [analysis_family["name"], analysis_family["samples"][0]["name"]]
     source_and_destination_paths = {
-        "delivery_source_path": project_dir / customer_id / ticket,
+        "delivery_source_path": project_dir / customer_id / ticket_id,
         "rsync_destination_path": project_dir / customer_id,
     }
     # WHEN then commands are generated
     commands: str = RsyncAPI.concatenate_rsync_commands(
         folder_list=folder_list,
         source_and_destination_paths=source_and_destination_paths,
-        ticket=ticket,
+        ticket=ticket_id,
     )
     # THEN the correct folder should be added to the source path
     assert (
         " ".join(
             [
                 str(source_and_destination_paths["delivery_source_path"] / analysis_family["name"]),
                 str(source_and_destination_paths["delivery_source_path"]),
@@ -182,28 +182,28 @@
 def test_slurm_rsync_single_case(
     all_samples_in_inbox: Path,
     case_obj: Family,
     destination_path: Path,
     rsync_api: RsyncAPI,
     caplog,
     mocker,
-    ticket: str,
+    ticket_id: str,
 ):
     """Test for running rsync on a single case using SLURM."""
     caplog.set_level(logging.INFO)
 
     # GIVEN paths needed to run rsync
     mocker.patch.object(RsyncAPI, "get_source_and_destination_paths")
     RsyncAPI.get_source_and_destination_paths.return_value = {
         "delivery_source_path": all_samples_in_inbox,
         "rsync_destination_path": destination_path,
     }
 
     mocker.patch.object(Store, "get_latest_ticket_from_case")
-    Store.get_latest_ticket_from_case.return_value = ticket
+    Store.get_latest_ticket_from_case.return_value = ticket_id
 
     # WHEN the destination path is created
     sbatch_number: int
     is_complete_delivery: bool
     is_complete_delivery, sbatch_number = rsync_api.slurm_rsync_single_case(
         case_id=case_obj.internal_id,
         case_files_present=True,
@@ -219,15 +219,15 @@
 def test_slurm_rsync_single_case_missing_file(
     all_samples_in_inbox: Path,
     case_obj: Family,
     destination_path: Path,
     rsync_api: RsyncAPI,
     caplog,
     mocker,
-    ticket: str,
+    ticket_id: str,
 ):
     """Test for running rsync on a single case with a missing file using SLURM."""
     caplog.set_level(logging.INFO)
 
     # GIVEN a valid mip case and sample folder missing
     shutil.rmtree(Path(all_samples_in_inbox, case_obj.links[0].sample.name))
 
@@ -235,15 +235,15 @@
     mocker.patch.object(RsyncAPI, "get_source_and_destination_paths")
     RsyncAPI.get_source_and_destination_paths.return_value = {
         "delivery_source_path": all_samples_in_inbox,
         "rsync_destination_path": destination_path,
     }
 
     mocker.patch.object(Store, "get_latest_ticket_from_case")
-    Store.get_latest_ticket_from_case.return_value = ticket
+    Store.get_latest_ticket_from_case.return_value = ticket_id
 
     # WHEN the destination path is created
     sbatch_number: int
     is_complete_delivery: bool
     is_complete_delivery, sbatch_number = rsync_api.slurm_rsync_single_case(
         case_id=case_obj.internal_id,
         case_files_present=True,
```

### Comparing `cg-27.1.9/tests/meta/test_invoice.py` & `cg-27.2.0/tests/meta/test_invoice.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/transfer/conftest.py` & `cg-27.2.0/tests/meta/transfer/conftest.py`

 * *Files 4% similar despite different names*

```diff
@@ -14,19 +14,19 @@
 def fixture_transfer_lims_api(sample_store: Store) -> Generator[TransferLims, None, None]:
     """Setup LIMS transfer API."""
     yield TransferLims(sample_store, MockLimsAPI(config=""))
 
 
 @pytest.fixture(name="external_data_directory", scope="session")
 def external_data_directory(
-    tmpdir_factory, customer_id: str, cust_sample_id: str, ticket: str
+    tmpdir_factory, customer_id: str, cust_sample_id: str, ticket_id: str
 ) -> Path:
     """Returns a customer folder with fastq.gz files in sample-directories."""
     cust_folder: Path = tmpdir_factory.mktemp(customer_id, numbered=False)
-    ticket_folder: Path = Path(cust_folder, ticket)
+    ticket_folder: Path = Path(cust_folder, ticket_id)
     ticket_folder.mkdir()
     samples: List[str] = [f"{cust_sample_id}1", f"{cust_sample_id}2"]
     for sample in samples:
         Path(ticket_folder, sample).mkdir(exist_ok=True, parents=True)
         for read in [1, 2]:
             Path(ticket_folder, sample, f"{sample}_fastq_{read}.fastq.gz").touch(exist_ok=True)
             Path(ticket_folder, sample, f"{sample}_fastq_{read}.fastq.gz.md5").touch(exist_ok=True)
```

### Comparing `cg-27.1.9/tests/meta/transfer/test_external_data.py` & `cg-27.2.0/tests/meta/transfer/test_external_data.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,40 +12,40 @@
 from cg.store import Store
 from cg.store.models import Family, Sample
 from cg.utils.checksum.checksum import check_md5sum, extract_md5sum
 
 from housekeeper.store.models import Version
 
 
-def test_create_log_dir(caplog, external_data_api: ExternalDataAPI, ticket: str):
+def test_create_log_dir(caplog, external_data_api: ExternalDataAPI, ticket_id: str):
     """Test generating the directory for logging."""
     caplog.set_level(logging.INFO)
 
     # WHEN the log directory is created
-    log_dir = external_data_api.create_log_dir(ticket=ticket, dry_run=True)
+    log_dir = external_data_api.create_log_dir(ticket=ticket_id, dry_run=True)
 
     # THEN the path is not created since it is a dry run
     assert "Would have created path" in caplog.text
 
     # THEN the created path should start with 2 dirs and then the ticket id
-    assert str(log_dir).startswith(f"/another/path/{ticket}")
+    assert str(log_dir).startswith(f"/another/path/{ticket_id}")
 
 
 def test_get_source_path(
     cust_sample_id: str,
     customer_id: str,
     external_data_api: ExternalDataAPI,
-    ticket: str,
+    ticket_id: str,
 ):
     """Test generating the source path."""
     # GIVEN a ticket number a customer and a customer sample id
 
     # WHEN the function is called and assigned
     source_path = external_data_api.get_source_path(
-        ticket=ticket,
+        ticket=ticket_id,
         customer=customer_id,
         cust_sample_id=cust_sample_id,
     )
 
     # THEN the return should be
     assert source_path == Path("server.name.se:/path/cust000/on/caesar/123456/child/")
 
@@ -72,35 +72,37 @@
     customer_id: str,
     cust_sample_id: str,
     external_data_api: ExternalDataAPI,
     external_data_directory: Path,
     helpers,
     mocker,
     sample_store: Store,
-    ticket: str,
+    ticket_id: str,
 ):
     caplog.set_level(logging.INFO)
 
     # GIVEN a Store with three samples, where only two samples are present in the source folder
     for sample in [f"{cust_sample_id}1", f"{cust_sample_id}2", f"{cust_sample_id}3"]:
-        helpers.add_sample(store=external_data_api.status_db, name=sample, original_ticket=ticket)
+        helpers.add_sample(
+            store=external_data_api.status_db, name=sample, original_ticket=ticket_id
+        )
 
     mocker.patch.object(Store, "get_customer_id_from_ticket")
     Store.get_customer_id_from_ticket.return_value = customer_id
 
     mocker.patch.object(ExternalDataAPI, "get_source_path")
     external_data_api.get_source_path.return_value = external_data_directory
 
     external_data_api.source_path = str(Path("").joinpath(*external_data_directory.parts[:-2]))
     external_data_api.destination_path = str(
         Path("").joinpath(*external_data_directory.parts[:-1], "%s")
     )
 
     # WHEN the transfer is initiated
-    external_data_api.transfer_sample_files_from_source(ticket=ticket, dry_run=True)
+    external_data_api.transfer_sample_files_from_source(ticket=ticket_id, dry_run=True)
 
     # THEN only the two samples present in the source directory are included in the rsync
 
     assert str(external_data_directory) in caplog.text
 
 
 def test_get_all_fastq(external_data_api: ExternalDataAPI, external_data_directory: Path):
@@ -144,21 +146,21 @@
 
 
 def test_add_transfer_to_housekeeper(
     case_id,
     external_data_api: ExternalDataAPI,
     fastq_file: Path,
     mocker,
-    ticket: str,
+    ticket_id: str,
 ):
     """Test adding samples from a case to Housekeeper"""
     # GIVEN a Store with a DNA case, which is available for analysis
     cases = external_data_api.status_db.query(Family).filter(Family.internal_id == case_id)
-    mocker.patch.object(Store, "get_cases_from_ticket")
-    Store.get_cases_from_ticket.return_value = cases
+    mocker.patch.object(Store, "get_cases_by_ticket_id")
+    Store.get_cases_by_ticket_id.return_value = cases
     samples = [fam_sample.sample for fam_sample in cases.all()[0].links]
 
     # GIVEN a list of paths and only two samples being available
     mocker.patch.object(ExternalDataAPI, "get_all_paths")
     ExternalDataAPI.get_all_paths.return_value = [fastq_file]
 
     mocker.patch.object(MockHousekeeperAPI, "last_version")
@@ -181,15 +183,15 @@
 
     # THEN none of the samples should exist in housekeeper
     assert all(
         external_data_api.housekeeper_api.bundle(sample.internal_id) is None for sample in samples
     )
 
     # WHEN the sample bundles are added to housekeeper
-    external_data_api.add_transfer_to_housekeeper(ticket=ticket)
+    external_data_api.add_transfer_to_housekeeper(ticket=ticket_id)
 
     # THEN two sample bundles exist in housekeeper and the file has been added to those bundles bundles
     added_samples = list(external_data_api.housekeeper_api.bundles())
     assert all(
         sample.internal_id in [added_sample.name for added_sample in added_samples]
         for sample in samples[:-1]
     )
@@ -201,20 +203,22 @@
 
 
 def test_get_available_samples(
     analysis_store_trio,
     customer_id: str,
     external_data_api: ExternalDataAPI,
     sample_obj: Sample,
-    ticket: str,
+    ticket_id: str,
     tmpdir_factory,
 ):
     # GIVEN one such sample exists
     tmp_dir_path: Path = Path(tmpdir_factory.mktemp(sample_obj.internal_id, numbered=False)).parent
-    available_samples = external_data_api.get_available_samples(folder=tmp_dir_path, ticket=ticket)
+    available_samples = external_data_api.get_available_samples(
+        folder=tmp_dir_path, ticket=ticket_id
+    )
     # THEN the function should return a list containing the sample object
     assert available_samples == [sample_obj]
 
 
 def test_curate_sample_folder(
     case_id, customer_id, dna_case, external_data_api: ExternalDataAPI, tmpdir_factory
 ):
@@ -228,20 +232,22 @@
     assert not tmp_folder.exists()
 
 
 def test_get_available_samples_no_samples_avail(
     analysis_store_trio,
     customer_id: str,
     external_data_api: ExternalDataAPI,
-    ticket: str,
+    ticket_id: str,
     tmpdir_factory,
 ):
     # GIVEN that the empty directory created does not contain any correct folders
     tmp_dir_path: Path = Path(tmpdir_factory.mktemp("not_sample_id", numbered=False))
-    available_samples = external_data_api.get_available_samples(folder=tmp_dir_path, ticket=ticket)
+    available_samples = external_data_api.get_available_samples(
+        folder=tmp_dir_path, ticket=ticket_id
+    )
     # THEN the function should return an empty list
     assert available_samples == []
 
 
 def test_checksum(fastq_file: Path):
     """Tests if the function correctly calculates md5sum and returns the correct result."""
     # GIVEN a fastq file with corresponding correct md5 file and a fastq file with a corresponding incorrect md5 file
```

### Comparing `cg-27.1.9/tests/meta/transfer/test_meta_transfer_flowcell.py` & `cg-27.2.0/tests/meta/transfer/test_meta_transfer_flowcell.py`

 * *Files 2% similar despite different names*

```diff
@@ -428,15 +428,15 @@
     transfer_flow_cell_api: Generator[TransferFlowCell, None, None],
     yet_another_flow_cell_id: str,
 ):
     """Test transfer of sequencing files."""
 
     # GIVEN a store with a received but not sequenced sample
     housekeeper_api: HousekeeperAPI = transfer_flow_cell_api.hk
-    assert len(flowcell_store.get_all_samples()) == 2
+    assert len(flowcell_store.get_samples()) == 2
     assert flowcell_store.get_flow_cells().count() == 0
     assert housekeeper_api.bundles().count() == 0
 
     # GIVEN a sample sheet
 
     # WHEN transferring the flowcell containing the sample
     with warnings.catch_warnings():
@@ -447,15 +447,15 @@
         )
 
     # THEN it should create a new flow cell record
     assert flowcell_store.get_flow_cells().count() == 1
     assert flow_cell.status == FlowCellStatus.ON_DISK
     assert isinstance(flow_cell.id, int)
     assert flow_cell.name == yet_another_flow_cell_id
-    status_sample = flowcell_store.get_all_samples()[0]
+    status_sample = flowcell_store.get_samples()[0]
     assert isinstance(status_sample.sequenced_at, datetime)
 
     # ... and it should store the fastq files and samplesheet for the sample in housekeeper
     hk_bundle = housekeeper_api.bundle(name=status_sample.internal_id)
 
     assert len(hk_bundle.versions[0].files) > 0
     assert (
```

### Comparing `cg-27.1.9/tests/meta/transfer/test_meta_transfer_lims.py` & `cg-27.2.0/tests/meta/transfer/test_meta_transfer_lims.py`

 * *Files 1% similar despite different names*

```diff
@@ -59,15 +59,15 @@
 
     # THEN the samples should have the same received_at as in lims
     assert has_same_received_at(lims_api, sample)
 
 
 def test_transfer_samples_include_unset_received_at(transfer_lims_api: TransferLims):
     sample_store = transfer_lims_api.status
-    samples = sample_store.get_all_samples()
+    samples = sample_store.get_samples()
     assert len(samples) >= 2
 
     # GIVEN sample with unset received_at
     untransfered_sample = samples[0]
     untransfered_sample.received_at = None
     untransfered_sample.preped_at = None
     untransfered_sample.sequenced_at = None
```

### Comparing `cg-27.1.9/tests/meta/upload/balsamic/test_balsamic.py` & `cg-27.2.0/tests/meta/upload/balsamic/test_balsamic.py`

 * *Files 8% similar despite different names*

```diff
@@ -20,40 +20,46 @@
 )
 
 
 def test_genotype_check_wgs_normal(balsamic_context: CGConfig):
     """Test a cancer case with WGS and normal sample that is Genotype compatible."""
     # GIVEN a balsamic case with WGS tag and a normal sample
     internal_id = "balsamic_case_wgs_paired_enough_reads"
-    case_obj: models.Family = balsamic_context.status_db.family(internal_id=internal_id)
+    case_obj: models.Family = balsamic_context.status_db.get_case_by_internal_id(
+        internal_id=internal_id
+    )
 
     # WHEN checking if the case is Genotype upload compatible
     passed_check = UploadGenotypesAPI.is_suitable_for_genotype_upload(case_obj)
 
     # THEN it should return True
     assert passed_check
 
 
 def test_genotype_check_non_wgs_normal(balsamic_context: CGConfig):
     """Test a cancer case with no WGS sample that is not Genotype compatible."""
     # GIVEN a balsamic case with a normal sample, but no WGS tag
     internal_id = "balsamic_case_tgs_paired"
-    case_obj: models.Family = balsamic_context.status_db.family(internal_id=internal_id)
+    case_obj: models.Family = balsamic_context.status_db.get_case_by_internal_id(
+        internal_id=internal_id
+    )
 
     # WHEN checking if the case is Genotype upload compatible
     passed_check = UploadGenotypesAPI.is_suitable_for_genotype_upload(case_obj)
 
     # THEN it should return False
     assert not passed_check
 
 
 def test_genotype_check_only_tumour(balsamic_context: CGConfig):
     """Test a cancer case with only a tumour sample that is not Genotype compatible."""
     # GIVEN a balsamic case with only tumour sample
     internal_id = "balsamic_case_wgs_single"
-    case_obj: models.Family = balsamic_context.status_db.family(internal_id=internal_id)
+    case_obj: models.Family = balsamic_context.status_db.get_case_by_internal_id(
+        internal_id=internal_id
+    )
 
     # WHEN checking if the case is Genotype upload compatible
     passed_check = UploadGenotypesAPI.is_suitable_for_genotype_upload(case_obj)
 
     # THEN it should return False
     assert not passed_check
```

### Comparing `cg-27.1.9/tests/meta/upload/conftest.py` & `cg-27.2.0/tests/meta/upload/conftest.py`

 * *Files 21% similar despite different names*

```diff
@@ -52,17 +52,17 @@
 
 
 @pytest.fixture(name="analysis_obj")
 def fixture_analysis_obj(
     analysis_store_trio: Store, case_id: str, timestamp: datetime, helpers: StoreHelpers
 ) -> Analysis:
     """Return an analysis object with a trio."""
-    case_obj = analysis_store_trio.family(case_id)
+    case_obj = analysis_store_trio.get_case_by_internal_id(internal_id=case_id)
     helpers.add_analysis(store=analysis_store_trio, case=case_obj, started_at=timestamp)
-    return analysis_store_trio.family(case_id).analyses[0]
+    return analysis_store_trio.get_case_by_internal_id(internal_id=case_id).analyses[0]
 
 
 @pytest.fixture(name="upload_genotypes_api")
 def fixture_upload_genotypes_api(
     real_housekeeper_api, genotype_api, upload_genotypes_hk_bundle, helpers: StoreHelpers
 ) -> UploadGenotypesAPI:
     """Create a upload genotypes api."""
@@ -85,15 +85,15 @@
     )
 
 
 @pytest.fixture(scope="function")
 def analysis(analysis_store, case_id, timestamp):
     """Fixture to mock an analysis."""
     _analysis = analysis_store.add_analysis(pipeline=Pipeline.BALSAMIC, version="version")
-    _analysis.family = analysis_store.family(case_id)
+    _analysis.family = analysis_store.get_case_by_internal_id(internal_id=case_id)
     _analysis.config_path = "dummy_path"
     _analysis.completed_at = timestamp
     yield _analysis
 
 
 @pytest.fixture(name="genotype_analysis_sex")
 def fixture_genotype_analysis_sex() -> dict:
@@ -128,15 +128,15 @@
 
     return mip_dna_case
 
 
 @pytest.fixture(name="mip_rna_case")
 def fixture_mip_rna_case(mip_rna_context: CGConfig, case_id: str):
     """Return a MIP RNA case."""
-    return mip_rna_context.status_db.family(internal_id=case_id)
+    return mip_rna_context.status_db.get_case_by_internal_id(internal_id=case_id)
 
 
 @pytest.fixture(name="mip_rna_analysis")
 def fixture_mip_rna_analysis(
     mip_rna_context: CGConfig, helpers: StoreHelpers, mip_rna_case: Family
 ) -> Family:
     """Return a MIP RNA analysis."""
```

### Comparing `cg-27.1.9/tests/meta/upload/gisaid/conftest.py` & `cg-27.2.0/tests/meta/upload/gisaid/conftest.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-from datetime import datetime, date
 from pathlib import Path
 from typing import List
 
 import pytest
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.apps.lims import LimsAPI
 from cg.meta.upload.gisaid import GisaidAPI
```

### Comparing `cg-27.1.9/tests/meta/upload/gisaid/fixtures/four_samples.csv` & `cg-27.2.0/tests/meta/upload/gisaid/fixtures/four_samples.csv`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/mutacc/conftest.py` & `cg-27.2.0/tests/meta/upload/mutacc/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/mutacc/test_meta_upload_mutacc.py` & `cg-27.2.0/tests/meta/upload/mutacc/test_meta_upload_mutacc.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/nipt/conftest.py` & `cg-27.2.0/tests/meta/upload/nipt/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/nipt/test_nipt_upload_api.py` & `cg-27.2.0/tests/meta/upload/nipt/test_nipt_upload_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/scout/conftest.py` & `cg-27.2.0/tests/meta/upload/scout/conftest.py`

 * *Files 1% similar despite different names*

```diff
@@ -113,15 +113,15 @@
     """Populate store with a RNA case that is connected to a DNA case via sample.subject_id."""
 
     store: Store = base_store
 
     # an existing RNA case with related sample
     rna_case = helpers.ensure_case(
         store=store,
-        name="rna_case",
+        case_name="rna_case",
         customer=helpers.ensure_customer(store=store),
         data_analysis=Pipeline.MIP_RNA,
         data_delivery=DataDelivery.SCOUT,
     )
     rna_case.internal_id = rna_case_id
 
     rna_sample_son = helpers.add_sample(
@@ -173,15 +173,15 @@
 
     for link in rna_case.links:
         link.sample.internal_id = link.sample.name
 
     # an existing DNA case with related sample
     dna_case = helpers.ensure_case(
         store=store,
-        name="dna_case",
+        case_name="dna_case",
         customer=helpers.ensure_customer(store=store),
         data_analysis=Pipeline.MIP_DNA,
         data_delivery=DataDelivery.SCOUT,
     )
     dna_case.internal_id = dna_case_id
 
     dna_sample_son = helpers.add_sample(
@@ -510,15 +510,15 @@
 
 @pytest.fixture(name="mip_dna_analysis")
 def fixture_mip_dna_analysis(
     analysis_store_trio: Store, case_id: str, timestamp: datetime, helpers: StoreHelpers
 ) -> Analysis:
     """Return a MIP DNA analysis object."""
     helpers.add_synopsis_to_case(store=analysis_store_trio, case_id=case_id)
-    case: Family = analysis_store_trio.family(case_id)
+    case: Family = analysis_store_trio.get_case_by_internal_id(internal_id=case_id)
     analysis: Analysis = helpers.add_analysis(
         store=analysis_store_trio,
         case=case,
         started_at=timestamp,
         pipeline=Pipeline.MIP_DNA,
         completed_at=timestamp,
     )
```

### Comparing `cg-27.1.9/tests/meta/upload/scout/test_generate_load_config.py` & `cg-27.2.0/tests/meta/upload/scout/test_generate_load_config.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/scout/test_meta_upload_scoutapi.py` & `cg-27.2.0/tests/meta/upload/scout/test_meta_upload_scoutapi.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/scout/test_meta_upload_scoutapi_rna.py` & `cg-27.2.0/tests/meta/upload/scout/test_meta_upload_scoutapi_rna.py`

 * *Files 3% similar despite different names*

```diff
@@ -12,20 +12,20 @@
 from cg.meta.upload.scout.uploadscoutapi import UploadScoutAPI
 from cg.store.models import Family, Sample
 import cg.store as Store
 from tests.store_helpers import StoreHelpers
 
 
 def set_is_tumour_on_case(store: Store, case_id: str, is_tumour: bool):
-    for link in store.family(case_id).links:
+    for link in store.get_case_by_internal_id(internal_id=case_id).links:
         link.sample.is_tumour = is_tumour
 
 
 def get_subject_id_from_case(store: Store, case_id: str) -> str:
-    for link in store.family(case_id).links:
+    for link in store.get_case_by_internal_id(internal_id=case_id).links:
         return link.sample.subject_id
 
 
 def ensure_two_dna_tumour_matches(
     dna_case_id: str,
     another_sample_id: str,
     helpers: StoreHelpers,
@@ -33,15 +33,15 @@
     rna_store: Store,
 ) -> None:
     """Ensures that we have one RNA case that has two matching DNA cases via subject id and tumour state."""
     set_is_tumour_on_case(store=rna_store, case_id=rna_case_id, is_tumour=True)
     subject_id: str = get_subject_id_from_case(store=rna_store, case_id=rna_case_id)
     set_is_tumour_on_case(store=rna_store, case_id=dna_case_id, is_tumour=True)
     dna_extra_case = helpers.ensure_case(
-        store=rna_store, customer=rna_store.family(dna_case_id).customer
+        store=rna_store, customer=rna_store.get_case_by_internal_id(dna_case_id).customer
     )
     another_sample_id = helpers.add_sample(
         store=rna_store,
         name=another_sample_id,
         subject_id=subject_id,
         is_tumour=True,
         application_tag=SequencingMethod.WGS,
@@ -57,15 +57,15 @@
     rna_case_id: str,
     rna_store: Store,
 ) -> None:
     """Ensures that we have an extra RNA case that matches by subject_id the existing RNA case and DNA cases."""
     rna_extra_case = helpers.ensure_case(
         store=rna_store,
         data_analysis=Pipeline.MIP_RNA,
-        customer=rna_store.family(rna_case_id).customer,
+        customer=rna_store.get_case_by_internal_id(rna_case_id).customer,
     )
     subject_id: str = get_subject_id_from_case(store=rna_store, case_id=rna_case_id)
     another_rna_sample_id = helpers.add_sample(
         store=rna_store,
         internal_id=another_rna_sample_id,
         subject_id=subject_id,
         is_tumour=False,
@@ -248,17 +248,17 @@
     rna_case_id: str,
     rna_store: Store,
     upload_scout_api: UploadScoutAPI,
 ):
     """Test that A RNA case's gene fusion report"""
 
     # GIVEN a sample in the RNA case is NOT connected to a sample in the DNA case via subject_id (i.e. same subject_id)
-    for link in rna_store.family(rna_case_id).links:
+    for link in rna_store.get_case_by_internal_id(rna_case_id).links:
         link.sample.subject_id = ""
-    for link in rna_store.family(dna_case_id).links:
+    for link in rna_store.get_case_by_internal_id(dna_case_id).links:
         link.sample.subject_id = ""
     rna_store.commit()
     upload_scout_api.status_db = rna_store
 
     # GIVEN the connected RNA case has a research fusion report in Housekeeper
 
     # WHEN running the method to upload RNA files to Scout
@@ -276,17 +276,17 @@
     rna_store: Store,
     upload_scout_api: UploadScoutAPI,
 ):
     """Test that A RNA case's gene fusion report and junction splice files for all samples can be loaded via a cg CLI
     command into an already existing DNA case"""
 
     # GIVEN a sample in the RNA case is NOT connected to a sample in the DNA case via subject_id (i.e. same subject_id)
-    for link in rna_store.family(rna_case_id).links:
+    for link in rna_store.get_case_by_internal_id(rna_case_id).links:
         link.sample.subject_id = ""
-    for link in rna_store.family(dna_case_id).links:
+    for link in rna_store.get_case_by_internal_id(dna_case_id).links:
         link.sample.subject_id = ""
     rna_store.commit()
     upload_scout_api.status_db = rna_store
 
     # GIVEN the connected RNA sample has a bigWig in Housekeeper
 
     # WHEN running the method to upload RNA files to Scout
@@ -304,17 +304,17 @@
     rna_store: Store,
     upload_scout_api: UploadScoutAPI,
 ):
     """Test that A RNA case's junction splice files for all samples can be loaded via a cg CLI
     command into an already existing DNA case"""
 
     # GIVEN a sample in the RNA case is NOT connected to a sample in the DNA case via subject_id (i.e. same subject_id)
-    for link in rna_store.family(rna_case_id).links:
+    for link in rna_store.get_case_by_internal_id(rna_case_id).links:
         link.sample.subject_id = ""
-    for link in rna_store.family(dna_case_id).links:
+    for link in rna_store.get_case_by_internal_id(dna_case_id).links:
         link.sample.subject_id = ""
     rna_store.commit()
     upload_scout_api.status_db = rna_store
 
     # GIVEN the connected RNA sample has a junction bed in Housekeeper
 
     # WHEN running the method to upload RNA files to Scout
@@ -514,15 +514,15 @@
     rna_case_id: str,
     rna_store: Store,
     upload_scout_api: UploadScoutAPI,
 ):
     """Test that the create_rna_dna_sample_case_map returns a nested dictionary."""
 
     # GIVEN an RNA case with RNA samples that are connected by subject ID to DNA samples in a DNA case
-    rna_case: Family = rna_store.families(enquiry=rna_case_id).first()
+    rna_case: Family = rna_store.get_case_by_internal_id(internal_id=rna_case_id)
 
     # WHEN running the method to create a nested dictionary with the relationships between RNA/DNA samples and DNA cases
     rna_dna_case_map: dict = upload_scout_api.create_rna_dna_sample_case_map(rna_case=rna_case)
 
     # THEN the output should be a nested dictionary for each key: {key:{value:[]}}
     assert all(isinstance(items, dict) for items in rna_dna_case_map.values())
 
@@ -531,16 +531,16 @@
     rna_case_id: str,
     rna_store: Store,
     upload_scout_api: UploadScoutAPI,
 ):
     """Test that for a given RNA case the RNA samples are added to the rna_dna_case_map."""
 
     # GIVEN an RNA case and the associated RNA samples
-    rna_case: Family = rna_store.families(enquiry=rna_case_id).first()
-    rna_sample_list: List[Sample] = rna_store.get_samples_by_enquiry(enquiry="rna")
+    rna_case: Family = rna_store.get_case_by_internal_id(internal_id=rna_case_id)
+    rna_sample_list: List[Sample] = rna_store.get_samples_by_name_pattern(name_pattern="rna")
 
     # WHEN running the method to create a nested dictionary with the relationships between RNA/DNA samples and DNA cases
     rna_dna_case_map: dict = upload_scout_api.create_rna_dna_sample_case_map(rna_case=rna_case)
 
     # THEN the resulting dictionary should contain all RNA samples in the case
     for key in rna_sample_list:
         assert key.internal_id in list(rna_dna_case_map.keys())
@@ -577,17 +577,17 @@
     rna_sample_son_id: str,
     rna_store: Store,
     upload_scout_api: UploadScoutAPI,
 ):
     """Test for a given RNA sample, the DNA case name matches to the case name of the DNA sample in rna_dna_case_map."""
 
     # GIVEN an RNA sample, a DNA sample, and a DNA case
-    rna_sample: models.Sample = rna_store.get_sample_by_internal_id(rna_sample_son_id)
-    dna_sample: models.Sample = rna_store.get_sample_by_internal_id(dna_sample_son_id)
-    dna_case: models.Family = rna_store.families(enquiry=dna_case_id).first()
+    rna_sample: Sample = rna_store.get_sample_by_internal_id(rna_sample_son_id)
+    dna_sample: Sample = rna_store.get_sample_by_internal_id(dna_sample_son_id)
+    dna_case: Family = rna_store.get_case_by_internal_id(internal_id=dna_case_id)
 
     # WHEN adding the RNA sample rna_dna_case_map
     rna_dna_case_map: dict = {}
     upload_scout_api._add_rna_sample(
         rna_sample=rna_sample, rna_dna_sample_case_map=rna_dna_case_map
     )
```

### Comparing `cg-27.1.9/tests/meta/upload/scout/test_scout_config_builder.py` & `cg-27.2.0/tests/meta/upload/scout/test_scout_config_builder.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/test_meta_upload_coverage.py` & `cg-27.2.0/tests/meta/upload/test_meta_upload_coverage.py`

 * *Files 4% similar despite different names*

```diff
@@ -24,15 +24,15 @@
 
 
 def test_data(coverage_upload_api, analysis_store, case_id):
     """test getting data for chanjo"""
     # GIVEN a coverage api and an analysis object
     coverage_api = coverage_upload_api
     case_name = case_id
-    case_obj = analysis_store.family(case_name)
+    case_obj = analysis_store.get_case_by_internal_id(internal_id=case_name)
     analysis_obj = MockAnalysis(case_obj=case_obj)
 
     # WHEN using the data method
     results = coverage_api.data(analysis_obj=analysis_obj)
 
     # THEN this returns the data needed to upload samples to chanjo
     assert results["family"] == case_name
@@ -41,20 +41,20 @@
 
 
 def test_upload(chanjo_config, populated_housekeeper_api, analysis_store, mocker, case_id):
     """test uploading with chanjo."""
     # GIVEN a coverage api and a data dictionary
     mock_upload = mocker.patch.object(ChanjoAPI, "upload")
     mock_sample = mocker.patch.object(ChanjoAPI, "sample")
-    mock_remove = mocker.patch.object(ChanjoAPI, "delete_sample")
+    mocker.patch.object(ChanjoAPI, "delete_sample")
     hk_api = populated_housekeeper_api
     chanjo_api = ChanjoAPI(config=chanjo_config)
     coverage_api = UploadCoverageApi(status_api=None, hk_api=hk_api, chanjo_api=chanjo_api)
     family_name = case_id
-    case_obj = analysis_store.family(family_name)
+    case_obj = analysis_store.get_case_by_internal_id(family_name)
     analysis_obj = MockAnalysis(case_obj=case_obj)
     data = coverage_api.data(analysis_obj=analysis_obj)
 
     # WHEN uploading samples in data dictionary
     coverage_api.upload(data=data, replace=True)
 
     # THEN methods sample, and upload should each have been called three times
```

### Comparing `cg-27.1.9/tests/meta/upload/test_upload_api.py` & `cg-27.2.0/tests/meta/upload/test_upload_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/test_upload_genotypes_api.py` & `cg-27.2.0/tests/meta/upload/test_upload_genotypes_api.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/vogue/conftest.py` & `cg-27.2.0/tests/meta/upload/vogue/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/upload/vogue/test_upload_vogue.py` & `cg-27.2.0/tests/meta/upload/vogue/test_upload_vogue.py`

 * *Files 1% similar despite different names*

```diff
@@ -87,9 +87,8 @@
         (timestamp_now,),
     ):
         result = UploadVogueAPI(
             mock_genotype_api, mock_vogue_api, mock_store
         ).update_analysis_uploaded_to_vogue_date(mock_analysis)
 
     # THEN the analysis object should have a vogue_uploaded_date set to the default value
-    # dt.datetime.now()
     assert result.uploaded_to_vogue_at == timestamp_now
```

### Comparing `cg-27.1.9/tests/meta/workflow/conftest.py` & `cg-27.2.0/tests/meta/workflow/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/workflow/test_analysis.py` & `cg-27.2.0/tests/meta/workflow/test_analysis.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/meta/workflow/test_balsamic.py` & `cg-27.2.0/tests/meta/workflow/test_balsamic.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,9 @@
 """Tests for BALSAMIC analysis"""
-import logging
 from pathlib import Path
-from typing import Dict
 
 import pytest
 from _pytest.logging import LogCaptureFixture
 
 from cg.constants.constants import SampleType
 from cg.constants.observations import ObservationsFileWildcards
 from cg.constants.sequencing import Variants
```

### Comparing `cg-27.1.9/tests/meta/workflow/test_microsalt.py` & `cg-27.2.0/tests/meta/workflow/test_microsalt.py`

 * *Files 9% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 ):
     """QC check for a microsalt case that should fail."""
     caplog.set_level(logging.INFO)
     store: Store = qc_microsalt_context.status_db
     microsalt_api: MicrosaltAnalysisAPI = qc_microsalt_context.meta_apis["analysis_api"]
 
     # GIVEN a case that is to be stored
-    microsalt_case: Family = store.family(microsalt_case_qc_fail)
+    microsalt_case: Family = store.get_case_by_internal_id(internal_id=microsalt_case_qc_fail)
     for index in range(4):
         microsalt_case.samples[index].reads = 1000
 
     mocker.patch.object(MicrosaltAnalysisAPI, "create_qc_done_file")
 
     # WHEN performing QC check
     qc_pass: bool = microsalt_api.microsalt_qc(
@@ -54,15 +54,15 @@
 ):
     """QC check for a microsalt case that should pass."""
     caplog.set_level(logging.INFO)
     store: Store = qc_microsalt_context.status_db
     microsalt_api: MicrosaltAnalysisAPI = qc_microsalt_context.meta_apis["analysis_api"]
 
     # GIVEN a case that is to be stored
-    microsalt_case: Family = store.family(microsalt_case_qc_pass)
+    microsalt_case: Family = store.get_case_by_internal_id(internal_id=microsalt_case_qc_pass)
     microsalt_case.samples[1].control = ControlEnum.negative
     microsalt_case.samples[1].reads = 1100000
 
     mocker.patch.object(MicrosaltAnalysisAPI, "create_qc_done_file")
 
     # WHEN performing QC check
     qc_pass: bool = microsalt_api.microsalt_qc(
@@ -87,15 +87,15 @@
     """QC check for a microsalt case where a negative control fails QC."""
 
     caplog.set_level(logging.INFO)
     store = qc_microsalt_context.status_db
     microsalt_api: MicrosaltAnalysisAPI = qc_microsalt_context.meta_apis["analysis_api"]
 
     # GIVEN a case that is to be stored
-    microsalt_case: Family = store.family(microsalt_case_qc_fail)
+    microsalt_case: Family = store.get_case_by_internal_id(internal_id=microsalt_case_qc_fail)
     microsalt_case.samples[0].control = ControlEnum.negative
 
     mocker.patch.object(MicrosaltAnalysisAPI, "create_qc_done_file")
 
     # WHEN performing QC check
     qc_pass: bool = microsalt_api.microsalt_qc(
         case_id=microsalt_case_qc_fail,
@@ -123,15 +123,15 @@
     store = qc_microsalt_context.status_db
     microsalt_api: MicrosaltAnalysisAPI = qc_microsalt_context.meta_apis["analysis_api"]
     mocker.patch.object(MicrosaltAnalysisAPI, "create_qc_done_file")
     mocker.patch.object(TrailblazerAPI, "set_analysis_status")
     mocker.patch.object(TrailblazerAPI, "add_comment")
 
     # GIVEN a store with a QC ready microsalt case that will pass QC
-    microsalt_pass_case: Family = store.family(microsalt_case_qc_pass)
+    microsalt_pass_case: Family = store.get_case_by_internal_id(internal_id=microsalt_case_qc_pass)
     microsalt_pass_case.samples[1].control = "negative"
     microsalt_pass_case.samples[1].reads = 1100000
 
     mocker.patch.object(
         MicrosaltAnalysisAPI,
         "get_completed_cases",
         return_value=[microsalt_pass_case],
@@ -165,15 +165,15 @@
     store = qc_microsalt_context.status_db
     microsalt_api: MicrosaltAnalysisAPI = qc_microsalt_context.meta_apis["analysis_api"]
     mocker.patch.object(MicrosaltAnalysisAPI, "create_qc_done_file")
     mocker.patch.object(TrailblazerAPI, "set_analysis_status")
     mocker.patch.object(TrailblazerAPI, "add_comment")
 
     # GIVEN a store with a QC ready microsalt case that will fail QC
-    microsalt_fail_case: Family = store.family(microsalt_case_qc_fail)
+    microsalt_fail_case: Family = store.get_case_by_internal_id(internal_id=microsalt_case_qc_fail)
 
     mocker.patch.object(
         MicrosaltAnalysisAPI,
         "get_completed_cases",
         return_value=[microsalt_fail_case],
     )
     mocker.patch.object(
```

### Comparing `cg-27.1.9/tests/meta/workflow/test_prepare_fastq_api.py` & `cg-27.2.0/tests/meta/workflow/test_prepare_fastq_api.py`

 * *Files 4% similar despite different names*

```diff
@@ -17,15 +17,15 @@
     """Test when spring decompression is needed."""
 
     # GIVEN a populated prepare_fastq_api
     prepare_fastq_api = PrepareFastqAPI(
         store=analysis_store_single_case, compress_api=populated_compress_spring_api
     )
     # GIVEN a store with a case that has linked samples
-    case_obj: Family = analysis_store_single_case.family(case_id)
+    case_obj: Family = analysis_store_single_case.get_case_by_internal_id(internal_id=case_id)
     assert case_obj
     # GIVEN that the case has linked samples
     link_objects = [link_obj for link_obj in case_obj.links]
     assert link_objects
     # GIVEN a that there exists a version with only spring in housekeeper
     version_object = populated_compress_spring_api.hk_api.get_latest_bundle_version(
         bundle_name=sample_id
@@ -48,15 +48,15 @@
     """Test when spring decompression is not needed"""
 
     # GIVEN a populated prepare_fastq_api
     prepare_fastq_api = PrepareFastqAPI(
         store=analysis_store_single_case, compress_api=populated_compress_api_fastq_spring
     )
     # GIVEN a store with a case that has linked samples
-    case_obj: Family = analysis_store_single_case.family(case_id)
+    case_obj: Family = analysis_store_single_case.get_case_by_internal_id(internal_id=case_id)
     assert case_obj
     # GIVEN that the case has linked samples
     link_objects = [link_obj for link_obj in case_obj.links]
     assert link_objects
 
     # WHEN checking if spring decompression is needed
     res = prepare_fastq_api.is_spring_decompression_needed(case_id)
@@ -118,15 +118,15 @@
     """Test when FASTQ needs to be added to Housekeeper."""
 
     # GIVEN a populated prepare_fastq_api
     prepare_fastq_api = PrepareFastqAPI(
         store=analysis_store_single_case, compress_api=populated_compress_spring_api
     )
     # GIVEN a store with a case that has linked samples
-    case_obj: Family = analysis_store_single_case.family(case_id)
+    case_obj: Family = analysis_store_single_case.get_case_by_internal_id(internal_id=case_id)
     assert case_obj
     # GIVEN that the case has linked samples
     link_objects = [link_obj for link_obj in case_obj.links]
     assert link_objects
     # GIVEN a that there exists a version with only spring in housekeeper
     version_object = populated_compress_spring_api.hk_api.get_latest_bundle_version(
         bundle_name=sample_id
```

### Comparing `cg-27.1.9/tests/mocks/balsamic_analysis_mock.py` & `cg-27.2.0/tests/mocks/balsamic_analysis_mock.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/mocks/crunchy.py` & `cg-27.2.0/tests/mocks/crunchy.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/mocks/hk_mock.py` & `cg-27.2.0/tests/mocks/hk_mock.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Module for mocking out the HK api in CG"""
 
 import datetime
 import logging
 import tempfile
 from contextlib import contextmanager
 from pathlib import Path
-from typing import List, Optional, Dict, Iterable
+from typing import List, Optional, Dict, Set
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.constants import SequencingFileTag
 from cg.exc import HousekeeperBundleVersionMissingError
 
 from housekeeper.store.models import File, Version, Bundle
 
@@ -169,19 +169,24 @@
                     "root": str(ROOT_PATH),
                 }
             }
         self._database = config.get("housekeeper", {}).get("database")
         self.root_path = config.get("housekeeper", {}).get("root", str(ROOT_PATH))
 
     # Mock specific functions
-    def fetch_file_from_version(self, version_obj, tags):
+    def get_file_from_version(self, version: Version, tags: Set[str]):
         if tags.intersection(self._missing_tags):
             return None
         return self._files[0]
 
+    def get_latest_file_from_version(self, version: Version, tags: Set[str]):
+        if tags.intersection(self._missing_tags):
+            return None
+        return self._files[-1]
+
     def get_file_from_latest_version(self, bundle_name: str, tags: List[str]) -> Optional[File]:
         """Find a file in the latest version of a bundle."""
         version: Version = self.last_version(bundle=bundle_name)
         if not version:
             LOG.info(f"Bundle: {bundle_name} not found in Housekeeper")
             raise HousekeeperBundleVersionMissingError
         return self.files(version=version.id, tags=tags).first()
```

### Comparing `cg-27.1.9/tests/mocks/limsmock.py` & `cg-27.2.0/tests/mocks/limsmock.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/mocks/madeline.py` & `cg-27.2.0/tests/mocks/madeline.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/mocks/mip_analysis_mock.py` & `cg-27.2.0/tests/mocks/mip_analysis_mock.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/mocks/osticket.py` & `cg-27.2.0/tests/mocks/osticket.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 """Mock the os ticket api"""
 
 import logging
 import os.path
-from typing import Optional, List
+from typing import Optional
 
 from flask import Flask
 
 from cg.apps.osticket import OsTicket
 from cg.exc import TicketCreationError
 
 LOG = logging.getLogger(__name__)
@@ -22,16 +22,16 @@
         self.osticket_email = "james.holden@scilifelab.se"
         self.mail_container_uri = "dummy_uri"
         self._ticket_nr: str = "123456"
         self._should_fail: bool = False
         self._return_none: bool = False
         self.email_uri = "http://localhost:0000/sendmail"
 
-    def set_ticket_nr(self, ticket: str) -> None:
-        self._ticket_nr = ticket
+    def set_ticket_nr(self, ticket_id: str) -> None:
+        self._ticket_nr = ticket_id
 
     def init_app(self, app: Flask):
         """Initialize the API in Flask."""
 
     def setup(
         self,
         api_key: str = None,
```

### Comparing `cg-27.1.9/tests/mocks/process_mock.py` & `cg-27.2.0/tests/mocks/process_mock.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/mocks/report.py` & `cg-27.2.0/tests/mocks/report.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/mocks/scout.py` & `cg-27.2.0/tests/mocks/scout.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 """Mock the scout api"""
 
 import logging
 from pathlib import Path
-from datetime import datetime
 from pydantic import BaseModel, validator
-from typing import List, Optional
+from typing import List
 from typing_extensions import Literal
 
 from cg.apps.scout.scoutapi import ScoutAPI
 
 LOG = logging.getLogger(__name__)
 
 
@@ -71,15 +70,15 @@
 
     def nr_alignment_updates(self) -> int:
         """Return how many time alignment file was updated"""
         return self._alignment_file_updated
 
     # Overridden functions
 
-    def upload(self, data: dict, threshold: int = 5, force: bool = False):
+    def upload(self, data: dict, force: bool = False):
         """Load analysis of a new case into Scout."""
         LOG.debug("Case loaded successfully to Scout")
 
     def update_alignment_file(self, case_id: str, sample_id: str, alignment_path: Path):
         """Update alignment file for individual in case"""
         self._alignment_file_updated += 1
```

### Comparing `cg-27.1.9/tests/mocks/store_model.py` & `cg-27.2.0/tests/mocks/store_model.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/mocks/tb_mock.py` & `cg-27.2.0/tests/mocks/tb_mock.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/balsamic/conftest.py` & `cg-27.2.0/tests/models/balsamic/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/balsamic/test_balsamic_analysis.py` & `cg-27.2.0/tests/models/balsamic/test_balsamic_analysis.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/conftest.py` & `cg-27.2.0/tests/models/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/demultiplexing/conftest.py` & `cg-27.2.0/tests/models/demultiplexing/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/demultiplexing/test_demux_results.py` & `cg-27.2.0/tests/models/demultiplexing/test_demux_results.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/demultiplexing/test_flowcell_model.py` & `cg-27.2.0/tests/models/demultiplexing/test_flowcell_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 from pathlib import Path
 
-from cg.constants.demultiplexing import DemultiplexingDirsAndFiles
 from cg.models.demultiplex.flow_cell import FlowCell
 
 
 def test_flowcell_id(flow_cell_path: Path):
     """Test parsing of flow cell id."""
     # GIVEN the path to a finished flow cell run
     # GIVEN the flow cell id
```

### Comparing `cg-27.1.9/tests/models/mip/conftest.py` & `cg-27.2.0/tests/models/mip/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/mip/test_mip_analysis.py` & `cg-27.2.0/tests/models/mip/test_mip_analysis.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/mip/test_mip_config.py` & `cg-27.2.0/tests/models/mip/test_mip_config.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/mip/test_mip_metrics_deliverables.py` & `cg-27.2.0/tests/models/mip/test_mip_metrics_deliverables.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/mip/test_mip_sample_info.py` & `cg-27.2.0/tests/models/mip/test_mip_sample_info.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/nextflow/conftest.py` & `cg-27.2.0/tests/models/nextflow/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/nextflow/test_nextflow_deliver.py` & `cg-27.2.0/tests/models/nextflow/test_nextflow_deliver.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/observations/conftest.py` & `cg-27.2.0/tests/models/observations/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/observations/test_observations_input_files.py` & `cg-27.2.0/tests/models/observations/test_observations_input_files.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/report/test_validators.py` & `cg-27.2.0/tests/models/report/test_validators.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/rnafusion/conftest.py` & `cg-27.2.0/tests/models/rnafusion/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/rnafusion/test_rnafusion_sample.py` & `cg-27.2.0/tests/models/rnafusion/test_rnafusion_sample.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/test_cg_models.py` & `cg-27.2.0/tests/models/test_cg_models.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/test_file_data.py` & `cg-27.2.0/tests/models/test_file_data.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/models/test_flowcell_class.py` & `cg-27.2.0/tests/models/test_flowcell_class.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/server/conftest.py` & `cg-27.2.0/tests/server/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/api/add/test_store_add_base.py` & `cg-27.2.0/tests/store/api/add/test_store_add_base.py`

 * *Files 2% similar despite different names*

```diff
@@ -73,19 +73,21 @@
     assert stored_microbial_sample.reference_genome == reference_genome
     assert stored_microbial_sample.application_version == application_version
     assert stored_microbial_sample.priority_human == priority
     assert stored_microbial_sample.organism == organism
 
 
 def test_add_pool(rml_pool_store: Store):
-    """Tests whether new pools are invoiced as default"""
+    """Tests whether new pools are invoiced as default."""
     # GIVEN a valid customer and a valid application_version
     customer: Customer = rml_pool_store.get_customers()[0]
     application = rml_pool_store.get_application_by_tag(tag="RMLP05R800")
-    app_version = rml_pool_store.application_version(application=application, version=1)
+    app_version = rml_pool_store.get_application_version_by_application_entry_id(
+        application_entry_id=application.id
+    )
 
     # WHEN adding a new pool
     new_pool = rml_pool_store.add_pool(
         customer=customer,
         name="pool2",
         order="123456",
         ordered=dt.now(),
```

### Comparing `cg-27.1.9/tests/store/api/add/test_store_add_customer.py` & `cg-27.2.0/tests/store/api/add/test_store_add_customer.py`

 * *Files 1% similar despite different names*

```diff
@@ -23,15 +23,15 @@
 
     contact_field = f"{contact_type}_contact"
     setattr(new_customer, contact_field, new_user)
     store.add_commit(new_customer)
 
     # THEN contact should be stored on the customer
     assert (
-        getattr(store.get_customer_by_customer_id(customer_id=internal_id), contact_field)
+        getattr(store.get_customer_by_internal_id(customer_internal_id=internal_id), contact_field)
         == new_user
     )
 
 
 @pytest.mark.parametrize("contact_type", ["delivery", "primary", "invoice"])
 def test_contact_structure(store: Store, contact_type):
     # GIVEN the Customer model
```

### Comparing `cg-27.1.9/tests/store/api/add/test_store_add_flow_celll.py` & `cg-27.2.0/tests/store/api/add/test_store_add_flow_celll.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/api/delete/test_store_api_delete.py` & `cg-27.2.0/tests/store/api/delete/test_store_api_delete.py`

 * *Files 5% similar despite different names*

```diff
@@ -94,22 +94,24 @@
 
 def test_store_api_delete_non_existing_case(
     case_id_does_not_exist: str, store_with_multiple_cases_and_samples: Store
 ):
     """Test that nothing happens when trying to delete a case that does not exist."""
 
     # GIVEN a database containing some cases but not a specific case
-    case: Family = store_with_multiple_cases_and_samples.family(case_id_does_not_exist)
-    existing_cases: List[Family] = store_with_multiple_cases_and_samples.families().all()
+    case: Family = store_with_multiple_cases_and_samples.get_case_by_internal_id(
+        internal_id=case_id_does_not_exist
+    )
+    existing_cases: List[Family] = store_with_multiple_cases_and_samples.get_cases()
 
     assert not case
     assert existing_cases
 
     # WHEN removing empty cases, specifying the non existing case
     store_with_multiple_cases_and_samples.delete_cases_without_samples(
-        case_ids=[case_id_does_not_exist]
+        case_internal_ids=[case_id_does_not_exist]
     )
 
     # THEN no case has been deleted and nothing happens
-    remaining_cases: List[Family] = store_with_multiple_cases_and_samples.families().all()
+    remaining_cases: List[Family] = store_with_multiple_cases_and_samples.get_cases()
 
     assert len(remaining_cases) == len(existing_cases)
```

### Comparing `cg-27.1.9/tests/store/api/status/test_analyses_to_clean.py` & `cg-27.2.0/tests/store/api/status/test_analyses_to_clean.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/api/status/test_analyses_to_delivery_report.py` & `cg-27.2.0/tests/store/api/status/test_analyses_to_delivery_report.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 """This file tests the analyses_to_delivery_report part of the status api"""
-from datetime import datetime, timedelta
 
 from cg.constants import Pipeline, DataDelivery
 from cg.constants.subject import PhenotypeStatus
 from cg.store import Store
 from cg.utils.date import get_date
```

### Comparing `cg-27.1.9/tests/store/api/test_find_basic_data.py` & `cg-27.2.0/tests/store/api/find/test_find_basic_data.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,20 @@
 from typing import Optional, List
 from sqlalchemy.orm import Query
-from cg.store import Store
-from cg.store.models import Bed, BedVersion, Customer, Collaboration, Organism, User, Application
 from cg.constants.constants import MicrosaltAppTags
+from cg.store import Store
+from cg.store.models import (
+    Application,
+    Bed,
+    BedVersion,
+    Customer,
+    Collaboration,
+    Organism,
+    User,
+)
 
 
 def test_get_active_beds(base_store: Store):
     """Test returning not archived bed records from the database."""
 
     # GIVEN a store with beds
 
@@ -178,21 +186,21 @@
         bed_version_short_name=bed_version_short_name
     )
 
     # THEN return a bed version with the supplied bed version short name
     assert bed_version.shortname == bed_version_short_name
 
 
-def test_get_customer_by_customer_id(base_store: Store, customer_id: str):
+def test_get_customer_by_internal_id(base_store: Store, customer_id: str):
     """Test function to return the customer by customer id."""
 
     # GIVEN a store with customer records
 
     # WHEN getting the query for the customer
-    customer: Customer = base_store.get_customer_by_customer_id(customer_id=customer_id)
+    customer: Customer = base_store.get_customer_by_internal_id(customer_internal_id=customer_id)
 
     # THEN return a customer with the supplied customer internal id
     assert customer.internal_id == customer_id
 
 
 def test_get_customers(base_store: Store, customer_id: str):
     """Test function to return customers."""
```

### Comparing `cg-27.1.9/tests/store/api/test_find_business_data.py` & `cg-27.2.0/tests/store/api/find/test_find_business_data.py`

 * *Files 6% similar despite different names*

```diff
@@ -17,27 +17,28 @@
     Sample,
     Invoice,
     Pool,
     Customer,
 )
 from tests.store_helpers import StoreHelpers
 from cg.constants.invoice import CustomerNames
-from tests.store.conftest import fixture_store_with_a_pool_with_and_without_attributes
 
 
-def test_find_analysis_via_date(
+def test_get_analysis_by_case_entry_id_and_started_at(
     sample_store: Store, helpers: StoreHelpers, timestamp_now: datetime
 ):
     """Test returning an analysis using a date."""
     # GIVEN a case with an analysis with a start date in the database
     analysis = helpers.add_analysis(store=sample_store, started_at=timestamp_now)
     assert analysis.started_at
 
     # WHEN getting analysis via case_id and start date
-    db_analysis = sample_store.analysis(analysis.family, analysis.started_at)
+    db_analysis = sample_store.get_analysis_by_case_entry_id_and_started_at(
+        case_entry_id=analysis.family.id, started_at_date=analysis.started_at
+    )
 
     # THEN the analysis should have been retrieved
     assert db_analysis == analysis
 
 
 def test_get_flow_cell_sample_links_query(re_sequenced_sample_store: Store):
     """Test function to return the flow cell sample links query from the database."""
@@ -348,53 +349,57 @@
     # THEN return true
     assert is_on_disk is True
 
     # THEN log the status of the flow cell
     assert f"{flow_cell.name}: status is {flow_cell.status}" in caplog.text
 
 
-def test_get_customer_id_from_ticket(analysis_store, customer_id, ticket: str):
+def test_get_customer_id_from_ticket(analysis_store, customer_id, ticket_id: str):
     """Tests if the function in fact returns the correct customer."""
     # Given a store with a ticket
 
     # Then the function should return the customer connected to the ticket
-    assert analysis_store.get_customer_id_from_ticket(ticket) == customer_id
+    assert analysis_store.get_customer_id_from_ticket(ticket_id) == customer_id
 
 
-def test_get_latest_ticket_from_case(case_id: str, analysis_store_single_case, ticket: str):
+def test_get_latest_ticket_from_case(case_id: str, analysis_store_single_case, ticket_id: str):
     """Tests if the correct ticket is returned for the given case."""
     # GIVEN a populated store with a case
 
     # WHEN the function is called
     ticket_from_case: str = analysis_store_single_case.get_latest_ticket_from_case(case_id=case_id)
 
     # THEN the ticket should be correct
-    assert ticket == ticket_from_case
+    assert ticket_id == ticket_from_case
 
 
 def test_get_ready_made_library_expected_reads(case_id: str, rml_pool_store: Store):
     """Test if the correct number of expected reads is returned."""
 
     # GIVEN a case with a sample with an application version
     application_version: ApplicationVersion = (
-        rml_pool_store.family(case_id).links[ListIndexes.FIRST.value].sample.application_version
+        rml_pool_store.get_case_by_internal_id(internal_id=case_id)
+        .links[ListIndexes.FIRST.value]
+        .sample.application_version
     )
 
     # WHEN the expected reads is fetched from the case
     expected_reads: int = rml_pool_store.get_ready_made_library_expected_reads(case_id=case_id)
 
     # THEN the fetched reads should be equal to the expected reads of the application versions application
     assert application_version.application.expected_reads == expected_reads
 
 
 def test_get_application_by_case(case_id: str, rml_pool_store: Store):
     """Test that the correct application is returned on a case."""
     # GIVEN a case with a sample with an application version
     application_version: ApplicationVersion = (
-        rml_pool_store.family(case_id).links[ListIndexes.FIRST.value].sample.application_version
+        rml_pool_store.get_case_by_internal_id(internal_id=case_id)
+        .links[ListIndexes.FIRST.value]
+        .sample.application_version
     )
 
     # WHEN the application is fetched from the case
     application: Application = rml_pool_store.get_application_by_case(case_id=case_id)
 
     # THEN the fetched application should be equal to the application version application
     assert application_version.application == application
@@ -440,114 +445,27 @@
 
 
 def test_find_cases_for_non_existing_case(store_with_multiple_cases_and_samples: Store):
     """Test that nothing happens when trying to find a case that does not exist."""
 
     # GIVEN a database containing some cases but not a specific case
     case_id: str = "some_case"
-    case: Family = store_with_multiple_cases_and_samples.family(case_id)
+    case: Family = store_with_multiple_cases_and_samples.get_case_by_internal_id(
+        internal_id=case_id
+    )
 
     assert not case
 
     # WHEN trying to find cases with samples given the non existing case id
     cases = store_with_multiple_cases_and_samples.filter_cases_with_samples(case_ids=[case_id])
 
     # THEN no cases are found
     assert not cases
 
 
-def test_get_all_pools_and_samples_for_invoice_by_invoice_id(store: Store, helpers: StoreHelpers):
-    """Test that all pools and samples for an invoice can be fetched."""
-
-    # GIVEN a database with a pool and a sample
-    pool = helpers.ensure_pool(store=store, name="pool_1")
-    sample = helpers.add_sample(store=store, name="sample_1")
-
-    # AND an invoice with the pool and sample
-    invoice: Invoice = helpers.ensure_invoice(store=store, pools=[pool], samples=[sample])
-
-    # ASSERT that there is an invoice with a pool and a sample
-    assert len(invoice.pools) == 1
-    assert len(invoice.samples) == 1
-
-    # WHEN fetching all pools and samples for the invoice
-    records = store.get_pools_and_samples_for_invoice_by_invoice_id(invoice_id=invoice.id)
-    # THEN the pool and sample should be returned
-    assert pool in records
-    assert sample in records
-
-
-def test_get_samples_by_subject_id(
-    store_with_samples_subject_id_and_tumour_status: Store,
-    helpers: StoreHelpers,
-    customer_id: str = "cust123",
-    subject_id: str = "test_subject",
-):
-    """Test that samples can be fetched by subject id."""
-    # GIVEN a database with two samples that have a subject ID but only one is tumour
-
-    # ASSERT that there are two samples in the store
-    assert len(store_with_samples_subject_id_and_tumour_status.get_all_samples()) == 2
-
-    # ASSERT that there is a customer with the given customer id
-    assert store_with_samples_subject_id_and_tumour_status.get_customer_by_customer_id(
-        customer_id=customer_id
-    )
-
-    # WHEN fetching the sample by subject id and customer_id
-    samples = store_with_samples_subject_id_and_tumour_status.get_samples_by_subject_id(
-        subject_id=subject_id, customer_id=customer_id
-    )
-
-    # THEN two samples should be returned
-    assert samples and len(samples) == 2
-
-
-def test_get_samples_by_subject_id_and_is_tumour(
-    store_with_samples_subject_id_and_tumour_status: Store,
-    helpers: StoreHelpers,
-    customer_id: str = "cust123",
-    subject_id: str = "test_subject",
-    is_tumour: bool = True,
-):
-    """Test that samples can be fetched by subject id."""
-    # GIVEN a database with two samples that have a subject ID but only one is tumour
-
-    # ASSERT that there are two samples in the store
-    assert len(store_with_samples_subject_id_and_tumour_status.get_all_samples()) == 2
-
-    # ASSERT that there is a customer with the given customer id
-    assert store_with_samples_subject_id_and_tumour_status.get_customer_by_customer_id(
-        customer_id=customer_id
-    )
-    # WHEN fetching the sample by subject id and customer_id
-    samples: List[
-        Sample
-    ] = store_with_samples_subject_id_and_tumour_status.get_samples_by_subject_id_and_is_tumour(
-        subject_id=subject_id, customer_id=customer_id, is_tumour=is_tumour
-    )
-
-    # THEN two samples should be returned
-    assert samples and len(samples) == 1
-
-
-def test_filter_get_sample_by_name(store_with_samples_that_have_names: Store, name="sample_1"):
-    """Test that samples can be fetched by name."""
-    # GIVEN a database with two samples of which one has a name
-
-    # ASSERT that there are two samples in the store
-    assert len(store_with_samples_that_have_names.get_all_samples()) == 2
-
-    # WHEN fetching the sample by name
-    samples: Sample = store_with_samples_that_have_names.get_sample_by_name(name=name)
-
-    # THEN one sample should be returned
-    assert samples and samples.name == name
-
-
 def test_is_case_down_sampled_true(base_store: Store, case_obj: Family, sample_id: str):
     """Tests the down sampling check when all samples are down sampled."""
     # GIVEN a case where all samples are down sampled
     for sample in case_obj.samples:
         sample.from_sample = sample_id
     base_store.commit()
 
@@ -746,7 +664,27 @@
 
     pools: List[Pool] = store_with_multiple_pools_for_customer.get_pools_to_render(
         customers=store_with_multiple_pools_for_customer.get_customers(), enquiry=pool_order_1
     )
 
     # THEN one pools should be returned
     assert len(pools) == 1
+
+
+def test_get_case_by_name_and_customer_case_found(store_with_multiple_cases_and_samples: Store):
+    """Test that a case can be found by customer and case name."""
+    # GIVEN a database with multiple cases for a customer
+    case: Family = store_with_multiple_cases_and_samples._get_query(table=Family).first()
+    customer: Customer = store_with_multiple_cases_and_samples._get_query(table=Customer).first()
+
+    assert case.customer == customer
+
+    # WHEN fetching a case by customer and case name
+    filtered_case: Family = store_with_multiple_cases_and_samples.get_case_by_name_and_customer(
+        customer=customer,
+        case_name=case.name,
+    )
+
+    # THEN the correct case should be returned
+    assert filtered_case is not None
+    assert filtered_case.customer_id == customer.id
+    assert filtered_case.name == case.name
```

### Comparing `cg-27.1.9/tests/store/api/test_store_api_status.py` & `cg-27.2.0/tests/store/api/status/test_store_api_status.py`

 * *Files 16% similar despite different names*

```diff
@@ -5,66 +5,14 @@
 from cg.constants import Pipeline, Priority
 from cg.constants.subject import PhenotypeStatus
 from cg.store import Store
 from cg.store.models import Analysis, Application, Family, Sample
 from tests.store_helpers import StoreHelpers
 
 
-def test_samples_to_receive_external(sample_store, helpers):
-    """Test fetching external sample."""
-    store = sample_store
-    # GIVEN a store with a mixture of samples
-    assert len(store.get_all_samples()) > 1
-
-    # WHEN finding external samples to receive
-    external_query: List[Sample] = store.get_all_samples_to_receive(external=True)
-
-    # ASSERT that external_query is a list[sample]
-    assert isinstance(external_query, list)
-    # THEN assert that only the external sample is returned
-    assert len(external_query) == 1
-
-    first_sample = external_query[0]
-    # THEN assert that the sample is external in database
-    assert first_sample.application_version.application.is_external is True
-    # THEN assert that the sample is does not have a received at stamp
-    assert first_sample.received_at is None
-
-
-def test_get_all_samples_to_receive_internal(sample_store):
-    # GIVEN a store with samples in a mix of states
-    assert len(sample_store.get_all_samples()) > 1
-    assert len([sample for sample in sample_store.get_all_samples() if sample.received_at]) > 1
-
-    # WHEN finding which samples are in queue to receive
-    assert len(sample_store.get_all_samples_to_receive()) == 1
-    first_sample = sample_store.get_all_samples_to_receive()[0]
-    assert first_sample.application_version.application.is_external is False
-    assert first_sample.received_at is None
-
-
-def test_samples_to_sequence(sample_store):
-    # GIVEN a store with sample in a mix of states
-    assert len(sample_store.get_all_samples()) > 1
-    assert len([sample for sample in sample_store.get_all_samples() if sample.sequenced_at]) >= 1
-
-    # WHEN finding which samples are in queue to be sequenced
-    sequence_samples: List[Sample] = sample_store.get_all_samples_to_sequence()
-
-    # THEN it should list the received and partly sequenced samples
-    assert len(sequence_samples) == 2
-    assert {sample.name for sample in sequence_samples} == set(
-        ["sequenced-partly", "received-prepared"]
-    )
-    for sample in sequence_samples:
-        assert sample.sequenced_at is None
-        if sample.name == "sequenced-partly":
-            assert sample.reads > 0
-
-
 def test_case_in_uploaded_observations(helpers: StoreHelpers, sample_store: Store, loqusdb_id: str):
     """Test retrieval of uploaded observations."""
 
     # GIVEN a case with observations that has been uploaded to Loqusdb
     analysis: Analysis = helpers.add_analysis(store=sample_store, pipeline=Pipeline.MIP_DNA)
     analysis.family.customer.loqus_upload = True
     sample: Sample = helpers.add_sample(sample_store, loqusdb_id=loqusdb_id)
@@ -253,15 +201,15 @@
     """Tests if actions of cases are changed to analyze."""
     # Given a store with a case with action None
     action = analysis_store.Family.query.filter(Family.internal_id == case_id).first().action
 
     assert action == None
 
     # When setting the case to "analyze"
-    analysis_store.set_case_action(case_id=case_id, action="analyze")
+    analysis_store.set_case_action(case_internal_id=case_id, action="analyze")
     new_action = analysis_store.Family.query.filter(Family.internal_id == case_id).first().action
 
     # Then the action should be set to analyze
     assert new_action == "analyze"
 
 
 def test_sequencing_qc_priority_express_sample_with_one_half_of_the_reads(
```

### Comparing `cg-27.1.9/tests/store/api/test_store_api_status_analysis.py` & `cg-27.2.0/tests/store/api/status/test_store_api_status_analysis.py`

 * *Files 17% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 from cg.store.models import Analysis, Family, Sample
 from tests.store_helpers import StoreHelpers
 
 
 def test_get_families_with_extended_models(
     base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
 ):
-    """Test that a query is returned from the database"""
+    """Test that a query is returned from the database."""
 
     # GIVEN a sequenced sample
     test_sample: Sample = helpers.add_sample(base_store, sequenced_at=timestamp_now)
 
     # GIVEN a completed analysis
     test_analysis: Analysis = helpers.add_analysis(
         base_store, completed_at=timestamp_now, pipeline=Pipeline.MIP_DNA
@@ -40,15 +40,15 @@
     assert cases
 
     # THEN analysis should be part of cases attributes
     assert case.analyses[0].pipeline == Pipeline.MIP_DNA
 
 
 def test_get_families_with_extended_models_when_no_case(base_store: Store):
-    """test that no case is returned from the database when no cases"""
+    """test that no case is returned from the database when no cases."""
 
     # GIVEN an empty database
 
     # WHEN getting cases to analyse
     cases: List[Query] = list(base_store._get_outer_join_cases_with_analyses_query())
 
     # THEN no cases should be returned
@@ -78,15 +78,15 @@
     assert cases
     assert test_sample == cases[0].links[0].sample
 
 
 def test_that_many_cases_can_have_one_sample_each(
     base_store: Store, helpers: StoreHelpers, max_nr_of_cases: int, timestamp_now: datetime
 ):
-    """Test that tests that cases are returned even if there are many result rows in the query"""
+    """Test that tests that cases are returned even if there are many result rows in the query."""
 
     # GIVEN a database with max_nr_of_cases cases
     test_cases: List[Family] = helpers.add_cases_with_samples(
         base_store, max_nr_of_cases, sequenced_at=timestamp_now
     )
 
     # WHEN getting cases to analyse
@@ -95,15 +95,15 @@
     # THEN cases should contain all cases since they are to be analysed
     assert len(cases) == len(test_cases)
 
 
 def test_that_cases_can_have_many_samples(
     base_store: Store, helpers, max_nr_of_samples: int, timestamp_now: datetime
 ):
-    """Test that tests that cases are returned even if there are many result rows in the query"""
+    """Test that tests that cases are returned even if there are many result rows in the query."""
 
     # GIVEN a cases with max_nr_of_samples sequenced samples
     case_with_50: Family = helpers.add_case_with_samples(
         base_store, "case_with_50_samples", max_nr_of_samples, sequenced_at=timestamp_now
     )
 
     # GIVEN a sequnced sample
@@ -155,15 +155,15 @@
     assert cases
 
     # THEN test case should be among the cases returned for analysis
     assert test_analysis.family in cases
 
 
 def test_new_external_case_not_in_result(base_store: Store, helpers: StoreHelpers):
-    """Test that a case with one external sample that has no specified data_analysis does not show up"""
+    """Test that a case with one external sample that has no specified data_analysis does not show up."""
 
     # GIVEN an externally sequenced sample
     test_sample: Sample = helpers.add_sample(base_store, sequenced_at=None, is_external=True)
 
     # GIVEN a cancer case
     test_case: Family = helpers.add_case(base_store, data_analysis=Pipeline.BALSAMIC)
 
@@ -175,15 +175,15 @@
 
     # THEN cases should not contain the test case
     assert test_case not in cases
 
 
 def test_case_to_re_analyse(base_store: Store, helpers: StoreHelpers, timestamp_now: datetime):
     """Test that a case marked for re-analyse with one sample that has been sequenced and
-    with completed analysis do show up among the cases to analyse"""
+    with completed analysis do show up among the cases to analyse."""
 
     # GIVEN a sequenced sample
     test_sample: Sample = helpers.add_sample(base_store, sequenced_at=timestamp_now)
 
     # GIVEN a completed analysis
     test_analysis: Analysis = helpers.add_analysis(
         base_store, completed_at=timestamp_now, pipeline=Pipeline.MIP_DNA
@@ -205,15 +205,15 @@
     assert test_analysis.family in cases
 
 
 def test_all_samples_and_analysis_completed(
     base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
 ):
     """Test that a case with one sample that has been sequenced and with completed
-    analysis don't show up among the cases to analyse"""
+    analysis don't show up among the cases to analyse."""
 
     # GIVEN a sequenced sample
     test_sample: Sample = helpers.add_sample(base_store, sequenced_at=timestamp_now)
 
     # GIVEN a completed analysis
     test_analysis: Analysis = helpers.add_analysis(base_store, completed_at=timestamp_now)
 
@@ -229,15 +229,15 @@
     # THEN cases should not contain the test case
     assert not cases
 
 
 def test_specified_analysis_in_result(
     base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
 ):
-    """Test that a case with one sample that has specified data_analysis does show up"""
+    """Test that a case with one sample that has specified data_analysis does show up."""
 
     # GIVEN a sequenced sample
     test_sample: Sample = helpers.add_sample(base_store, sequenced_at=timestamp_now)
 
     # GIVEN a cancer case
     test_case: Family = helpers.add_case(base_store, data_analysis=Pipeline.BALSAMIC)
 
@@ -254,15 +254,15 @@
     assert test_case in cases
 
 
 def test_exclude_other_pipeline_analysis_from_result(
     base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
 ):
     """Test that a case with specified analysis and with one sample does not show up among
-    others"""
+    others."""
 
     # GIVEN a sequenced sample
     test_sample: Sample = helpers.add_sample(base_store, sequenced_at=timestamp_now)
 
     # GIVEN a cancer case
     test_case = helpers.add_case(base_store, data_analysis=Pipeline.BALSAMIC)
 
@@ -276,15 +276,15 @@
     assert test_case not in cases
 
 
 def test_one_of_two_sequenced_samples(
     base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
 ):
     """Test that a case with one sequenced samples and one not sequenced sample do not shows up among the
-    cases to analyse"""
+    cases to analyse."""
 
     # GIVEN a case
     test_case: Family = helpers.add_case(base_store)
 
     # GIVEN a sequenced sample
     sequenced_sample: Sample = helpers.add_sample(base_store, sequenced_at=timestamp_now)
 
@@ -302,15 +302,15 @@
     assert not cases
 
 
 def test_one_of_one_sequenced_samples(
     base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
 ):
     """Test that a case with one of one samples that has been sequenced shows up among the
-    cases to analyse"""
+    cases to analyse."""
 
     # GIVEN a case
     test_case: Family = helpers.add_case(base_store)
 
     # GIVEN a sequenced sample
     test_sample = helpers.add_sample(base_store, sequenced_at=timestamp_now)
 
@@ -322,7 +322,96 @@
     cases: List[Family] = base_store.cases_to_analyze(pipeline=Pipeline.MIP_DNA)
 
     # THEN cases should be returned
     assert cases
 
     # THEN cases should contain the test case
     assert test_case in cases
+
+
+def test_get_analyses_for_case_and_pipeline_before(
+    store_with_analyses_for_cases_not_uploaded_fluffy: Store,
+    timestamp_now: datetime,
+    pipeline: Pipeline = Pipeline.FLUFFY,
+    case_id: str = "yellowhog",
+):
+    """Test to get all analyses before a given date."""
+
+    # GIVEN a database with a number of analyses
+
+    # WHEN getting all analyses before a given date
+    analyses: List[
+        Analysis
+    ] = store_with_analyses_for_cases_not_uploaded_fluffy.get_analyses_for_case_and_pipeline_started_at_before(
+        case_internal_id=case_id, started_at_before=timestamp_now, pipeline=pipeline
+    )
+
+    # THEN assert that the analyses before the given date are returned
+    for analysis in analyses:
+        assert analysis.started_at < timestamp_now
+        assert analysis.family.internal_id == case_id
+        assert analysis.pipeline == pipeline
+
+
+def test_get_analyses_for_case_before(
+    store_with_analyses_for_cases_not_uploaded_fluffy: Store,
+    timestamp_now: datetime,
+    case_id: str = "yellowhog",
+):
+    """Test to get all analyses before a given date."""
+
+    # GIVEN a database with a number of analyses
+
+    # WHEN getting all analyses before a given date
+    analyses: List[
+        Analysis
+    ] = store_with_analyses_for_cases_not_uploaded_fluffy.get_analyses_for_case_started_at_before(
+        case_internal_id=case_id,
+        started_at_before=timestamp_now,
+    )
+
+    # THEN assert that the analyses before the given date are returned
+    for analysis in analyses:
+        assert analysis.started_at < timestamp_now
+        assert analysis.family.internal_id == case_id
+
+
+def test_get_analyses_for_pipeline_before(
+    store_with_analyses_for_cases_not_uploaded_fluffy: Store,
+    timestamp_now: datetime,
+    pipeline: Pipeline = Pipeline.FLUFFY,
+):
+    """Test to get all analyses for a pipeline before a given date."""
+
+    # GIVEN a database with a number of analyses
+
+    # WHEN getting all analyses before a given date
+    analyses: List[
+        Analysis
+    ] = store_with_analyses_for_cases_not_uploaded_fluffy.get_analyses_for_pipeline_started_at_before(
+        started_at_before=timestamp_now, pipeline=pipeline
+    )
+
+    # THEN assert that the analyses before the given date are returned
+    for analysis in analyses:
+        assert analysis.started_at < timestamp_now
+        assert analysis.pipeline == pipeline
+
+
+def test_get_analyses_before(
+    store_with_analyses_for_cases_not_uploaded_fluffy: Store,
+    timestamp_now: datetime,
+):
+    """Test to get all analyses for a pipeline before a given date."""
+
+    # GIVEN a database with a number of analyses
+
+    # WHEN getting all analyses before a given date
+    analyses: List[
+        Analysis
+    ] = store_with_analyses_for_cases_not_uploaded_fluffy.get_analyses_started_at_before(
+        started_at_before=timestamp_now
+    )
+
+    # THEN assert that the analyses before the given date are returned
+    for analysis in analyses:
+        assert analysis.started_at < timestamp_now
```

### Comparing `cg-27.1.9/tests/store/api/test_store_api_status_cases.py` & `cg-27.2.0/tests/store/api/status/test_store_api_status_cases.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 """This script tests the cli methods to add families to status-db"""
 from datetime import datetime, timedelta
 
 from cg.constants import CASE_ACTIONS, DataDelivery, Pipeline
 from cg.store import Store
-
+from cg.store.models import Analysis, Family
 from cg.constants import Priority
 
 
 def test_delivered_at_affects_tat(base_store: Store, helpers):
     """test that the estimated turnaround time is affected by the delivered_at date"""
 
     # GIVEN a database with a case and a samples receive_at, prepared_at, sequenced_at,
@@ -1268,16 +1268,16 @@
 
 def test_analysis_completed_at(base_store: Store, helpers):
     """Test to that cases displays when they were completed"""
 
     # GIVEN a database with an analysis that is completed
     analysis = helpers.add_analysis(base_store, completed_at=datetime.now())
     assert analysis.completed_at is not None
-    assert base_store.families().count() == 1
-    assert base_store.analyses().count() == 1
+    assert base_store._get_query(table=Family).count() == 1
+    assert base_store._get_query(table=Analysis).count() == 1
 
     # WHEN getting active cases
     cases = base_store.cases()
 
     # THEN cases should contain info on completion occasion
     assert cases
     for case in cases:
```

### Comparing `cg-27.1.9/tests/store/api/test_store_import_func.py` & `cg-27.2.0/tests/store/api/test_store_import_func.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/conftest.py` & `cg-27.2.0/tests/store/conftest.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,19 +1,21 @@
 """Fixtures for store tests."""
-import datetime
+import datetime as dt
 import enum
 from pathlib import Path
-from typing import Generator
+from typing import Generator, List
 import pytest
 
 from cg.constants import Pipeline
 from cg.constants.subject import Gender
 from cg.store import Store
-from cg.store.models import Analysis, Family, Sample
+from cg.store.models import Analysis, Application, Family, Sample, Customer
 from tests.store_helpers import StoreHelpers
+from tests.store.api.conftest import fixture_applications_store
+from tests.conftest import fixture_old_timestamp
 
 
 class StoreConftestFixture(enum.Enum):
     INTERNAL_ID_SAMPLE_WITH_ATTRIBUTES: str = "sample_with_attributes"
     NAME_SAMPLE_WITH_ATTRIBUTES: str = "sample_with_attributes"
     SUBJECT_ID_SAMPLE_WITH_ATTRIBUTES: str = "test_subject_id"
     DOWN_SAMPLED_TO_SAMPLE_WITH_ATTRIBUTES: int = 1
@@ -32,14 +34,26 @@
     PREP_CATEGORY_APPLICATION_WITH_ATTRIBUTES: str = "wgs"
     PREP_CATEGORY_APPLICATION_WITHOUT_ATTRIBUTES: str = "wes"
     TAG_APPLICATION_WITHOUT_ATTRIBUTES: str = "test_tag_2"
 
     INVOICE_ID_INVOICE_WITH_ATTRIBUTES: int = 1
     INVOICE_ID_INVOICE_WITHOUT_ATTRIBUTES: int = 2
 
+    @staticmethod
+    def generate_year_interval(n_entries: int, old_timestamp: dt.datetime) -> List[int]:
+        """Create a list of approximately uniformly distributed year numbers from 1 to present."""
+        start: int = old_timestamp.year
+        stop: int = dt.date.today().year
+        step: float = (stop - start) / (n_entries - 1)
+        output = [start]
+
+        for i in range(1, n_entries):
+            output.append(output[0] + round(i * step))
+        return output
+
 
 @pytest.fixture(name="application_versions_file")
 def fixture_application_versions_file(fixtures_dir: Path) -> str:
     """Return application version import file."""
     return Path(fixtures_dir, "store", "api", "application_versions.xlsx").as_posix()
 
 
@@ -110,16 +124,16 @@
 
 
 @pytest.fixture(name="microbial_store")
 def fixture_microbial_store(
     base_store: Store, microbial_submitted_order: dict
 ) -> Generator[Store, None, None]:
     """Set up a microbial store instance."""
-    customer: Customer = base_store.get_customer_by_customer_id(
-        customer_id=microbial_submitted_order["customer"]
+    customer: Customer = base_store.get_customer_by_internal_id(
+        customer_internal_id=microbial_submitted_order["customer"]
     )
 
     for sample_data in microbial_submitted_order["items"]:
         application_version = base_store.get_application_by_tag(
             sample_data["application"]
         ).versions[0]
         organism = base_store.Organism(
@@ -142,40 +156,58 @@
     base_store.commit()
     yield base_store
 
 
 @pytest.fixture(name="analysis_obj")
 def fixture_analysis_obj(analysis_store: Store) -> Analysis:
     """Return an analysis object from a populated store."""
-    return analysis_store.analyses()[0]
+    return analysis_store._get_query(table=Analysis)[0]
 
 
 @pytest.fixture(name="case_obj")
 def fixture_case_obj(analysis_store: Store) -> Family:
     """Return a case models object."""
-    return analysis_store.families()[0]
+    return analysis_store.get_cases()[0]
 
 
 @pytest.fixture(name="sample_obj")
 def fixture_sample_obj(analysis_store) -> Sample:
     """Return a sample models object."""
-    return analysis_store.get_all_samples()[0]
+    return analysis_store.get_samples()[0]
 
 
 @pytest.fixture(name="sequencer_name")
 def fixture_sequencer_name() -> str:
     """Return sequencer name."""
     return "A00689"
 
 
+@pytest.fixture(name="invalid_application_id")
+def fixture_invalid_application_id() -> int:
+    """Return an invalid application id."""
+    return -1
+
+
+@pytest.fixture(name="invalid_application_tag")
+def fixture_invalid_application_tag() -> str:
+    """Return an invalid application tag."""
+    return "invalid-tag"
+
+
+@pytest.fixture(name="invalid_application_version_version")
+def fixture_invalid_application_version_version() -> int:
+    """Return an invalid version of an Application Version."""
+    return -1
+
+
 @pytest.fixture(name="store_with_a_sample_that_has_many_attributes_and_one_without")
 def fixture_store_with_a_sample_that_has_many_attributes_and_one_without(
     store: Store,
     helpers: StoreHelpers,
-    timestamp_now=datetime.datetime.now(),
+    timestamp_now=dt.datetime.now(),
 ) -> Store:
     """Return a store with a sample that has many attributes and one without."""
     helpers.add_sample(
         store,
         internal_id=StoreConftestFixture.INTERNAL_ID_SAMPLE_WITH_ATTRIBUTES.value,
         name=StoreConftestFixture.NAME_SAMPLE_WITH_ATTRIBUTES.value,
         is_external=True,
@@ -209,15 +241,15 @@
     return store
 
 
 @pytest.fixture(name="store_with_a_pool_with_and_without_attributes")
 def fixture_store_with_a_pool_with_and_without_attributes(
     store: Store,
     helpers: StoreHelpers,
-    timestamp_now=datetime.datetime.now(),
+    timestamp_now=dt.datetime.now(),
 ) -> Store:
     """Return a store with a pool with and without attributes."""
     helpers.ensure_pool(
         store=store,
         delivered_at=timestamp_now,
         received_at=timestamp_now,
         invoice_id=StoreConftestFixture.INVOICE_ID_POOL_WITH_ATTRIBUTES.value,
@@ -238,15 +270,15 @@
     return store
 
 
 @pytest.fixture(name="store_with_an_application_with_and_without_attributes")
 def fixture_store_with_an_application_with_and_without_attributes(
     store: Store,
     helpers: StoreHelpers,
-    timestamp_now=datetime.datetime.now(),
+    timestamp_now=dt.datetime.now(),
 ) -> Store:
     """Return a store with an application with and without attributes."""
     helpers.ensure_application(
         store=store,
         tag=StoreConftestFixture.TAG_APPLICATION_WITH_ATTRIBUTES.value,
         prep_category=StoreConftestFixture.PREP_CATEGORY_APPLICATION_WITH_ATTRIBUTES.value,
         is_external=True,
@@ -260,27 +292,94 @@
         is_external=False,
         is_archived=False,
     )
 
     return store
 
 
+@pytest.fixture(name="store_with_different_application_versions")
+def fixture_store_with_different_application_versions(
+    applications_store: Store,
+    helpers: StoreHelpers,
+    old_timestamp: dt.datetime,
+) -> Store:
+    """Returns a store with application versions with different applications, dates and versions."""
+    applications: List[Application] = applications_store.get_applications()
+    years: List[int] = StoreConftestFixture.generate_year_interval(
+        n_entries=len(applications),
+        old_timestamp=old_timestamp,
+    )
+    versions: List[int] = list(range(1, len(applications) + 1))
+
+    for application, year, version in zip(applications, years, versions):
+        helpers.ensure_application_version(
+            store=applications_store,
+            application_tag=application.tag,
+            valid_from=dt.datetime(year, 1, 1, 1, 1, 1),
+            version=version,
+        )
+    return applications_store
+
+
 @pytest.fixture(name="store_with_an_invoice_with_and_without_attributes")
 def fixture_store_with_an_invoice_with_and_without_attributes(
     store: Store,
     helpers: StoreHelpers,
-    timestamp_now=datetime.datetime.now(),
+    timestamp_now=dt.datetime.now(),
 ) -> Store:
     """Return a store with an invoice with and without attributes."""
     helpers.ensure_invoice(
         store=store,
         invoice_id=StoreConftestFixture.INVOICE_ID_INVOICE_WITH_ATTRIBUTES.value,
         invoiced_at=timestamp_now,
     )
 
     helpers.ensure_invoice(
         store=store,
         invoice_id=StoreConftestFixture.INVOICE_ID_INVOICE_WITHOUT_ATTRIBUTES.value,
         invoiced_at=None,
     )
-
     return store
+
+
+@pytest.fixture(name="store_with_case_and_analysis")
+def fixture_store_with_case_and_analysis(
+    store: Store, helpers: StoreHelpers, analysis_type: str = "wgs"
+) -> Store:
+    """Return a store with a case and analysis."""
+    # GIVEN a store with a case and analysis
+    case = helpers.add_case(store=store, name="test_case", internal_id="test_case_internal_id")
+    helpers.add_analysis(store=store, case=case)
+    yield store
+
+
+@pytest.fixture(name="store_with_older_and_newer_analyses")
+def fixture_store_with_older_and_newer_analyses(
+    base_store: Store,
+    helpers: StoreHelpers,
+    case_obj: Family,
+    timestamp_now: dt.datetime,
+    timestamp_yesterday: dt.datetime,
+    old_timestamp: dt.datetime,
+) -> Store:
+    """Return a store with  older and newer analyses."""
+    analysis = base_store.Analysis.query.first()
+    analysis.uploaded_at = timestamp_now
+    analysis.uploaded_to_vogue_at = timestamp_now
+    analysis.cleaned_at = timestamp_now
+    analysis.started_at = timestamp_now
+    analysis.completed_at = timestamp_now
+    base_store.add_commit(analysis)
+    times = [timestamp_now, timestamp_yesterday, old_timestamp]
+    for time in times:
+        helpers.add_analysis(
+            store=base_store,
+            case=case_obj,
+            pipeline=Pipeline.BALSAMIC,
+            started_at=time,
+            completed_at=time,
+            uploaded_at=time,
+            uploaded_to_vogue_at=time,
+            cleaned_at=time,
+        )
+
+    yield base_store
```

### Comparing `cg-27.1.9/tests/store/filters/test_status_analyses_filters.py` & `cg-27.2.0/tests/store/filters/test_status_analyses_filters.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,281 +1,437 @@
-from datetime import datetime
+from datetime import datetime, timedelta
 
 from alchy import Query
 from cgmodels.cg.constants import Pipeline
 
-
+from typing import List
 from cg.store import Store
 from cg.store.models import Analysis, Family
 from cg.store.filters.status_analysis_filters import (
-    get_valid_analyses_in_production,
-    get_analyses_with_pipeline,
-    get_completed_analyses,
-    get_not_completed_analyses,
-    get_filter_uploaded_analyses,
-    get_not_uploaded_analyses,
-    get_analyses_with_delivery_report,
-    get_analyses_without_delivery_report,
-    get_report_analyses_by_pipeline,
-    order_analyses_by_uploaded_at,
-    order_analyses_by_completed_at,
+    filter_valid_analyses_in_production,
+    filter_analyses_with_pipeline,
+    filter_completed_analyses,
+    filter_not_completed_analyses,
+    filter_uploaded_analyses,
+    filter_not_uploaded_analyses,
+    filter_analyses_with_delivery_report,
+    filter_analyses_without_delivery_report,
+    filter_report_analyses_by_pipeline,
+    filter_analyses_by_case_entry_id,
+    filter_analyses_completed_after,
+    filter_analyses_completed_before,
+    filter_analyses_not_uploaded_to_vogue,
+    filter_analyses_not_cleaned,
+    filter_analyses_started_before,
+    order_analyses_by_completed_at_asc,
+    order_analyses_by_uploaded_at_asc,
+    filter_analyses_by_started_at,
 )
 from tests.store_helpers import StoreHelpers
 
 
-def test_get_valid_analyses_in_production(
+def test_filter_valid_analyses_in_production(
     base_store: Store,
     helpers: StoreHelpers,
     case_obj: Family,
     timestamp_now: datetime,
     old_timestamp: datetime,
 ):
     """Test that an expected analysis is returned when it has a production valid completed_at date."""
 
     # GIVEN a set of mock analyses
     analysis: Analysis = helpers.add_analysis(store=base_store, completed_at=timestamp_now)
     outdated_analysis: Analysis = helpers.add_analysis(
         store=base_store, case=case_obj, completed_at=old_timestamp
     )
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
 
     # WHEN retrieving valid in production analyses
-    analyses: Query = get_valid_analyses_in_production(analyses_query)
+    analyses: Query = filter_valid_analyses_in_production(
+        analyses=base_store._get_query(table=Analysis)
+    )
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
     # THEN only the up-to-date analysis should be returned
     assert analysis in analyses
     assert outdated_analysis not in analyses
 
 
-def test_get_analyses_with_pipeline(base_store: Store, helpers: StoreHelpers, case_obj: Family):
+def test_filter_analyses_with_pipeline(base_store: Store, helpers: StoreHelpers, case_obj: Family):
     """Test analyses filtering by pipeline."""
 
     # GIVEN a set of mock analyses
     balsamic_analysis: Analysis = helpers.add_analysis(store=base_store, pipeline=Pipeline.BALSAMIC)
     mip_analysis: Analysis = helpers.add_analysis(
         store=base_store, case=case_obj, pipeline=Pipeline.MIP_DNA
     )
 
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
-
     # WHEN extracting the analyses
-    analyses: Query = get_analyses_with_pipeline(analyses_query, pipeline=Pipeline.BALSAMIC)
+    analyses: Query = filter_analyses_with_pipeline(
+        analyses=base_store._get_query(table=Analysis), pipeline=Pipeline.BALSAMIC
+    )
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
     # THEN only the BALSAMIC analysis should be retrieved
     assert balsamic_analysis in analyses
     assert mip_analysis not in analyses
 
 
-def test_get_completed_analyses(base_store: Store, helpers: StoreHelpers, timestamp_now: datetime):
+def test_filter_completed_analyses(
+    base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
+):
     """Test filtering of completed analyses."""
 
     # GIVEN a mock analysis
     analysis: Analysis = helpers.add_analysis(store=base_store, completed_at=timestamp_now)
 
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
-
     # WHEN retrieving the completed analyses
-    analyses: Query = get_completed_analyses(analyses_query)
+    analyses: Query = filter_completed_analyses(analyses=base_store._get_query(table=Analysis))
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
     # THEN the completed analysis should be obtained
     assert analysis in analyses
 
 
-def test_get_not_completed_analyses(base_store: Store, helpers: StoreHelpers):
+def test_filter_not_completed_analyses(base_store: Store, helpers: StoreHelpers):
     """Test filtering of ongoing analyses."""
 
     # GIVEN a mock not completed analysis
     analysis_not_completed: Analysis = helpers.add_analysis(store=base_store, completed_at=None)
 
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
-
     # WHEN retrieving the not completed analyses
-    analyses: Query = get_not_completed_analyses(analyses_query)
+    analyses: Query = filter_not_completed_analyses(analyses=base_store._get_query(table=Analysis))
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
     # THEN the expected analysis should be retrieved
     assert analysis_not_completed in analyses
 
 
-def test_get_filter_uploaded_analyses(
+def test_filter_filter_uploaded_analyses(
     base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
 ):
     """Test filtering of analysis with an uploaded_at field."""
 
     # GIVEN a mock uploaded analysis
     analysis: Analysis = helpers.add_analysis(store=base_store, uploaded_at=timestamp_now)
 
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
-
     # WHEN calling the upload filtering function
-    analyses: Query = get_filter_uploaded_analyses(analyses_query)
+    analyses: Query = filter_uploaded_analyses(analyses=base_store._get_query(table=Analysis))
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
     # THEN the uploaded analysis should be retrieved
     assert analysis in analyses
 
 
-def test_get_not_uploaded_analyses(base_store: Store, helpers: StoreHelpers):
+def test_filter_not_uploaded_analyses(base_store: Store, helpers: StoreHelpers):
     """Test filtering of analysis that has not been uploaded."""
 
     # GIVEN a mock not uploaded analysis
     not_uploaded_analysis: Analysis = helpers.add_analysis(store=base_store, uploaded_at=None)
 
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
-
     # WHEN calling the upload filtering function
-    analyses: Query = get_not_uploaded_analyses(analyses_query)
+    analyses: Query = filter_not_uploaded_analyses(analyses=base_store._get_query(table=Analysis))
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
     # THEN the uploaded analysis should be retrieved
     assert not_uploaded_analysis in analyses
 
 
-def test_get_analyses_with_delivery_report(
+def test_filter_analyses_with_delivery_report(
     base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
 ):
     """Test filtering of analysis with a delivery report generated."""
 
     # GIVEN an analysis with a delivery report
     analysis: Analysis = helpers.add_analysis(store=base_store, delivery_reported_at=timestamp_now)
 
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
-
     # WHEN calling the delivery report analysis filtering function
-    analyses: Query = get_analyses_with_delivery_report(analyses_query)
+    analyses: Query = filter_analyses_with_delivery_report(
+        analyses=base_store._get_query(table=Analysis)
+    )
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
     # THEN the analysis containing the delivery report should be extracted
     assert analysis in analyses
 
 
-def test_get_analyses_without_delivery_report(base_store: Store, helpers: StoreHelpers):
+def test_filter_analyses_without_delivery_report(base_store: Store, helpers: StoreHelpers):
     """Test filtering of analysis without a delivery report generated."""
 
     # GIVEN an analysis with a delivery report
     analysis_without_delivery_report: Analysis = helpers.add_analysis(
         store=base_store, delivery_reported_at=None
     )
 
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
-
     # WHEN calling the delivery report analysis filtering function
-    analyses: Query = get_analyses_without_delivery_report(analyses_query)
+    analyses: Query = filter_analyses_without_delivery_report(
+        analyses=base_store._get_query(table=Analysis)
+    )
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
     # THEN the analysis without a delivery report should be extracted
     assert analysis_without_delivery_report in analyses
 
 
-def test_get_report_analyses_by_pipeline(
+def test_filter_report_analyses_by_pipeline(
     base_store: Store, helpers: StoreHelpers, case_obj: Family
 ):
     """Test filtering delivery report related analysis by pipeline."""
 
     # GIVEN a set of mock analysis
     balsamic_analysis: Analysis = helpers.add_analysis(store=base_store, pipeline=Pipeline.BALSAMIC)
     fluffy_analysis: Analysis = helpers.add_analysis(
         store=base_store, case=case_obj, pipeline=Pipeline.FLUFFY
     )
 
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
-
     # WHEN filtering delivery report related analyses
-    analyses: Query = get_report_analyses_by_pipeline(analyses_query)
+    analyses: Query = filter_report_analyses_by_pipeline(
+        analyses=base_store._get_query(table=Analysis), pipeline=Pipeline.BALSAMIC
+    )
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
     # THEN only the delivery report supported analysis should be retrieved
     assert balsamic_analysis in analyses
     assert fluffy_analysis not in analyses
 
 
-def test_order_analyses_by_completed_at(
-    base_store: Store,
+def test_order_analyses_by_completed_at_asc(
+    store: Store,
     helpers: StoreHelpers,
     case_obj: Family,
     timestamp_now: datetime,
     timestamp_yesterday: datetime,
 ):
     """Test sorting of analyses by the completed_at field."""
 
     # GIVEN a set of mock analyses
-    new_analysis: Analysis = helpers.add_analysis(store=base_store, completed_at=timestamp_now)
+    new_analysis: Analysis = helpers.add_analysis(store=store, completed_at=timestamp_now)
     old_analysis: Analysis = helpers.add_analysis(
-        store=base_store, case=case_obj, completed_at=timestamp_yesterday
+        store=store, case=case_obj, completed_at=timestamp_yesterday
     )
 
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
-
     # WHEN ordering the analyses by the completed_at field
-    analyses: Query = order_analyses_by_completed_at(analyses_query)
+    analyses: Query = order_analyses_by_completed_at_asc(analyses=store._get_query(table=Analysis))
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
     # THEN the oldest analysis should be the first one in the list
-    assert old_analysis == analyses.all()[0]
-    assert new_analysis == analyses.all()[1]
+    for index in range(0, analyses.count() - 1):
+        assert analyses.all()[index].completed_at <= analyses.all()[index + 1].completed_at
 
 
-def test_order_analyses_by_uploaded_at(
-    base_store: Store,
+def test_order_analyses_by_uploaded_at_asc(
+    store_with_older_and_newer_analyses: Store,
     helpers: StoreHelpers,
     case_obj: Family,
     timestamp_now: datetime,
     timestamp_yesterday: datetime,
 ):
     """Test sorting of analyses by the uploaded_at field."""
+    # GIVEN a store with mock analyses
+
+    # WHEN ordering the analyses by the uploaded_at field
+    analyses: Query = order_analyses_by_uploaded_at_asc(
+        analyses=store_with_older_and_newer_analyses._get_query(table=Analysis)
+    )
+
+    # ASSERT that analyses is a query
+    assert isinstance(analyses, Query)
+
+    # THEN the oldest analysis should be the first one in the list
+    for index in range(0, analyses.count() - 1):
+        assert analyses.all()[index].uploaded_at <= analyses.all()[index + 1].uploaded_at
+
+
+def test_filter_analysis_by_case(base_store: Store, helpers: StoreHelpers, case_obj: Family):
+    """Test filtering of analyses by case."""
 
     # GIVEN a set of mock analyses
-    new_analysis: Analysis = helpers.add_analysis(
-        store=base_store, completed_at=timestamp_now, uploaded_at=timestamp_now
+    analysis: Analysis = helpers.add_analysis(store=base_store)
+    analysis_other_case: Analysis = helpers.add_analysis(store=base_store, case=case_obj)
+
+    # WHEN filtering the analyses by case
+    analyses: Query = filter_analyses_by_case_entry_id(
+        analyses=base_store._get_query(table=Analysis), case_entry_id=case_obj.id
     )
-    old_analysis: Analysis = helpers.add_analysis(
+
+    # ASSERT that analyses is a query
+    assert isinstance(analyses, Query)
+
+    # THEN only the analysis belonging to the case should be retrieved
+    assert analysis not in analyses
+    assert analysis_other_case in analyses
+    assert analysis_other_case.family == case_obj
+
+
+def test_filter_analysis_completed_before(
+    base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
+):
+    """Test filtering of analyses completed before a given date."""
+
+    # GIVEN a set of mock analyses
+
+    analysis_old: Analysis = helpers.add_analysis(
+        store=base_store, completed_at=timestamp_now - timedelta(days=1)
+    )
+    analysis: Analysis = helpers.add_analysis(
+        store=base_store, completed_at=timestamp_now, case=analysis_old.family
+    )
+
+    # WHEN filtering the analyses by completed_at
+    analyses: Query = filter_analyses_completed_before(
+        base_store._get_query(table=Analysis), timestamp_now
+    )
+
+    # ASSERT that analyses is a query
+    assert isinstance(analyses, Query)
+
+    # THEN only the analysis completed before the given date should be retrieved
+    assert analysis not in analyses
+    assert analysis_old in analyses
+
+
+def test_filter_analysis_completed_after(
+    base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
+):
+    """Test filtering of analyses completed after a given date."""
+
+    # GIVEN a set of mock analyses
+    analysis: Analysis = helpers.add_analysis(
         store=base_store,
-        case=case_obj,
-        completed_at=timestamp_yesterday,
-        uploaded_at=timestamp_yesterday,
+        completed_at=timestamp_now,
+    )
+    analysis_new: Analysis = helpers.add_analysis(
+        store=base_store, completed_at=timestamp_now + timedelta(days=1), case=analysis.family
     )
 
-    # GIVEN an analysis query
-    analyses_query: Query = base_store.latest_analyses()
+    # WHEN filtering the analyses by completed_at
+    analyses: Query = filter_analyses_completed_after(
+        base_store._get_query(table=Analysis), completed_at_date=timestamp_now
+    )
 
-    # WHEN ordering the analyses by the uploaded_at field
-    analyses: Query = order_analyses_by_uploaded_at(analyses_query)
+    # ASSERT that analyses is a query
+    assert isinstance(analyses, Query)
+
+    # THEN only the analysis completed after the given date should be retrieved
+    assert analysis not in analyses
+    assert analysis_new in analyses
+
+
+def test_filter_analysis_started_before(
+    base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
+):
+    """Test filtering of analyses started before a given date."""
+
+    # GIVEN a set of mock analyses
+    analysis_old: Analysis = helpers.add_analysis(
+        store=base_store, started_at=timestamp_now - timedelta(days=1)
+    )
+    analysis: Analysis = helpers.add_analysis(
+        store=base_store, started_at=timestamp_now, case=analysis_old.family
+    )
+
+    # WHEN filtering the analyses by started_at
+    analyses: Query = filter_analyses_started_before(
+        analyses=base_store._get_query(table=Analysis), started_at_date=timestamp_now
+    )
 
-    # ASSERT that analyeses is a query
+    # ASSERT that analyses is a query
     assert isinstance(analyses, Query)
 
-    # THEN the oldest analysis should be the first one in the list
-    assert old_analysis == analyses.all()[0]
-    assert new_analysis == analyses.all()[1]
+    # THEN all analyses started before the given date should be retrieved
+    for analysis in analyses:
+        assert analysis.started_at <= timestamp_now
+
+
+def test_filter_analysis_not_cleaned(
+    base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
+):
+    """Test filtering of analyses that have not been cleaned."""
+
+    # GIVEN a set of mock analyses
+    analysis_cleaned: Analysis = helpers.add_analysis(store=base_store, cleaned_at=timestamp_now)
+    analysis: Analysis = helpers.add_analysis(
+        store=base_store, cleaned_at=None, case=analysis_cleaned.family
+    )
+
+    # WHEN filtering the analyses by cleaned_at
+    analyses: Query = filter_analyses_not_cleaned(analyses=base_store._get_query(table=Analysis))
+
+    # ASSERT that analyses is a query
+    assert isinstance(analyses, Query)
+
+    # THEN only the analysis that have not been cleaned should be retrieved
+    assert analysis in analyses
+    assert analysis_cleaned not in analyses
+
+
+def test_filter_analyses_not_uploaded_to_vogue(
+    base_store: Store, helpers: StoreHelpers, timestamp_now: datetime
+):
+    """Test filtering of analyses that have not been uploaded to vogue."""
+
+    # GIVEN a set of mock analyses
+    analysis_uploaded: Analysis = helpers.add_analysis(
+        store=base_store, uploaded_to_vogue_at=timestamp_now
+    )
+    analysis: Analysis = helpers.add_analysis(
+        store=base_store, uploaded_to_vogue_at=None, case=analysis_uploaded.family
+    )
+
+    # WHEN filtering the analyses by uploaded_at
+    analyses: Query = filter_analyses_not_uploaded_to_vogue(
+        analyses=base_store._get_query(table=Analysis)
+    )
+
+    # ASSERT that analyses is a query
+    assert isinstance(analyses, Query)
+
+    # THEN only the analysis that have not been uploaded to vogue should be retrieved
+    assert analysis in analyses
+    assert analysis_uploaded not in analyses
+
+
+def test_filter_analyses_by_started_at(
+    base_store: Store, helpers: StoreHelpers, timestamp_now: datetime, timestamp_yesterday: datetime
+):
+    """Test filtering of analyses by started at."""
+
+    # GIVEN a set of mock analyses
+    analysis_started_now: Analysis = helpers.add_analysis(
+        store=base_store, started_at=timestamp_now
+    )
+    analysis_started_old: Analysis = helpers.add_analysis(
+        store=base_store,
+        started_at=timestamp_yesterday,
+        case=analysis_started_now.family,
+    )
+
+    # WHEN filtering the analyses by started_at
+    analyses: Query = filter_analyses_by_started_at(
+        analyses=base_store._get_query(table=Analysis), started_at_date=timestamp_yesterday
+    )
+
+    # ASSERT that analyses is a query
+    assert isinstance(analyses, Query)
+
+    # THEN only the analysis that have been started after the given date should be retrieved
+    assert analysis_started_now not in analyses
+    assert analysis_started_old in analyses
```

### Comparing `cg-27.1.9/tests/store/filters/test_status_application_filters.py` & `cg-27.2.0/tests/store/filters/test_status_application_filters.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,16 +6,14 @@
     filter_applications_is_external,
     filter_applications_is_not_external,
     filter_applications_is_not_archived,
 )
 
 from cg.store import Store
 from cg.store.models import Application
-from tests.store_helpers import StoreHelpers
-from typing import List
 from sqlalchemy.orm import Query
 from tests.store.conftest import StoreConftestFixture
 
 
 def test_filter_get_application_by_tag(
     store_with_an_application_with_and_without_attributes: Store,
     tag=StoreConftestFixture.TAG_APPLICATION_WITH_ATTRIBUTES.value,
```

### Comparing `cg-27.1.9/tests/store/filters/test_status_bed_filters.py` & `cg-27.2.0/tests/store/filters/test_status_bed_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/filters/test_status_bed_version_filters.py` & `cg-27.2.0/tests/store/filters/test_status_bed_version_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/filters/test_status_collaboration_filters.py` & `cg-27.2.0/tests/store/filters/test_status_collaboration_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/filters/test_status_flow_cell_filters.py` & `cg-27.2.0/tests/store/filters/test_status_flow_cell_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/filters/test_status_invoice_filters.py` & `cg-27.2.0/tests/store/filters/test_status_invoice_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/filters/test_status_pool_filters.py` & `cg-27.2.0/tests/store/filters/test_status_pool_filters.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,23 @@
 from alchy import Query
-from typing import List
 from cg.store import Store
 from cg.store.models import Pool
-from tests.store_helpers import StoreHelpers
-from cg.constants.invoice import CustomerNames
 from cg.store.filters.status_pool_filters import (
     filter_pools_is_received,
     filter_pools_is_not_received,
     filter_pools_is_delivered,
     filter_pools_is_not_delivered,
     filter_pools_without_invoice_id,
     filter_pools_do_invoice,
     filter_pools_do_not_invoice,
     filter_pools_by_invoice_id,
     filter_pools_by_order_enquiry,
     filter_pools_by_name_enquiry,
     filter_pools_by_customer_id,
 )
-from datetime import datetime
 from tests.store.conftest import StoreConftestFixture
 
 
 def test_filter_pools_is_delivered(
     store_with_a_pool_with_and_without_attributes: Store,
     name=StoreConftestFixture.NAME_POOL_WITH_ATTRIBUTES.value,
 ):
```

### Comparing `cg-27.1.9/tests/store/test_delivery.py` & `cg-27.2.0/tests/store/test_delivery.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,18 +21,18 @@
     assert delivery_types == {Pipeline.MIP_DNA, Pipeline.FASTQ}
 
 
 def test_list_samples_to_deliver(base_store, helpers):
     """Test to fetch samples ready for delivery"""
     store = base_store
     # GIVEN a populated store without samples
-    assert len(store.get_all_samples()) == 0
+    assert len(store.get_samples()) == 0
     # GIVEN inserting a sample that should be delivered
     helpers.add_sample(store, sequenced_at=dt.datetime.now())
-    assert len(store.get_all_samples()) == 1
+    assert len(store.get_samples()) == 1
 
     # WHEN asking for samples to deliver
     samples_to_deliver: List[Sample] = store.get_samples_to_deliver()
     # THEN it should return the sample which is ready to deliver
     assert len(samples_to_deliver) == 1
     assert isinstance(samples_to_deliver[0].sequenced_at, dt.datetime)
 
@@ -44,14 +44,14 @@
     helpers.add_sample(store, sequenced_at=dt.datetime.now())
     helpers.add_sample(
         store,
         name="delivered",
         sequenced_at=dt.datetime.now(),
         delivered_at=dt.datetime.now(),
     )
-    assert len(store.get_all_samples()) == 2
+    assert len(store.get_samples()) == 2
 
     # WHEN asking for samples to deliver
     samples_to_deliver: List[Sample] = store.get_samples_to_deliver()
     # THEN it should return the sample which is ready to deliver
     assert len(samples_to_deliver) == 1
     assert isinstance(samples_to_deliver[0].sequenced_at, dt.datetime)
```

### Comparing `cg-27.1.9/tests/store/test_organism_filters.py` & `cg-27.2.0/tests/store/filters/test_status_organism_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/test_panel_filters.py` & `cg-27.2.0/tests/store/filters/test_status_panel_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store/test_status_customer_filters.py` & `cg-27.2.0/tests/store/filters/test_status_customer_filters.py`

 * *Files 13% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 def test_filter_customer_by_customer_id(base_store: Store, customer_id: str):
     """Test return customer by customer internal id."""
     # GIVEN a store containing customers
 
     # WHEN retrieving a customer
     customer: Customer = filter_customer_by_customer_internal_id(
         customers=base_store._get_query(table=Customer),
-        customer_id=customer_id,
+        customer_internal_id=customer_id,
     ).first()
 
     # THEN a customer should be returned
     assert customer
 
     # THEN the internal id should match the original
     assert customer.internal_id == customer_id
```

### Comparing `cg-27.1.9/tests/store/test_user_filters.py` & `cg-27.2.0/tests/store/filters/test_status_user_filters.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/store_helpers.py` & `cg-27.2.0/tests/store_helpers.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Utility functions to simply add test data in a cg store."""
 import logging
 from datetime import datetime
-from typing import List, Optional
+from typing import List, Optional, Dict
 
 from housekeeper.store.models import Bundle, Version
 
 from cg.apps.housekeeper.hk import HousekeeperAPI
 from cg.constants import DataDelivery, Pipeline
 from cg.constants.pedigree import Pedigree
 from cg.constants.priority import PriorityTerms
@@ -71,25 +71,26 @@
         prep_category: str = "wgs",
         is_external: bool = False,
         is_rna: bool = False,
         description: str = None,
         sequencing_depth: int = None,
         is_accredited: bool = False,
         version: int = 1,
+        valid_from: datetime = datetime.now(),
         **kwargs,
     ) -> ApplicationVersion:
         """Utility function to return existing or create application version for tests."""
         if is_rna:
             application_tag = "rna_tag"
             prep_category = "wts"
 
-        application = store.get_application_by_tag(tag=application_tag)
+        application: Application = store.get_application_by_tag(tag=application_tag)
         if not application:
-            application = StoreHelpers.add_application(
-                store,
+            application: Application = StoreHelpers.add_application(
+                store=store,
                 application_tag=application_tag,
                 prep_category=prep_category,
                 is_external=is_external,
                 description=description,
                 is_accredited=is_accredited,
                 sequencing_depth=sequencing_depth,
                 **kwargs,
@@ -97,24 +98,47 @@
 
         prices = {
             PriorityTerms.STANDARD: 10,
             PriorityTerms.PRIORITY: 20,
             PriorityTerms.EXPRESS: 30,
             PriorityTerms.RESEARCH: 5,
         }
-        application_version = store.application_version(application=application, version=version)
-        if not application_version:
-            application_version = store.add_version(
-                application=application, version=version, valid_from=datetime.now(), prices=prices
-            )
 
-            store.add_commit(application_version)
+        application_version: ApplicationVersion = StoreHelpers.add_application_version(
+            store=store,
+            application=application,
+            prices=prices,
+            version=version,
+            valid_from=valid_from,
+        )
         return application_version
 
     @staticmethod
+    def add_application_version(
+        store: Store,
+        application: Application,
+        prices: Dict,
+        version: int = 1,
+        valid_from: datetime = datetime.now(),
+    ) -> ApplicationVersion:
+        """Add an application version to store."""
+        new_record: ApplicationVersion = store.get_application_version_by_application_entry_id(
+            application_entry_id=application.id
+        )
+        if not new_record:
+            new_record: ApplicationVersion = store.add_application_version(
+                application=application,
+                version=version,
+                valid_from=valid_from,
+                prices=prices,
+            )
+        store.add_commit(new_record)
+        return new_record
+
+    @staticmethod
     def ensure_application(
         store: Store,
         tag: str,
         prep_category: str = "wgs",
         description: str = "dummy_description",
         is_archived: bool = False,
         **kwargs,
@@ -190,25 +214,25 @@
             collaboration = store.add_collaboration(collaboration_id, collaboration_id)
         return collaboration
 
     @staticmethod
     def ensure_customer(
         store: Store,
         customer_id: str = "cust000",
-        name: str = "Production",
+        customer_name: str = "Production",
         scout_access: bool = False,
     ) -> Customer:
         """Utility function to return existing or create customer for tests."""
         collaboration: Collaboration = StoreHelpers.ensure_collaboration(store)
-        customer: Customer = store.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = store.get_customer_by_internal_id(customer_internal_id=customer_id)
 
         if not customer:
             customer = store.add_customer(
                 internal_id=customer_id,
-                name=name,
+                name=customer_name,
                 scout_access=scout_access,
                 invoice_address="Test street",
                 invoice_reference="ABCDEF",
             )
             customer.collaborations.append(collaboration)
             store.add_commit(customer)
         return customer
@@ -224,14 +248,15 @@
         delivery_reported_at: datetime = None,
         cleaned_at: datetime = None,
         pipeline: Pipeline = Pipeline.BALSAMIC,
         pipeline_version: str = "1.0",
         data_delivery: DataDelivery = DataDelivery.FASTQ_QC,
         uploading: bool = False,
         config_path: str = None,
+        uploaded_to_vogue_at: datetime = None,
     ) -> Analysis:
         """Utility function to add an analysis for tests."""
 
         if not case:
             case = StoreHelpers.add_case(store, data_analysis=pipeline, data_delivery=data_delivery)
 
         analysis = store.add_analysis(pipeline=pipeline, version=pipeline_version)
@@ -247,14 +272,16 @@
             analysis.cleaned_at = cleaned_at
         if uploading:
             analysis.upload_started_at = upload_started or datetime.now()
         if config_path:
             analysis.config_path = config_path
         if pipeline:
             analysis.pipeline = str(pipeline)
+        if uploaded_to_vogue_at:
+            analysis.uploaded_to_vogue_at = uploaded_to_vogue_at
 
         analysis.limitations = "A limitation"
         analysis.family = case
         store.add_commit(analysis)
         return analysis
 
     @staticmethod
@@ -359,15 +386,15 @@
             panels = case_obj.panels
         for panel_abbreivation in panels:
             StoreHelpers.ensure_panel(
                 store=store, panel_abbreviation=panel_abbreivation, customer_id=customer_id
             )
 
         if not case_obj:
-            case_obj: Optional[Family] = store.family(internal_id=name)
+            case_obj: Optional[Family] = store.get_case_by_internal_id(internal_id=name)
         if not case_obj:
             case_obj = store.add_case(
                 data_analysis=data_analysis,
                 data_delivery=data_delivery,
                 name=name,
                 panels=panels,
                 ticket=ticket,
@@ -380,31 +407,35 @@
         case_obj.customer = customer
         store.add_commit(case_obj)
         return case_obj
 
     @staticmethod
     def ensure_case(
         store: Store,
-        name: str = "test-case",
+        case_name: str = "test-case",
         case_id: str = "blueeagle",
         customer: Customer = None,
         data_analysis: Pipeline = Pipeline.MIP_DNA,
         data_delivery: DataDelivery = DataDelivery.SCOUT,
+        action: str = None,
     ):
         """Load a case with samples and link relations."""
         if not customer:
             customer = StoreHelpers.ensure_customer(store=store)
-        case = store.family(internal_id=case_id) or store.find_family(customer=customer, name=name)
+        case = store.get_case_by_internal_id(
+            internal_id=case_id
+        ) or store.get_case_by_name_and_customer(customer=customer, case_name=case_name)
         if not case:
             case = StoreHelpers.add_case(
                 store=store,
                 data_analysis=data_analysis,
                 data_delivery=data_delivery,
-                name=name,
+                name=case_name,
                 internal_id=case_id,
+                action=action,
             )
             case.customer = customer
         return case
 
     @staticmethod
     def ensure_case_from_dict(
         store: Store,
@@ -528,15 +559,15 @@
             organism=organism,
             reads=6000000,
             sex=Gender.UNKNOWN,
         )
         sample.customer = customer
         case = StoreHelpers.ensure_case(
             store=store,
-            name=str(ticket),
+            case_name=str(ticket),
             customer=customer,
             data_analysis=Pipeline.MICROSALT,
             data_delivery=DataDelivery.FASTQ_QC,
         )
         StoreHelpers.add_relationship(store=store, case=case, sample=sample)
         return sample
 
@@ -591,15 +622,15 @@
         return link
 
     @staticmethod
     def add_synopsis_to_case(
         store: Store, case_id: str, synopsis: str = "a synopsis"
     ) -> Optional[Family]:
         """Function for adding a synopsis to a case in the database."""
-        case_obj: Family = store.family(internal_id=case_id)
+        case_obj: Family = store.get_case_by_internal_id(internal_id=case_id)
         if not case_obj:
             LOG.warning("Could not find case")
             return None
         case_obj.synopsis = synopsis
         store.commit()
         return case_obj
 
@@ -701,15 +732,15 @@
         delivered_at: datetime = None,
         received_at: datetime = None,
         no_invoice: bool = None,
         invoice_id: int = None,
     ) -> Pool:
         """Utility function to add a pool that can be used in tests."""
         customer_id = customer_id or "cust000"
-        customer: Customer = store.get_customer_by_customer_id(customer_id=customer_id)
+        customer: Customer = store.get_customer_by_internal_id(customer_internal_id=customer_id)
         if not customer:
             customer = StoreHelpers.ensure_customer(store, customer_id=customer_id)
 
         application_version = StoreHelpers.ensure_application_version(
             store=store,
             application_tag=application_tag,
             prep_category=application_type,
```

### Comparing `cg-27.1.9/tests/test_store_helpers.py` & `cg-27.2.0/tests/test_store_helpers.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,15 +1,10 @@
 """
 Tests for command module
 """
-from subprocess import CalledProcessError
-
-import pytest
-
-from cg.utils import Process
 
 
 def test_add_microbial_sample(base_store, helpers):
     # GIVEN a base_store
 
     # WHEN using the helper to add a microbial sample
     sample = helpers.add_microbial_sample(base_store)
```

### Comparing `cg-27.1.9/tests/utils/conftest.py` & `cg-27.2.0/tests/utils/conftest.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/utils/test_commands.py` & `cg-27.2.0/tests/utils/test_commands.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/utils/test_date.py` & `cg-27.2.0/tests/utils/test_date.py`

 * *Files identical despite different names*

### Comparing `cg-27.1.9/tests/utils/test_dict.py` & `cg-27.2.0/tests/utils/test_dict.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,10 @@
 """Tests for the dict module."""
 from pathlib import Path
-from typing import Dict
 
-from housekeeper.store.models import File
 
 from cg.utils.dict import get_list_from_dictionary, get_full_path_dictionary
 
 
 def test_get_list_from_dictionary():
     """Test the formatting of the flattened dictionary."""
```

### Comparing `cg-27.1.9/tests/utils/test_utils.py` & `cg-27.2.0/tests/utils/test_utils.py`

 * *Files identical despite different names*

